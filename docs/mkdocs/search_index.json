{
    "docs": [
        {
            "location": "/", 
            "text": "Aqueduct\n\n\nAqueduct is an HTTP web server framework for building REST applications written in Dart.\n\n\nHow to Use this Documentation\n\n\nThe menu on the left contains a hierarchy documents. Those documents - and how you should use them - are described in the following table:\n\n\n\n\n\n\n\n\nLocation\n\n\nDescription\n\n\nRecommended Usage\n\n\n\n\n\n\n\n\n\n\nTop-Level (e.g. Tour, Core Concepts)\n\n\nIntroductory and quick reference documents\n\n\nRead these documents when you are new to Aqueduct\n\n\n\n\n\n\nSnippets\n\n\nExample code snippets of common behaviors\n\n\nRead these documents for examples and inspiration\n\n\n\n\n\n\nTutorial\n\n\nA linear, guided tutorial to building your first application\n\n\nA 1-3 hour long tutorial to learn Aqueduct\n\n\n\n\n\n\nGuides\n\n\nA hierarchy of in-depth guides for the many facets of Aqueduct\n\n\nRefer to these documents often to understand concepts and usage of Aqueduct\n\n\n\n\n\n\n\n\nIn addition to these guides, be sure to use the \nAPI Reference\n to look up classes, methods, functions and other elements of the framework.\n\n\nGetting Started Tips\n\n\nThe best way to get started is to read the \nCore Concepts guide\n while working through the \ntutorial\n. Then, add new features to the application created during the tutorial by looking up the classes you are using in the \nAPI Reference\n, and implementing behavior not found in the tutorial. It's a good idea to install a tool like \nDash\n for viewing the API Reference.\n\n\nOnce you have the basic concepts down, start reading the guides in the left hand menu to take advantage of the many features of the framework. Check out the repository of examples \nhere\n.\n\n\nImport \nthis file\n into IntelliJ IDEA for Aqueduct file and code templates.\n\n\nAqueduct is catered towards test-driven development - the best way to write an application is to write tests using a \ntest harness\n and run those tests after implementing an endpoint. You may also run the command \naqueduct document client\n in your project directory to generate a web client for your application. This client can be opened in any browser and will execute requests against your locally running application.", 
            "title": "Home"
        }, 
        {
            "location": "/#aqueduct", 
            "text": "Aqueduct is an HTTP web server framework for building REST applications written in Dart.", 
            "title": "Aqueduct"
        }, 
        {
            "location": "/#how-to-use-this-documentation", 
            "text": "The menu on the left contains a hierarchy documents. Those documents - and how you should use them - are described in the following table:     Location  Description  Recommended Usage      Top-Level (e.g. Tour, Core Concepts)  Introductory and quick reference documents  Read these documents when you are new to Aqueduct    Snippets  Example code snippets of common behaviors  Read these documents for examples and inspiration    Tutorial  A linear, guided tutorial to building your first application  A 1-3 hour long tutorial to learn Aqueduct    Guides  A hierarchy of in-depth guides for the many facets of Aqueduct  Refer to these documents often to understand concepts and usage of Aqueduct     In addition to these guides, be sure to use the  API Reference  to look up classes, methods, functions and other elements of the framework.", 
            "title": "How to Use this Documentation"
        }, 
        {
            "location": "/#getting-started-tips", 
            "text": "The best way to get started is to read the  Core Concepts guide  while working through the  tutorial . Then, add new features to the application created during the tutorial by looking up the classes you are using in the  API Reference , and implementing behavior not found in the tutorial. It's a good idea to install a tool like  Dash  for viewing the API Reference.  Once you have the basic concepts down, start reading the guides in the left hand menu to take advantage of the many features of the framework. Check out the repository of examples  here .  Import  this file  into IntelliJ IDEA for Aqueduct file and code templates.  Aqueduct is catered towards test-driven development - the best way to write an application is to write tests using a  test harness  and run those tests after implementing an endpoint. You may also run the command  aqueduct document client  in your project directory to generate a web client for your application. This client can be opened in any browser and will execute requests against your locally running application.", 
            "title": "Getting Started Tips"
        }, 
        {
            "location": "/core_concepts/", 
            "text": "Resources\n\n\nResources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships.\n\n\nResources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body.\n\n\nFor more details on the concept of a resource, see the \nRFC Specification for HTTP/1.1\n.\n\n\nRouting\n\n\nResources are identified by the path of an HTTP request. For example, the URL \nhttp://example.com/organizations\n identifies the collection of organization resources on the server \nhttp://example.com\n. The URL \nhttp://example.com/organizations/1\n identifies a single organization.\n\n\nAn application exposes \nroutes\n for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route \n/organizations\n will match requests with the path \n/organizations\n. The route \n/organizations/:id\n will match the paths \n/organizations/1\n, \n/organizations/2\n, and so on.\n\n\nComplex routes can be formed with additional syntax. See the guide on \nrouting\n for usage details.\n\n\nControllers\n\n\nControllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid.\n\n\nControllers are linked together to form a series of actions to take for a request. These linked together controllers are called a \nchannel\n. If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows.\n\n\nThere are two flavors of controllers. An \nendpoint controller\n performs operations on a resource or resource collection, and always sends a response. Endpoint controllers \nfulfill\n requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers.\n\n\nA \nmiddleware controller\n takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request.\n\n\nA channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on \nControllers\n and \nResourceControllers\n for usage details.\n\n\nThe Application Channel\n\n\nThe application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its \nentry point\n. Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route.\n\n\nThe application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the \nApplication Channel\n for more details.\n\n\nServices\n\n\nA service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries.\n\n\nThe primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request.\n\n\nFor more details on injecting services, see the guide on the \nApplication Channel\n.\n\n\nIsolates\n\n\nIsolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads.\n\n\nA benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'.\n\n\nBindings\n\n\nA request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails.\n\n\nBindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on \nResource Controllers\n.\n\n\nQueries and Data Models\n\n\nApplication store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Aqueduct's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test.\n\n\nYour application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Aqueduct's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application.\n\n\nFor more details, see the guide on \nDatabases\n.\n\n\nAuthorization\n\n\nOAuth 2.0 is a standardized authorization framework. Aqueduct contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Aqueduct ORM to store artifacts in PostgreSQL.\n\n\nFor more details, see the guide on \nAuthorization\n.\n\n\nDocumentation\n\n\nOpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Aqueduct objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make.\n\n\nFor more details, see the guide on \nOpenAPI Documentation\n.", 
            "title": "Core Concepts"
        }, 
        {
            "location": "/core_concepts/#resources", 
            "text": "Resources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships.  Resources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body.  For more details on the concept of a resource, see the  RFC Specification for HTTP/1.1 .", 
            "title": "Resources"
        }, 
        {
            "location": "/core_concepts/#routing", 
            "text": "Resources are identified by the path of an HTTP request. For example, the URL  http://example.com/organizations  identifies the collection of organization resources on the server  http://example.com . The URL  http://example.com/organizations/1  identifies a single organization.  An application exposes  routes  for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route  /organizations  will match requests with the path  /organizations . The route  /organizations/:id  will match the paths  /organizations/1 ,  /organizations/2 , and so on.  Complex routes can be formed with additional syntax. See the guide on  routing  for usage details.", 
            "title": "Routing"
        }, 
        {
            "location": "/core_concepts/#controllers", 
            "text": "Controllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid.  Controllers are linked together to form a series of actions to take for a request. These linked together controllers are called a  channel . If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows.  There are two flavors of controllers. An  endpoint controller  performs operations on a resource or resource collection, and always sends a response. Endpoint controllers  fulfill  requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers.  A  middleware controller  takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request.  A channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on  Controllers  and  ResourceControllers  for usage details.", 
            "title": "Controllers"
        }, 
        {
            "location": "/core_concepts/#the-application-channel", 
            "text": "The application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its  entry point . Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route.  The application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the  Application Channel  for more details.", 
            "title": "The Application Channel"
        }, 
        {
            "location": "/core_concepts/#services", 
            "text": "A service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries.  The primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request.  For more details on injecting services, see the guide on the  Application Channel .", 
            "title": "Services"
        }, 
        {
            "location": "/core_concepts/#isolates", 
            "text": "Isolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads.  A benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'.", 
            "title": "Isolates"
        }, 
        {
            "location": "/core_concepts/#bindings", 
            "text": "A request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails.  Bindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on  Resource Controllers .", 
            "title": "Bindings"
        }, 
        {
            "location": "/core_concepts/#queries-and-data-models", 
            "text": "Application store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Aqueduct's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test.  Your application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Aqueduct's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application.  For more details, see the guide on  Databases .", 
            "title": "Queries and Data Models"
        }, 
        {
            "location": "/core_concepts/#authorization", 
            "text": "OAuth 2.0 is a standardized authorization framework. Aqueduct contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Aqueduct ORM to store artifacts in PostgreSQL.  For more details, see the guide on  Authorization .", 
            "title": "Authorization"
        }, 
        {
            "location": "/core_concepts/#documentation", 
            "text": "OpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Aqueduct objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make.  For more details, see the guide on  OpenAPI Documentation .", 
            "title": "Documentation"
        }, 
        {
            "location": "/getting_started/", 
            "text": "Getting Started with Aqueduct\n\n\nInstallation\n\n\n\n\nInstall Dart\n.\n\n\n\n\nActivate the Aqueduct CLI\n\n\npub global activate aqueduct\n\n\n\n\n\n\n\n\n\nCreate a new project.\n\n\naqueduct create my_project\n\n\n\n\n\n\n\n\n\nOpen the project directory in an \nIntelliJ IDE\n, \nAtom\n or \nVisual Studio Code\n. All three IDEs have a Dart plugin.\n\n\nHow to Learn Aqueduct\n\n\nThere are different approaches depending on how you prefer to learn.\n\n\n\n\nThe \nguided tutorial\n is a hands-on walkthrough where you build an application while learning basic Aqueduct concepts.\n\n\nThe \nexample repository\n contains a few deployable applications that you may review or tinker with.\n\n\nThe guides (located in the menu on this website) dive deeply into the concepts of Aqueduct and show example code.\n\n\nCreating a new project\n and using the \nAPI reference\n to jump right in.\n\n\n\n\nIt is best to first understand how HTTP requests are responded to - the foundation of Aqueduct - before moving on to topics such as the ORM and OAuth 2.0. Both the tutorial and the \nHTTP guides\n are the primary source of this information. A project created by the \naqueduct\n tool has example routes connected for modification, too.\n\n\nCreating a Project\n\n\nThe \naqueduct create\n command-line tool creates new Aqueduct project directories. The default template contains the minimal project structure for running an Aqueduct application. A project name must be snake_case.\n\n\naqueduct create my_project_name\n\n\n\n\n\nOther templates exist that contain foundational code for using Aqueduct's ORM and OAuth 2.0 implementation. These templates can be listed:\n\n\naqueduct create list-templates\n\n\n\n\n\nYou may provide the name of a template when creating a project to use that template:\n\n\naqueduct create -t db my_project_name\n\n\n\n\n\nUsing the Aqueduct ORM\n\n\nAqueduct's ORM uses PostgreSQL. During development, you will need a locally running instance of PostgreSQL. On macOS, installing  \nPostgres.app\n is a very convenient way to run PostgreSQL locally. For other platforms, see \nPostgreSQL's downloads page\n.\n\n\nWhen creating a project, use the \ndb\n template. If adding to an existing project, see \nthis guide\n.\n\n\nTo create a database, make sure PostgreSQL is running and open the command-line utility to connect to it.\n\n\npsql\n\n\n\n\n\n\n\nLocation of psql with Postgres.app\n\n\nIf you installed Postgres.app, \npsql\n is inside the application bundle. You can run this tool by selecting \nOpen psql\n from the status bar item in the Finder.\n\n\n\n\nThen, create a database that your application will connect to and a user that it will connect with:\n\n\nCREATE\n \nDATABASE\n \nmy_database_name\n;\n\n\nCREATE\n \nUSER\n \ndart_app\n \nWITH\n \nPASSWORD\n \ndart\n;\n\n\nGRANT\n \nALL\n \nON\n \nDATABASE\n \nmy_database_name\n \nTO\n \ndart_app\n;\n\n\n\n\n\n\nAn application must create a \nManagedContext\n that handles the connection to this database:\n\n\nclass\n \nMyChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nvar\n \nstore\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n      \ndart_app\n,\n \ndart\n,\n \nlocalhost\n,\n \n5432\n,\n \nmy_database_name\n);\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \nstore\n);\n\n  \n}\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nOnce you have declared \nManagedObject\ns in your application, generate the database schema by generating and executing migrations from your project's directory:\n\n\naqueduct db generate\naqueduct db upgrade --connect postgres://dart_app:dart@localhost:5432/my_database_name\n\n\n\n\n\nSee the guides on \nconnecting to a database\n and \ntesting with a database\n for more details on configuring a database connection.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/#getting-started-with-aqueduct", 
            "text": "", 
            "title": "Getting Started with Aqueduct"
        }, 
        {
            "location": "/getting_started/#installation", 
            "text": "Install Dart .   Activate the Aqueduct CLI  pub global activate aqueduct    Create a new project.  aqueduct create my_project    Open the project directory in an  IntelliJ IDE ,  Atom  or  Visual Studio Code . All three IDEs have a Dart plugin.", 
            "title": "Installation"
        }, 
        {
            "location": "/getting_started/#how-to-learn-aqueduct", 
            "text": "There are different approaches depending on how you prefer to learn.   The  guided tutorial  is a hands-on walkthrough where you build an application while learning basic Aqueduct concepts.  The  example repository  contains a few deployable applications that you may review or tinker with.  The guides (located in the menu on this website) dive deeply into the concepts of Aqueduct and show example code.  Creating a new project  and using the  API reference  to jump right in.   It is best to first understand how HTTP requests are responded to - the foundation of Aqueduct - before moving on to topics such as the ORM and OAuth 2.0. Both the tutorial and the  HTTP guides  are the primary source of this information. A project created by the  aqueduct  tool has example routes connected for modification, too.", 
            "title": "How to Learn Aqueduct"
        }, 
        {
            "location": "/getting_started/#creating-a-project", 
            "text": "The  aqueduct create  command-line tool creates new Aqueduct project directories. The default template contains the minimal project structure for running an Aqueduct application. A project name must be snake_case.  aqueduct create my_project_name  Other templates exist that contain foundational code for using Aqueduct's ORM and OAuth 2.0 implementation. These templates can be listed:  aqueduct create list-templates  You may provide the name of a template when creating a project to use that template:  aqueduct create -t db my_project_name", 
            "title": "Creating a Project"
        }, 
        {
            "location": "/getting_started/#using-the-aqueduct-orm", 
            "text": "Aqueduct's ORM uses PostgreSQL. During development, you will need a locally running instance of PostgreSQL. On macOS, installing   Postgres.app  is a very convenient way to run PostgreSQL locally. For other platforms, see  PostgreSQL's downloads page .  When creating a project, use the  db  template. If adding to an existing project, see  this guide .  To create a database, make sure PostgreSQL is running and open the command-line utility to connect to it.  psql   Location of psql with Postgres.app  If you installed Postgres.app,  psql  is inside the application bundle. You can run this tool by selecting  Open psql  from the status bar item in the Finder.   Then, create a database that your application will connect to and a user that it will connect with:  CREATE   DATABASE   my_database_name ;  CREATE   USER   dart_app   WITH   PASSWORD   dart ;  GRANT   ALL   ON   DATABASE   my_database_name   TO   dart_app ;   An application must create a  ManagedContext  that handles the connection to this database:  class   MyChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     var   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n     var   store   =   new   PostgreSQLPersistentStore . fromConnectionInfo ( \n       dart_app ,   dart ,   localhost ,   5432 ,   my_database_name ); \n     context   =   new   ManagedContext ( dataModel ,   store ); \n   } \n\n   ...  }   Once you have declared  ManagedObject s in your application, generate the database schema by generating and executing migrations from your project's directory:  aqueduct db generate\naqueduct db upgrade --connect postgres://dart_app:dart@localhost:5432/my_database_name  See the guides on  connecting to a database  and  testing with a database  for more details on configuring a database connection.", 
            "title": "Using the Aqueduct ORM"
        }, 
        {
            "location": "/tour/", 
            "text": "Aqueduct: A Tour\n\n\nThe tour demonstrates many of Aqueduct's features.\n\n\nCommand-Line Interface (CLI)\n\n\nThe \naqueduct\n command line tool creates, runs and documents Aqueduct applications; manages database migrations; and manages OAuth client identifiers. Install by running \npub global activate aqueduct\n on a machine with Dart installed.\n\n\nCreate and run an application:\n\n\naqueduct create my_app\ncd my_app/\naqueduct serve\n\n\n\n\n\nInitialization\n\n\nAn Aqueduct application starts at an \nApplicationChannel\n. You subclass it once per application to handle initialization tasks like setting up routes and database connections. An example application looks like this:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nclass\n \nTodoApp\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ncontext\n \n=\n \nManagedContext\n(...);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/projects/[:id]\n)\n\n      \n.\nlink\n(()\n \n=\n \nProjectController\n(\ncontext\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nRouting\n\n\nA \nrouter\n determines which controller object should handle a request. The \nroute specification syntax\n is a concise syntax to construct routes with variables and optional segments in a single statement.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \n// Handles /users, /users/1, /users/2, etc.\n\n  \nrouter\n\n    \n.\nroute\n(\n/projects/[:id]\n)\n\n    \n.\nlink\n(()\n \n=\n \nProjectController\n());\n\n\n  \n// Handles any route that starts with /file/\n\n  \nrouter\n\n    \n.\nroute\n(\n/file/*\n)\n\n    \n.\nlink\n(()\n \n=\n \nFileController\n());\n\n\n  \n// Handles the specific route /health\n\n  \nrouter\n\n    \n.\nroute\n(\n/health\n)\n\n    \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nResponse\n.\nok\n(\nnull\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n    \n\n\n\n\n\nControllers\n\n\nControllers\n handle requests. A controller handles a request by overriding its \nhandle\n method. This method either returns a response or a request. If a response is returned, that response is sent to the client. If the request is returned, the linked controller handles the request.\n\n\nclass\n \nSecretKeyAuthorizer\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\nrequest\n.\nraw\n.\nheaders\n.\nvalue\n(\nx-secret-key\n)\n \n==\n \nsecret!\n)\n \n{\n\n      \nreturn\n \nrequest\n;\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nbadRequest\n();\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis behavior allows for middleware controllers to be linked together, such that a request goes through a number of steps before it is finally handled.\n\n\nAll controllers execute their code in an exception handler. If an exception is thrown in your controller code, a response with an appropriate error code is returned. You subclass \nHandlerException\n to provide error response customization for application-specific exceptions.\n\n\nResourceControllers\n\n\nResourceControllers\n are the most often used controller. Each operation - e.g. \nPOST /projects\n, \nGET /projects\n and \nGET /projects/1\n - is mapped to methods in a subclass. Parameters of those methods are annotated to bind the values of the request when the method is invoked.\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n\n\n\nclass\n \nProjectController\n \nextends\n \nResourceController\n \n{\n    \n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetProjectById\n(@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \n//\n \nGET\n \n/\nprojects\n/:\nid\n\n    \nreturn\n \nResponse\n.\nok\n(...)\n;\n\n  \n}\n\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \ncreateProject\n(\n@\nBind\n.\nbody\n()\n \nProject\n \nproject\n)\n \nasync\n \n{\n\n    \n// POST /project\n\n    \nfinal\n \ninserted\n \n=\n \nawait\n \ninsertProject\n(\nproject\n);\n\n    \nreturn\n \nResponse\n.\nok\n(\ninserted\n);\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllProjects\n(\n\n    \n@\nBind\n.\nheader\n(\nx-client-id\n)\n \nString\n \nclientId\n,\n\n    \n{\n@\nBind\n.\nquery\n(\nlimit\n)\n \nint\n \nlimit:\n \n10\n})\n \nasync\n \n{\n\n    \n// GET /projects\n\n    \nreturn\n \nResponse\n.\nok\n(...);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nManagedObjectControllers\n\n\nManagedObjectController\nT\ns are \nResourceController\ns that automatically map a REST interface to database queries; e.g. \nPOST\n inserts a row, \nGET\n gets all row of a type. They do not need to be subclassed, but can be to provide customization.\n\n\nrouter\n\n  \n.\nroute\n(\n/users/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nManagedObjectController\nProject\n(\ncontext\n));\n\n\n\n\n\n\nConfiguration\n\n\nAn application's configuration is written in a YAML file. Each environment your application runs in (e.g., locally, under test, production, development) has different values for things like the port to listen on and database connection credentials. The format of a configuration file is defined by your application. An example looks like:\n\n\n// config.yaml\ndatabase:\n  host: api.projects.com\n  port: 5432\n  databaseName: project\nport: 8000\n\n\n\n\n\nSubclass \nConfiguration\n and declare a property for each key in your configuration file:\n\n\nclass\n \nTodoConfig\n \nextends\n \nConfiguration\n \n{\n\n  \nTodoConfig\n(\nString\n \npath\n)\n \n:\n \nsuper\n.\nfromFile\n(\nFile\n(\npath\n));\n\n\n  \nDatabaseConfiguration\n \ndatabase\n;\n\n  \nint\n \nport\n;\n\n\n}\n\n\n\n\n\n\nThe default name of your configuration file is \nconfig.yaml\n, but can be changed at the command-line. You create an instance of your configuration from the configuration file path from your application options:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nclass\n \nTodoApp\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \noptions\n \n=\n \nTodoConfig\n(\noptions\n.\nconfigurationFilePath\n);\n\n    \n...\n\n  \n}\n\n\n}\n\n\n\n\n\n\nRunning and Concurrency\n\n\nAqueduct applications are run with the \naqueduct serve\n command line tool. You can attach debugging and instrumentation tools and specify how many threads the application should run on:\n\n\naqueduct serve --observe --isolates 5 --port 8888\n\n\n\n\n\nAqueduct applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit.\n\n\nPostgreSQL ORM\n\n\nThe \nQuery\nT\n class configures and executes database queries. Its type argument determines what table is to be queried and the type of object you will work with in your code.\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n\n\n\nclass\n \nProjectController\n \nextends\n \nResourceController\n \n{\n\n  \nProjectController\n(\nthis\n.\ncontext\n)\n;\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllProjects\n()\n \nasync\n \n{\n\n    \nfinal\n \nquery\n \n=\n \nQuery\nProject\n(\ncontext\n);\n\n\n    \nfinal\n \nresults\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nresults\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nConfiguration of the query - like its \nWHERE\n clause - are configured through a fluent, type-safe syntax. A property selector identifies which column of the table to apply an expression to. The following query fetches all project's due in the next week and includes their tasks by joining the related table.\n\n\nfinal\n \nnextWeek\n \n=\n \nDateTime\n.\nnow\n().\nadd\n(\nDuration\n(\ndays:\n \n7\n));\n\n\nfinal\n \nquery\n \n=\n \nQuery\nProject\n(\ncontext\n)\n\n  \n..\nwhere\n((\nproject\n)\n \n=\n \nproject\n.\ndueDate\n).\nisLessThan\n(\nnextWeek\n)\n\n  \n..\njoin\n(\nset\n:\n \n(\nproject\n)\n \n=\n \nproject\n.\ntasks\n);\n\n\nfinal\n \nprojects\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nRows are inserted or updated by setting the statically-typed values of a query.\n\n\nfinal\n \ninsertQuery\n \n=\n \nQuery\nProject\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBuild an aqueduct\n\n  \n..\nvalues\n.\ndueDate\n \n=\n \nDateTime\n(\nyear\n,\n \nmonth\n);\n\n\nvar\n \nnewProject\n \n=\n \nawait\n \ninsertQuery\n.\ninsert\n();\n  \n\n\nfinal\n \nupdateQuery\n \n=\n \nQuery\nProject\n(\ncontext\n)\n\n  \n..\nwhere\n((\nproject\n)\n \n=\n \nproject\n.\nid\n).\nequalTo\n(\nnewProject\n.\nid\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBuild a miniature aqueduct\n;\n\n\nnewProject\n \n=\n \nawait\n \nupdateQuery\n.\nupdateOne\n();\n  \n\n\n\n\n\nQuery\nT\ns can perform sorting, joining and paging queries.\n\n\nfinal\n \noverdueQuery\n \n=\n \nQuery\nProject\n(\ncontext\n)\n\n  \n..\nwhere\n((\nproject\n)\n \n=\n \nproject\n.\ndueDate\n).\nlessThan\n(\nDateTime\n().\nnow\n())\n\n  \n..\nsortBy\n((\nproject\n)\n \n=\n \nproject\n.\ndueDate\n,\n \nQuerySortOrder\n.\nascending\n)\n\n  \n..\njoin\n(\nobject:\n \n(\nproject\n)\n \n=\n \nproject\n.\nowner\n);\n\n\n\nfinal\n \noverdueProjectsAndTheirOwners\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nControllers will interpret exceptions thrown by queries to return an appropriate error response to the client. For example, unique constraint conflicts return 409, missing required properties return 400 and database connection failure returns 503.\n\n\nDefining a Data Model\n\n\nTo use the ORM, you declare your tables as Dart types and create a subclass of \nManagedObject\nT\n. A subclass maps to a table in the database, each instance maps to a row, and each property is a column. The following declaration will map to a table named \n_project\n with columns \nid\n, \nname\n and \ndueDate\n.\n\n\nclass\n \nProject\n \nextends\n \nManagedObject\n_Project\n \nimplements\n \n_Project\n \n{\n\n  \nbool\n \nget\n \nisPastDue\n \n=\n \ndueDate\n.\ndifference\n(\nDateTime\n.\nnow\n()).\ninSeconds\n \n \n0\n;\n\n\n}\n\n\n\nclass\n \n_Project\n  \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \nname\n;\n\n\n  \nDateTime\n \ndueDate\n;\n\n\n}\n\n\n\n\n\n\nManaged objects have relationships to other managed objects. Relationships can be has-one, has-many and many-to-many. A relationship is always two-sided - the related types must declare a property that references each other.\n\n\nclass\n \nProject\n \nextends\n \nManagedObject\n_Project\n \nimplements\n \n_Project\n \n{}\n\n\nclass\n \n_Project\n \n{\n\n  \n...\n\n\n  \n// Project has-many Tasks\n\n  \nManagedSet\nTask\n \ntasks\n;\n\n\n}\n\n\n\nclass\n \nTask\n \nextends\n \nManagedObject\n_Task\n \nimplements\n \n_Task\n \n{}\n\n\nclass\n \n_Task\n \n{\n\n  \n...\n\n\n  \n// Task belongs to a project, maps to \nproject_id\n foreign key column\n\n  \n@\nRelate\n(\n#\ntasks\n)\n\n  \nProject\n \nproject\n;\n\n\n}\n\n\n\n\n\n\nManagedObject\nT\ns are serializable and can be directly read from a request body, or encoded as a response body.\n\n\nclass\n \nProjectController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nput\n(\nid\n)\n\n  \nFuture\nResponse\n \nupdateProject\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nprojectId\n,\n \n@\nBind\n.\nbody\n()\n \nProject\n \nproject\n)\n \nasync\n \n{\n\n    \nfinal\n \nquery\n \n=\n \nQuery\nProject\n(\ncontext\n)\n\n      \n..\nwhere\n((\nproject\n)\n \n=\n \nproject\n.\nid\n).\nequalTo\n(\nprojectId\n)\n\n      \n..\nvalues\n \n=\n \nproject\n;\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nupdateOne\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nDatabase Migrations\n\n\nThe CLI will automatically generate database migration scripts by detecting changes to your managed objects. The following, when ran in a project directory, will generate and execute a database migration.\n\n\naqueduct db generate\naqueduct db upgrade --connect postgres://user:password@host:5432/database\n\n\n\n\n\nYou can edit migration files by hand to alter any assumptions or enter required values, and run \naqueduct db validate\n to ensure the changes still yield the same schema. Be sure to keep generated files in version control.\n\n\nOAuth 2.0\n\n\nAn OAuth 2.0 server implementation handles authentication and authorization for Aqueduct applications. You create an \nAuthServer\n and its delegate as services in your application. The delegate is configurable and manages how tokens are generated and stored. By default, access tokens are a random 32-byte string and client identifiers, tokens and access codes are stored in your database using the ORM.\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ncontext\n \n=\n \nManagedContext\n(...);\n\n\n    \nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n  \n\n}\n\n\n\n\n\n\nBuilt-in authentication controllers for exchanging user credentials for access tokens are named \nAuthController\n and \nAuthCodeController\n. \nAuthorizer\ns are middleware that require a valid access token to access their linked controller.\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \n// POST /auth/token with username and password (or access code) to get access token\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/token\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n\n\n  \n// GET /auth/code returns login form, POST /auth/code grants access code\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/code\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthCodeController\n(\nauthServer\n));\n\n\n  \n// ProjectController requires request to include access token\n\n  \nrouter\n\n    \n.\nroute\n(\n/projects/[:id]\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n    \n.\nlink\n(()\n \n=\n \nProjectController\n(\ncontext\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nThe CLI has tools to manage OAuth 2.0 client identifiers and access scopes.\n\n\naqueduct auth add-client \\\n  --id com.app.mobile \\\n  --secret foobar \\\n  --redirect-uri https://somewhereoutthere.com \\\n  --allowed-scopes \nusers projects admin.readonly\n\n\n\n\n\n\nLogging\n\n\nAll requests are logged to an application-wide logger. Set up a listener for the logger in \nApplicationChannel\n to write log messages to the console or another medium.\n\n\nclass\n \nWildfireChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nlogger\n.\nonRecord\n.\nlisten\n((\nrecord\n)\n \n{\n\n      \nprint\n(\n$\nrecord\n);\n\n    \n});\n\n  \n}\n\n\n}\n\n\n\n\n\n\nTesting\n\n\nAqueduct tests start a local version of your application and execute requests. You write expectations on the responses. A \nTestHarness\n manages the starting and stopping of an application, and exposes a default \nAgent\n for executing requests. An \nAgent\n can be configured to have default headers, and multiple agents can be used within the same test.\n\n\nimport\n \nharness/app.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nfinal\n \nharness\n \n=\n \nTestHarness\nTodoApp\n()..\ninstall\n();\n\n\n  \ntest\n(\nGET /projects returns all projects\n \n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/projects\n);\n\n    \nexpectResponse\n(\nresponse\n,\n \n200\n,\n \nbody:\n \nevery\n(\npartial\n({\n\n      \nid\n:\n \ngreaterThan\n(\n0\n),\n\n      \nname\n:\n \nisNotNull\n,\n\n      \ndueDate\n:\n \nisNotNull\n\n    \n})));\n\n  \n});\n\n\n}\n\n\n\n\n\n\nTesting with a Database\n\n\nAqueduct's ORM uses PostgreSQL as its database. Before your tests run, Aqueduct will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite).\n\n\nThis behavior, and behavior for managing applications with an OAuth 2.0 provider, are available as \nharness mixins\n.\n\n\nDocumentation\n\n\nOpenAPI documents describe your application's interface. These documents can be used to generate documentation and client code. A document can be generated by reflecting on your application's codebase, just run the \naqueduct document\n command.\n\n\nThe \naqueduct document client\n command creates a web page that can be used to configure issue requests specific to your application.", 
            "title": "Tour"
        }, 
        {
            "location": "/tour/#aqueduct-a-tour", 
            "text": "The tour demonstrates many of Aqueduct's features.", 
            "title": "Aqueduct: A Tour"
        }, 
        {
            "location": "/tour/#command-line-interface-cli", 
            "text": "The  aqueduct  command line tool creates, runs and documents Aqueduct applications; manages database migrations; and manages OAuth client identifiers. Install by running  pub global activate aqueduct  on a machine with Dart installed.  Create and run an application:  aqueduct create my_app\ncd my_app/\naqueduct serve", 
            "title": "Command-Line Interface (CLI)"
        }, 
        {
            "location": "/tour/#initialization", 
            "text": "An Aqueduct application starts at an  ApplicationChannel . You subclass it once per application to handle initialization tasks like setting up routes and database connections. An example application looks like this:  import   package:aqueduct/aqueduct.dart ;  class   TodoApp   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     context   =   ManagedContext (...); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router \n       . route ( /projects/[:id] ) \n       . link (()   =   ProjectController ( context )); \n\n     return   router ; \n   }  }", 
            "title": "Initialization"
        }, 
        {
            "location": "/tour/#routing", 
            "text": "A  router  determines which controller object should handle a request. The  route specification syntax  is a concise syntax to construct routes with variables and optional segments in a single statement.  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   // Handles /users, /users/1, /users/2, etc. \n   router \n     . route ( /projects/[:id] ) \n     . link (()   =   ProjectController ()); \n\n   // Handles any route that starts with /file/ \n   router \n     . route ( /file/* ) \n     . link (()   =   FileController ()); \n\n   // Handles the specific route /health \n   router \n     . route ( /health ) \n     . linkFunction (( req )   async   =   Response . ok ( null )); \n\n   return   router ;  }", 
            "title": "Routing"
        }, 
        {
            "location": "/tour/#controllers", 
            "text": "Controllers  handle requests. A controller handles a request by overriding its  handle  method. This method either returns a response or a request. If a response is returned, that response is sent to the client. If the request is returned, the linked controller handles the request.  class   SecretKeyAuthorizer   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     if   ( request . raw . headers . value ( x-secret-key )   ==   secret! )   { \n       return   request ; \n     } \n\n     return   Response . badRequest (); \n   }  }   This behavior allows for middleware controllers to be linked together, such that a request goes through a number of steps before it is finally handled.  All controllers execute their code in an exception handler. If an exception is thrown in your controller code, a response with an appropriate error code is returned. You subclass  HandlerException  to provide error response customization for application-specific exceptions.", 
            "title": "Controllers"
        }, 
        {
            "location": "/tour/#resourcecontrollers", 
            "text": "ResourceControllers  are the most often used controller. Each operation - e.g.  POST /projects ,  GET /projects  and  GET /projects/1  - is mapped to methods in a subclass. Parameters of those methods are annotated to bind the values of the request when the method is invoked.  import   package:aqueduct/aqueduct.dart  class   ProjectController   extends   ResourceController   {     \n   @ Operation . get ( id ) \n   Future Response   getProjectById (@ Bind . path ( id )   int   id )   async   { \n     //   GET   / projects /: id \n     return   Response . ok (...) ; \n   } \n\n   @ Operation . post () \n   Future Response   createProject ( @ Bind . body ()   Project   project )   async   { \n     // POST /project \n     final   inserted   =   await   insertProject ( project ); \n     return   Response . ok ( inserted ); \n   } \n\n   @ Operation . get () \n   Future Response   getAllProjects ( \n     @ Bind . header ( x-client-id )   String   clientId , \n     { @ Bind . query ( limit )   int   limit:   10 })   async   { \n     // GET /projects \n     return   Response . ok (...); \n   }  }", 
            "title": "ResourceControllers"
        }, 
        {
            "location": "/tour/#managedobjectcontrollers", 
            "text": "ManagedObjectController T s are  ResourceController s that automatically map a REST interface to database queries; e.g.  POST  inserts a row,  GET  gets all row of a type. They do not need to be subclassed, but can be to provide customization.  router \n   . route ( /users/[:id] ) \n   . link (()   =   ManagedObjectController Project ( context ));", 
            "title": "ManagedObjectControllers"
        }, 
        {
            "location": "/tour/#configuration", 
            "text": "An application's configuration is written in a YAML file. Each environment your application runs in (e.g., locally, under test, production, development) has different values for things like the port to listen on and database connection credentials. The format of a configuration file is defined by your application. An example looks like:  // config.yaml\ndatabase:\n  host: api.projects.com\n  port: 5432\n  databaseName: project\nport: 8000  Subclass  Configuration  and declare a property for each key in your configuration file:  class   TodoConfig   extends   Configuration   { \n   TodoConfig ( String   path )   :   super . fromFile ( File ( path )); \n\n   DatabaseConfiguration   database ; \n   int   port ;  }   The default name of your configuration file is  config.yaml , but can be changed at the command-line. You create an instance of your configuration from the configuration file path from your application options:  import   package:aqueduct/aqueduct.dart ;  class   TodoApp   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     var   options   =   TodoConfig ( options . configurationFilePath ); \n     ... \n   }  }", 
            "title": "Configuration"
        }, 
        {
            "location": "/tour/#running-and-concurrency", 
            "text": "Aqueduct applications are run with the  aqueduct serve  command line tool. You can attach debugging and instrumentation tools and specify how many threads the application should run on:  aqueduct serve --observe --isolates 5 --port 8888  Aqueduct applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit.", 
            "title": "Running and Concurrency"
        }, 
        {
            "location": "/tour/#postgresql-orm", 
            "text": "The  Query T  class configures and executes database queries. Its type argument determines what table is to be queried and the type of object you will work with in your code.  import   package:aqueduct/aqueduct.dart  class   ProjectController   extends   ResourceController   { \n   ProjectController ( this . context ) ; \n\n   final   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getAllProjects ()   async   { \n     final   query   =   Query Project ( context ); \n\n     final   results   =   await   query . fetch (); \n\n     return   Response . ok ( results ); \n   }  }   Configuration of the query - like its  WHERE  clause - are configured through a fluent, type-safe syntax. A property selector identifies which column of the table to apply an expression to. The following query fetches all project's due in the next week and includes their tasks by joining the related table.  final   nextWeek   =   DateTime . now (). add ( Duration ( days:   7 ));  final   query   =   Query Project ( context ) \n   .. where (( project )   =   project . dueDate ). isLessThan ( nextWeek ) \n   .. join ( set :   ( project )   =   project . tasks );  final   projects   =   await   query . fetch ();   Rows are inserted or updated by setting the statically-typed values of a query.  final   insertQuery   =   Query Project ( context ) \n   .. values . name   =   Build an aqueduct \n   .. values . dueDate   =   DateTime ( year ,   month );  var   newProject   =   await   insertQuery . insert ();    final   updateQuery   =   Query Project ( context ) \n   .. where (( project )   =   project . id ). equalTo ( newProject . id ) \n   .. values . name   =   Build a miniature aqueduct ;  newProject   =   await   updateQuery . updateOne ();     Query T s can perform sorting, joining and paging queries.  final   overdueQuery   =   Query Project ( context ) \n   .. where (( project )   =   project . dueDate ). lessThan ( DateTime (). now ()) \n   .. sortBy (( project )   =   project . dueDate ,   QuerySortOrder . ascending ) \n   .. join ( object:   ( project )   =   project . owner );  final   overdueProjectsAndTheirOwners   =   await   query . fetch ();   Controllers will interpret exceptions thrown by queries to return an appropriate error response to the client. For example, unique constraint conflicts return 409, missing required properties return 400 and database connection failure returns 503.", 
            "title": "PostgreSQL ORM"
        }, 
        {
            "location": "/tour/#defining-a-data-model", 
            "text": "To use the ORM, you declare your tables as Dart types and create a subclass of  ManagedObject T . A subclass maps to a table in the database, each instance maps to a row, and each property is a column. The following declaration will map to a table named  _project  with columns  id ,  name  and  dueDate .  class   Project   extends   ManagedObject _Project   implements   _Project   { \n   bool   get   isPastDue   =   dueDate . difference ( DateTime . now ()). inSeconds     0 ;  }  class   _Project    { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( indexed:   true ) \n   String   name ; \n\n   DateTime   dueDate ;  }   Managed objects have relationships to other managed objects. Relationships can be has-one, has-many and many-to-many. A relationship is always two-sided - the related types must declare a property that references each other.  class   Project   extends   ManagedObject _Project   implements   _Project   {}  class   _Project   { \n   ... \n\n   // Project has-many Tasks \n   ManagedSet Task   tasks ;  }  class   Task   extends   ManagedObject _Task   implements   _Task   {}  class   _Task   { \n   ... \n\n   // Task belongs to a project, maps to  project_id  foreign key column \n   @ Relate ( # tasks ) \n   Project   project ;  }   ManagedObject T s are serializable and can be directly read from a request body, or encoded as a response body.  class   ProjectController   extends   ResourceController   { \n   @ Operation . put ( id ) \n   Future Response   updateProject ( @ Bind . path ( id )   int   projectId ,   @ Bind . body ()   Project   project )   async   { \n     final   query   =   Query Project ( context ) \n       .. where (( project )   =   project . id ). equalTo ( projectId ) \n       .. values   =   project ; \n\n     return   Response . ok ( await   query . updateOne ()); \n   }  }", 
            "title": "Defining a Data Model"
        }, 
        {
            "location": "/tour/#database-migrations", 
            "text": "The CLI will automatically generate database migration scripts by detecting changes to your managed objects. The following, when ran in a project directory, will generate and execute a database migration.  aqueduct db generate\naqueduct db upgrade --connect postgres://user:password@host:5432/database  You can edit migration files by hand to alter any assumptions or enter required values, and run  aqueduct db validate  to ensure the changes still yield the same schema. Be sure to keep generated files in version control.", 
            "title": "Database Migrations"
        }, 
        {
            "location": "/tour/#oauth-20", 
            "text": "An OAuth 2.0 server implementation handles authentication and authorization for Aqueduct applications. You create an  AuthServer  and its delegate as services in your application. The delegate is configurable and manages how tokens are generated and stored. By default, access tokens are a random 32-byte string and client identifiers, tokens and access codes are stored in your database using the ORM.  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppApplicationChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     context   =   ManagedContext (...); \n\n     final   delegate   =   ManagedAuthDelegate User ( context ); \n     authServer   =   AuthServer ( delegate ); \n   }    }   Built-in authentication controllers for exchanging user credentials for access tokens are named  AuthController  and  AuthCodeController .  Authorizer s are middleware that require a valid access token to access their linked controller.  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   // POST /auth/token with username and password (or access code) to get access token \n   router \n     . route ( /auth/token ) \n     . link (()   =   AuthController ( authServer )); \n\n   // GET /auth/code returns login form, POST /auth/code grants access code \n   router \n     . route ( /auth/code ) \n     . link (()   =   AuthCodeController ( authServer )); \n\n   // ProjectController requires request to include access token \n   router \n     . route ( /projects/[:id] ) \n     . link (()   =   Authorizer . bearer ( authServer )) \n     . link (()   =   ProjectController ( context )); \n\n   return   router ;  }   The CLI has tools to manage OAuth 2.0 client identifiers and access scopes.  aqueduct auth add-client \\\n  --id com.app.mobile \\\n  --secret foobar \\\n  --redirect-uri https://somewhereoutthere.com \\\n  --allowed-scopes  users projects admin.readonly", 
            "title": "OAuth 2.0"
        }, 
        {
            "location": "/tour/#logging", 
            "text": "All requests are logged to an application-wide logger. Set up a listener for the logger in  ApplicationChannel  to write log messages to the console or another medium.  class   WildfireChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     logger . onRecord . listen (( record )   { \n       print ( $ record ); \n     }); \n   }  }", 
            "title": "Logging"
        }, 
        {
            "location": "/tour/#testing", 
            "text": "Aqueduct tests start a local version of your application and execute requests. You write expectations on the responses. A  TestHarness  manages the starting and stopping of an application, and exposes a default  Agent  for executing requests. An  Agent  can be configured to have default headers, and multiple agents can be used within the same test.  import   harness/app.dart ;  void   main ()   { \n   final   harness   =   TestHarness TodoApp ().. install (); \n\n   test ( GET /projects returns all projects   ,   ()   async   { \n     var   response   =   await   harness . agent . get ( /projects ); \n     expectResponse ( response ,   200 ,   body:   every ( partial ({ \n       id :   greaterThan ( 0 ), \n       name :   isNotNull , \n       dueDate :   isNotNull \n     }))); \n   });  }", 
            "title": "Testing"
        }, 
        {
            "location": "/tour/#testing-with-a-database", 
            "text": "Aqueduct's ORM uses PostgreSQL as its database. Before your tests run, Aqueduct will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite).  This behavior, and behavior for managing applications with an OAuth 2.0 provider, are available as  harness mixins .", 
            "title": "Testing with a Database"
        }, 
        {
            "location": "/tour/#documentation", 
            "text": "OpenAPI documents describe your application's interface. These documents can be used to generate documentation and client code. A document can be generated by reflecting on your application's codebase, just run the  aqueduct document  command.  The  aqueduct document client  command creates a web page that can be used to configure issue requests specific to your application.", 
            "title": "Documentation"
        }, 
        {
            "location": "/best_practices/", 
            "text": "Best Practices for Developing Aqueduct Applications\n\n\nKeep Dart Projects Separate\n\n\nBecause Dart is cross-platform, developers should avoid combining client application projects with Aqueduct projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository.\n\n\nA typical directory structure for an multi-faceted application looks like this:\n\n\napplication_name/\n  aqueduct/\n  flutter/\n  angular/\n  shared/\n\n\n\n\n\n\n\nProject Definition\n\n\nA \nproject\n is a directory that contain a \npubspec.yaml\n file and \nlib\n directory.\n\n\n\n\nIt is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with \naqueduct document\n and use one of the many open-source tools for generating client data model types.\n\n\nUse Test Driven Development (or something close to it)\n\n\nIn Aqueduct, testing is a first-class citizen. The \naqueduct_test\n package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the \naqueduct_test\n package is geared specifically for replacing these tools while retaining automated tests as the project grows.\n\n\nAn example test suite looks like this:\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nfinal\n \nharness\n \n=\n \nnew\n \nHarness\n()..\ninstall\n();\n\n\n  \ntest\n(\nGET /endpoint returns 200 and a simple object\n,\n \n()\n \nasync\n \n{\n\n    \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/endpoint\n);\n\n    \nexpectResponse\n(\nresponse\n,\n \n200\n,\n \nbody:\n \n{\nkey\n:\n \nvalue\n});\n\n  \n});\n\n\n}\n\n\n\n\n\n\nUse a bin Script to Verify Assumptions\n\n\nKeep a simple Dart script file in the \nbin/\n directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control.\n\n\nimport\n \npackage:myapp/myapp.dart\n;\n\n\n\nFuture\n \nmain\n()\n \nasync\n \n{\n\n  \nvar\n \nwhatIsThis\n \n=\n \nawait\n \nsomeYetToBeNamedUsefullyMethod\n();\n\n  \nprint\n(\n$\nwhatIsThis\n);\n\n\n}\n\n\n\n\n\n\nCreate New Projects from a Template\n\n\nUse \naqueduct create\n to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with \naqueduct create list-templates\n.\n\n\nUse a Debugger\n\n\nA debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the \nbin/main.dart\n script.\n\n\nIn IntelliJ IDEA, right-click on any file with a \nmain\n function (which includes test suites) and select \nDebug\n option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed.\n\n\nUse the Suggested Project Directory Structure\n\n\nSee \nAqueduct Project Structure\n.\n\n\nPass Services to Controllers in entryPoint\n\n\nPass service objects to controllers in \nentryPoint\n and only pass the services the controller will use.\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nGitHub\n \ngithubService\n;\n\n  \nPostgreSQLConnection\n \ndatabaseConnection\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ndatabaseConnection\n \n=\n \nnew\n \nPostgreSQLConnection\n();\n\n    \ngithubService\n \n=\n \nnew\n \nGitHub\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/data\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nDBController\n(\ndatabaseConnection\n));\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/github\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nGitHubController\n(\ngithubService\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nPassing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application.\n\n\nMinimize the access a controller has to its dependencies; e.g. don't pass it a \nStreamController\n when it only needs \nSink\n or a \nStream\n.\n\n\nUse a Test Harness\n\n\nA test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located \nhere\n.\n\n\nUse config.src.yaml\n\n\nUse the convention of \nconfig.src.yaml file\n to prevent configuration errors and inject test dependencies.\n\n\nUnderstand how Aqueduct Uses Isolates\n\n\nSee more in \nApplication Structure\n.\n\n\nUse ResourceController Subclasses\n\n\nSubclassing \nResourceController\n provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers.\n\n\nKeep ApplicationChannel Tidy\n\n\nA \nApplicationChannel\n should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file.\n\n\nAvoid Raw SQL Queries\n\n\nPrefer to use the Aqueduct ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model.\n\n\nUse API Reference\n\n\nAqueduct is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable.\n\n\nMany types in Aqueduct have a prefix in common with related types. For example, types like \nAuthServer\n, \nAuthServerDelegate\n and \nAuthCode\n are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g, \nasMap\n is a common method name).\n\n\nWhen looking for a solution, look at the \nAPI reference\n for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior.\n\n\nUse try-catch Sparingly\n\n\nAll request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception.\n\n\nCode that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.", 
            "title": "Best Practices"
        }, 
        {
            "location": "/best_practices/#best-practices-for-developing-aqueduct-applications", 
            "text": "", 
            "title": "Best Practices for Developing Aqueduct Applications"
        }, 
        {
            "location": "/best_practices/#keep-dart-projects-separate", 
            "text": "Because Dart is cross-platform, developers should avoid combining client application projects with Aqueduct projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository.  A typical directory structure for an multi-faceted application looks like this:  application_name/\n  aqueduct/\n  flutter/\n  angular/\n  shared/   Project Definition  A  project  is a directory that contain a  pubspec.yaml  file and  lib  directory.   It is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with  aqueduct document  and use one of the many open-source tools for generating client data model types.", 
            "title": "Keep Dart Projects Separate"
        }, 
        {
            "location": "/best_practices/#use-test-driven-development-or-something-close-to-it", 
            "text": "In Aqueduct, testing is a first-class citizen. The  aqueduct_test  package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the  aqueduct_test  package is geared specifically for replacing these tools while retaining automated tests as the project grows.  An example test suite looks like this:  void   main ()   { \n   final   harness   =   new   Harness ().. install (); \n\n   test ( GET /endpoint returns 200 and a simple object ,   ()   async   { \n     final   response   =   await   harness . agent . get ( /endpoint ); \n     expectResponse ( response ,   200 ,   body:   { key :   value }); \n   });  }", 
            "title": "Use Test Driven Development (or something close to it)"
        }, 
        {
            "location": "/best_practices/#use-a-bin-script-to-verify-assumptions", 
            "text": "Keep a simple Dart script file in the  bin/  directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control.  import   package:myapp/myapp.dart ;  Future   main ()   async   { \n   var   whatIsThis   =   await   someYetToBeNamedUsefullyMethod (); \n   print ( $ whatIsThis );  }", 
            "title": "Use a bin Script to Verify Assumptions"
        }, 
        {
            "location": "/best_practices/#create-new-projects-from-a-template", 
            "text": "Use  aqueduct create  to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with  aqueduct create list-templates .", 
            "title": "Create New Projects from a Template"
        }, 
        {
            "location": "/best_practices/#use-a-debugger", 
            "text": "A debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the  bin/main.dart  script.  In IntelliJ IDEA, right-click on any file with a  main  function (which includes test suites) and select  Debug  option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed.", 
            "title": "Use a Debugger"
        }, 
        {
            "location": "/best_practices/#use-the-suggested-project-directory-structure", 
            "text": "See  Aqueduct Project Structure .", 
            "title": "Use the Suggested Project Directory Structure"
        }, 
        {
            "location": "/best_practices/#pass-services-to-controllers-in-entrypoint", 
            "text": "Pass service objects to controllers in  entryPoint  and only pass the services the controller will use.  class   AppChannel   extends   ApplicationChannel   { \n   GitHub   githubService ; \n   PostgreSQLConnection   databaseConnection ; \n\n   @ override \n   Future   prepare ()   async   { \n     databaseConnection   =   new   PostgreSQLConnection (); \n     githubService   =   new   GitHub (); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /data ) \n       . link (()   =   new   DBController ( databaseConnection )); \n\n     router \n       . route ( /github ) \n       . link (()   =   new   GitHubController ( githubService )); \n\n     return   router ; \n   }  }   Passing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application.  Minimize the access a controller has to its dependencies; e.g. don't pass it a  StreamController  when it only needs  Sink  or a  Stream .", 
            "title": "Pass Services to Controllers in entryPoint"
        }, 
        {
            "location": "/best_practices/#use-a-test-harness", 
            "text": "A test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located  here .", 
            "title": "Use a Test Harness"
        }, 
        {
            "location": "/best_practices/#use-configsrcyaml", 
            "text": "Use the convention of  config.src.yaml file  to prevent configuration errors and inject test dependencies.", 
            "title": "Use config.src.yaml"
        }, 
        {
            "location": "/best_practices/#understand-how-aqueduct-uses-isolates", 
            "text": "See more in  Application Structure .", 
            "title": "Understand how Aqueduct Uses Isolates"
        }, 
        {
            "location": "/best_practices/#use-resourcecontroller-subclasses", 
            "text": "Subclassing  ResourceController  provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers.", 
            "title": "Use ResourceController Subclasses"
        }, 
        {
            "location": "/best_practices/#keep-applicationchannel-tidy", 
            "text": "A  ApplicationChannel  should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file.", 
            "title": "Keep ApplicationChannel Tidy"
        }, 
        {
            "location": "/best_practices/#avoid-raw-sql-queries", 
            "text": "Prefer to use the Aqueduct ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model.", 
            "title": "Avoid Raw SQL Queries"
        }, 
        {
            "location": "/best_practices/#use-api-reference", 
            "text": "Aqueduct is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable.  Many types in Aqueduct have a prefix in common with related types. For example, types like  AuthServer ,  AuthServerDelegate  and  AuthCode  are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g,  asMap  is a common method name).  When looking for a solution, look at the  API reference  for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior.", 
            "title": "Use API Reference"
        }, 
        {
            "location": "/best_practices/#use-try-catch-sparingly", 
            "text": "All request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception.  Code that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.", 
            "title": "Use try-catch Sparingly"
        }, 
        {
            "location": "/intellij/", 
            "text": "Aqueduct IntellIJ IDEA Templates\n\n\nThis document describes how to install file and code templates for Aqueduct when using an IntelliJ IDE (e.g., IDEA, IDEA CE, Webstorm).\n\n\nInstallation\n\n\nDownload the \nthis file\n and import it into IntelliJ by selecting \nImport Settings...\n from the \nFile\n menu.\n\n\nFile Templates\n\n\nFile templates are created by selecting \nNew\n from the \nFile\n menu or by right-clicking a directory in the project navigator. The following templates exists:\n\n\n\n\n\n\n\n\nTemplate Name\n\n\nBehavior\n\n\n\n\n\n\n\n\n\n\nAqueduct ResourceController\n\n\nCreates a new file with the skeleton of an \nResourceController\n.\n\n\n\n\n\n\nAqueduct ManagedObject\n\n\nCreates a new file with the skeleton of a \nManagedObject\n subclass\n\n\n\n\n\n\nAqueduct Test\n\n\nCreates a new file that creates and installs a \nTestHarness\n subclass from your project.\n\n\n\n\n\n\n\n\nLive Templates\n\n\nLive templates are keywords that expand into a larger code block. Typing the keyword in a Dart file and hitting return will enter common Aqueduct code. Live templates often have placeholders that can by jumped between by using the return key.\n\n\nLive Templates: HTTP\n\n\n\n\n\n\n\n\nShortcut\n\n\nBehavior\n\n\n\n\n\n\n\n\n\n\noperation\n\n\nCreates a new operation method in a \nResourceController\n.\n\n\n\n\n\n\nbindbody\n\n\nAdds a body binding to an operation method.\n\n\n\n\n\n\nbindheader\n\n\nAdds a header binding to an operation method.\n\n\n\n\n\n\nbindquery\n\n\nAdds a query binding to an operation method.\n\n\n\n\n\n\nbindpath\n\n\nAdds a path binding to an operation method.\n\n\n\n\n\n\n\n\nLive Templates: ORM\n\n\n\n\n\n\n\n\nShortcut\n\n\nBehavior\n\n\n\n\n\n\n\n\n\n\nps\n\n\nEnters the property selector syntax for \nQuery.where\n, \nQuery.join\n and other query configuration methods.\n\n\n\n\n\n\ncolumn\n\n\nAdds a column annotated field to a \nManagedObject\n.\n\n\n\n\n\n\nrelate\n\n\nAdds a relationship annotated field to a \nManagedObject\n.\n\n\n\n\n\n\n\n\nLive Templates: Testing\n\n\n\n\n\n\n\n\nShortcut\n\n\nBehavior\n\n\n\n\n\n\n\n\n\n\ntest\n\n\nCreates a test closure in a test file.", 
            "title": "IntelliJ IDEA Templates"
        }, 
        {
            "location": "/intellij/#aqueduct-intellij-idea-templates", 
            "text": "This document describes how to install file and code templates for Aqueduct when using an IntelliJ IDE (e.g., IDEA, IDEA CE, Webstorm).", 
            "title": "Aqueduct IntellIJ IDEA Templates"
        }, 
        {
            "location": "/intellij/#installation", 
            "text": "Download the  this file  and import it into IntelliJ by selecting  Import Settings...  from the  File  menu.", 
            "title": "Installation"
        }, 
        {
            "location": "/intellij/#file-templates", 
            "text": "File templates are created by selecting  New  from the  File  menu or by right-clicking a directory in the project navigator. The following templates exists:     Template Name  Behavior      Aqueduct ResourceController  Creates a new file with the skeleton of an  ResourceController .    Aqueduct ManagedObject  Creates a new file with the skeleton of a  ManagedObject  subclass    Aqueduct Test  Creates a new file that creates and installs a  TestHarness  subclass from your project.", 
            "title": "File Templates"
        }, 
        {
            "location": "/intellij/#live-templates", 
            "text": "Live templates are keywords that expand into a larger code block. Typing the keyword in a Dart file and hitting return will enter common Aqueduct code. Live templates often have placeholders that can by jumped between by using the return key.", 
            "title": "Live Templates"
        }, 
        {
            "location": "/intellij/#live-templates-http", 
            "text": "Shortcut  Behavior      operation  Creates a new operation method in a  ResourceController .    bindbody  Adds a body binding to an operation method.    bindheader  Adds a header binding to an operation method.    bindquery  Adds a query binding to an operation method.    bindpath  Adds a path binding to an operation method.", 
            "title": "Live Templates: HTTP"
        }, 
        {
            "location": "/intellij/#live-templates-orm", 
            "text": "Shortcut  Behavior      ps  Enters the property selector syntax for  Query.where ,  Query.join  and other query configuration methods.    column  Adds a column annotated field to a  ManagedObject .    relate  Adds a relationship annotated field to a  ManagedObject .", 
            "title": "Live Templates: ORM"
        }, 
        {
            "location": "/intellij/#live-templates-testing", 
            "text": "Shortcut  Behavior      test  Creates a test closure in a test file.", 
            "title": "Live Templates: Testing"
        }, 
        {
            "location": "/tut/getting-started/", 
            "text": "1. Getting Started\n\n\nBy the end of this tutorial, you will have created an Aqueduct application that serves fictional heroes from a PostgreSQL database. You will learn the following:\n\n\n\n\nRun an Aqueduct application\n\n\nRoute HTTP requests to the appropriate handler in your code\n\n\nStore and retrieve database data\n\n\nWrite automated tests for each endpoint\n\n\nRequire authorization for HTTP requests\n\n\n\n\n\n\nGetting Help\n\n\nIf at anytime you get stuck, hop on over to the \nAqueduct Slack channel\n. You can also see a finished version of this application \nhere\n.\n\n\n\n\nInstallation\n\n\nTo get started, make sure you have the following software installed:\n\n\n\n\nDart (\nInstall Instructions\n)\n\n\nIntelliJ IDEA or any other Jetbrains IDE, including the free Community Edition (\nInstall Instructions\n)\n\n\nThe IntelliJ IDEA Dart Plugin (\nInstall Instructions\n)\n\n\n\n\nInstall the \naqueduct\n command line tool by running the following command in your shell:\n\n\npub global activate aqueduct\n\n\n\n\n\n\n\nIf you get warning text about your \nPATH\n, make sure to read it before moving on.\n\n\n\n\nCreating a Project\n\n\nCreate a new project named \nheroes\n by entering the following in your shell:\n\n\naqueduct create heroes\n\n\n\n\n\nThis creates a \nheroes\n project directory. Open this directory with IntelliJ IDEA by dragging the project folder onto IntellIJ IDEA's icon.\n\n\nIn IntelliJ's project view, locate the \nlib\n directory; this is where your project's code will go. This project has two source files - \nheroes.dart\n and \nchannel.dart\n. Open the file \nheroes.dart\n. Click \nEnable Dart Support\n in the top right corner of the editor.\n\n\nHandling HTTP Requests\n\n\nIn your browser, navigate to \nhttp://aqueduct-tutorial.stablekernel.io\n. This browser application is a 'Hero Manager' - it allows a user to view, create, delete and update heroes. (It is a slightly modified version of the \nAngularDart Tour of Heroes Tutorial\n.) It will make HTTP requests to \nhttp://localhost:8888\n to fetch and manipulate hero data. The application you will build in this tutorial respond to those requests.\n\n\n\n\nRunning the Browser Application Locally\n\n\nThe browser application is served over HTTP so that it can access your Aqueduct application when it runs locally on your machine. Your browser may warn you about navigating to an insecure webpage, because it is in fact insecure. You can run this application locally by grabbing the source code from \nhere\n.\n\n\n\n\nIn this first chapter, you will write code to handle two requests: one to get a list of heroes, and the other to get a single hero by its identifier. Those requests are:\n\n\n\n\nGET /heroes\n to the list of heroes\n\n\nGET /heroes/:id\n to get an individual hero\n\n\n\n\n\n\nHTTP Operation Shorthand\n\n\nThe term \nGET /heroes\n is called an operation. It is the combination of the HTTP method and the path of the request. Each operation is  unique to an application, so your code is segmented into units for each operation. Sections with a colon, like the ':id' segment, are  variable: they can be 1, 2, 3, and so on.\n\n\n\n\nController Objects Handle Requests\n\n\nRequests are handled by \ncontroller objects\n. A controller object can respond to a request. It can also take other action and let another controller respond. For example, it might check if the request is authorized, or send analytical data to some other service. Controllers are composed together, and each controller in the composition performs its logic in order. This allows for some controllers to be reused, and for  better code organization. A composition of controllers is called a \nchannel\n because requests flow in one direction through the controllers.\n\n\nOur application will link two controllers:\n\n\n\n\na \nRouter\n that makes sure the request path is \n/heroes\n or \n/heroes/:id\n\n\na \nHeroesControllers\n that responds with hero objects\n\n\n\n\nYour application starts with a channel object called the \napplication channel\n. You link the controllers in your application to this channel.\n\n\n\n\nEach application has a subclass of \nApplicationChannel\n that you override methods in to set up your controllers. This type is already declared in \nlib/channel.dart\n - open this file and find \nApplicationChannel.entryPoint\n:\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/example\n)\n\n      \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n        \nreturn\n \nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n      \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n\n\n\n\nWhen your application gets a request, the \nentryPoint\n controller is the first to handle it. In our case, this is a \nRouter\n - a subclass of \nController\n.\n\n\n\n\nController Subclassing\nEvery controller you use will be a subclass of \nController\n. There are some controller subclasses already in Aqueduct for common behaviors.\n\n\n\n\n\n\nYou use the \nroute\n method on a router to attach a controller to a \nroute\n. A route is a string syntax that matches the path of a request. In our current implementation, the route will match every request with the path \n/example\n. When that request is received, a linked function runs and returns a 200 OK response with an example JSON object body.\n\n\nWe need to route the path \n/heroes\n to a controller of our own, so we can control what happens. Let's create a \nHeroesController\n. Create a new file in \nlib/controller/heroes_controller.dart\n and add the following code (you will need to create the subdirectory \nlib/controller/\n):\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:heroes/heroes.dart\n;\n\n\n\nclass\n \nHeroesController\n \nextends\n \nController\n \n{\n\n  \nfinal\n \n_heroes\n \n=\n \n[\n\n    \n{\nid\n:\n \n11\n,\n \nname\n:\n \nMr. Nice\n},\n\n    \n{\nid\n:\n \n12\n,\n \nname\n:\n \nNarco\n},\n\n    \n{\nid\n:\n \n13\n,\n \nname\n:\n \nBombasto\n},\n\n    \n{\nid\n:\n \n14\n,\n \nname\n:\n \nCeleritas\n},\n\n    \n{\nid\n:\n \n15\n,\n \nname\n:\n \nMagneta\n},\n    \n  \n];\n\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n(\n_heroes\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNotice that \nHeroesController\n is a subclass of \nController\n; this is what makes it a controller object. It overrides its \nhandle\n method by returning a \nResponse\n object. This response object has a 200 OK status code, and it body contains a JSON-encoded list of hero objects. When a controller returns a \nResponse\n object from its \nhandle\n method, it is sent to the client.\n\n\nRight now, our \nHeroesController\n isn't hooked up to the application channel. We need to link it to the router. First, import our new file at the top of \nchannel.dart\n.\n\n\nimport\n \ncontroller/heroes_controller.dart\n;\n\n\n\n\n\n\nThen link this \nHeroesController\n to the \nRouter\n for the path \n/heroes\n:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/heroes\n)\n\n    \n.\nlink\n(()\n \n=\n \nHeroesController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/example\n)\n\n    \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n    \n});\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nWe now have a application that will return a list of heroes. In the project directory, run the following command from the command-line:\n\n\naqueduct serve\n\n\n\n\n\nThis will start your application running locally. Reload the browser page \nhttp://aqueduct-tutorial.stablekernel.io\n. It will make a request to \nhttp://localhost:8888/heroes\n and your application will serve it. You'll see your heroes in your web browser:\n\n\nScreenshot of Heroes Application\n\n\n\n\nYou can also see the actual response of your request by entering the following into your shell:\n\n\ncurl -X GET http://localhost:8888/heroes\n\n\n\n\n\nYou'll get JSON output like this:\n\n\n[\n\n  \n{\nid\n:\n11\n,\nname\n:\nMr. Nice\n},\n\n  \n{\nid\n:\n12\n,\nname\n:\nNarco\n},\n\n  \n{\nid\n:\n13\n,\nname\n:\nBombasto\n},\n\n  \n{\nid\n:\n14\n,\nname\n:\nCeleritas\n},\n\n  \n{\nid\n:\n15\n,\nname\n:\nMagneta\n}\n\n\n]\n\n\n\n\n\n\nYou'll also see this request logged in the shell that you started \naqueduct serve\n in.\n\n\nLinking Controllers\n\n\nWhen a controller handles a request, it can either send a response or let one of its linked controllers handle the request. By default, a \nRouter\n will send a 404 Not Found response for any request. Adding a route to a \nRouter\n creates an entry point to a new channel that controllers can be linked to. In our application, \nHeroesController\n is linked to the route \n/heroes\n.\n\n\nControllers come in two different flavors: endpoint and middleware. Endpoint controllers, like \nHeroesController\n, always send a response. They implement the behavior that a request is seeking. Middleware controllers, like \nRouter\n, handles requests before they reach an endpoint controller. A router, for example, handles a request by directing it to the right controller. Controllers like \nAuthorizer\n verify the authorization of the request. You can create all kinds of controllers to provide any behavior you like.\n\n\nA channel can have zero or many middleware controllers, but must end in an endpoint controller. Most controllers can only have one linked controller, but a \nRouter\n allows for many. For example, a larger application might look like this:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/users\n)\n\n    \n.\nlink\n(()\n \n=\n \nAPIKeyValidator\n())\n\n    \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n())\n\n    \n.\nlink\n(()\n \n=\n \nUsersController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/posts\n)\n\n    \n.\nlink\n(()\n \n=\n \nAPIKeyValidator\n())\n\n    \n.\nlink\n(()\n \n=\n \nPostsController\n());\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nEach of these objects is a subclass of \nController\n, giving them the ability to be linked together to handle requests. A request goes through controllers in the order they are linked. A request for the path \n/users\n will go through an \nAPIKeyValidator\n, an \nAuthorizer\n and finally a \nUsersController\n. Each of these controllers has an opportunity to respond, preventing the next controller from receiving the request.\n\n\nAdvanced Routing\n\n\nRight now, our application handles \nGET /heroes\n requests. The browser application uses the this list to populate its hero dashboard. If we click on an individual hero, the browser application will display an individual hero. When navigating to this page, the browser application makes a request to our server for an individual hero. This request contains the unique id of the selected hero in the path, e.g. \n/heroes/11\n or \n/heroes/13\n.\n\n\nOur server doesn't handle this request yet - it only handles requests that have exactly the path \n/heroes\n. Since a request for individual heroes will have a path that changes depending on the hero, we need our route to include a \npath variable\n.\n\n\nA path variable is a segment of route that matches a value for the same segment in the incoming request path. A path variable is a segment prefixed with a colon (\n:\n). For example, the route \n/heroes/:id\n contains a path variable named \nid\n. If the request path is \n/heroes/1\n, \n/heroes/2\n, and so on, the request will be sent to our \nHeroesController\n. The \nHeroesController\n will have access to the value of the path variable to determine which hero to return.\n\n\nThere's one hiccup. The route \n/heroes/:id\n no longer matches the path \n/heroes\n. It'd be a lot easier to organize our code if both \n/heroes\n and \n/heroes/:id\n went to our \nHeroesController\n; it does heroic stuff. For this reason, we can declare the \n:id\n portion of our route to be optional by wrapping it in square brackets. In \nchannel.dart\n, modify the \n/heroes\n route:\n\n\nrouter\n\n  \n.\nroute\n(\n/heroes/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nHeroesController\n());\n\n\n\n\n\n\nSince the second segment of the path is optional, the path \n/heroes\n still matches the route. If the path contains a second segment, the value of that segment is bound to the path variable named \nid\n. We can access path variables through the \nRequest\n object. In \nheroes_controller.dart\n, modify \nhandle\n:\n\n\n// In just a moment, we\nll replace this code with something even better,\n\n\n// but it\ns important to understand where this information comes from first!\n\n\n@\noverride\n\n\nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n  \nif\n \n(\nrequest\n.\npath\n.\nvariables\n.\ncontainsKey\n(\nid\n))\n \n{\n\n    \nfinal\n \nid\n \n=\n \nint\n.\nparse\n(\nrequest\n.\npath\n.\nvariables\n[\nid\n]);\n\n    \nfinal\n \nhero\n \n=\n \n_heroes\n.\nfirstWhere\n((\nhero\n)\n \n=\n \nhero\n[\nid\n]\n \n==\n \nid\n,\n \norElse:\n \n()\n \n=\n \nnull\n);\n\n    \nif\n \n(\nhero\n \n==\n \nnull\n)\n \n{\n\n      \nreturn\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nhero\n);\n\n  \n}\n\n\n  \nreturn\n \nResponse\n.\nok\n(\n_heroes\n);\n\n\n}\n\n\n\n\n\n\nIn your shell currently running the application, hit Ctrl-C to stop the application. Then, run \naqueduct serve\n again. In the browser application, click on a hero and you will be taken to a detail page for that hero.\n\n\n\n\nYou can verify that your server is responding correctly by executing \ncurl -X GET http://localhost:8888/heroes/11\n to view the single hero object. You can also trigger a 404 Not Found response by getting a hero that doesn't exist.\n\n\nResourceControllers and Operation Methods\n\n\nOur \nHeroesController\n is OK right now, but it'll soon run into a problem: what happens when we want to create a new hero? Or update an existing hero's name? Our \nhandle\n method will start to get unmanageable, quickly.\n\n\nThat's where \nResourceController\n comes in. A \nResourceController\n allows you to create a distinct method for each operation that we can perform on our heroes. One method will handle getting a list of heroes, another will handle getting a single hero, and so on. Each method has an annotation that identifies the HTTP method and path variables the request must have to trigger it.\n\n\nIn \nheroes_controller.dart\n, replace \nHeroesController\n with the following:\n\n\nclass\n \nHeroesController\n \nextends\n \nResourceController\n \n{\n\n  \nfinal\n \n_heroes\n \n=\n \n[\n\n    \n{\nid\n:\n \n11\n,\n \nname\n:\n \nMr. Nice\n},\n\n    \n{\nid\n:\n \n12\n,\n \nname\n:\n \nNarco\n},\n\n    \n{\nid\n:\n \n13\n,\n \nname\n:\n \nBombasto\n},\n\n    \n{\nid\n:\n \n14\n,\n \nname\n:\n \nCeleritas\n},\n\n    \n{\nid\n:\n \n15\n,\n \nname\n:\n \nMagneta\n},\n\n  \n];\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllHeroes\n()\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n(\n_heroes\n);\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetHeroByID\n()\n \nasync\n \n{\n\n    \nfinal\n \nid\n \n=\n \nint\n.\nparse\n(\nrequest\n.\npath\n.\nvariables\n[\nid\n]);\n\n    \nfinal\n \nhero\n \n=\n \n_heroes\n.\nfirstWhere\n((\nhero\n)\n \n=\n \nhero\n[\nid\n]\n \n==\n \nid\n,\n \norElse:\n \n()\n \n=\n \nnull\n);\n\n    \nif\n \n(\nhero\n \n==\n \nnull\n)\n \n{\n\n      \nreturn\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nhero\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNotice that we didn't have to override \nhandle\n in \nResourceController\n. A \nResourceController\n implements this method to call one of our \noperation methods\n. An operation method - like \ngetAllHeroes\n and \ngetHeroByID\n - must have an \nOperation\n annotation. The named constructor \nOperation.get\n means these methods get called when the request's method is GET. An operation method must also return a \nFuture\nResponse\n.\n\n\ngetHeroByID\n's annotation also has an argument - the name of our path variable \nid\n. If that path variable exists in the request's path, \ngetHeroByID\n will be called. If it doesn't exist, \ngetAllHeroes\n will be called.\n\n\n\n\nNaming Operation Methods\n\n\nThe plain English phrase for an operation - like 'get hero by id' - is a really good name for an operation method and a good name will be useful when you generate OpenAPI documentation from your code.\n\n\n\n\nReload the application by hitting Ctrl-C in the terminal that ran \naqueduct serve\n and then run \naqueduct serve\n again. The browser application should still behave the same.\n\n\n\n\nBrowser Clients\n\n\nIn addition to \ncurl\n, you can create a SwaggerUI browser application that executes requests against your locally running application. In your project directory, run \naqueduct document client\n and it will generate a file named \nclient.html\n. Open this file in your browser for a UI that constructs and executes requests that your application supports.\n\n\n\n\nRequest Binding\n\n\nIn our \ngetHeroByID\n method, we make a dangerous assumption that the path variable 'id' can be parsed into an integer. If 'id' were something else, like a string, \nint.parse\n would throw an exception. When exceptions are thrown in operation methods, the controller catches it and sends a 500 Server Error response. 500s are bad, they don't tell the client what's wrong. A 404 Not Found is a better response here, but writing the code to catch that exception and create this response is cumbersome.\n\n\nInstead, we can rely on a feature of operation methods called \nrequest binding\n. An operation method can declare parameters and \nbind\n them to properties of the request. When our operation method gets called, it will be passed values from the request as arguments. Request bindings automatically parse values into the type of the parameter (and return a better error response if parsing fails). Change the method \ngetHeroByID()\n:\n\n\n@\nOperation\n.\nget\n(\nid\n)\n\n\nFuture\nResponse\n \ngetHeroByID\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n  \nfinal\n \nhero\n \n=\n \n_heroes\n.\nfirstWhere\n((\nhero\n)\n \n=\n \nhero\n[\nid\n]\n \n==\n \nid\n,\n \norElse:\n \n()\n \n=\n \nnull\n);\n\n\n  \nif\n \n(\nhero\n \n==\n \nnull\n)\n \n{\n\n    \nreturn\n \nResponse\n.\nnotFound\n();\n\n  \n}\n\n\n  \nreturn\n \nResponse\n.\nok\n(\nhero\n);\n\n\n}\n\n\n\n\n\n\nThe value of the path variable \nid\n will be parsed as an integer and be available to this method in the \nid\n parameter. The \n@Bind\n annotation on an operation method parameter tells Aqueduct the value from the request we want bound. Using the named constructor \nBind.path\n binds a path variable, and the name of that variable is indicated in the argument to this constructor.\n\n\nYou can bind path variables, headers, query parameters and bodies. When binding path variables, we have to specify which path variable with the argument to \n@Bind.path(pathVariableName)\n.\n\n\n\n\nBound Parameter Names\n\n\nThe name of a bound parameter doesn't have to match the name of the path variable. We could have declared it as \n@Bind.path('id') int heroID\n. Only the argument to \nBind\n's constructor must match the actual name of the path variable. This is valuable for other types of bindings, like headers, that may contain characters that aren't valid Dart variable names, e.g. \nX-API-Key\n.\n\n\n\n\nThe More You Know: Multi-threading and Application State\n\n\nIn this simple exercise, we used a constant list of heroes as our source of data. For a simple getting-your-feet-wet demo, this is fine. However, in a real application, you'd store this data in a database. That way you could add data to it and not risk losing it when the application was restarted.\n\n\nMore generally, a web server should never hang on to data that can change. While previously just a best practice, stateless web servers are becoming a requirement with the prevalence of containerization and tools like Kubernetes. Aqueduct makes it a bit easier to detect violations of this rule with its multi-threading strategy.\n\n\nWhen you run an Aqueduct application, it creates multiple threads. Each of these threads has its own isolated heap in memory; meaning data that exists on one thread can't be accessed from other threads. In Dart, these isolated threads are called \nisolates\n.\n\n\nAn instance of your application channel is created for each isolate. Each HTTP request is given to just one of the isolates to be handled. In a sense, your one application behaves the same as running your application on multiple servers behind a load balancer. (It also makes your application substantially faster.)\n\n\nIf you are storing any data in your application, you'll find out really quickly. Why? A request that changes data will only change that data in one of your application's isolates. When you make a request to get that data again, its unlikely that you'll see the changes - another isolate with different data will probably handle that request.\n\n\nNext Chapter: Reading from a Database", 
            "title": "1. Getting Started"
        }, 
        {
            "location": "/tut/getting-started/#1-getting-started", 
            "text": "By the end of this tutorial, you will have created an Aqueduct application that serves fictional heroes from a PostgreSQL database. You will learn the following:   Run an Aqueduct application  Route HTTP requests to the appropriate handler in your code  Store and retrieve database data  Write automated tests for each endpoint  Require authorization for HTTP requests    Getting Help  If at anytime you get stuck, hop on over to the  Aqueduct Slack channel . You can also see a finished version of this application  here .", 
            "title": "1. Getting Started"
        }, 
        {
            "location": "/tut/getting-started/#installation", 
            "text": "To get started, make sure you have the following software installed:   Dart ( Install Instructions )  IntelliJ IDEA or any other Jetbrains IDE, including the free Community Edition ( Install Instructions )  The IntelliJ IDEA Dart Plugin ( Install Instructions )   Install the  aqueduct  command line tool by running the following command in your shell:  pub global activate aqueduct   If you get warning text about your  PATH , make sure to read it before moving on.", 
            "title": "Installation"
        }, 
        {
            "location": "/tut/getting-started/#creating-a-project", 
            "text": "Create a new project named  heroes  by entering the following in your shell:  aqueduct create heroes  This creates a  heroes  project directory. Open this directory with IntelliJ IDEA by dragging the project folder onto IntellIJ IDEA's icon.  In IntelliJ's project view, locate the  lib  directory; this is where your project's code will go. This project has two source files -  heroes.dart  and  channel.dart . Open the file  heroes.dart . Click  Enable Dart Support  in the top right corner of the editor.", 
            "title": "Creating a Project"
        }, 
        {
            "location": "/tut/getting-started/#handling-http-requests", 
            "text": "In your browser, navigate to  http://aqueduct-tutorial.stablekernel.io . This browser application is a 'Hero Manager' - it allows a user to view, create, delete and update heroes. (It is a slightly modified version of the  AngularDart Tour of Heroes Tutorial .) It will make HTTP requests to  http://localhost:8888  to fetch and manipulate hero data. The application you will build in this tutorial respond to those requests.   Running the Browser Application Locally  The browser application is served over HTTP so that it can access your Aqueduct application when it runs locally on your machine. Your browser may warn you about navigating to an insecure webpage, because it is in fact insecure. You can run this application locally by grabbing the source code from  here .   In this first chapter, you will write code to handle two requests: one to get a list of heroes, and the other to get a single hero by its identifier. Those requests are:   GET /heroes  to the list of heroes  GET /heroes/:id  to get an individual hero    HTTP Operation Shorthand  The term  GET /heroes  is called an operation. It is the combination of the HTTP method and the path of the request. Each operation is  unique to an application, so your code is segmented into units for each operation. Sections with a colon, like the ':id' segment, are  variable: they can be 1, 2, 3, and so on.", 
            "title": "Handling HTTP Requests"
        }, 
        {
            "location": "/tut/getting-started/#controller-objects-handle-requests", 
            "text": "Requests are handled by  controller objects . A controller object can respond to a request. It can also take other action and let another controller respond. For example, it might check if the request is authorized, or send analytical data to some other service. Controllers are composed together, and each controller in the composition performs its logic in order. This allows for some controllers to be reused, and for  better code organization. A composition of controllers is called a  channel  because requests flow in one direction through the controllers.  Our application will link two controllers:   a  Router  that makes sure the request path is  /heroes  or  /heroes/:id  a  HeroesControllers  that responds with hero objects   Your application starts with a channel object called the  application channel . You link the controllers in your application to this channel.   Each application has a subclass of  ApplicationChannel  that you override methods in to set up your controllers. This type is already declared in  lib/channel.dart  - open this file and find  ApplicationChannel.entryPoint :     @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router \n       . route ( /example ) \n       . linkFunction (( request )   async   { \n         return   Response . ok ({ key :   value }); \n       }); \n\n     return   router ; \n   }   When your application gets a request, the  entryPoint  controller is the first to handle it. In our case, this is a  Router  - a subclass of  Controller .   Controller Subclassing Every controller you use will be a subclass of  Controller . There are some controller subclasses already in Aqueduct for common behaviors.    You use the  route  method on a router to attach a controller to a  route . A route is a string syntax that matches the path of a request. In our current implementation, the route will match every request with the path  /example . When that request is received, a linked function runs and returns a 200 OK response with an example JSON object body.  We need to route the path  /heroes  to a controller of our own, so we can control what happens. Let's create a  HeroesController . Create a new file in  lib/controller/heroes_controller.dart  and add the following code (you will need to create the subdirectory  lib/controller/ ):  import   package:aqueduct/aqueduct.dart ;  import   package:heroes/heroes.dart ;  class   HeroesController   extends   Controller   { \n   final   _heroes   =   [ \n     { id :   11 ,   name :   Mr. Nice }, \n     { id :   12 ,   name :   Narco }, \n     { id :   13 ,   name :   Bombasto }, \n     { id :   14 ,   name :   Celeritas }, \n     { id :   15 ,   name :   Magneta },     \n   ]; \n\n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     return   Response . ok ( _heroes ); \n   }  }   Notice that  HeroesController  is a subclass of  Controller ; this is what makes it a controller object. It overrides its  handle  method by returning a  Response  object. This response object has a 200 OK status code, and it body contains a JSON-encoded list of hero objects. When a controller returns a  Response  object from its  handle  method, it is sent to the client.  Right now, our  HeroesController  isn't hooked up to the application channel. We need to link it to the router. First, import our new file at the top of  channel.dart .  import   controller/heroes_controller.dart ;   Then link this  HeroesController  to the  Router  for the path  /heroes :  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /heroes ) \n     . link (()   =   HeroesController ()); \n\n   router \n     . route ( /example ) \n     . linkFunction (( request )   async   { \n       return   Response . ok ({ key :   value }); \n     }); \n\n   return   router ;  }   We now have a application that will return a list of heroes. In the project directory, run the following command from the command-line:  aqueduct serve  This will start your application running locally. Reload the browser page  http://aqueduct-tutorial.stablekernel.io . It will make a request to  http://localhost:8888/heroes  and your application will serve it. You'll see your heroes in your web browser:", 
            "title": "Controller Objects Handle Requests"
        }, 
        {
            "location": "/tut/getting-started/#screenshot-of-heroes-application", 
            "text": "You can also see the actual response of your request by entering the following into your shell:  curl -X GET http://localhost:8888/heroes  You'll get JSON output like this:  [ \n   { id : 11 , name : Mr. Nice }, \n   { id : 12 , name : Narco }, \n   { id : 13 , name : Bombasto }, \n   { id : 14 , name : Celeritas }, \n   { id : 15 , name : Magneta }  ]   You'll also see this request logged in the shell that you started  aqueduct serve  in.", 
            "title": "Screenshot of Heroes Application"
        }, 
        {
            "location": "/tut/getting-started/#linking-controllers", 
            "text": "When a controller handles a request, it can either send a response or let one of its linked controllers handle the request. By default, a  Router  will send a 404 Not Found response for any request. Adding a route to a  Router  creates an entry point to a new channel that controllers can be linked to. In our application,  HeroesController  is linked to the route  /heroes .  Controllers come in two different flavors: endpoint and middleware. Endpoint controllers, like  HeroesController , always send a response. They implement the behavior that a request is seeking. Middleware controllers, like  Router , handles requests before they reach an endpoint controller. A router, for example, handles a request by directing it to the right controller. Controllers like  Authorizer  verify the authorization of the request. You can create all kinds of controllers to provide any behavior you like.  A channel can have zero or many middleware controllers, but must end in an endpoint controller. Most controllers can only have one linked controller, but a  Router  allows for many. For example, a larger application might look like this:  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /users ) \n     . link (()   =   APIKeyValidator ()) \n     . link (()   =   Authorizer . bearer ()) \n     . link (()   =   UsersController ()); \n\n   router \n     . route ( /posts ) \n     . link (()   =   APIKeyValidator ()) \n     . link (()   =   PostsController ()); \n\n   return   router ;  }   Each of these objects is a subclass of  Controller , giving them the ability to be linked together to handle requests. A request goes through controllers in the order they are linked. A request for the path  /users  will go through an  APIKeyValidator , an  Authorizer  and finally a  UsersController . Each of these controllers has an opportunity to respond, preventing the next controller from receiving the request.", 
            "title": "Linking Controllers"
        }, 
        {
            "location": "/tut/getting-started/#advanced-routing", 
            "text": "Right now, our application handles  GET /heroes  requests. The browser application uses the this list to populate its hero dashboard. If we click on an individual hero, the browser application will display an individual hero. When navigating to this page, the browser application makes a request to our server for an individual hero. This request contains the unique id of the selected hero in the path, e.g.  /heroes/11  or  /heroes/13 .  Our server doesn't handle this request yet - it only handles requests that have exactly the path  /heroes . Since a request for individual heroes will have a path that changes depending on the hero, we need our route to include a  path variable .  A path variable is a segment of route that matches a value for the same segment in the incoming request path. A path variable is a segment prefixed with a colon ( : ). For example, the route  /heroes/:id  contains a path variable named  id . If the request path is  /heroes/1 ,  /heroes/2 , and so on, the request will be sent to our  HeroesController . The  HeroesController  will have access to the value of the path variable to determine which hero to return.  There's one hiccup. The route  /heroes/:id  no longer matches the path  /heroes . It'd be a lot easier to organize our code if both  /heroes  and  /heroes/:id  went to our  HeroesController ; it does heroic stuff. For this reason, we can declare the  :id  portion of our route to be optional by wrapping it in square brackets. In  channel.dart , modify the  /heroes  route:  router \n   . route ( /heroes/[:id] ) \n   . link (()   =   HeroesController ());   Since the second segment of the path is optional, the path  /heroes  still matches the route. If the path contains a second segment, the value of that segment is bound to the path variable named  id . We can access path variables through the  Request  object. In  heroes_controller.dart , modify  handle :  // In just a moment, we ll replace this code with something even better,  // but it s important to understand where this information comes from first!  @ override  Future RequestOrResponse   handle ( Request   request )   async   { \n   if   ( request . path . variables . containsKey ( id ))   { \n     final   id   =   int . parse ( request . path . variables [ id ]); \n     final   hero   =   _heroes . firstWhere (( hero )   =   hero [ id ]   ==   id ,   orElse:   ()   =   null ); \n     if   ( hero   ==   null )   { \n       return   Response . notFound (); \n     } \n\n     return   Response . ok ( hero ); \n   } \n\n   return   Response . ok ( _heroes );  }   In your shell currently running the application, hit Ctrl-C to stop the application. Then, run  aqueduct serve  again. In the browser application, click on a hero and you will be taken to a detail page for that hero.   You can verify that your server is responding correctly by executing  curl -X GET http://localhost:8888/heroes/11  to view the single hero object. You can also trigger a 404 Not Found response by getting a hero that doesn't exist.", 
            "title": "Advanced Routing"
        }, 
        {
            "location": "/tut/getting-started/#resourcecontrollers-and-operation-methods", 
            "text": "Our  HeroesController  is OK right now, but it'll soon run into a problem: what happens when we want to create a new hero? Or update an existing hero's name? Our  handle  method will start to get unmanageable, quickly.  That's where  ResourceController  comes in. A  ResourceController  allows you to create a distinct method for each operation that we can perform on our heroes. One method will handle getting a list of heroes, another will handle getting a single hero, and so on. Each method has an annotation that identifies the HTTP method and path variables the request must have to trigger it.  In  heroes_controller.dart , replace  HeroesController  with the following:  class   HeroesController   extends   ResourceController   { \n   final   _heroes   =   [ \n     { id :   11 ,   name :   Mr. Nice }, \n     { id :   12 ,   name :   Narco }, \n     { id :   13 ,   name :   Bombasto }, \n     { id :   14 ,   name :   Celeritas }, \n     { id :   15 ,   name :   Magneta }, \n   ]; \n\n   @ Operation . get () \n   Future Response   getAllHeroes ()   async   { \n     return   Response . ok ( _heroes ); \n   } \n\n   @ Operation . get ( id ) \n   Future Response   getHeroByID ()   async   { \n     final   id   =   int . parse ( request . path . variables [ id ]); \n     final   hero   =   _heroes . firstWhere (( hero )   =   hero [ id ]   ==   id ,   orElse:   ()   =   null ); \n     if   ( hero   ==   null )   { \n       return   Response . notFound (); \n     } \n\n     return   Response . ok ( hero ); \n   }  }   Notice that we didn't have to override  handle  in  ResourceController . A  ResourceController  implements this method to call one of our  operation methods . An operation method - like  getAllHeroes  and  getHeroByID  - must have an  Operation  annotation. The named constructor  Operation.get  means these methods get called when the request's method is GET. An operation method must also return a  Future Response .  getHeroByID 's annotation also has an argument - the name of our path variable  id . If that path variable exists in the request's path,  getHeroByID  will be called. If it doesn't exist,  getAllHeroes  will be called.   Naming Operation Methods  The plain English phrase for an operation - like 'get hero by id' - is a really good name for an operation method and a good name will be useful when you generate OpenAPI documentation from your code.   Reload the application by hitting Ctrl-C in the terminal that ran  aqueduct serve  and then run  aqueduct serve  again. The browser application should still behave the same.   Browser Clients  In addition to  curl , you can create a SwaggerUI browser application that executes requests against your locally running application. In your project directory, run  aqueduct document client  and it will generate a file named  client.html . Open this file in your browser for a UI that constructs and executes requests that your application supports.", 
            "title": "ResourceControllers and Operation Methods"
        }, 
        {
            "location": "/tut/getting-started/#request-binding", 
            "text": "In our  getHeroByID  method, we make a dangerous assumption that the path variable 'id' can be parsed into an integer. If 'id' were something else, like a string,  int.parse  would throw an exception. When exceptions are thrown in operation methods, the controller catches it and sends a 500 Server Error response. 500s are bad, they don't tell the client what's wrong. A 404 Not Found is a better response here, but writing the code to catch that exception and create this response is cumbersome.  Instead, we can rely on a feature of operation methods called  request binding . An operation method can declare parameters and  bind  them to properties of the request. When our operation method gets called, it will be passed values from the request as arguments. Request bindings automatically parse values into the type of the parameter (and return a better error response if parsing fails). Change the method  getHeroByID() :  @ Operation . get ( id )  Future Response   getHeroByID ( @ Bind . path ( id )   int   id )   async   { \n   final   hero   =   _heroes . firstWhere (( hero )   =   hero [ id ]   ==   id ,   orElse:   ()   =   null ); \n\n   if   ( hero   ==   null )   { \n     return   Response . notFound (); \n   } \n\n   return   Response . ok ( hero );  }   The value of the path variable  id  will be parsed as an integer and be available to this method in the  id  parameter. The  @Bind  annotation on an operation method parameter tells Aqueduct the value from the request we want bound. Using the named constructor  Bind.path  binds a path variable, and the name of that variable is indicated in the argument to this constructor.  You can bind path variables, headers, query parameters and bodies. When binding path variables, we have to specify which path variable with the argument to  @Bind.path(pathVariableName) .   Bound Parameter Names  The name of a bound parameter doesn't have to match the name of the path variable. We could have declared it as  @Bind.path('id') int heroID . Only the argument to  Bind 's constructor must match the actual name of the path variable. This is valuable for other types of bindings, like headers, that may contain characters that aren't valid Dart variable names, e.g.  X-API-Key .", 
            "title": "Request Binding"
        }, 
        {
            "location": "/tut/getting-started/#the-more-you-know-multi-threading-and-application-state", 
            "text": "In this simple exercise, we used a constant list of heroes as our source of data. For a simple getting-your-feet-wet demo, this is fine. However, in a real application, you'd store this data in a database. That way you could add data to it and not risk losing it when the application was restarted.  More generally, a web server should never hang on to data that can change. While previously just a best practice, stateless web servers are becoming a requirement with the prevalence of containerization and tools like Kubernetes. Aqueduct makes it a bit easier to detect violations of this rule with its multi-threading strategy.  When you run an Aqueduct application, it creates multiple threads. Each of these threads has its own isolated heap in memory; meaning data that exists on one thread can't be accessed from other threads. In Dart, these isolated threads are called  isolates .  An instance of your application channel is created for each isolate. Each HTTP request is given to just one of the isolates to be handled. In a sense, your one application behaves the same as running your application on multiple servers behind a load balancer. (It also makes your application substantially faster.)  If you are storing any data in your application, you'll find out really quickly. Why? A request that changes data will only change that data in one of your application's isolates. When you make a request to get that data again, its unlikely that you'll see the changes - another isolate with different data will probably handle that request.", 
            "title": "The More You Know: Multi-threading and Application State"
        }, 
        {
            "location": "/tut/getting-started/#next-chapter-reading-from-a-database", 
            "text": "", 
            "title": "Next Chapter: Reading from a Database"
        }, 
        {
            "location": "/tut/executing-queries/", 
            "text": "2. Reading from a Database\n\n\nWe will continue to build on the last chapter's project, \nheroes\n, by storing our heroes in a database. This will let us to edit our heroes and keep the changes when we restart the application.\n\n\nObject-Relational Mapping\n\n\nA relational database management system (like PostgreSQL or MySQL) stores its data in the form of tables. A table represents some sort of entity - like a person or a bank account. Each table has columns that describe the attributes of that entity - like a name or a balance. Every row in a table is an instance of that entity - like a single person named Bob or a bank account.\n\n\nIn an object-oriented framework like Aqueduct, we have representations for tables, columns and rows. A class represents a table, its instances are rows, and instance properties are column values. An ORM translates rows in a database to and from objects in an application.\n\n\n\n\n\n\n\n\nAqueduct\n\n\nDatabase\n\n\nExample #1\n\n\nExample #2\n\n\n\n\n\n\n\n\n\n\nClass\n\n\nTable\n\n\nPerson\n\n\nBank Account\n\n\n\n\n\n\nInstance\n\n\nRow\n\n\nA person named Bob\n\n\nSally's Bank Account\n\n\n\n\n\n\nProperty\n\n\nColumn\n\n\nPerson's Name\n\n\nBank Account Balance\n\n\n\n\n\n\n\n\nIn Aqueduct, each database table-class pairing is called an \nentity\n. Collectively, an application's entities are called its \ndata model\n.\n\n\nBuilding a Data Model\n\n\nIn our \nheroes\n application, we will have one type of entity - a \"hero\". To create a new entity, we subclass \nManagedObject\nT\n. Create a new directory \nlib/model/\n and then add a new file to this directory named \nhero.dart\n. Add the following code:\n\n\nimport\n \npackage:heroes/heroes.dart\n;\n\n\n\nclass\n \nHero\n \nextends\n \nManagedObject\n_Hero\n \nimplements\n \n_Hero\n \n{}\n\n\n\nclass\n \n_Hero\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\nunique:\n \ntrue\n)\n\n  \nString\n \nname\n;\n\n\n}\n\n\n\n\n\n\nThis declares a \nHero\n entity. Entities are always made up of two classes.\n\n\nThe \n_Hero\n class is a direct mapping of a database table. This table's name will have the same name as the class: \n_Hero\n. Every property declared in this class will have a corresponding column in this table. Therefore, the \n_Hero\n table will have two columns - \nid\n and \nname\n. The \nid\n column is this table's primary key (a unique identifier for each hero). The name of each hero must be unique.\n\n\nThe other class, \nHero\n, is what we work with in our code - when we fetch heroes from a database, they will be instances of \nHero\n.\n\n\nThe \nHero\n class is called the \ninstance type\n of the entity, because that's what we have instances of. \n_Hero\n is the \ntable definition\n of the entity. You won't use the table definition for anything other than describing the database table.\n\n\nAn instance type must \nimplement\n its table definition; this gives our \nHero\n all of the properties of \n_Hero\n. An instance type must \nextend\n \nManagedObject\nT\n, where \nT\n is also the table definition. \nManagedObject\nT\n has behavior for automatically transferring objects to the database and back (among other things).\n\n\n\n\nTransient Properties\n\n\nProperties declared in the instance type aren't stored in the database. This is different than properties in the table definition. For example, a database table might have a \nfirstName\n and \nlastName\n, but it's useful in some places to have a \nfullName\n property. Declaring the \nfullName\n property in the instance type means we have easy access to the full name, but we still store the first and last name individually.\n\n\n\n\nDefining a Context\n\n\nOur application needs to know two things to execute database queries:\n\n\n\n\nWhat is the data model (our collection of entities)?\n\n\nWhat database are we connecting to?\n\n\n\n\nBoth of these things are set up when an application is first started. In \nchannel.dart\n, add a new property \ncontext\n and update \nprepare()\n:\n\n\nclass\n \nHeroesChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nlogger\n.\nonRecord\n.\nlisten\n((\nrec\n)\n \n=\n \nprint\n(\n$\nrec\n \n${\nrec\n.\nerror\n \n??\n \n}\n \n${\nrec\n.\nstackTrace\n \n??\n \n}\n));\n\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npersistentStore\n \n=\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n      \nheroes_user\n,\n \npassword\n,\n \nlocalhost\n,\n \n5432\n,\n \nheroes\n);\n\n\n    \ncontext\n \n=\n \nManagedContext\n(\ndataModel\n,\n \npersistentStore\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \n...\n\n\n\n\n\n\nManagedDataModel.fromCurrentMirrorSystem()\n will find all of our \nManagedObject\nT\n subclasses and 'compile' them into a data model. A \nPostgreSQLPersistentStore\n takes database connection information that it will use to connect and send queries to a database. Together, these objects are packaged in a \nManagedContext\n.\n\n\n\n\nConfiguring a Database Connection\n\n\nThis tutorial hardcodes the information needed to connect to a database. In a future chapter, we will move these values to a configuration file so that we can change them during tests and various deployment environments.\n\n\n\n\nThe context will coordinate with these two objects to execute queries and translate objects to and from the database. Controllers that make database queries need a reference to the context. So, we'll want \nHeroesController\n to have access to the context.\n\n\nIn \nheroes_controller.dart\n, add a property and create a new constructor:\n\n\nclass\n \nHeroesController\n \nextends\n \nResourceController\n \n{\n\n  \nHeroesController\n(\nthis\n.\ncontext\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n  \n  \n...\n\n\n\n\n\n\nNow that \nHeroesController\n requires a context in its constructor, we need to pass it the context we created in \nprepare()\n. Update \nentryPoint\n in \nchannel.dart\n.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/heroes/[:id]\n)\n\n    \n.\nlink\n(()\n \n=\n \nHeroesController\n(\ncontext\n));\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/example\n)\n\n    \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n  \n});\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nNow that we've 'injected' this context into our \nHeroesController\n constructor, each \nHeroesController\n can execute database queries.\n\n\n\n\nService Objects and Dependency Injection\n\n\nOur context is an example of a \nservice object\n. A service encapsulates logic and state into a single object that can be reused in multiple controllers. A typical service object accesses another server, like a database or another REST API. Some service objects may simply provide a simplified interface to a complex process, like applying transforms to an image. Services are passed in a controller's constructor;\nthis is called \ndependency injection\n. Unlike many frameworks, Aqueduct does not require a complex dependency injection framework; this is because you write the code to create instances of your controllers and can pass whatever you like in their constructor.\n\n\n\n\nExecuting Queries\n\n\nOur operation methods in \nHeroesController\n currently return heroes from an in-memory list. To fetch data from a database instead of this list, we create and execute instances of \nQuery\nT\n in our \nManagedContext\n.\n\n\nLet's start by replacing \ngetAllHeroes\n in \nheroes_controller.dart\n. Make sure to import your \nmodel/hero.dart\n file at the top:\n\n\nimport\n \npackage:heroes/heroes.dart\n;\n\n\nimport\n \npackage:heroes/model/hero.dart\n;\n\n\n\nclass\n \nHeroesController\n \nextends\n \nResourceController\n \n{\n\n  \nHeroesController\n(\nthis\n.\ncontext\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllHeroes\n()\n \nasync\n \n{\n\n    \nfinal\n \nheroQuery\n \n=\n \nQuery\nHero\n(\ncontext\n);\n\n    \nfinal\n \nheroes\n \n=\n \nawait\n \nheroQuery\n.\nfetch\n();\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nheroes\n);\n\n  \n}\n\n\n\n...\n\n\n\n\n\n\nHere, we create an instance of \nQuery\nHero\n and then execute its \nfetch()\n method. The type argument to \nQuery\nT\n is an instance type; it lets the query know which table to fetch rows from and the type of objects that are returned by the query. The context argument tells it which database to fetch it from. The \nfetch()\n execution method returns a \nList\nHero\n. We write that list to the body of the response.\n\n\nNow, let's update \ngetHeroByID\n to fetch a single hero from the database.\n\n\n@\nOperation\n.\nget\n(\nid\n)\n\n\nFuture\nResponse\n \ngetHeroByID\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n  \nfinal\n \nheroQuery\n \n=\n \nQuery\nHero\n(\ncontext\n)\n\n    \n..\nwhere\n((\nh\n)\n \n=\n \nh\n.\nid\n).\nequalTo\n(\nid\n);\n    \n\n  \nfinal\n \nhero\n \n=\n \nawait\n \nheroQuery\n.\nfetchOne\n();\n\n\n  \nif\n \n(\nhero\n \n==\n \nnull\n)\n \n{\n\n    \nreturn\n \nResponse\n.\nnotFound\n();\n\n  \n}\n\n  \nreturn\n \nResponse\n.\nok\n(\nhero\n);\n\n\n}\n\n\n\n\n\n\nThis query does two interesting things. First, it uses the \nwhere\n method to filter heroes that have the same \nid\n as the path variable. For example, \n/heroes/1\n will fetch a hero with an \nid\n of \n1\n. This works because \nQuery.where\n adds a SQL WHERE clause to the query. We'd get the following SQL:\n\n\nSELECT\n \nid\n,\n \nname\n \nFROM\n \n_question\n \nWHERE\n \nid\n \n=\n \n1\n;\n\n\n\n\n\n\nThe \nwhere\n method uses the \nproperty selector\n syntax. This syntax is a closure that takes an argument of the type being queried, and must return a property of that object. This creates an expression object that targets the selected property. By invoking methods like \nequalTo\n on this expression object, a boolean expression is added to the query.\n\n\n\n\nProperty Selectors\n\n\nMany query configuration methods use the property selector syntax. Setting up a keyboard shortcut (called a Live Template in IntelliJ) to enter the syntax is beneficial. A downloadable settings configuration for IntelliJ exists \nhere\n that includes this shortcut.\n\n\n\n\nThe \nfetchOne()\n execution method will fetch a single object that fulfills all of the expressions applied to the query. If no database row meets the criteria, \nnull\n is returned. Our controller returns a 404 Not Found response in that scenario.\n\n\nWe have now written code that fetches heroes from a database instead of from in memory, but we don't have a database - yet.\n\n\n\n\nfetchObjectWithID, fetchOne() and Unique Properties\n\n\nYou can also fetch an object by its primary key with the method \nManagedContext.fetchObjectWithID\n. When fetching with \nfetchOne\n, make sure the search criteria is guaranteed to be unique.\n\n\n\n\nSetting Up a Database\n\n\nFor development, you'll need to install a PostgreSQL server on your local machine. If you are on macOS, use \nPostgres.app\n. This native macOS application manages starting and stopping PostgreSQL servers on your machine. For other platforms, see \nthis page\n.\n\n\n\n\n9.6 or Greater\n\n\nThe minimum version of PostgreSQL needed to work with Aqueduct is 9.6.\n\n\n\n\nIf you installed Postgres.app, open the application and select the \n+\n button on the bottom left corner of the screen to create a new database server. Choose a version (at least 9.6, but the most recent version is best), name the server whatever you like, and leave the rest of the options unchanged before clicking \nCreate Server\n. Once the server has been created, click \nStart\n.\n\n\nA list of databases available on this server will be shown as named, database icons. Double-click on any of them to open the \npsql\n command-line tool.\n\n\n\n\npsql\n\n\nFor other platforms, \npsql\n should be available in your \n$PATH\n. You can also add \nPostgres.app\n's \npsql\n to your path with the directions \nhere\n.\n\n\n\n\nIn \npsql\n, create a new database and a user to manage it.\n\n\nCREATE\n \nDATABASE\n \nheroes\n;\n\n\nCREATE\n \nUSER\n \nheroes_user\n \nWITH\n \ncreatedb\n;\n\n\nALTER\n \nUSER\n \nheroes_user\n \nWITH\n \npassword\n \npassword\n;\n\n\nGRANT\n \nall\n \nON\n \ndatabase\n \nheroes\n \nTO\n \nheroes_user\n;\n\n\n\n\n\n\nNext, we need to create the table where heroes are stored in this database. From your project directory, run the following command:\n\n\naqueduct db generate\n\n\n\n\n\nThis command will create a new \nmigration file\n. A migration file is a Dart script that runs a series of SQL commands to alter a database's schema. It is created in a new directory in your project named \nmigrations/\n. Open \nmigrations/00000001_initial.migration.dart\n, it should look like this:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \ndart:async\n;\n\n\n\nclass\n \nMigration1\n \nextends\n \nMigration\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nupgrade\n()\n \nasync\n \n{\n\n    \ndatabase\n.\ncreateTable\n(\nSchemaTable\n(\n\n      \n_Hero\n,\n \n[\n\n        \nSchemaColumn\n(\nid\n,\n \nManagedPropertyType\n.\nbigInteger\n,\n\n            \nisPrimaryKey:\n \ntrue\n,\n \nautoincrement:\n \ntrue\n,\n \nisIndexed:\n \nfalse\n,\n \nisNullable:\n \nfalse\n,\n \nisUnique:\n \nfalse\n),\n\n        \nSchemaColumn\n(\nname\n,\n \nManagedPropertyType\n.\nstring\n,\n\n            \nisPrimaryKey:\n \nfalse\n,\n \nautoincrement:\n \nfalse\n,\n \nisIndexed:\n \nfalse\n,\n \nisNullable:\n \nfalse\n,\n \nisUnique:\n \ntrue\n),\n\n      \n],\n\n    \n));\n\n  \n}\n\n\n  \n@\noverride\n\n  \nFuture\n \ndowngrade\n()\n \nasync\n \n{}\n\n\n  \n@\noverride\n\n  \nFuture\n \nseed\n()\n \nasync\n \n{}\n\n\n}\n\n\n\n\n\n\nIn a moment, we'll execute this migration file. That will create a new table named \n_Hero\n with columns for \nid\n and \nname\n. Before we run it, we should seed the database with some initial heroes. In the \nseed()\n method, add the following:\n\n\n@\noverride\n\n\nFuture\n \nseed\n()\n \nasync\n \n{\n\n  \nfinal\n \nheroNames\n \n=\n \n[\nMr. Nice\n,\n \nNarco\n,\n \nBombasto\n,\n \nCeleritas\n,\n \nMagneta\n];\n\n\n  \nfor\n \n(\nfinal\n \nheroName\n \nin\n \nheroNames\n)\n \n{\n    \n    \nawait\n \ndatabase\n.\nstore\n.\nexecute\n(\nINSERT INTO _Hero (name) VALUES (@name)\n,\n \nsubstitutionValues:\n \n{\n\n      \nname\n:\n \nheroName\n\n    \n});\n\n  \n}\n\n\n}\n\n\n\n\n\n\nApply this migration file to our locally running \nheroes\n database with the following command in the project directory:\n\n\naqueduct\n \ndb\n \nupgrade\n \n--\nconnect\n \npostgres:\n//heroes_user:password@localhost:5432/heroes\n\n\n\n\n\n\nRe-run your application with \naqueduct serve\n. Then, reload \nhttp://aqueduct-tutorial.stablekernel.io\n. Your dashboard of heroes and detail page for each will still show up - but this time, they are sourced from a database.\n\n\n\n\nManagedObjects and Migration Scripts\n\n\nIn our migration's \nseed()\n method, we executed SQL queries instead of using the Aqueduct ORM. \nIt is very important that you do not use\n \nQuery\nT\n, \nManagedObject\nT\n or other elements of the Aqueduct ORM in migration files. Migration files represent an ordered series of historical steps that describe your database schema. If you replay those steps (which is what executing a migration file does), you will end up with the same database schema every time. However, a \nManagedObject\nT\n subclass changes over time - the definition of a managed object is not historical, it only represents the current point in time. Since a \nManagedObject\nT\n subclass can change, using one in our migration file would mean that our migration file could change.\n\n\n\n\nQuery Parameters and HTTP Headers\n\n\nIn the browser application, the dashboard has a text field for searching heroes. When you enter text into it, it will send the search term to the server by appending a query parameter to \nGET /heroes\n. For example, if you entered the text \nabc\n, it'd make this request:\n\n\nGET /heroes?name=abc\n\n\n\n\n\n\n\n\nOur Aqueduct application can use this value to return a list of heroes that contains the search string. In \nheroes_controller.dart\n, modify \ngetAllHeroes()\n to bind the 'name' query parameter:\n\n\n@\nOperation\n.\nget\n()\n\n\nFuture\nResponse\n \ngetAllHeroes\n({\n@\nBind\n.\nquery\n(\nname\n)\n \nString\n \nname\n})\n \nasync\n \n{\n\n  \nfinal\n \nheroQuery\n \n=\n \nQuery\nHero\n(\ncontext\n);\n\n  \nif\n \n(\nname\n \n!=\n \nnull\n)\n \n{\n\n    \nheroQuery\n.\nwhere\n((\nh\n)\n \n=\n \nh\n.\nname\n).\ncontains\n(\nname\n,\n \ncaseSensitive:\n \nfalse\n);\n\n  \n}\n\n  \nfinal\n \nheroes\n \n=\n \nawait\n \nheroQuery\n.\nfetch\n();\n\n\n  \nreturn\n \nResponse\n.\nok\n(\nheroes\n);\n\n\n}\n\n\n\n\n\n\nYou can re-run your Aqueduct application and use the search bar in the client application.\n\n\nThe \n@Bind.query('name')\n annotation will bind the value of the 'name' query parameter if it is included in the request URL. Otherwise, \nname\n will be null.\n\n\nNotice that \nname\n is an \noptional parameter\n (it is surrounded by curly brackets). An optional parameter in an operation method is also optional in the HTTP request. If we removed the curly brackets from this binding, the 'name' query parameter would become required and the request \nGET /heroes\n without \n?name=x\n would fail with a 400 Bad Request.\n\n\n\n\nResourceController Binding\n\n\nThere is even more to bindings than we've shown (like automatically parsing bound values into types like \nint\n and \nDateTime\n). For more information, see \nResourceControllers\n.\n\n\n\n\nBinding query and header parameters in a operation method is a good way to make your code more intentional and avoid boilerplate parsing code. Aqueduct is able to generate better documentation when using bindings.\n\n\nNext: Storing Data", 
            "title": "2. Reading from a Database"
        }, 
        {
            "location": "/tut/executing-queries/#2-reading-from-a-database", 
            "text": "We will continue to build on the last chapter's project,  heroes , by storing our heroes in a database. This will let us to edit our heroes and keep the changes when we restart the application.", 
            "title": "2. Reading from a Database"
        }, 
        {
            "location": "/tut/executing-queries/#object-relational-mapping", 
            "text": "A relational database management system (like PostgreSQL or MySQL) stores its data in the form of tables. A table represents some sort of entity - like a person or a bank account. Each table has columns that describe the attributes of that entity - like a name or a balance. Every row in a table is an instance of that entity - like a single person named Bob or a bank account.  In an object-oriented framework like Aqueduct, we have representations for tables, columns and rows. A class represents a table, its instances are rows, and instance properties are column values. An ORM translates rows in a database to and from objects in an application.     Aqueduct  Database  Example #1  Example #2      Class  Table  Person  Bank Account    Instance  Row  A person named Bob  Sally's Bank Account    Property  Column  Person's Name  Bank Account Balance     In Aqueduct, each database table-class pairing is called an  entity . Collectively, an application's entities are called its  data model .", 
            "title": "Object-Relational Mapping"
        }, 
        {
            "location": "/tut/executing-queries/#building-a-data-model", 
            "text": "In our  heroes  application, we will have one type of entity - a \"hero\". To create a new entity, we subclass  ManagedObject T . Create a new directory  lib/model/  and then add a new file to this directory named  hero.dart . Add the following code:  import   package:heroes/heroes.dart ;  class   Hero   extends   ManagedObject _Hero   implements   _Hero   {}  class   _Hero   { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( unique:   true ) \n   String   name ;  }   This declares a  Hero  entity. Entities are always made up of two classes.  The  _Hero  class is a direct mapping of a database table. This table's name will have the same name as the class:  _Hero . Every property declared in this class will have a corresponding column in this table. Therefore, the  _Hero  table will have two columns -  id  and  name . The  id  column is this table's primary key (a unique identifier for each hero). The name of each hero must be unique.  The other class,  Hero , is what we work with in our code - when we fetch heroes from a database, they will be instances of  Hero .  The  Hero  class is called the  instance type  of the entity, because that's what we have instances of.  _Hero  is the  table definition  of the entity. You won't use the table definition for anything other than describing the database table.  An instance type must  implement  its table definition; this gives our  Hero  all of the properties of  _Hero . An instance type must  extend   ManagedObject T , where  T  is also the table definition.  ManagedObject T  has behavior for automatically transferring objects to the database and back (among other things).   Transient Properties  Properties declared in the instance type aren't stored in the database. This is different than properties in the table definition. For example, a database table might have a  firstName  and  lastName , but it's useful in some places to have a  fullName  property. Declaring the  fullName  property in the instance type means we have easy access to the full name, but we still store the first and last name individually.", 
            "title": "Building a Data Model"
        }, 
        {
            "location": "/tut/executing-queries/#defining-a-context", 
            "text": "Our application needs to know two things to execute database queries:   What is the data model (our collection of entities)?  What database are we connecting to?   Both of these things are set up when an application is first started. In  channel.dart , add a new property  context  and update  prepare() :  class   HeroesChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     logger . onRecord . listen (( rec )   =   print ( $ rec   ${ rec . error   ??   }   ${ rec . stackTrace   ??   } )); \n\n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   persistentStore   =   PostgreSQLPersistentStore . fromConnectionInfo ( \n       heroes_user ,   password ,   localhost ,   5432 ,   heroes ); \n\n     context   =   ManagedContext ( dataModel ,   persistentStore ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     ...   ManagedDataModel.fromCurrentMirrorSystem()  will find all of our  ManagedObject T  subclasses and 'compile' them into a data model. A  PostgreSQLPersistentStore  takes database connection information that it will use to connect and send queries to a database. Together, these objects are packaged in a  ManagedContext .   Configuring a Database Connection  This tutorial hardcodes the information needed to connect to a database. In a future chapter, we will move these values to a configuration file so that we can change them during tests and various deployment environments.   The context will coordinate with these two objects to execute queries and translate objects to and from the database. Controllers that make database queries need a reference to the context. So, we'll want  HeroesController  to have access to the context.  In  heroes_controller.dart , add a property and create a new constructor:  class   HeroesController   extends   ResourceController   { \n   HeroesController ( this . context ); \n\n   final   ManagedContext   context ;   \n   ...   Now that  HeroesController  requires a context in its constructor, we need to pass it the context we created in  prepare() . Update  entryPoint  in  channel.dart .  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /heroes/[:id] ) \n     . link (()   =   HeroesController ( context )); \n\n   router \n     . route ( /example ) \n     . linkFunction (( request )   async   { \n       return   new   Response . ok ({ key :   value }); \n   }); \n\n   return   router ;  }   Now that we've 'injected' this context into our  HeroesController  constructor, each  HeroesController  can execute database queries.   Service Objects and Dependency Injection  Our context is an example of a  service object . A service encapsulates logic and state into a single object that can be reused in multiple controllers. A typical service object accesses another server, like a database or another REST API. Some service objects may simply provide a simplified interface to a complex process, like applying transforms to an image. Services are passed in a controller's constructor;\nthis is called  dependency injection . Unlike many frameworks, Aqueduct does not require a complex dependency injection framework; this is because you write the code to create instances of your controllers and can pass whatever you like in their constructor.", 
            "title": "Defining a Context"
        }, 
        {
            "location": "/tut/executing-queries/#executing-queries", 
            "text": "Our operation methods in  HeroesController  currently return heroes from an in-memory list. To fetch data from a database instead of this list, we create and execute instances of  Query T  in our  ManagedContext .  Let's start by replacing  getAllHeroes  in  heroes_controller.dart . Make sure to import your  model/hero.dart  file at the top:  import   package:heroes/heroes.dart ;  import   package:heroes/model/hero.dart ;  class   HeroesController   extends   ResourceController   { \n   HeroesController ( this . context ); \n\n   final   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getAllHeroes ()   async   { \n     final   heroQuery   =   Query Hero ( context ); \n     final   heroes   =   await   heroQuery . fetch (); \n\n     return   Response . ok ( heroes ); \n   }  ...   Here, we create an instance of  Query Hero  and then execute its  fetch()  method. The type argument to  Query T  is an instance type; it lets the query know which table to fetch rows from and the type of objects that are returned by the query. The context argument tells it which database to fetch it from. The  fetch()  execution method returns a  List Hero . We write that list to the body of the response.  Now, let's update  getHeroByID  to fetch a single hero from the database.  @ Operation . get ( id )  Future Response   getHeroByID ( @ Bind . path ( id )   int   id )   async   { \n   final   heroQuery   =   Query Hero ( context ) \n     .. where (( h )   =   h . id ). equalTo ( id );     \n\n   final   hero   =   await   heroQuery . fetchOne (); \n\n   if   ( hero   ==   null )   { \n     return   Response . notFound (); \n   } \n   return   Response . ok ( hero );  }   This query does two interesting things. First, it uses the  where  method to filter heroes that have the same  id  as the path variable. For example,  /heroes/1  will fetch a hero with an  id  of  1 . This works because  Query.where  adds a SQL WHERE clause to the query. We'd get the following SQL:  SELECT   id ,   name   FROM   _question   WHERE   id   =   1 ;   The  where  method uses the  property selector  syntax. This syntax is a closure that takes an argument of the type being queried, and must return a property of that object. This creates an expression object that targets the selected property. By invoking methods like  equalTo  on this expression object, a boolean expression is added to the query.   Property Selectors  Many query configuration methods use the property selector syntax. Setting up a keyboard shortcut (called a Live Template in IntelliJ) to enter the syntax is beneficial. A downloadable settings configuration for IntelliJ exists  here  that includes this shortcut.   The  fetchOne()  execution method will fetch a single object that fulfills all of the expressions applied to the query. If no database row meets the criteria,  null  is returned. Our controller returns a 404 Not Found response in that scenario.  We have now written code that fetches heroes from a database instead of from in memory, but we don't have a database - yet.   fetchObjectWithID, fetchOne() and Unique Properties  You can also fetch an object by its primary key with the method  ManagedContext.fetchObjectWithID . When fetching with  fetchOne , make sure the search criteria is guaranteed to be unique.", 
            "title": "Executing Queries"
        }, 
        {
            "location": "/tut/executing-queries/#setting-up-a-database", 
            "text": "For development, you'll need to install a PostgreSQL server on your local machine. If you are on macOS, use  Postgres.app . This native macOS application manages starting and stopping PostgreSQL servers on your machine. For other platforms, see  this page .   9.6 or Greater  The minimum version of PostgreSQL needed to work with Aqueduct is 9.6.   If you installed Postgres.app, open the application and select the  +  button on the bottom left corner of the screen to create a new database server. Choose a version (at least 9.6, but the most recent version is best), name the server whatever you like, and leave the rest of the options unchanged before clicking  Create Server . Once the server has been created, click  Start .  A list of databases available on this server will be shown as named, database icons. Double-click on any of them to open the  psql  command-line tool.   psql  For other platforms,  psql  should be available in your  $PATH . You can also add  Postgres.app 's  psql  to your path with the directions  here .   In  psql , create a new database and a user to manage it.  CREATE   DATABASE   heroes ;  CREATE   USER   heroes_user   WITH   createdb ;  ALTER   USER   heroes_user   WITH   password   password ;  GRANT   all   ON   database   heroes   TO   heroes_user ;   Next, we need to create the table where heroes are stored in this database. From your project directory, run the following command:  aqueduct db generate  This command will create a new  migration file . A migration file is a Dart script that runs a series of SQL commands to alter a database's schema. It is created in a new directory in your project named  migrations/ . Open  migrations/00000001_initial.migration.dart , it should look like this:  import   package:aqueduct/aqueduct.dart ;  import   dart:async ;  class   Migration1   extends   Migration   { \n   @ override \n   Future   upgrade ()   async   { \n     database . createTable ( SchemaTable ( \n       _Hero ,   [ \n         SchemaColumn ( id ,   ManagedPropertyType . bigInteger , \n             isPrimaryKey:   true ,   autoincrement:   true ,   isIndexed:   false ,   isNullable:   false ,   isUnique:   false ), \n         SchemaColumn ( name ,   ManagedPropertyType . string , \n             isPrimaryKey:   false ,   autoincrement:   false ,   isIndexed:   false ,   isNullable:   false ,   isUnique:   true ), \n       ], \n     )); \n   } \n\n   @ override \n   Future   downgrade ()   async   {} \n\n   @ override \n   Future   seed ()   async   {}  }   In a moment, we'll execute this migration file. That will create a new table named  _Hero  with columns for  id  and  name . Before we run it, we should seed the database with some initial heroes. In the  seed()  method, add the following:  @ override  Future   seed ()   async   { \n   final   heroNames   =   [ Mr. Nice ,   Narco ,   Bombasto ,   Celeritas ,   Magneta ]; \n\n   for   ( final   heroName   in   heroNames )   {     \n     await   database . store . execute ( INSERT INTO _Hero (name) VALUES (@name) ,   substitutionValues:   { \n       name :   heroName \n     }); \n   }  }   Apply this migration file to our locally running  heroes  database with the following command in the project directory:  aqueduct   db   upgrade   -- connect   postgres: //heroes_user:password@localhost:5432/heroes   Re-run your application with  aqueduct serve . Then, reload  http://aqueduct-tutorial.stablekernel.io . Your dashboard of heroes and detail page for each will still show up - but this time, they are sourced from a database.   ManagedObjects and Migration Scripts  In our migration's  seed()  method, we executed SQL queries instead of using the Aqueduct ORM.  It is very important that you do not use   Query T ,  ManagedObject T  or other elements of the Aqueduct ORM in migration files. Migration files represent an ordered series of historical steps that describe your database schema. If you replay those steps (which is what executing a migration file does), you will end up with the same database schema every time. However, a  ManagedObject T  subclass changes over time - the definition of a managed object is not historical, it only represents the current point in time. Since a  ManagedObject T  subclass can change, using one in our migration file would mean that our migration file could change.", 
            "title": "Setting Up a Database"
        }, 
        {
            "location": "/tut/executing-queries/#query-parameters-and-http-headers", 
            "text": "In the browser application, the dashboard has a text field for searching heroes. When you enter text into it, it will send the search term to the server by appending a query parameter to  GET /heroes . For example, if you entered the text  abc , it'd make this request:  GET /heroes?name=abc    Our Aqueduct application can use this value to return a list of heroes that contains the search string. In  heroes_controller.dart , modify  getAllHeroes()  to bind the 'name' query parameter:  @ Operation . get ()  Future Response   getAllHeroes ({ @ Bind . query ( name )   String   name })   async   { \n   final   heroQuery   =   Query Hero ( context ); \n   if   ( name   !=   null )   { \n     heroQuery . where (( h )   =   h . name ). contains ( name ,   caseSensitive:   false ); \n   } \n   final   heroes   =   await   heroQuery . fetch (); \n\n   return   Response . ok ( heroes );  }   You can re-run your Aqueduct application and use the search bar in the client application.  The  @Bind.query('name')  annotation will bind the value of the 'name' query parameter if it is included in the request URL. Otherwise,  name  will be null.  Notice that  name  is an  optional parameter  (it is surrounded by curly brackets). An optional parameter in an operation method is also optional in the HTTP request. If we removed the curly brackets from this binding, the 'name' query parameter would become required and the request  GET /heroes  without  ?name=x  would fail with a 400 Bad Request.   ResourceController Binding  There is even more to bindings than we've shown (like automatically parsing bound values into types like  int  and  DateTime ). For more information, see  ResourceControllers .   Binding query and header parameters in a operation method is a good way to make your code more intentional and avoid boilerplate parsing code. Aqueduct is able to generate better documentation when using bindings.", 
            "title": "Query Parameters and HTTP Headers"
        }, 
        {
            "location": "/tut/executing-queries/#next-storing-data", 
            "text": "", 
            "title": "Next: Storing Data"
        }, 
        {
            "location": "/tut/storing-data/", 
            "text": "3. Storing Data in a Database\n\n\nIn the previous exercise, we loaded some heroes into the database our application reads from. Now, we will allow our application to store, delete and modify heroes in the database. Before we embark on this part of the journey, it's important that we understand how an HTTP API is intended to work.\n\n\nHTTP Resources and Methods\n\n\nThe \nHTTP specification\n defines the concept of a \nresource\n. A resource can be anything - a hero, a bank account, a light switch in your home, a temperature sensor in Antarctica, etc. Some of these things are physical objects (the light switch), and some are digital - and they are all resources. An HTTP server application is an interface to these resources; a client requests that something be done with a resource, and the server finds a way to get it done.\n\n\nResources are identified with a URI. A URI \nuniversally identifies\n a resource: it has the address of a server to connect to, and a path that identifies the resource on that server. When writing Aqueduct applications, we don't care much about the server part of a URL - the internet figures out that part. What we do care about is the path of the URL - like \n/heroes\n.\n\n\nAn application uses the URL path to determine which resource the request wants to work with. Right now, our application works with hero resources. A request with the path \n/heroes/1\n wants to do something with an individual hero (that is identified by the number \n1\n). A request with the path \n/heroes\n will act on the entire collection of heroes.\n\n\nThese actions are primarily described by the request method (like GET, POST, OR DELETE). Each of these methods has a general meaning that describes an action that can be applied to a resource. For example, a \nGET /heroes\n means \"get me all of the hero resources\". The meaning for each of these methods are as follows:\n\n\n\n\nGET: returns a collection of some resource or an individual resource\n\n\nPOST: inserts or appends a resource to a collection of some resource; a representation of the resource is in the request body\n\n\nPUT: replaces a resource with the contents of the request body (or in some cases, replaces the entire collection of some resource)\n\n\nDELETE: deletes a resource (or in some cases, deletes the entire collection of some resource)\n\n\n\n\nIt turns out, we can create a lot of incredible behavior by just combining these methods and a request path. More importantly, by following these specifications, client applications can use generic libraries to access any HTTP API with very little effort. This allows us to create complex systems that are easily made available to a browser, mobile phone or any other internet-connected device.\n\n\nInserting Data\n\n\nWe'll start by adding behavior that allows for new heroes to be inserted into the database. Following our previous discussion, the HTTP request must take the form \nPOST /heroes\n - we are appending a new hero to the collection of heroes. This request will contain the JSON representation of a hero in its body, for example:\n\n\n{\n\n  \nname\n:\n \nMaster of Aqueducts\n\n\n}\n\n\n\n\n\n\nOur \nHeroesController\n will handle this operation. In general, a single endpoint controller should handle every operation on a resource collection and its individual resources. In \nheroes_controller.dart\n, add the following operation method:\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \ncreateHero\n()\n \nasync\n \n{\n\n  \nfinal\n \nMap\nString\n,\n \ndynamic\n \nbody\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\n();\n\n  \nfinal\n \nquery\n \n=\n \nQuery\nHero\n(\ncontext\n)\n\n    \n..\nvalues\n.\nname\n \n=\n \nbody\n[\nname\n]\n \nas\n \nString\n;\n\n\n  \nfinal\n \ninsertedHero\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n\n\n  \nreturn\n \nResponse\n.\nok\n(\ninsertedHero\n);\n\n\n}\n\n\n\n\n\n\nThere are three important things happening here: this method decodes the JSON object from the request's body, constructs a query that inserts a new hero with the name in the JSON object, and then returns the newly inserted hero in the response.\n\n\nIf the decoded body doesn't match the type of the variable or parameter it is being assigned to, a status code 400 exception is thrown. This means that decoding the body in this way checks that the body is the expected format and returns an error to the client on your behalf if it is not. For example, if someone posts a list of JSON objects, they will get a 400 Bad Request response because we expect a single JSON object in our method.\n\n\nAn insertion query sets the properties of its \nvalues\n object. The \nvalues\n object is an instance of the type being inserted. Invoking \ninsert\n on a query inserts a row with its values. A new hero, with its primary key set by the database, is returned and returned as the body of the response. The generated SQL for the above would be something like:\n\n\nINSERT\n \nINTO\n \n_Hero\n \n(\nname\n)\n \nVALUES\n \n(\nHero Name\n);\n\n\n\n\n\n\n\n\nColumn Attributes\n\n\nThe \nid\n of a hero is automatically generated because of its \n@primaryKey\n annotation. This annotation is a \nColumn\n that configures the id to be both a primary key and be 'auto-incrementing'. Auto-incremented columns values are generated automatically (1, 2, 3...). See \nthe API reference for Column\n for column options.\n\n\n\n\nRe-run your application. In the browser application, click on \nHeroes\n near the top of the page. Then, enter a name into the \nHero name:\n field and click \nAdd\n. The new hero will appear. You can re-run the application and that hero will still be available, because it has been stored in the database on your machine.\n\n\n\n\nAssigning values one-by-one from a request body to a query is cumbersome. You can also auto-magically ingest a request body into a managed object and assign it to the \nvalues\n of a query:\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \ncreateHero\n()\n \nasync\n \n{\n\n  \nfinal\n \nhero\n \n=\n \nHero\n()\n\n    \n..\nread\n(\nawait\n \nrequest\n.\nbody\n.\ndecode\n(),\n \nignore:\n \n[\nid\n]);\n\n  \nfinal\n \nquery\n \n=\n \nQuery\nHero\n(\ncontext\n)..\nvalues\n \n=\n \nhero\n;\n\n\n  \nfinal\n \ninsertedHero\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n\n\n  \nreturn\n \nResponse\n.\nok\n(\ninsertedHero\n);\n\n\n}\n\n\n\n\n\n\nThe \nread\n method reads a \nMap\nString, dynamic\n into a managed object. Each key's value is assigned to the property of the same name. The \nignore:\n optional parameter removes values for that key from the map before reading it. You can also reject or require keys in this way. If a request body contains a key that isn't declared as property of the managed object, a 400 status code exception is thrown.\n\n\n\n\nSub-resources\n\n\nWe mentioned that a single controller should handle every operation for a resource collection and its individual resources. Some resources are complex enough that they can have sub-resources. For example, an organization of heroes (like the X-Men or Fantastic Four) contains heroes, but it might also contain buildings and equipment owned by the organization. The heroes, buildings and equipment are sub-resources of an organization.  Each sub-resource should have its own route and controller instead of trying to shove everything into a single route and controller. See the following code snippet for an example.\n\n\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nreturn\n \nRouter\n()\n\n    \n..\nroute\n(\n/organizations/[:orgName]\n)\n\n      \n.\nlink\n(()\n \n=\n \nOrganizationController\n());\n\n    \n..\nroute\n(\n/organizations/:orgName/heroes/[:heroID]\n)\n\n      \n.\nlink\n(()\n \n=\n \nOrgHeroesController\n());\n\n    \n..\nroute\n(\n/organizations/:orgName/buildings/[:buildingID]\n)\n\n      \n.\nlink\n(()\n \n=\n \nOrgBuildingController\n());\n\n\n}\n\n\n\n\n\n\nRequest and Response Bodies\n\n\nSo far, we've largely glossed over how request and response bodies are handled, and now is a good time to dig in to this topic.\n\n\nResponse Body Encoding\n\n\nWhen we create a response, we specify its status code and optionally its headers and body. For example, the following creates a response with a status code of 200 OK with an empty list body:\n\n\nResponse\n.\nok\n([])\n\n\n\n\n\n\nThe first argument to \nResponse.ok\n is a \nbody object\n. A body object is automatically encoded according to the \ncontentType\n of its response. By default, the content type of a response is \napplication/json\n - so by default, all of our response body objects are JSON-encoded in the response body.\n\n\n\n\nOther Response Constructors\n\n\nThe default constructor for a \nResponse\n takes a status code, map of headers and a body object: \nResponse(200, {}, \"body\")\n. There are many named constructors for \nResponse\n, like \nResponse.ok\n or \nResponse.notFound\n. These constructors set the status code and expose parameters that are intended for that type of response. For example, a 200 OK response should have a body, so \nResponse.ok\n has a required body object argument. See \nthe API reference for Response\n for possible constructors and properties of a response.\n\n\n\n\nTo change the format a body object is encoded into, you set the \ncontentType\n of the response. For example,\n\n\nResponse\n.\nok\n([])\n\n  \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\napplication\n,\n \nxml\n);\n\n\n\n\n\n\nThe default supported content types are JSON, \napplication/x-www-form-urlencoded\n and all \ntext/*\n types. To encode other content-types, you must register a \nCodec\n with \nCodecRegistry.\n A body object is only valid if the codec selected by the response's content-type can encode it. If it can't, an error will be thrown and a 500 Server Error response is sent instead.\n\n\nTypes that implement \nSerializable\n may also be body objects. Objects that implement this type provide an \nasMap()\n method that converts their properties into a \nMap\n before being passed to the encoder. This \nMap\n must be encodable for the response's content-type codec. You may also provide a \nList\n of \nSerializable\n, for which the list of each object's \nasMap()\n is passed to the encoder.\n\n\nManagedObject\n implements the \nSerializable\n interface, and therefore all managed objects (and lists of managed objects) can be body objects.\n\n\nRequest Body Decoding\n\n\nEvery \nRequest\n has a \nbody\n property of type \nRequestBody\n. A \nRequestBody\n decodes the contents of the request body into Dart objects that you use in your application. This decoding is performed by the \nCodec\n that is associated with the request's content-type. The decoded object is determined by the format of the data - for example, a JSON array decodes into a \nList\n, a JSON object into a \nMap\n.\n\n\nWhen you write code to decode a request body, you are also validating the request body is in the expected format. For example, your \nHeroesController\n invokes \ndecode\n like this:\n\n\nMap\nString\n,\n \ndynamic\n \nbody\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\n();\n\n\n\n\n\n\nThe \ndecode\n method has a type argument that is inferred to be a \nMap\nString, dynamic\n. If the decoded body is not a \nMap\n, an exception is thrown that sends an appropriate error response to the client.\n\n\nYou may also bind the body of a request to an operation method parameter. Let's bind a \nHero\n instance to a request body in our \nHeroesController\n. Update the code in that file to the following:\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \ncreateHero\n(\n@\nBind\n.\nbody\n(\nignore:\n \n[\nid\n])\n \nHero\n \ninputHero\n)\n \nasync\n \n{\n\n  \nfinal\n \nquery\n \n=\n \nQuery\nHero\n(\ncontext\n)\n\n    \n..\nvalues\n \n=\n \ninputHero\n;\n\n\n  \nfinal\n \ninsertedHero\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n\n\n  \nreturn\n \nResponse\n.\nok\n(\ninsertedHero\n);\n\n\n}\n\n\n\n\n\n\nValues in the request body object are decoded into a \nHero\n object - each key in the request body maps to a property of our \nHero\n. For example, the value for the key 'name' is stored in the \ninputHero.name\n. If decoding the request body into a \nHero\n instance fails for any reason, a 400 Bad Request response is sent and the operation method is not called.\n\n\n\n\nBinding Serializables\nA body can be bound to any type - a request will only succeed if the decoded body matches the expected type. When a \nSerializable\n subclass (or \nList\nSerializable\n) is bound to a body, it enforces the body to be decoded into a \nMap\nString, dynamic\n (or a \nList\nMap\nString, dynamic\n). All \nManagedObject\ns implement \nSerializable\n, and therefore you may bind managed objects (and lists of such) using body binding.\n\n\n\n\n\n\nRe-run your \nheroes\n application. On \nhttp://aqueduct-tutorial.stablekernel.io\n, click on the \nHeroes\n button on the top of the screen. In the text field, enter a new hero name and click \nAdd\n. You'll see your new hero added to the list! You can shutdown your application and run it again and you'll still be able to fetch your new hero.\n\n\n\n\n\n\nQuery Construction\n\n\nProperties like \nvalues\n and \nwhere\n prevent errors by type and name checking columns with the analyzer. They're also great for speeding up writing code because your IDE will autocomplete property names. There is \nspecific behavior\n a query uses to decide whether it should include a value from these two properties in the SQL it generates.\n\n\n\n\nNext Chapter: Writing Tests", 
            "title": "3. Storing Data in a Database"
        }, 
        {
            "location": "/tut/storing-data/#3-storing-data-in-a-database", 
            "text": "In the previous exercise, we loaded some heroes into the database our application reads from. Now, we will allow our application to store, delete and modify heroes in the database. Before we embark on this part of the journey, it's important that we understand how an HTTP API is intended to work.", 
            "title": "3. Storing Data in a Database"
        }, 
        {
            "location": "/tut/storing-data/#http-resources-and-methods", 
            "text": "The  HTTP specification  defines the concept of a  resource . A resource can be anything - a hero, a bank account, a light switch in your home, a temperature sensor in Antarctica, etc. Some of these things are physical objects (the light switch), and some are digital - and they are all resources. An HTTP server application is an interface to these resources; a client requests that something be done with a resource, and the server finds a way to get it done.  Resources are identified with a URI. A URI  universally identifies  a resource: it has the address of a server to connect to, and a path that identifies the resource on that server. When writing Aqueduct applications, we don't care much about the server part of a URL - the internet figures out that part. What we do care about is the path of the URL - like  /heroes .  An application uses the URL path to determine which resource the request wants to work with. Right now, our application works with hero resources. A request with the path  /heroes/1  wants to do something with an individual hero (that is identified by the number  1 ). A request with the path  /heroes  will act on the entire collection of heroes.  These actions are primarily described by the request method (like GET, POST, OR DELETE). Each of these methods has a general meaning that describes an action that can be applied to a resource. For example, a  GET /heroes  means \"get me all of the hero resources\". The meaning for each of these methods are as follows:   GET: returns a collection of some resource or an individual resource  POST: inserts or appends a resource to a collection of some resource; a representation of the resource is in the request body  PUT: replaces a resource with the contents of the request body (or in some cases, replaces the entire collection of some resource)  DELETE: deletes a resource (or in some cases, deletes the entire collection of some resource)   It turns out, we can create a lot of incredible behavior by just combining these methods and a request path. More importantly, by following these specifications, client applications can use generic libraries to access any HTTP API with very little effort. This allows us to create complex systems that are easily made available to a browser, mobile phone or any other internet-connected device.", 
            "title": "HTTP Resources and Methods"
        }, 
        {
            "location": "/tut/storing-data/#inserting-data", 
            "text": "We'll start by adding behavior that allows for new heroes to be inserted into the database. Following our previous discussion, the HTTP request must take the form  POST /heroes  - we are appending a new hero to the collection of heroes. This request will contain the JSON representation of a hero in its body, for example:  { \n   name :   Master of Aqueducts  }   Our  HeroesController  will handle this operation. In general, a single endpoint controller should handle every operation on a resource collection and its individual resources. In  heroes_controller.dart , add the following operation method:  @ Operation . post ()  Future Response   createHero ()   async   { \n   final   Map String ,   dynamic   body   =   await   request . body . decode (); \n   final   query   =   Query Hero ( context ) \n     .. values . name   =   body [ name ]   as   String ; \n\n   final   insertedHero   =   await   query . insert (); \n\n   return   Response . ok ( insertedHero );  }   There are three important things happening here: this method decodes the JSON object from the request's body, constructs a query that inserts a new hero with the name in the JSON object, and then returns the newly inserted hero in the response.  If the decoded body doesn't match the type of the variable or parameter it is being assigned to, a status code 400 exception is thrown. This means that decoding the body in this way checks that the body is the expected format and returns an error to the client on your behalf if it is not. For example, if someone posts a list of JSON objects, they will get a 400 Bad Request response because we expect a single JSON object in our method.  An insertion query sets the properties of its  values  object. The  values  object is an instance of the type being inserted. Invoking  insert  on a query inserts a row with its values. A new hero, with its primary key set by the database, is returned and returned as the body of the response. The generated SQL for the above would be something like:  INSERT   INTO   _Hero   ( name )   VALUES   ( Hero Name );    Column Attributes  The  id  of a hero is automatically generated because of its  @primaryKey  annotation. This annotation is a  Column  that configures the id to be both a primary key and be 'auto-incrementing'. Auto-incremented columns values are generated automatically (1, 2, 3...). See  the API reference for Column  for column options.   Re-run your application. In the browser application, click on  Heroes  near the top of the page. Then, enter a name into the  Hero name:  field and click  Add . The new hero will appear. You can re-run the application and that hero will still be available, because it has been stored in the database on your machine.   Assigning values one-by-one from a request body to a query is cumbersome. You can also auto-magically ingest a request body into a managed object and assign it to the  values  of a query:  @ Operation . post ()  Future Response   createHero ()   async   { \n   final   hero   =   Hero () \n     .. read ( await   request . body . decode (),   ignore:   [ id ]); \n   final   query   =   Query Hero ( context ).. values   =   hero ; \n\n   final   insertedHero   =   await   query . insert (); \n\n   return   Response . ok ( insertedHero );  }   The  read  method reads a  Map String, dynamic  into a managed object. Each key's value is assigned to the property of the same name. The  ignore:  optional parameter removes values for that key from the map before reading it. You can also reject or require keys in this way. If a request body contains a key that isn't declared as property of the managed object, a 400 status code exception is thrown.   Sub-resources  We mentioned that a single controller should handle every operation for a resource collection and its individual resources. Some resources are complex enough that they can have sub-resources. For example, an organization of heroes (like the X-Men or Fantastic Four) contains heroes, but it might also contain buildings and equipment owned by the organization. The heroes, buildings and equipment are sub-resources of an organization.  Each sub-resource should have its own route and controller instead of trying to shove everything into a single route and controller. See the following code snippet for an example.   @ override  Controller   get   entryPoint   { \n   return   Router () \n     .. route ( /organizations/[:orgName] ) \n       . link (()   =   OrganizationController ()); \n     .. route ( /organizations/:orgName/heroes/[:heroID] ) \n       . link (()   =   OrgHeroesController ()); \n     .. route ( /organizations/:orgName/buildings/[:buildingID] ) \n       . link (()   =   OrgBuildingController ());  }", 
            "title": "Inserting Data"
        }, 
        {
            "location": "/tut/storing-data/#request-and-response-bodies", 
            "text": "So far, we've largely glossed over how request and response bodies are handled, and now is a good time to dig in to this topic.", 
            "title": "Request and Response Bodies"
        }, 
        {
            "location": "/tut/storing-data/#response-body-encoding", 
            "text": "When we create a response, we specify its status code and optionally its headers and body. For example, the following creates a response with a status code of 200 OK with an empty list body:  Response . ok ([])   The first argument to  Response.ok  is a  body object . A body object is automatically encoded according to the  contentType  of its response. By default, the content type of a response is  application/json  - so by default, all of our response body objects are JSON-encoded in the response body.   Other Response Constructors  The default constructor for a  Response  takes a status code, map of headers and a body object:  Response(200, {}, \"body\") . There are many named constructors for  Response , like  Response.ok  or  Response.notFound . These constructors set the status code and expose parameters that are intended for that type of response. For example, a 200 OK response should have a body, so  Response.ok  has a required body object argument. See  the API reference for Response  for possible constructors and properties of a response.   To change the format a body object is encoded into, you set the  contentType  of the response. For example,  Response . ok ([]) \n   .. contentType   =   new   ContentType ( application ,   xml );   The default supported content types are JSON,  application/x-www-form-urlencoded  and all  text/*  types. To encode other content-types, you must register a  Codec  with  CodecRegistry.  A body object is only valid if the codec selected by the response's content-type can encode it. If it can't, an error will be thrown and a 500 Server Error response is sent instead.  Types that implement  Serializable  may also be body objects. Objects that implement this type provide an  asMap()  method that converts their properties into a  Map  before being passed to the encoder. This  Map  must be encodable for the response's content-type codec. You may also provide a  List  of  Serializable , for which the list of each object's  asMap()  is passed to the encoder.  ManagedObject  implements the  Serializable  interface, and therefore all managed objects (and lists of managed objects) can be body objects.", 
            "title": "Response Body Encoding"
        }, 
        {
            "location": "/tut/storing-data/#request-body-decoding", 
            "text": "Every  Request  has a  body  property of type  RequestBody . A  RequestBody  decodes the contents of the request body into Dart objects that you use in your application. This decoding is performed by the  Codec  that is associated with the request's content-type. The decoded object is determined by the format of the data - for example, a JSON array decodes into a  List , a JSON object into a  Map .  When you write code to decode a request body, you are also validating the request body is in the expected format. For example, your  HeroesController  invokes  decode  like this:  Map String ,   dynamic   body   =   await   request . body . decode ();   The  decode  method has a type argument that is inferred to be a  Map String, dynamic . If the decoded body is not a  Map , an exception is thrown that sends an appropriate error response to the client.  You may also bind the body of a request to an operation method parameter. Let's bind a  Hero  instance to a request body in our  HeroesController . Update the code in that file to the following:  @ Operation . post ()  Future Response   createHero ( @ Bind . body ( ignore:   [ id ])   Hero   inputHero )   async   { \n   final   query   =   Query Hero ( context ) \n     .. values   =   inputHero ; \n\n   final   insertedHero   =   await   query . insert (); \n\n   return   Response . ok ( insertedHero );  }   Values in the request body object are decoded into a  Hero  object - each key in the request body maps to a property of our  Hero . For example, the value for the key 'name' is stored in the  inputHero.name . If decoding the request body into a  Hero  instance fails for any reason, a 400 Bad Request response is sent and the operation method is not called.   Binding Serializables A body can be bound to any type - a request will only succeed if the decoded body matches the expected type. When a  Serializable  subclass (or  List Serializable ) is bound to a body, it enforces the body to be decoded into a  Map String, dynamic  (or a  List Map String, dynamic ). All  ManagedObject s implement  Serializable , and therefore you may bind managed objects (and lists of such) using body binding.    Re-run your  heroes  application. On  http://aqueduct-tutorial.stablekernel.io , click on the  Heroes  button on the top of the screen. In the text field, enter a new hero name and click  Add . You'll see your new hero added to the list! You can shutdown your application and run it again and you'll still be able to fetch your new hero.    Query Construction  Properties like  values  and  where  prevent errors by type and name checking columns with the analyzer. They're also great for speeding up writing code because your IDE will autocomplete property names. There is  specific behavior  a query uses to decide whether it should include a value from these two properties in the SQL it generates.", 
            "title": "Request Body Decoding"
        }, 
        {
            "location": "/tut/storing-data/#next-chapter-writing-tests", 
            "text": "", 
            "title": "Next Chapter: Writing Tests"
        }, 
        {
            "location": "/tut/writing-tests/", 
            "text": "4. Configuration and Writing Tests\n\n\nWe will continue to build on the last chapter's project, \nheroes\n, by writing automated tests for it. We will also set up configurable environments for our application.\n\n\nApplication Configuration\n\n\nRight now, our application hardcodes its database connection information. This is bad because we want to use a different database when we're testing, running locally and running in production. It's also bad because we'd have to check our database password into version control.\n\n\nWe can create a configuration file to store values like database connection information, and use a different configuration file for each environment. The \nheroes\n application needs to be able to configure the username, password, host port and name of the database it uses. Open the file \nconfig.yaml\n, which is empty, and enter the following key-value pairs:\n\n\ndatabase\n:\n\n  \nhost\n:\n \nlocalhost\n\n  \nport\n:\n \n5432\n\n  \nusername\n:\n \nheroes_user\n\n  \npassword\n:\n \npassword\n\n  \ndatabaseName\n:\n \nheroes\n\n\n\n\n\n\nThese are the same values we used in our application channel. We'll want to replace the hardcoded values with whatever values are in this file. In \nlib/channel.dart\n, declare a new class at the bottom of the file:\n\n\nclass\n \nHeroConfig\n \nextends\n \nConfiguration\n \n{\n\n  \nHeroConfig\n(\nString\n \npath\n)\n:\n \nsuper\n.\nfromFile\n(\nFile\n(\npath\n));\n\n\n  \nDatabaseConfiguration\n \ndatabase\n;\n\n\n}\n\n\n\n\n\n\nA \nConfiguration\n subclass declares the expected properties of a configuration file. \nHeroConfig\n has one property named \ndatabase\n - this matches the name of our top-level key in \nconfig.yaml\n. A \nDatabaseConfiguration\n is a built-in configuration type that has properties for \nhost\n, \nport\n, \nusername\n, \npassword\n and \ndatabaseName\n. We can load \nconfig.yaml\n into a \nHeroConfig\n because they have the same structure and all of the key names match the property names in our configuration types.\n\n\n\n\nInvalid Configuration\n\n\nIf your configuration file and configuration object don't have a matching structure, an error will be thrown when your application starts and tell you which values are missing.\n\n\n\n\nLet's load \nconfig.yaml\n and use its values to set up our database connection by replacing the \nprepare\n method in \nlib/channel.dart\n:\n\n\n@\noverride\n\n\nFuture\n \nprepare\n()\n \nasync\n \n{\n\n  \nlogger\n.\nonRecord\n.\nlisten\n(\n\n      \n(\nrec\n)\n \n=\n \nprint\n(\n$\nrec\n \n${\nrec\n.\nerror\n \n??\n \n}\n \n${\nrec\n.\nstackTrace\n \n??\n \n}\n));\n\n\n  \nfinal\n \nconfig\n \n=\n \nHeroConfig\n(\noptions\n.\nconfigurationFilePath\n);\n\n  \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n  \nfinal\n \npersistentStore\n \n=\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n      \nconfig\n.\ndatabase\n.\nusername\n,\n\n      \nconfig\n.\ndatabase\n.\npassword\n,\n\n      \nconfig\n.\ndatabase\n.\nhost\n,\n\n      \nconfig\n.\ndatabase\n.\nport\n,\n\n      \nconfig\n.\ndatabase\n.\ndatabaseName\n);\n\n\n  \ncontext\n \n=\n \nManagedContext\n(\ndataModel\n,\n \npersistentStore\n);\n\n\n}\n\n\n\n\n\n\nWhen our application starts, our channel has access to an \noptions\n property that has the command-line arguments that started the application. By default, the value of \nconfigurationFilePath\n is \nconfig.yaml\n (it corresponds to \n--config-path\n in \naqueduct serve\n). When \nconfig.yaml\n is read, its values are read into a \nHeroConfig\n and are used to configure our database connection.\n\n\nRe-run your application and it'll work exactly the same as it did before - except now, we can substitute databases depending on how we run the application.\n\n\nConfiguration Template\n\n\nYou shouldn't check \nconfig.yaml\n into version control because it contains sensitive information. However, it is important to check in a \nconfiguration source file\n. A configuration source file has the same structure as \nHeroConfig\n, but it has values for your test environment - both locally and with continuous integration tools. It is also used as a template for your deployed configuration files.\n\n\n\n\nSensitive Information\n\n\nUse a platform like Heroku or Kubernetes. You can store sensitive information in secured environment variables. You can substitute environment variables in a configuration file by using the variable's name with a \n$\n prefix as a value, e.g. \npassword: $DATABASE_PASSWORD\n.\n\n\n\n\nA configuration source file should be named \nconfig.src.yaml\n, and one currently exists as an empty file in your project. Enter the following configuration into this file:\n\n\ndatabase:\n\n  \nhost:\n \nlocalhost\n\n  \nport:\n \n5432\n\n  \nusername:\n \ndart\n\n  \npassword:\n \ndart\n\n  \ndatabaseName:\n \ndart_test\n\n\n\n\n\n\nThis file has the expected structure, but has different values for the database information (for a database that we will create shortly). In the next section, we'll use this configuration file to run our automated tests.\n\n\nTesting in Aqueduct\n\n\nSo far, we've tested our application by using a web application. This isn't a good way to test an application. A better way is to write automated test cases. An automated test case not only tests the code you are working on, but makes sure the code you've worked on in the past continues to work as you make changes. A good development practice is to configure \nTravisCI\n to run all of your tests for every code change.\n\n\nBecause testing is so important, there is a package for writing Aqueduct application tests. In this chapter, we will use this package to make sure our hero endpoints are working correctly.\n\n\n\n\npackage:aqueduct_test\n\n\nThe package \naqueduct_test\n and \ntest\n was already added to your \npubspec.yaml\n file as a test dependency by the template generator.\n\n\n\n\nIn all Dart applications, a test suite is a Dart script with a \nmain\n function. In this function, the \ntest\n function is called multiple times to register expectations. A test passes if all of your expectations are met. An example Dart test looks like this:\n\n\nimport\n \npackage:test/test.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \ntest\n(\n1+1 = 2\n,\n \n()\n \n{\n\n    \n// Expect that 1 + 1 = 2\n\n    \nexpect\n(\n1\n \n+\n \n1\n,\n \nequals\n(\n2\n));\n\n  \n});\n\n\n}\n\n\n\n\n\n\nSetting up your Development Environment\n\n\nIn \nconfig.src.yaml\n, we target the database \ndart:dart@localhost:5432/dart_test\n. This is a 'special' database that is used by all Aqueduct applications for automated testing (by default). When your application is tested, its tables are temporarily added to this database and then discarded after tests complete. This means that no data is stored in between test runs.\n\n\nCreate this database by running \npsql\n and enter the following SQL:\n\n\nCREATE\n \nDATABASE\n \ndart_test\n;\n\n\nCREATE\n \nUSER\n \ndart\n \nWITH\n \ncreatedb\n;\n\n\nALTER\n \nUSER\n \ndart\n \nWITH\n \npassword\n \ndart\n;\n\n\nGRANT\n \nall\n \nON\n \ndatabase\n \ndart_test\n \nTO\n \ndart\n;\n\n\n\n\n\n\n\n\ndart_test Database\n\n\nYou only have to create this database once per machine, and in any continuous integration scripts. All of your Aqueduct applications will use this database for automated testing. Fun fact - you can run multiple application's tests simultaneously using this database because the tables only exist for the database connection that created them.\n\n\n\n\nWriting Your First Test\n\n\nWe will create a test suite to make sure that all hero endpoints return the right data, and make the right changes. Create a new file named \ntest/hero_controller_test.dart\n.\n\n\n\n\nTest Files Names and Locations\n\n\nA test file must end in \n_test.dart\n and must be in the \ntest/\n directory of your project, or it won't be run.\n\n\n\n\nAt the top of this file, import your application's \ntest harness\n and enter the following \nmain\n function:\n\n\nimport\n \nharness/app.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nfinal\n \nharness\n \n=\n \nHarness\n()..\ninstall\n();\n\n\n}\n\n\n\n\n\n\nA test harness is an object that starts and stops your application when running a test suite, as long as you call its \ninstall\n method. This harness can then send requests to your application, and you can expect that the response is correct. Add a test to the main function that makes sure we get back a 200 OK when we call \nGET /heroes\n:\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nfinal\n \nharness\n \n=\n \nHarness\n()..\ninstall\n();\n\n\n  \ntest\n(\nGET /heroes returns 200 OK\n,\n \n()\n \nasync\n \n{\n\n    \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/heroes\n);\n\n    \nexpectResponse\n(\nresponse\n,\n \n200\n);\n\n  \n});\n\n\n}\n\n\n\n\n\n\nA harness has an \nAgent\n that can send requests to the application it started. Methods like \nget\n and \npost\n take a path (and optionally headers and a body) and return a response object. This object is used in \nexpectResponse\n to validate the status code and other values. Tests in Aqueduct are written in this way: make a request, expect that the response is intended.\n\n\nBecause our application makes database queries, we have to to upload our database schema to the test database before each test. Fortunately, this is something our test harness can also do. In \ntest/harness/app.dart\n, mixin \nTestHarnessORMMixin\n and override two methods:\n\n\nclass\n \nHarness\n \nextends\n \nTestHarness\nHeroesChannel\n \nwith\n \nTestHarnessORMMixin\n \n{\n\n  \n@\noverride\n\n  \nManagedContext\n \nget\n \ncontext\n \n=\n \nchannel\n.\ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nonSetUp\n()\n \nasync\n \n{\n\n    \nawait\n \nresetData\n();\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe mixin gives our harness the method \nresetData\n. This method deletes everything from the test database and uploads the schema in a pristine state. By calling this method in \nonSetUp\n, our test harness will reset data before each test.\n\n\n\n\nNew Project Templates\n\n\nUsing the \n-t\n command-line argument with \naqueduct create\n allows you to select a template. Templates like \ndb\n and \ndb_and_auth\n have a test harness that already mixes in \nTestHarnessORMMixin\n.\n\n\n\n\nNow, we can run this test by right-clicking on the \nmain\n function in \nhero_controller_test.dart\n and selecting \nRun tests in 'hero_controller_test.dart'\n. A panel will appear that shows the results of your tests. You'll see a green checkmark next to the test in this panel to show that your test succeeded. If your test did not succeed, the reason will be printed to the console. If your test failed because of an error in your code, you will also be able to see the stack trace of the error.\n\n\n\n\nRunning Tests\n\n\nYou can also run all of your tests for an application by running \npub run test\n from your project's directory. You can re-run a test with the green play button at the top right corner of the screen, or the keyboard shortcut associated with it (this shortcut varies depending on your installation).\n\n\n\n\nWe should expect that more than just the status code is correct. Let's verify that the body is a list, where every element is an object that contains an id and name. Update your test:\n\n\ntest\n(\nGET /heroes returns 200 OK\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/heroes\n);\n\n  \nexpectResponse\n(\nresponse\n,\n \n200\n,\n \nbody:\n \neveryElement\n({\n\n    \nid\n:\n \ngreaterThan\n(\n0\n),\n\n    \nname\n:\n \nisString\n,\n\n  \n}));\n\n\n});\n\n\n\n\n\n\nThis expectation ensures that the body is a list and that every element is an object with a \nid\n greater than 0, and a \nname\n that is a string. When expecting a body value, the body is first decoded from its content-type before the expectation. In practice, this means that your JSON response body is deserialized into an object or list. Your expectations of the body are built from Dart objects like \nList\n and \nObject\n that deserialized from JSON.\n\n\n\n\nMatchers\n\n\nThe function \neveryElement\n is a \nMatcher\n from \npackage:matcher\n. There are many types of matchers for all kinds of scenarios, and \npackage:aqueduct_test\n includes Aqueduct-specific matchers. See the \naqueduct_test API Reference\n for all Aqueduct matchers.\n\n\n\n\nThis test actually has an error that we will fix in it by using another matcher. Right now, this endpoint returns an \nempty list\n because there are no heroes in the database! Let's insert a hero before we make this request, and also expect that there is at least one element in the body. Make sure to import \nhero.dart\n at the top of the file!\n\n\nimport\n \npackage:heroes/model/hero.dart\n;\n\n\n\nimport\n \nharness/app.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nfinal\n \nharness\n \n=\n \nHarness\n()..\ninstall\n();\n\n\n  \ntest\n(\nGET /heroes returns 200 OK\n,\n \n()\n \nasync\n \n{\n\n    \nfinal\n \nquery\n \n=\n \nQuery\nHero\n(\nharness\n.\napplication\n.\nchannel\n.\ncontext\n)\n\n      \n..\nvalues\n.\nname\n \n=\n \nBob\n;\n\n\n    \nawait\n \nquery\n.\ninsert\n();\n\n\n    \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/heroes\n);\n\n    \nexpectResponse\n(\nresponse\n,\n \n200\n,\n\n        \nbody:\n \nallOf\n([\n\n          \nhasLength\n(\ngreaterThan\n(\n0\n)),\n\n          \neveryElement\n({\n\n            \nid\n:\n \ngreaterThan\n(\n0\n),\n\n            \nname\n:\n \nisString\n,\n\n          \n})\n\n        \n]));\n\n  \n});\n\n\n}\n\n\n\n\n\n\nThis test first inserts a hero named 'Bob' before getting all heroes. We compose a matcher where each element has to match the expected list, but also have a length greater than 0. Re-run your tests, and they should still pass.\n\n\nWriting More Tests\n\n\nLet's write a few more tests for when we \nPOST /heroes\n. In the first test, we'll make a mistake on purpose to see how tests fail. Add the following test:\n\n\ntest\n(\nPOST /heroes returns 200 OK\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\npost\n(\n/heroes\n,\n \nbody:\n \n{\n\n    \nname\n:\n \nFred\n\n  \n});\n\n  \nexpectResponse\n(\nresponse\n,\n \n200\n,\n \nbody:\n \n{\n\n    \nid\n:\n \ngreaterThan\n(\n0\n),\n\n    \nname\n:\n \nBob\n\n  \n});\n\n\n});\n\n\n\n\n\n\nThis test creates a hero named 'Fred', but expects that the returned hero has the name 'Bob'. When we run the test, we see this test failure:\n\n\nExpected\n:\n \n---\n \nHTTP\n \nResponse\n \n---\n\n          \n-\n \nStatus\n \ncode\n \nmust\n \nbe\n \n200\n\n          \n-\n \nHeaders\n \ncan\n \nbe\n \nanything\n\n          \n-\n \nBody\n \nafter\n \ndecoding\n \nmust\n \nbe\n:\n\n\n            \n{\nid\n:\n \na\n \nvalue\n \ngreater\n \nthan\n \n0\n,\n \nname\n:\n \nBob\n}\n\n          \n---------------------\n\n  \nActual\n:\n \nTestResponse\n:\n-----------\n\n          \n-\n \nStatus\n \ncode\n \nis\n \n200\n\n          \n-\n \nHeaders\n \nare\n \nthe\n \nfollowing\n:\n\n            \n-\n \ncontent-encoding\n:\n \ngzip\n\n            \n-\n \ncontent-length\n:\n \n42\n\n            \n-\n \nx-frame-options\n:\n \nSAMEORIGIN\n\n            \n-\n \ncontent-type\n:\n \napplication\n/\njson\n;\n \ncharset\n=\nutf-8\n\n            \n-\n \nx-xss-protection\n:\n \n1\n;\n \nmode\n=\nblock\n\n            \n-\n \nx-content-type-options\n:\n \nnosniff\n\n            \n-\n \nserver\n:\n \naqueduct\n/\n1\n\n          \nDecoded\n \nbody\n \nis\n:\n\n          \n{\nid\n:\n \n1\n,\n \nname\n:\n \nFred\n}\n\n          \n-------------------------\n\n          \n\n   \nWhich\n:\n \nthe\n \nbody\n \ndiffers\n \nfor\n \nthe\n \nfollowing\n \nreasons\n:\n\n          \nwas\n \nFred\n \ninstead\n \nof\n \nBob\n \nat\n \nlocation\n \n[\nname\n]\n\n\n\n\n\n\nThe 'Expected' value tells us the response we expected - that it has a status code of 200, any headers and the body must have a certain structure. The 'Actual' value tells us what the actual response was - a 200 OK, a bunch of headers, and a body a hero named 'Fred'. 'Which' tells us exactly what went wrong - we were expecting 'Bob', not 'Fred'. Let's update our test to expect 'Fred'.\n\n\ntest\n(\nPOST /heroes returns 200 OK\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\npost\n(\n/heroes\n,\n \nbody:\n \n{\n\n    \nname\n:\n \nFred\n\n  \n});\n\n  \nexpectResponse\n(\nresponse\n,\n \n200\n,\n \nbody:\n \n{\n\n    \nid\n:\n \ngreaterThan\n(\n0\n),\n\n    \nname\n:\n \nFred\n\n  \n});\n\n\n});\n\n\n\n\n\n\nWe shouldn't just test success cases. Let's also expect that if we try and insert a hero with the same name, we get a 409 error response.\n\n\ntest\n(\nPOST /heroes returns 200 OK\n,\n \n()\n \nasync\n \n{\n\n  \nawait\n \nharness\n.\nagent\n.\npost\n(\n/heroes\n,\n \nbody:\n \n{\n\n    \nname\n:\n \nFred\n\n  \n});\n\n\n  \nfinal\n \nbadResponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\npost\n(\n/heroes\n,\n \nbody:\n \n{\n\n    \nname\n:\n \nFred\n\n  \n});\n\n  \nexpectResponse\n(\nbadResponse\n,\n \n409\n);\n\n\n});\n\n\n\n\n\n\nIn this test, we request two 'Fred' heroes be created, and the second request fails with a 409 because \nname\n is a unique property of a hero. Notice that the first request didn't fail, even though we had created a 'Fred' hero in the previous test - that's because we reset the database for each test in our harness.\n\n\nNext Chapter: Authentication and Authorization", 
            "title": "4. Configuration and Testing"
        }, 
        {
            "location": "/tut/writing-tests/#4-configuration-and-writing-tests", 
            "text": "We will continue to build on the last chapter's project,  heroes , by writing automated tests for it. We will also set up configurable environments for our application.", 
            "title": "4. Configuration and Writing Tests"
        }, 
        {
            "location": "/tut/writing-tests/#application-configuration", 
            "text": "Right now, our application hardcodes its database connection information. This is bad because we want to use a different database when we're testing, running locally and running in production. It's also bad because we'd have to check our database password into version control.  We can create a configuration file to store values like database connection information, and use a different configuration file for each environment. The  heroes  application needs to be able to configure the username, password, host port and name of the database it uses. Open the file  config.yaml , which is empty, and enter the following key-value pairs:  database : \n   host :   localhost \n   port :   5432 \n   username :   heroes_user \n   password :   password \n   databaseName :   heroes   These are the same values we used in our application channel. We'll want to replace the hardcoded values with whatever values are in this file. In  lib/channel.dart , declare a new class at the bottom of the file:  class   HeroConfig   extends   Configuration   { \n   HeroConfig ( String   path ) :   super . fromFile ( File ( path )); \n\n   DatabaseConfiguration   database ;  }   A  Configuration  subclass declares the expected properties of a configuration file.  HeroConfig  has one property named  database  - this matches the name of our top-level key in  config.yaml . A  DatabaseConfiguration  is a built-in configuration type that has properties for  host ,  port ,  username ,  password  and  databaseName . We can load  config.yaml  into a  HeroConfig  because they have the same structure and all of the key names match the property names in our configuration types.   Invalid Configuration  If your configuration file and configuration object don't have a matching structure, an error will be thrown when your application starts and tell you which values are missing.   Let's load  config.yaml  and use its values to set up our database connection by replacing the  prepare  method in  lib/channel.dart :  @ override  Future   prepare ()   async   { \n   logger . onRecord . listen ( \n       ( rec )   =   print ( $ rec   ${ rec . error   ??   }   ${ rec . stackTrace   ??   } )); \n\n   final   config   =   HeroConfig ( options . configurationFilePath ); \n   final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n   final   persistentStore   =   PostgreSQLPersistentStore . fromConnectionInfo ( \n       config . database . username , \n       config . database . password , \n       config . database . host , \n       config . database . port , \n       config . database . databaseName ); \n\n   context   =   ManagedContext ( dataModel ,   persistentStore );  }   When our application starts, our channel has access to an  options  property that has the command-line arguments that started the application. By default, the value of  configurationFilePath  is  config.yaml  (it corresponds to  --config-path  in  aqueduct serve ). When  config.yaml  is read, its values are read into a  HeroConfig  and are used to configure our database connection.  Re-run your application and it'll work exactly the same as it did before - except now, we can substitute databases depending on how we run the application.", 
            "title": "Application Configuration"
        }, 
        {
            "location": "/tut/writing-tests/#configuration-template", 
            "text": "You shouldn't check  config.yaml  into version control because it contains sensitive information. However, it is important to check in a  configuration source file . A configuration source file has the same structure as  HeroConfig , but it has values for your test environment - both locally and with continuous integration tools. It is also used as a template for your deployed configuration files.   Sensitive Information  Use a platform like Heroku or Kubernetes. You can store sensitive information in secured environment variables. You can substitute environment variables in a configuration file by using the variable's name with a  $  prefix as a value, e.g.  password: $DATABASE_PASSWORD .   A configuration source file should be named  config.src.yaml , and one currently exists as an empty file in your project. Enter the following configuration into this file:  database: \n   host:   localhost \n   port:   5432 \n   username:   dart \n   password:   dart \n   databaseName:   dart_test   This file has the expected structure, but has different values for the database information (for a database that we will create shortly). In the next section, we'll use this configuration file to run our automated tests.", 
            "title": "Configuration Template"
        }, 
        {
            "location": "/tut/writing-tests/#testing-in-aqueduct", 
            "text": "So far, we've tested our application by using a web application. This isn't a good way to test an application. A better way is to write automated test cases. An automated test case not only tests the code you are working on, but makes sure the code you've worked on in the past continues to work as you make changes. A good development practice is to configure  TravisCI  to run all of your tests for every code change.  Because testing is so important, there is a package for writing Aqueduct application tests. In this chapter, we will use this package to make sure our hero endpoints are working correctly.   package:aqueduct_test  The package  aqueduct_test  and  test  was already added to your  pubspec.yaml  file as a test dependency by the template generator.   In all Dart applications, a test suite is a Dart script with a  main  function. In this function, the  test  function is called multiple times to register expectations. A test passes if all of your expectations are met. An example Dart test looks like this:  import   package:test/test.dart ;  void   main ()   { \n   test ( 1+1 = 2 ,   ()   { \n     // Expect that 1 + 1 = 2 \n     expect ( 1   +   1 ,   equals ( 2 )); \n   });  }", 
            "title": "Testing in Aqueduct"
        }, 
        {
            "location": "/tut/writing-tests/#setting-up-your-development-environment", 
            "text": "In  config.src.yaml , we target the database  dart:dart@localhost:5432/dart_test . This is a 'special' database that is used by all Aqueduct applications for automated testing (by default). When your application is tested, its tables are temporarily added to this database and then discarded after tests complete. This means that no data is stored in between test runs.  Create this database by running  psql  and enter the following SQL:  CREATE   DATABASE   dart_test ;  CREATE   USER   dart   WITH   createdb ;  ALTER   USER   dart   WITH   password   dart ;  GRANT   all   ON   database   dart_test   TO   dart ;    dart_test Database  You only have to create this database once per machine, and in any continuous integration scripts. All of your Aqueduct applications will use this database for automated testing. Fun fact - you can run multiple application's tests simultaneously using this database because the tables only exist for the database connection that created them.", 
            "title": "Setting up your Development Environment"
        }, 
        {
            "location": "/tut/writing-tests/#writing-your-first-test", 
            "text": "We will create a test suite to make sure that all hero endpoints return the right data, and make the right changes. Create a new file named  test/hero_controller_test.dart .   Test Files Names and Locations  A test file must end in  _test.dart  and must be in the  test/  directory of your project, or it won't be run.   At the top of this file, import your application's  test harness  and enter the following  main  function:  import   harness/app.dart ;  void   main ()   { \n   final   harness   =   Harness ().. install ();  }   A test harness is an object that starts and stops your application when running a test suite, as long as you call its  install  method. This harness can then send requests to your application, and you can expect that the response is correct. Add a test to the main function that makes sure we get back a 200 OK when we call  GET /heroes :  void   main ()   { \n   final   harness   =   Harness ().. install (); \n\n   test ( GET /heroes returns 200 OK ,   ()   async   { \n     final   response   =   await   harness . agent . get ( /heroes ); \n     expectResponse ( response ,   200 ); \n   });  }   A harness has an  Agent  that can send requests to the application it started. Methods like  get  and  post  take a path (and optionally headers and a body) and return a response object. This object is used in  expectResponse  to validate the status code and other values. Tests in Aqueduct are written in this way: make a request, expect that the response is intended.  Because our application makes database queries, we have to to upload our database schema to the test database before each test. Fortunately, this is something our test harness can also do. In  test/harness/app.dart , mixin  TestHarnessORMMixin  and override two methods:  class   Harness   extends   TestHarness HeroesChannel   with   TestHarnessORMMixin   { \n   @ override \n   ManagedContext   get   context   =   channel . context ; \n\n   @ override \n   Future   onSetUp ()   async   { \n     await   resetData (); \n   }  }   The mixin gives our harness the method  resetData . This method deletes everything from the test database and uploads the schema in a pristine state. By calling this method in  onSetUp , our test harness will reset data before each test.   New Project Templates  Using the  -t  command-line argument with  aqueduct create  allows you to select a template. Templates like  db  and  db_and_auth  have a test harness that already mixes in  TestHarnessORMMixin .   Now, we can run this test by right-clicking on the  main  function in  hero_controller_test.dart  and selecting  Run tests in 'hero_controller_test.dart' . A panel will appear that shows the results of your tests. You'll see a green checkmark next to the test in this panel to show that your test succeeded. If your test did not succeed, the reason will be printed to the console. If your test failed because of an error in your code, you will also be able to see the stack trace of the error.   Running Tests  You can also run all of your tests for an application by running  pub run test  from your project's directory. You can re-run a test with the green play button at the top right corner of the screen, or the keyboard shortcut associated with it (this shortcut varies depending on your installation).   We should expect that more than just the status code is correct. Let's verify that the body is a list, where every element is an object that contains an id and name. Update your test:  test ( GET /heroes returns 200 OK ,   ()   async   { \n   final   response   =   await   harness . agent . get ( /heroes ); \n   expectResponse ( response ,   200 ,   body:   everyElement ({ \n     id :   greaterThan ( 0 ), \n     name :   isString , \n   }));  });   This expectation ensures that the body is a list and that every element is an object with a  id  greater than 0, and a  name  that is a string. When expecting a body value, the body is first decoded from its content-type before the expectation. In practice, this means that your JSON response body is deserialized into an object or list. Your expectations of the body are built from Dart objects like  List  and  Object  that deserialized from JSON.   Matchers  The function  everyElement  is a  Matcher  from  package:matcher . There are many types of matchers for all kinds of scenarios, and  package:aqueduct_test  includes Aqueduct-specific matchers. See the  aqueduct_test API Reference  for all Aqueduct matchers.   This test actually has an error that we will fix in it by using another matcher. Right now, this endpoint returns an  empty list  because there are no heroes in the database! Let's insert a hero before we make this request, and also expect that there is at least one element in the body. Make sure to import  hero.dart  at the top of the file!  import   package:heroes/model/hero.dart ;  import   harness/app.dart ;  void   main ()   { \n   final   harness   =   Harness ().. install (); \n\n   test ( GET /heroes returns 200 OK ,   ()   async   { \n     final   query   =   Query Hero ( harness . application . channel . context ) \n       .. values . name   =   Bob ; \n\n     await   query . insert (); \n\n     final   response   =   await   harness . agent . get ( /heroes ); \n     expectResponse ( response ,   200 , \n         body:   allOf ([ \n           hasLength ( greaterThan ( 0 )), \n           everyElement ({ \n             id :   greaterThan ( 0 ), \n             name :   isString , \n           }) \n         ])); \n   });  }   This test first inserts a hero named 'Bob' before getting all heroes. We compose a matcher where each element has to match the expected list, but also have a length greater than 0. Re-run your tests, and they should still pass.", 
            "title": "Writing Your First Test"
        }, 
        {
            "location": "/tut/writing-tests/#writing-more-tests", 
            "text": "Let's write a few more tests for when we  POST /heroes . In the first test, we'll make a mistake on purpose to see how tests fail. Add the following test:  test ( POST /heroes returns 200 OK ,   ()   async   { \n   final   response   =   await   harness . agent . post ( /heroes ,   body:   { \n     name :   Fred \n   }); \n   expectResponse ( response ,   200 ,   body:   { \n     id :   greaterThan ( 0 ), \n     name :   Bob \n   });  });   This test creates a hero named 'Fred', but expects that the returned hero has the name 'Bob'. When we run the test, we see this test failure:  Expected :   ---   HTTP   Response   --- \n           -   Status   code   must   be   200 \n           -   Headers   can   be   anything \n           -   Body   after   decoding   must   be : \n\n             { id :   a   value   greater   than   0 ,   name :   Bob } \n           --------------------- \n   Actual :   TestResponse : ----------- \n           -   Status   code   is   200 \n           -   Headers   are   the   following : \n             -   content-encoding :   gzip \n             -   content-length :   42 \n             -   x-frame-options :   SAMEORIGIN \n             -   content-type :   application / json ;   charset = utf-8 \n             -   x-xss-protection :   1 ;   mode = block \n             -   x-content-type-options :   nosniff \n             -   server :   aqueduct / 1 \n           Decoded   body   is : \n           { id :   1 ,   name :   Fred } \n           ------------------------- \n           \n    Which :   the   body   differs   for   the   following   reasons : \n           was   Fred   instead   of   Bob   at   location   [ name ]   The 'Expected' value tells us the response we expected - that it has a status code of 200, any headers and the body must have a certain structure. The 'Actual' value tells us what the actual response was - a 200 OK, a bunch of headers, and a body a hero named 'Fred'. 'Which' tells us exactly what went wrong - we were expecting 'Bob', not 'Fred'. Let's update our test to expect 'Fred'.  test ( POST /heroes returns 200 OK ,   ()   async   { \n   final   response   =   await   harness . agent . post ( /heroes ,   body:   { \n     name :   Fred \n   }); \n   expectResponse ( response ,   200 ,   body:   { \n     id :   greaterThan ( 0 ), \n     name :   Fred \n   });  });   We shouldn't just test success cases. Let's also expect that if we try and insert a hero with the same name, we get a 409 error response.  test ( POST /heroes returns 200 OK ,   ()   async   { \n   await   harness . agent . post ( /heroes ,   body:   { \n     name :   Fred \n   }); \n\n   final   badResponse   =   await   harness . agent . post ( /heroes ,   body:   { \n     name :   Fred \n   }); \n   expectResponse ( badResponse ,   409 );  });   In this test, we request two 'Fred' heroes be created, and the second request fails with a 409 because  name  is a unique property of a hero. Notice that the first request didn't fail, even though we had created a 'Fred' hero in the previous test - that's because we reset the database for each test in our harness.", 
            "title": "Writing More Tests"
        }, 
        {
            "location": "/tut/writing-tests/#next-chapter-authentication-and-authorization", 
            "text": "", 
            "title": "Next Chapter: Authentication and Authorization"
        }, 
        {
            "location": "/tut/oauth2/", 
            "text": "5. Adding Authentication and Authorization with OAuth 2.0\n\n\nOur \nheroes\n application lets anyone create or view the same set of heroes. We will continue to build on the last chapter's project, \nheroes\n, requiring a user to log in before viewing or creating heroes.\n\n\n\n\nWe're Done With the Browser App\n\n\nWe're at the point now where using the browser application to test our Aqueduct app gets a bit cumbersome. From here on out, we'll use \ncurl\n, \naqueduct document client\n and tests.\n\n\n\n\nThe Basics of OAuth 2.0\n\n\nOAuth 2.0\n is an authorization framework that also contains guidance on authentication. Authentication is the process of proving you are a particular user, typically through a username and password. Authorization is the process of ensuring that a user can access a particular resource or collection of resources. In our application, a user will have to be authenticated before being authorized to view or create heroes.\n\n\nIn a simple authentication and authorization scheme, each HTTP request contains the username and password (credentials) of the user in an \nAuthorization\n header. There are a number of security risks involved in doing this, so OAuth 2.0 takes another approach: you send your credentials once, and get a 'access token' in return. You then send this access token in each request. Because the server grants the token, it knows that you've already entered your credentials (you've \nauthenticated\n) and it remembers who the token belongs to. It's effectively the same thing as sending your credentials each time, except that the token has a time limit and can be revoked when things go wrong.\n\n\nAqueduct has a built-in OAuth 2.0 implementation that leverages the ORM. This implementation is part of the \naqueduct\n package, but it is a separate library named \naqueduct/managed_auth\n. It takes a few steps to set up that might be difficult to understand if you are not familiar with OAuth 2.0, but you'll get a well-tested, secure authorization implementation.\n\n\n\n\nAlternative Implementations\n\n\nUsing \npackage:aqueduct/managed_auth\n is preferable in most cases. In some cases, you may wish to store authorization information in different database system or use token formats like \nJWT\n. This is a complex topic that requires significant testing efforts, and is outside the scope of this tutorial.\n\n\n\n\nSetting up OAuth 2.0: Creating a User Type\n\n\nOur application needs some concept of a 'user' - a person who logs into the application to manage heroes. This user will have a username and password. In a later exercise, a user will also have a list of heroes that belong to them. Create a new file \nmodel/user.dart\n and enter the following code:\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\nimport\n \npackage:heroes/heroes.dart\n;\n\n\nimport\n \npackage:heroes/model/hero.dart\n;\n\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n,\n \nManagedAuthResourceOwner\n_User\n \n{}\n\n\n\nclass\n \n_User\n \nextends\n \nResourceOwnerTableDefinition\n \n{}\n\n\n\n\n\n\nThe imported library \npackage:aqueduct/managed_auth.dart\n contains types that use the ORM to store users, tokens and other OAuth 2.0 related data. One of those types is \nResourceOwnerTableDefinition\n, the superclass of our user's table definition. This type contains all of the required fields that Aqueduct needs to implement authentication.\n\n\n\n\nResource Owners\n\n\nA \nresource owner\n is a more general term for a 'user' that comes from the OAuth 2.0 specification. In the framework, you'll see types and variables using some variant of \nresource owner\n, but for all intents and purposes, you can consider this a 'user'.\n\n\n\n\nIf you are curious, \nResourceOwnerTableDefinition\n looks like this:\n\n\nclass\n \nResourceOwnerTableDefinition\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\nunique:\n \ntrue\n,\n \nindexed:\n \ntrue\n)\n\n  \nString\n \nusername\n;\n\n\n  \n@\nColumn\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nhashedPassword\n;\n\n\n  \n@\nColumn\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nsalt\n;\n\n\n  \nManagedSet\nManagedAuthToken\n \ntokens\n;\n\n\n}\n\n\n\n\n\n\nBecause these fields are in \nUser\n's table definition, our \nUser\n table has all of these database columns.\n\n\n\n\nManagedAuthResourceOwner\n\n\nNote that \nUser\n implements \nManagedAuthResourceOwner\n_User\n - this is a requirement of any OAuth 2.0 resource owner type when using \npackage:aqueduct/managed_auth\n.\n\n\n\n\nSetting up OAuth 2.0: AuthServer and its Delegate\n\n\nNow that we have a user, we need some way to create new users and authenticate them. Authentication is fairly tricky, especially in OAuth 2.0, so there is a service object that does the hard part for us called an \nAuthServer\n. This type has all of the logic needed to authentication and authorize users. For example, an \nAuthServer\n can generate a new token if given valid user credentials.\n\n\nIn \nchannel.dart\n, add the following imports to the top of your file:\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\nimport\n \npackage:heroes/model/user.dart\n;\n\n\n\n\n\n\nThen, declare a new \nauthServer\n property in your channel and initialize it in \nprepare\n:\n\n\nclass\n \nHeroesChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n// Add this field\n\n  \nAuthServer\n \nauthServer\n;\n\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nlogger\n.\nonRecord\n.\nlisten\n((\nrec\n)\n \n=\n \nprint\n(\n$\nrec\n \n${\nrec\n.\nerror\n \n??\n \n}\n \n${\nrec\n.\nstackTrace\n \n??\n \n}\n));\n\n\n    \nfinal\n \nconfig\n \n=\n \nHeroConfig\n(\noptions\n.\nconfigurationFilePath\n);\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npersistentStore\n \n=\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n      \nconfig\n.\ndatabase\n.\nusername\n,\n\n      \nconfig\n.\ndatabase\n.\npassword\n,\n\n      \nconfig\n.\ndatabase\n.\nhost\n,\n\n      \nconfig\n.\ndatabase\n.\nport\n,\n\n      \nconfig\n.\ndatabase\n.\ndatabaseName\n);\n\n\n    \ncontext\n \n=\n \nManagedContext\n(\ndataModel\n,\n \npersistentStore\n);\n\n\n    \n// Add these two lines:\n\n    \nfinal\n \nauthStorage\n \n=\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nAuthServer\n(\nauthStorage\n);\n\n  \n}\n\n  \n...\n\n\n\n\n\n\nWhile an \nAuthServer\n handles the logic of authentication and authorization, it doesn't know how to store or fetch the data it uses for those tasks. Instead, it relies on a \ndelegate\n object to handle storing and fetching data from a database. In our application, we use \nManagedAuthDelegate\nT\n - from \npackage:aqueduct/managed_auth\n - as the delegate. This type uses the ORM for these tasks; the type argument must be our application's user object.\n\n\n\n\nDelegation\n\n\nDelegation is a design pattern where an object has multiple callbacks that are grouped into an interface. Instead of defining a closure for each callback, a type implements methods that get called by the delegating object. It is a way of organizing large amounts of related callbacks into a tidy class.\n\n\n\n\nBy importing \naqueduct/managed_auth\n, we've added a few more managed objects to our application (to store tokens and other authentication data) and we also have a new \nUser\n managed object. It's a good time to run a database migration. From your project directory, run the following commands:\n\n\naqueduct db generate\naqueduct db upgrade --connect postgres://heroes_user:password@localhost:5432/heroes\n\n\n\n\n\nSetting up OAuth 2.0: Registering Users\n\n\nNow that we have the concept of a user, our database and application are set up to handle authentication, we can start creating new users. Let's create a new controller for registering users. This controller will accept \nPOST\n requests that contain a username and password in the body. It will insert a new user into the database and securely hash the user's password.\n\n\nBefore we create this controller, there is something we need to consider: our registration endpoint will require the user's password, but we store the user's password as a cryptographic hash. This prevents someone with access to your database from knowing a user's password. In order to bind the body of a request to a \nUser\n object, it needs a password field, but we don't want to store the password in the database without first hashing it.\n\n\nWe can accomplish this with \ntransient properties\n. A transient property is a property of a managed object that isn't stored in the database. They are declared in the managed object subclass instead of the table definition. By default, a transient property is not read from a request body or encoded into a response body; unless we add the \nSerialize\n annotation to it. Add this property to your \nUser\n type:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n,\n \nManagedAuthResourceOwner\n_User\n \n{\n\n  \n@\nSerialize\n(\ninput:\n \ntrue\n,\n \noutput:\n \nfalse\n)\n\n  \nString\n \npassword\n;\n\n\n}\n\n\n\n\n\n\nThis declares that a \nUser\n has a transient property \npassword\n that can be read on input (from a request body), but is not sent on output (to a response body). We don't have to run a database migration because transient properties are not stored in a database.\n\n\nNow, create the file \ncontroller/register_controller.dart\n and enter the following code:\n\n\nimport\n \ndart:async\n;\n\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:heroes/model/user.dart\n;\n\n\n\nclass\n \nRegisterController\n \nextends\n \nResourceController\n \n{\n\n  \nRegisterController\n(\nthis\n.\ncontext\n,\n \nthis\n.\nauthServer\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n\n  \nfinal\n \nAuthServer\n \nauthServer\n;\n\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \ncreateUser\n(\n@\nBind\n.\nbody\n()\n \nUser\n \nuser\n)\n \nasync\n \n{\n\n    \n// Check for required parameters before we spend time hashing\n\n    \nif\n \n(\nuser\n.\nusername\n \n==\n \nnull\n \n||\n \nuser\n.\npassword\n \n==\n \nnull\n)\n \n{\n\n      \nreturn\n \nResponse\n.\nbadRequest\n(\n\n        \nbody:\n \n{\nerror\n:\n \nusername and password required.\n});\n\n    \n}\n\n\n    \nuser\n\n      \n..\nsalt\n \n=\n \nAuthUtility\n.\ngenerateRandomSalt\n()\n\n      \n..\nhashedPassword\n \n=\n \nauthServer\n.\nhashPassword\n(\nuser\n.\npassword\n,\n \nuser\n.\nsalt\n);\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \nQuery\n(\ncontext\n,\n \nvalues:\n \nuser\n).\ninsert\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis controller takes POST requests that contain a user. A user has many fields (username, password, hashedPassword, salt), but we will calculate the latter two and only require that the request contain the first two. The controller generates a salt and hash of the password before storing it in the database. In \nchannel.dart\n, let's link this controller - don't forget to import it!\n\n\nimport\n \npackage:heroes/controller/register_controller.dart\n;\n\n\n\n...\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/heroes/[:id]\n)\n\n      \n.\nlink\n(()\n \n=\n \nHeroesController\n(\ncontext\n));\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/register\n)\n\n      \n.\nlink\n(()\n \n=\n \nRegisterController\n(\ncontext\n,\n \nauthServer\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n    \n\n\n\n\n\nLet's run the application and create a new user using \ncurl\n from the command-line. (We'll specify \n-n1\n to designate using one isolate and speed up startup.)\n\n\naqueduct serve -n1\n\n\n\n\n\nThen, issue a request to your server:\n\n\ncurl\n \n-\nX\n \nPOST\n \nhttp:\n//localhost:8888/register -H \nContent-Type: application/json\n -d \n{\nusername\n:\nbob\n, \npassword\n:\npassword\n}\n\n\n\n\n\n\nYou'll get back the new user object and its username:\n\n\n{\nid\n:1,\nusername\n:\nbob\n}\n\n\n\n\n\nSetting up OAuth 2.0: Authenticating Users\n\n\nNow that we have a user with a password, we can create an endpoint that takes user credentials and returns an access token. The good news is that this controller already exists in Aqueduct, you just have to hook it up to a route. Update \nentryPoint\n in \nchannel.dart\n to add an \nAuthController\n for the route \n/auth/token\n:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \n// add this route\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/token\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/heroes/[:id]\n)\n\n    \n.\nlink\n(()\n \n=\n \nHeroesController\n(\ncontext\n));\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/register\n)\n\n    \n.\nlink\n(()\n \n=\n \nRegisterController\n(\ncontext\n,\n \nauthServer\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nAn \nAuthController\n follows the OAuth 2.0 specification for granting access tokens when given valid user credentials. To understand how a request to this endpoint must be structured, we need to discuss OAuth 2.0 \nclients\n. In OAuth 2.0, a client is an application that is allowed to access your server on behalf of a user. A client can be a browser application, a mobile application, another server, a voice assistant, etc. A client always has an identifier string, typically something like 'com.stablekernel.account_app.mobile'.\n\n\nWhen authenticating, a user is always authenticated through a client. This client information must be attached to every authentication request, and the server must validate that the client had been previously registered. Therefore, we need to register a new client for our application. A client is stored in our application's database using the \naqueduct auth add-client\n CLI. Run the following command from your project directory:\n\n\naqueduct auth add-client --id com.heroes.tutorial --connect postgres://heroes_user:password@localhost:5432/heroes\n\n\n\n\n\n\n\nOAuth 2.0 Clients\n\n\nA client must have an identifier, but it may also have a secret, redirect URI and list of allowed scopes. See the \nguides on OAuth 2.0\n for how these options impacts authentication. Most notably, a client identifier must have a secret to issue a \nrefresh token\n. Clients are stored in an application's database.\n\n\n\n\nThis will insert a new row into an OAuth 2.0 client table created by our last round of database migration and allow us to make authentication requests. An authentication request must meet all of the following criteria:\n\n\n\n\nthe client identifier (and secret, if it exists) are included as a basic \nAuthorization\n header.\n\n\nthe username and password are included in the request body\n\n\nthe key-value \ngrant_type=password\n is included in the request body\n\n\nthe request body content-type is \napplication/x-www-form-urlencoded\n; this means the request body is effectively a query string (e.g. \nusername=bob\npassword=pw\ngrant_type=password\n)\n\n\n\n\nIn Dart code, this would look like this:\n\n\nimport\n \ndart:async\n;\n\n\nimport\n \ndart:convert\n;\n\n\n\nimport\n \npackage:http/http.dart\n\n    \nas\n \nhttp\n;\n \n// Must include http: any package in your pubspec.yaml\n\n\n\nFuture\nvoid\n \nmain\n()\n \nasync\n \n{\n\n  \nconst\n \nclientID\n \n=\n \norg.hasenbalg.zeiterfassung\n;\n\n  \nconst\n \nbody\n \n=\n \nusername=bob\npassword=password\ngrant_type=password\n;\n\n\n\n// Note the trailing colon (:) after the clientID.\n\n\n// A client identifier secret would follow this, but there is no secret, so it is the empty string.\n\n  \nfinal\n \nString\n \nclientCredentials\n \n=\n\n      \nconst\n \nBase64Encoder\n().\nconvert\n(\n$\nclientID\n:\n.\ncodeUnits\n);\n\n\n  \nfinal\n \nhttp\n.\nResponse\n \nresponse\n \n=\n\n      \nawait\n \nhttp\n.\npost\n(\nhttp://localhost:8888/auth/token\n,\n\n          \nheaders:\n \n{\n\n            \nContent-Type\n:\n \napplication/x-www-form-urlencoded\n,\n\n            \nAuthorization\n:\n \nBasic \n$\nclientCredentials\n\n          \n},\n\n          \nbody:\n \nbody\n);\n\n  \nprint\n(\nresponse\n.\nbody\n);\n\n\n}\n\n\n\n\n\n\nYou can execute that code or you can use the following \ncurl\n:\n\n\ncurl -X POST http://localhost:8888/auth/token -H \nAuthorization: Basic Y29tLmhlcm9lcy50dXRvcmlhbDo=\n -H \nContent-Type: application/x-www-form-urlencoded\n -d \nusername=bob\npassword=password\ngrant_type=password\n\n\n\n\n\n\nIf you were successful, you'll get the following response containing an access token:\n\n\n{\naccess_token\n:\n687PWKFHRTQ9MveQ2dKvP95D4cWie1gh\n,\ntoken_type\n:\nbearer\n,\nexpires_in\n:86399}\n\n\n\n\n\nHang on to this access token, we'll use it in a moment.\n\n\nSetting up OAuth 2.0: Securing Routes\n\n\nNow that we can create and authenticate users, we can protect our heroes from anonymous users by requiring an access token for hero requests. In \nchannel.dart\n, link an \nAuthorizer\n in the middle of the \n/heroes\n channel:\n\n\nrouter\n\n  \n.\nroute\n(\n/heroes/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n  \n.\nlink\n(()\n \n=\n \nHeroesController\n(\ncontext\n));\n\n\n\n\n\n\nAn \nAuthorizer\n protects a channel from unauthorized requests by validating the \nAuthorization\n header of a request. When created with \nAuthorizer.bearer\n, it ensures that the authorization header contains a valid access token. Restart your application and try and access the \n/heroes\n endpoint without including any authorization:\n\n\ncurl -X GET --verbose http://localhost:8888/heroes\n\n\n\n\n\nYou'll get a 401 Unauthorized response. Now, include your access token in a bearer authorization header (note that your token will be different):\n\n\ncurl -X GET http://localhost:8888/heroes -H \nAuthorization: Bearer 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh\n\n\n\n\n\n\nYou'll get back your list of heroes!\n\n\n\n\nOther Uses of Authorizer\n\n\nAn \nAuthorizer\n can validate access token scopes and basic authorization credentials. You'll see examples of these in a later exercise.", 
            "title": "5. Authentication and Authorization"
        }, 
        {
            "location": "/tut/oauth2/#5-adding-authentication-and-authorization-with-oauth-20", 
            "text": "Our  heroes  application lets anyone create or view the same set of heroes. We will continue to build on the last chapter's project,  heroes , requiring a user to log in before viewing or creating heroes.   We're Done With the Browser App  We're at the point now where using the browser application to test our Aqueduct app gets a bit cumbersome. From here on out, we'll use  curl ,  aqueduct document client  and tests.", 
            "title": "5. Adding Authentication and Authorization with OAuth 2.0"
        }, 
        {
            "location": "/tut/oauth2/#the-basics-of-oauth-20", 
            "text": "OAuth 2.0  is an authorization framework that also contains guidance on authentication. Authentication is the process of proving you are a particular user, typically through a username and password. Authorization is the process of ensuring that a user can access a particular resource or collection of resources. In our application, a user will have to be authenticated before being authorized to view or create heroes.  In a simple authentication and authorization scheme, each HTTP request contains the username and password (credentials) of the user in an  Authorization  header. There are a number of security risks involved in doing this, so OAuth 2.0 takes another approach: you send your credentials once, and get a 'access token' in return. You then send this access token in each request. Because the server grants the token, it knows that you've already entered your credentials (you've  authenticated ) and it remembers who the token belongs to. It's effectively the same thing as sending your credentials each time, except that the token has a time limit and can be revoked when things go wrong.  Aqueduct has a built-in OAuth 2.0 implementation that leverages the ORM. This implementation is part of the  aqueduct  package, but it is a separate library named  aqueduct/managed_auth . It takes a few steps to set up that might be difficult to understand if you are not familiar with OAuth 2.0, but you'll get a well-tested, secure authorization implementation.   Alternative Implementations  Using  package:aqueduct/managed_auth  is preferable in most cases. In some cases, you may wish to store authorization information in different database system or use token formats like  JWT . This is a complex topic that requires significant testing efforts, and is outside the scope of this tutorial.", 
            "title": "The Basics of OAuth 2.0"
        }, 
        {
            "location": "/tut/oauth2/#setting-up-oauth-20-creating-a-user-type", 
            "text": "Our application needs some concept of a 'user' - a person who logs into the application to manage heroes. This user will have a username and password. In a later exercise, a user will also have a list of heroes that belong to them. Create a new file  model/user.dart  and enter the following code:  import   package:aqueduct/managed_auth.dart ;  import   package:heroes/heroes.dart ;  import   package:heroes/model/hero.dart ;  class   User   extends   ManagedObject _User   implements   _User ,   ManagedAuthResourceOwner _User   {}  class   _User   extends   ResourceOwnerTableDefinition   {}   The imported library  package:aqueduct/managed_auth.dart  contains types that use the ORM to store users, tokens and other OAuth 2.0 related data. One of those types is  ResourceOwnerTableDefinition , the superclass of our user's table definition. This type contains all of the required fields that Aqueduct needs to implement authentication.   Resource Owners  A  resource owner  is a more general term for a 'user' that comes from the OAuth 2.0 specification. In the framework, you'll see types and variables using some variant of  resource owner , but for all intents and purposes, you can consider this a 'user'.   If you are curious,  ResourceOwnerTableDefinition  looks like this:  class   ResourceOwnerTableDefinition   { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( unique:   true ,   indexed:   true ) \n   String   username ; \n\n   @ Column ( omitByDefault:   true ) \n   String   hashedPassword ; \n\n   @ Column ( omitByDefault:   true ) \n   String   salt ; \n\n   ManagedSet ManagedAuthToken   tokens ;  }   Because these fields are in  User 's table definition, our  User  table has all of these database columns.   ManagedAuthResourceOwner  Note that  User  implements  ManagedAuthResourceOwner _User  - this is a requirement of any OAuth 2.0 resource owner type when using  package:aqueduct/managed_auth .", 
            "title": "Setting up OAuth 2.0: Creating a User Type"
        }, 
        {
            "location": "/tut/oauth2/#setting-up-oauth-20-authserver-and-its-delegate", 
            "text": "Now that we have a user, we need some way to create new users and authenticate them. Authentication is fairly tricky, especially in OAuth 2.0, so there is a service object that does the hard part for us called an  AuthServer . This type has all of the logic needed to authentication and authorize users. For example, an  AuthServer  can generate a new token if given valid user credentials.  In  channel.dart , add the following imports to the top of your file:  import   package:aqueduct/managed_auth.dart ;  import   package:heroes/model/user.dart ;   Then, declare a new  authServer  property in your channel and initialize it in  prepare :  class   HeroesChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   // Add this field \n   AuthServer   authServer ; \n\n   Future   prepare ()   async   { \n     logger . onRecord . listen (( rec )   =   print ( $ rec   ${ rec . error   ??   }   ${ rec . stackTrace   ??   } )); \n\n     final   config   =   HeroConfig ( options . configurationFilePath ); \n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   persistentStore   =   PostgreSQLPersistentStore . fromConnectionInfo ( \n       config . database . username , \n       config . database . password , \n       config . database . host , \n       config . database . port , \n       config . database . databaseName ); \n\n     context   =   ManagedContext ( dataModel ,   persistentStore ); \n\n     // Add these two lines: \n     final   authStorage   =   ManagedAuthDelegate User ( context ); \n     authServer   =   AuthServer ( authStorage ); \n   } \n   ...   While an  AuthServer  handles the logic of authentication and authorization, it doesn't know how to store or fetch the data it uses for those tasks. Instead, it relies on a  delegate  object to handle storing and fetching data from a database. In our application, we use  ManagedAuthDelegate T  - from  package:aqueduct/managed_auth  - as the delegate. This type uses the ORM for these tasks; the type argument must be our application's user object.   Delegation  Delegation is a design pattern where an object has multiple callbacks that are grouped into an interface. Instead of defining a closure for each callback, a type implements methods that get called by the delegating object. It is a way of organizing large amounts of related callbacks into a tidy class.   By importing  aqueduct/managed_auth , we've added a few more managed objects to our application (to store tokens and other authentication data) and we also have a new  User  managed object. It's a good time to run a database migration. From your project directory, run the following commands:  aqueduct db generate\naqueduct db upgrade --connect postgres://heroes_user:password@localhost:5432/heroes", 
            "title": "Setting up OAuth 2.0: AuthServer and its Delegate"
        }, 
        {
            "location": "/tut/oauth2/#setting-up-oauth-20-registering-users", 
            "text": "Now that we have the concept of a user, our database and application are set up to handle authentication, we can start creating new users. Let's create a new controller for registering users. This controller will accept  POST  requests that contain a username and password in the body. It will insert a new user into the database and securely hash the user's password.  Before we create this controller, there is something we need to consider: our registration endpoint will require the user's password, but we store the user's password as a cryptographic hash. This prevents someone with access to your database from knowing a user's password. In order to bind the body of a request to a  User  object, it needs a password field, but we don't want to store the password in the database without first hashing it.  We can accomplish this with  transient properties . A transient property is a property of a managed object that isn't stored in the database. They are declared in the managed object subclass instead of the table definition. By default, a transient property is not read from a request body or encoded into a response body; unless we add the  Serialize  annotation to it. Add this property to your  User  type:  class   User   extends   ManagedObject _User   implements   _User ,   ManagedAuthResourceOwner _User   { \n   @ Serialize ( input:   true ,   output:   false ) \n   String   password ;  }   This declares that a  User  has a transient property  password  that can be read on input (from a request body), but is not sent on output (to a response body). We don't have to run a database migration because transient properties are not stored in a database.  Now, create the file  controller/register_controller.dart  and enter the following code:  import   dart:async ;  import   package:aqueduct/aqueduct.dart ;  import   package:heroes/model/user.dart ;  class   RegisterController   extends   ResourceController   { \n   RegisterController ( this . context ,   this . authServer ); \n\n   final   ManagedContext   context ; \n   final   AuthServer   authServer ; \n\n   @ Operation . post () \n   Future Response   createUser ( @ Bind . body ()   User   user )   async   { \n     // Check for required parameters before we spend time hashing \n     if   ( user . username   ==   null   ||   user . password   ==   null )   { \n       return   Response . badRequest ( \n         body:   { error :   username and password required. }); \n     } \n\n     user \n       .. salt   =   AuthUtility . generateRandomSalt () \n       .. hashedPassword   =   authServer . hashPassword ( user . password ,   user . salt ); \n\n     return   Response . ok ( await   Query ( context ,   values:   user ). insert ()); \n   }  }   This controller takes POST requests that contain a user. A user has many fields (username, password, hashedPassword, salt), but we will calculate the latter two and only require that the request contain the first two. The controller generates a salt and hash of the password before storing it in the database. In  channel.dart , let's link this controller - don't forget to import it!  import   package:heroes/controller/register_controller.dart ;  ... \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router \n       . route ( /heroes/[:id] ) \n       . link (()   =   HeroesController ( context )); \n\n     router \n       . route ( /register ) \n       . link (()   =   RegisterController ( context ,   authServer )); \n\n     return   router ; \n   }  }       Let's run the application and create a new user using  curl  from the command-line. (We'll specify  -n1  to designate using one isolate and speed up startup.)  aqueduct serve -n1  Then, issue a request to your server:  curl   - X   POST   http: //localhost:8888/register -H  Content-Type: application/json  -d  { username : bob ,  password : password }   You'll get back the new user object and its username:  { id :1, username : bob }", 
            "title": "Setting up OAuth 2.0: Registering Users"
        }, 
        {
            "location": "/tut/oauth2/#setting-up-oauth-20-authenticating-users", 
            "text": "Now that we have a user with a password, we can create an endpoint that takes user credentials and returns an access token. The good news is that this controller already exists in Aqueduct, you just have to hook it up to a route. Update  entryPoint  in  channel.dart  to add an  AuthController  for the route  /auth/token :  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   // add this route \n   router \n     . route ( /auth/token ) \n     . link (()   =   AuthController ( authServer )); \n\n   router \n     . route ( /heroes/[:id] ) \n     . link (()   =   HeroesController ( context )); \n\n   router \n     . route ( /register ) \n     . link (()   =   RegisterController ( context ,   authServer )); \n\n   return   router ;  }   An  AuthController  follows the OAuth 2.0 specification for granting access tokens when given valid user credentials. To understand how a request to this endpoint must be structured, we need to discuss OAuth 2.0  clients . In OAuth 2.0, a client is an application that is allowed to access your server on behalf of a user. A client can be a browser application, a mobile application, another server, a voice assistant, etc. A client always has an identifier string, typically something like 'com.stablekernel.account_app.mobile'.  When authenticating, a user is always authenticated through a client. This client information must be attached to every authentication request, and the server must validate that the client had been previously registered. Therefore, we need to register a new client for our application. A client is stored in our application's database using the  aqueduct auth add-client  CLI. Run the following command from your project directory:  aqueduct auth add-client --id com.heroes.tutorial --connect postgres://heroes_user:password@localhost:5432/heroes   OAuth 2.0 Clients  A client must have an identifier, but it may also have a secret, redirect URI and list of allowed scopes. See the  guides on OAuth 2.0  for how these options impacts authentication. Most notably, a client identifier must have a secret to issue a  refresh token . Clients are stored in an application's database.   This will insert a new row into an OAuth 2.0 client table created by our last round of database migration and allow us to make authentication requests. An authentication request must meet all of the following criteria:   the client identifier (and secret, if it exists) are included as a basic  Authorization  header.  the username and password are included in the request body  the key-value  grant_type=password  is included in the request body  the request body content-type is  application/x-www-form-urlencoded ; this means the request body is effectively a query string (e.g.  username=bob password=pw grant_type=password )   In Dart code, this would look like this:  import   dart:async ;  import   dart:convert ;  import   package:http/http.dart \n     as   http ;   // Must include http: any package in your pubspec.yaml  Future void   main ()   async   { \n   const   clientID   =   org.hasenbalg.zeiterfassung ; \n   const   body   =   username=bob password=password grant_type=password ;  // Note the trailing colon (:) after the clientID.  // A client identifier secret would follow this, but there is no secret, so it is the empty string. \n   final   String   clientCredentials   = \n       const   Base64Encoder (). convert ( $ clientID : . codeUnits ); \n\n   final   http . Response   response   = \n       await   http . post ( http://localhost:8888/auth/token , \n           headers:   { \n             Content-Type :   application/x-www-form-urlencoded , \n             Authorization :   Basic  $ clientCredentials \n           }, \n           body:   body ); \n   print ( response . body );  }   You can execute that code or you can use the following  curl :  curl -X POST http://localhost:8888/auth/token -H  Authorization: Basic Y29tLmhlcm9lcy50dXRvcmlhbDo=  -H  Content-Type: application/x-www-form-urlencoded  -d  username=bob password=password grant_type=password   If you were successful, you'll get the following response containing an access token:  { access_token : 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh , token_type : bearer , expires_in :86399}  Hang on to this access token, we'll use it in a moment.", 
            "title": "Setting up OAuth 2.0: Authenticating Users"
        }, 
        {
            "location": "/tut/oauth2/#setting-up-oauth-20-securing-routes", 
            "text": "Now that we can create and authenticate users, we can protect our heroes from anonymous users by requiring an access token for hero requests. In  channel.dart , link an  Authorizer  in the middle of the  /heroes  channel:  router \n   . route ( /heroes/[:id] ) \n   . link (()   =   Authorizer . bearer ( authServer )) \n   . link (()   =   HeroesController ( context ));   An  Authorizer  protects a channel from unauthorized requests by validating the  Authorization  header of a request. When created with  Authorizer.bearer , it ensures that the authorization header contains a valid access token. Restart your application and try and access the  /heroes  endpoint without including any authorization:  curl -X GET --verbose http://localhost:8888/heroes  You'll get a 401 Unauthorized response. Now, include your access token in a bearer authorization header (note that your token will be different):  curl -X GET http://localhost:8888/heroes -H  Authorization: Bearer 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh   You'll get back your list of heroes!   Other Uses of Authorizer  An  Authorizer  can validate access token scopes and basic authorization credentials. You'll see examples of these in a later exercise.", 
            "title": "Setting up OAuth 2.0: Securing Routes"
        }, 
        {
            "location": "/application/", 
            "text": "Tasks\n\n\nAn Aqueduct application starts an HTTP server and invokes your code for each request. The code that is invoked might depend on the request's path, method, and other attributes. For example, the request \nGET /heroes\n will invoke different code than \nPOST /authors\n. You configure which code is invoked in an \nApplicationChannel\n subclass; every application declares exactly one \nApplicationChannel\n subclass.\n\n\nThis subclass also sets up services, reads configuration data from files and environment variables and performs any other initialization for your application. For example, an application channel often reads database connection information from environment variables and then sets up a connection to that database.\n\n\nAqueduct applications create multiple threads, and each thread takes turn handling incoming requests. Your application channel subclass is created for each thread, creating replica instances of your application.\n\n\nGuides\n\n\n\n\nStarting and Stopping Applications\n\n\nConfiguring an Application and its Environment\n\n\nApplication and Project Structure\n\n\nPerformance: Multi-threading", 
            "title": "Overview"
        }, 
        {
            "location": "/application/#tasks", 
            "text": "An Aqueduct application starts an HTTP server and invokes your code for each request. The code that is invoked might depend on the request's path, method, and other attributes. For example, the request  GET /heroes  will invoke different code than  POST /authors . You configure which code is invoked in an  ApplicationChannel  subclass; every application declares exactly one  ApplicationChannel  subclass.  This subclass also sets up services, reads configuration data from files and environment variables and performs any other initialization for your application. For example, an application channel often reads database connection information from environment variables and then sets up a connection to that database.  Aqueduct applications create multiple threads, and each thread takes turn handling incoming requests. Your application channel subclass is created for each thread, creating replica instances of your application.", 
            "title": "Tasks"
        }, 
        {
            "location": "/application/#guides", 
            "text": "Starting and Stopping Applications  Configuring an Application and its Environment  Application and Project Structure  Performance: Multi-threading", 
            "title": "Guides"
        }, 
        {
            "location": "/application/channel/", 
            "text": "Starting and Stopping an Application\n\n\nLearn how an application is initialized so it can serve requests.\n\n\nOverview\n\n\nApplications are started by running \naqueduct serve\n or \ndart bin/main.script\n in an Aqueduct project directory. Either way, a number of threads are created and your \nApplicationChannel\n subclass is instantiated on each thread. The channel subclass initializes application behavior which is often the following:\n\n\n\n\nreads configuration data for environment specific setup\n\n\ninitializes service objects like \ndatabase connections\n\n\nsets up \ncontroller\n objects to handle requests\n\n\n\n\nInitializing ApplicationChannel Controllers\n\n\nEach application channel has an \nentry point\n - a controller that handles all incoming requests. This controller is often a router that routes requests to an appropriate handler. Every controller that will be used in the application is linked to either the entry point in some way. Here's an example:\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/users\n)\n\n      \n.\nlink\n(()\n \n=\n \nAuthorizer\n())\n\n      \n.\nlink\n(()\n \n=\n \nUserController\n());\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis method links together a \nRouter\n -\n \nAuthorizer\n -\n \nUserController\n. Because the router is returned from this method, it handles all incoming requests. It will pass a request to an \nAuthorizer\n when the request path is \n/users\n, which will then pass that request to a \nUserController\n if it is authorized.\n\n\nAll controllers in your application will be linked to the entry point, either directly or indirectly.\n\n\n\n\nLinking Controllers\n\n\nThe \nlink()\n method takes a closure that creates a new controller. Some controllers get instantiated for each request, and others get reused for every request. See \nthe chapter on controllers\n for more information.\n\n\n\n\nInitializing Service Objects\n\n\nControllers often need to get (or create) information from outside the application. The most common example is database access, but it could be anything: another REST API, a connected device, etc. A \nservice object\n encapsulates the information and behavior needed to work with an external system. This separation of concerns between controllers and service objects allows for better structured and more testable code.\n\n\nService objects are instantiated by overriding \nApplicationChannel.prepare\n.\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nPostgreSQLConnection\n \ndatabase\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ndatabase\n \n=\n \nPostgreSQLConnection\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/users\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n())\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nUserController\n(\ndatabase\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis methods gets invoked before \nentryPoint\n. You store created services in instance variables so that you can inject them into controllers in \nentryPoint\n. Services are injected through a controller's constructor arguments. For example, the above shows a \ndatabase\n service that is injected into \nUserController\n.\n\n\nApplication Channel Configuration\n\n\nA benefit to using service objects is that they can be altered depending on the environment the application is running in without requiring changes to code. For example, the database an application will connect to will be different when running in production than when running tests.\n\n\nBesides service configuration, there may be other types of initialization an application wants to take. Common tasks include adding codecs to \nCodecRegistry\n or setting the default \nCORSPolicy\n. All of this initialization is done in \nprepare()\n.\n\n\nSome of the information needed to configure an application will come from a configuration file or environment variables. For more information on using a configuration file and environment variables to guide initialization, see \nthis guide\n.\n\n\nMulti-threaded Aqueduct Applications\n\n\nAqueduct applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called \nisolates\n. An instance of your \nApplicationChannel\n is created for each isolate. When your application receives an HTTP request, the request is passed to one of these instances' entry points. These instances are replicas of one another and it doesn't matter which instance processes the request. This isolate-channel architecture is very similar to running multiple servers that run the same application.\n\n\nThe number of isolates an application will use is configurable at startup when using the \naqueduct serve\n command.\n\n\nAn isolate can't share memory with another isolate. If an object is created on one isolate, it \ncannot\n be referenced by another. Therefore, each \nApplicationChannel\n instance has its own set of services that are configured in the same way. This behavior also makes design patterns like connection pooling implicit; instead of a pool of database connections, there is a pool of application channels that each have their own database connection.\n\n\nThis architecture intentionally prevents you from keeping state in your application. When you scale to multiple servers, you can trust that your cluster works correctly because you are already effectively clustering on a single server node. For further reading on writing multi-threaded applications, see \nthis guide\n.\n\n\nInitialization Callbacks\n\n\nBoth \nprepare()\n and \nentryPoint\n are part of the initialization process of an application channel. Most applications only ever need these two methods. Another method, that is rarely used, is \nwillStartReceivingRequests()\n. This method is called after \nprepare()\n and \nentryPoint\n have been executed, and right before your application will start receiving requests.\n\n\nThese three initialization callbacks are called once per isolate to initialize the channel running on that isolate. For initialization that should only occur \nonce per application start\n (regardless of how many isolates are running), an \nApplicationChannel\n subclass can implement a static method named \ninitializeApplication()\n.\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationOptions\n \noptions\n)\n \nasync\n \n{\n\n    \n...\n \ndo\n \none\n \ntime\n \nsetup\n \n...\n\n  \n}\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nThis method is invoked before any \nApplicationChannel\n instances are created. Any changes made to \noptions\n will be available in each \nApplicationChannel\n's \noptions\n property.\n\n\nFor example:\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n\n  \nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationOptions\n \noptions\n)\n \nasync\n \n{\n        \n    \noptions\n.\ncontext\n[\nspecial item\n]\n \n=\n \nxyz\n;\n\n  \n}\n  \n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \nparsedConfigValues\n \n=\n \noptions\n.\ncontext\n[\nspecial item\n];\n \n// == xyz\n\n    \n...\n\n  \n}\n\n\n}\n\n\n\n\n\n\nEach isolate has its own heap. \ninitializeApplication\n is executed in the main isolate, whereas each \nApplicationChannel\n is instantiated in its own isolate. This means that any values stored in \nApplicationOptions\n must be safe to pass across isolates - i.e., they can't contain references to closures.\n\n\nAdditionally, any global variables or static properties that are set in the main isolate \nwill not be set\n in other isolates. Configuration types like \nCodecRegistry\n do not share values across isolates, because they use a static property to hold a reference to the repository of codecs. Therefore, they must be set up in \nApplicationChannel.prepare()\n.\n\n\nAlso, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of \ninitializeApplication\n exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately.\n\n\nApplication Channel File\n\n\nAn \nApplicationChannel\n subclass is most often declared in its own file named \nlib/channel.dart\n. This file must be exported from the application library file. For example, if the application is named \nwildfire\n, the application library file is \nlib/wildfire.dart\n. Here is a sample directory structure:\n\n\nwildfire/\n  lib/\n    wildfire.dart\n    channel.dart\n    controllers/\n      user_controller.dart      \n    ...\n\n\n\n\n\nSee \nthis guide\n for more details on how an Aqueduct application's files are structured.\n\n\nLazy Services\n\n\nMany service objects will establish a persistent network connection. A network connection can sometimes be interrupted and have to re-establish itself. If these connections are only opened when the application first starts, the application will not be able to reopen these connections without restarting the application. This would be very bad.\n\n\nFor that reason, services should manage their own connectivity behavior. For example, a database connection should connect it when it is asked to execute a query. If it already has a valid connection, it will go ahead and execute the query. Otherwise, it will establish the connection and then execute the query. The caller doesn't care - it gets a \nFuture\n with the desired result.\n\n\nThe pseudo-code looks something like this:\n\n\nFuture\n \nexecute\n(\nString\n \nsql\n)\n \nasync\n \n{\n\n  \nif\n \n(\nconnection\n \n==\n \nnull\n \n||\n \n!\nconnection\n.\nisAvailable\n)\n \n{\n\n    \nconnection\n \n=\n \nnew\n \nConnection\n(...);\n\n    \nawait\n \nconnection\n.\nopen\n();\n\n  \n}\n\n\n  \nreturn\n \nconnection\n.\nexecuteSQL\n(\nsql\n);\n\n\n}\n\n\n\n\n\n\nThe Application Object\n\n\nHidden in all of this discussion is the \nApplication\nT\n object. Because the \naqueduct serve\n command manages creating an \nApplication\nT\n instance, your code rarely concerns itself with this type.\n\n\nAn \nApplication\nT\n is the top-level object in an Aqueduct application; it sets up HTTP listeners and directs requests to \nApplicationChannel\ns. The \nApplication\nT\n itself is just a generic container for \nApplicationChannel\ns; it doesn't do much other than kick everything off.\n\n\nThe application's \nstart\n method will initialize at least one instance of the application's \nApplicationChannel\n. If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a \nApplicationChannel\n subclass would trigger this type of startup exception.\n\n\nAn \nApplication\nT\n has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the channel's \noptions\n property, an instance of \nApplicationOptions\n.", 
            "title": "Starting and Stopping Applications"
        }, 
        {
            "location": "/application/channel/#starting-and-stopping-an-application", 
            "text": "Learn how an application is initialized so it can serve requests.", 
            "title": "Starting and Stopping an Application"
        }, 
        {
            "location": "/application/channel/#overview", 
            "text": "Applications are started by running  aqueduct serve  or  dart bin/main.script  in an Aqueduct project directory. Either way, a number of threads are created and your  ApplicationChannel  subclass is instantiated on each thread. The channel subclass initializes application behavior which is often the following:   reads configuration data for environment specific setup  initializes service objects like  database connections  sets up  controller  objects to handle requests", 
            "title": "Overview"
        }, 
        {
            "location": "/application/channel/#initializing-applicationchannel-controllers", 
            "text": "Each application channel has an  entry point  - a controller that handles all incoming requests. This controller is often a router that routes requests to an appropriate handler. Every controller that will be used in the application is linked to either the entry point in some way. Here's an example:  class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /users ) \n       . link (()   =   Authorizer ()) \n       . link (()   =   UserController ()); \n\n     return   router ; \n   }  }   This method links together a  Router  -   Authorizer  -   UserController . Because the router is returned from this method, it handles all incoming requests. It will pass a request to an  Authorizer  when the request path is  /users , which will then pass that request to a  UserController  if it is authorized.  All controllers in your application will be linked to the entry point, either directly or indirectly.   Linking Controllers  The  link()  method takes a closure that creates a new controller. Some controllers get instantiated for each request, and others get reused for every request. See  the chapter on controllers  for more information.", 
            "title": "Initializing ApplicationChannel Controllers"
        }, 
        {
            "location": "/application/channel/#initializing-service-objects", 
            "text": "Controllers often need to get (or create) information from outside the application. The most common example is database access, but it could be anything: another REST API, a connected device, etc. A  service object  encapsulates the information and behavior needed to work with an external system. This separation of concerns between controllers and service objects allows for better structured and more testable code.  Service objects are instantiated by overriding  ApplicationChannel.prepare .  class   AppChannel   extends   ApplicationChannel   { \n   PostgreSQLConnection   database ; \n\n   @ override \n   Future   prepare ()   async   { \n     database   =   PostgreSQLConnection (); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /users ) \n       . link (()   =   new   Authorizer ()) \n       . link (()   =   new   UserController ( database )); \n\n     return   router ; \n   }  }   This methods gets invoked before  entryPoint . You store created services in instance variables so that you can inject them into controllers in  entryPoint . Services are injected through a controller's constructor arguments. For example, the above shows a  database  service that is injected into  UserController .", 
            "title": "Initializing Service Objects"
        }, 
        {
            "location": "/application/channel/#application-channel-configuration", 
            "text": "A benefit to using service objects is that they can be altered depending on the environment the application is running in without requiring changes to code. For example, the database an application will connect to will be different when running in production than when running tests.  Besides service configuration, there may be other types of initialization an application wants to take. Common tasks include adding codecs to  CodecRegistry  or setting the default  CORSPolicy . All of this initialization is done in  prepare() .  Some of the information needed to configure an application will come from a configuration file or environment variables. For more information on using a configuration file and environment variables to guide initialization, see  this guide .", 
            "title": "Application Channel Configuration"
        }, 
        {
            "location": "/application/channel/#multi-threaded-aqueduct-applications", 
            "text": "Aqueduct applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called  isolates . An instance of your  ApplicationChannel  is created for each isolate. When your application receives an HTTP request, the request is passed to one of these instances' entry points. These instances are replicas of one another and it doesn't matter which instance processes the request. This isolate-channel architecture is very similar to running multiple servers that run the same application.  The number of isolates an application will use is configurable at startup when using the  aqueduct serve  command.  An isolate can't share memory with another isolate. If an object is created on one isolate, it  cannot  be referenced by another. Therefore, each  ApplicationChannel  instance has its own set of services that are configured in the same way. This behavior also makes design patterns like connection pooling implicit; instead of a pool of database connections, there is a pool of application channels that each have their own database connection.  This architecture intentionally prevents you from keeping state in your application. When you scale to multiple servers, you can trust that your cluster works correctly because you are already effectively clustering on a single server node. For further reading on writing multi-threaded applications, see  this guide .", 
            "title": "Multi-threaded Aqueduct Applications"
        }, 
        {
            "location": "/application/channel/#initialization-callbacks", 
            "text": "Both  prepare()  and  entryPoint  are part of the initialization process of an application channel. Most applications only ever need these two methods. Another method, that is rarely used, is  willStartReceivingRequests() . This method is called after  prepare()  and  entryPoint  have been executed, and right before your application will start receiving requests.  These three initialization callbacks are called once per isolate to initialize the channel running on that isolate. For initialization that should only occur  once per application start  (regardless of how many isolates are running), an  ApplicationChannel  subclass can implement a static method named  initializeApplication() .  class   AppChannel   extends   ApplicationChannel   { \n   static   Future   initializeApplication ( ApplicationOptions   options )   async   { \n     ...   do   one   time   setup   ... \n   } \n\n   ...  }   This method is invoked before any  ApplicationChannel  instances are created. Any changes made to  options  will be available in each  ApplicationChannel 's  options  property.  For example:  class   AppChannel   extends   ApplicationChannel   { \n\n   static   Future   initializeApplication ( ApplicationOptions   options )   async   {         \n     options . context [ special item ]   =   xyz ; \n   }   \n\n   Future   prepare ()   async   { \n     var   parsedConfigValues   =   options . context [ special item ];   // == xyz \n     ... \n   }  }   Each isolate has its own heap.  initializeApplication  is executed in the main isolate, whereas each  ApplicationChannel  is instantiated in its own isolate. This means that any values stored in  ApplicationOptions  must be safe to pass across isolates - i.e., they can't contain references to closures.  Additionally, any global variables or static properties that are set in the main isolate  will not be set  in other isolates. Configuration types like  CodecRegistry  do not share values across isolates, because they use a static property to hold a reference to the repository of codecs. Therefore, they must be set up in  ApplicationChannel.prepare() .  Also, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of  initializeApplication  exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately.", 
            "title": "Initialization Callbacks"
        }, 
        {
            "location": "/application/channel/#application-channel-file", 
            "text": "An  ApplicationChannel  subclass is most often declared in its own file named  lib/channel.dart . This file must be exported from the application library file. For example, if the application is named  wildfire , the application library file is  lib/wildfire.dart . Here is a sample directory structure:  wildfire/\n  lib/\n    wildfire.dart\n    channel.dart\n    controllers/\n      user_controller.dart      \n    ...  See  this guide  for more details on how an Aqueduct application's files are structured.", 
            "title": "Application Channel File"
        }, 
        {
            "location": "/application/channel/#lazy-services", 
            "text": "Many service objects will establish a persistent network connection. A network connection can sometimes be interrupted and have to re-establish itself. If these connections are only opened when the application first starts, the application will not be able to reopen these connections without restarting the application. This would be very bad.  For that reason, services should manage their own connectivity behavior. For example, a database connection should connect it when it is asked to execute a query. If it already has a valid connection, it will go ahead and execute the query. Otherwise, it will establish the connection and then execute the query. The caller doesn't care - it gets a  Future  with the desired result.  The pseudo-code looks something like this:  Future   execute ( String   sql )   async   { \n   if   ( connection   ==   null   ||   ! connection . isAvailable )   { \n     connection   =   new   Connection (...); \n     await   connection . open (); \n   } \n\n   return   connection . executeSQL ( sql );  }", 
            "title": "Lazy Services"
        }, 
        {
            "location": "/application/channel/#the-application-object", 
            "text": "Hidden in all of this discussion is the  Application T  object. Because the  aqueduct serve  command manages creating an  Application T  instance, your code rarely concerns itself with this type.  An  Application T  is the top-level object in an Aqueduct application; it sets up HTTP listeners and directs requests to  ApplicationChannel s. The  Application T  itself is just a generic container for  ApplicationChannel s; it doesn't do much other than kick everything off.  The application's  start  method will initialize at least one instance of the application's  ApplicationChannel . If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a  ApplicationChannel  subclass would trigger this type of startup exception.  An  Application T  has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the channel's  options  property, an instance of  ApplicationOptions .", 
            "title": "The Application Object"
        }, 
        {
            "location": "/application/configure/", 
            "text": "Configuring an Application and its Environment\n\n\nThis guide covers configuring an Aqueduct application.\n\n\nConfiguration Files\n\n\nAqueduct applications use YAML configuration files to provide environment-specific values like database connection information. Use separate configuration files for testing and different deployment environments.\n\n\nThe path of a configuration file is available to an \nApplicationChannel\n through its \noptions\n property.\n\n\nclass\n \nTodoAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \nconfig\n \n=\n \nTodoConfiguration\n(\noptions\n.\nconfigurationFilePath\n);\n\n    \n...\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe default value is \nconfig.yaml\n.\n\n\nThe best practice for reading a configuration file is to subclass \nConfiguration\n. A \nConfiguration\n declares a property for each key in a configuration file. For example, see the following \nConfiguration\n subclass:\n\n\nclass\n \nTodoConfiguration\n \nextends\n \nConfiguration\n \n{\n\n  \nTodoConfiguration\n(\nString\n \nfileName\n)\n \n:\n \nsuper\n.\nfromFile\n(\nFile\n(\nfileName\n));\n\n\n  \nDatabaseConnectionConfiguration\n \ndatabase\n;\n\n  \nString\n \napiBaseURL\n;\n\n\n  \n@\noptionalConfiguration\n\n  \nint\n \nidentifier\n;\n\n\n}\n\n\n\n\n\n\nThis would read a YAML file like this:\n\n\ndatabase\n:\n\n  \nusername\n:\n \nfred\n\n  \npassword\n:\n \nfredspassword\n\n  \nhost\n:\n \ndb\n.\nmyapp\n.\ncom\n\n  \nport\n:\n \n5432\n\n  \ndatabaseName\n:\n \nfredsdb\n\n\napiBaseURL\n:\n \n/\napi\n\n\nidentifier\n:\n \n2\n\n\n\n\n\n\nIf required properties are omitted from the YAML file being read, application startup will fail and throw an informative error.\n\n\nEnvironment Variables\n\n\nA configuration file can use an environment variable instead of a literal value. In \nconfig.yaml\n, use a \n$\n-prefixed environment variable name instead of a value:\n\n\ndatabase: $DATABASE_CONNECTION_URL\napiBaseURL: /api\n\n\n\n\n\nIf the environment variable \nDATABASE_CONNECTION_URL\n's value were \n\"postgres://user:password@localhost:5432/test\"\n, the value of \nTodoConfiguration.database\n will be that string at runtime.\n\n\nThe \nsafe_config package\n has instructions for more additional usages.\n\n\nConfiguration Conventions and Deployment Options\n\n\nAqueduct uses two configuration files for a project: \nconfig.yaml\n and \nconfig.src.yaml\n. The latter is the \nconfiguration source file\n. The configuration source file declares key-value pairs that will be used when running the application tests. Deployed instances use \nconfig.yaml\n.\n\n\nThis pattern is used for two reasons:\n\n\n\n\nIt is the template for the \nconfig.yaml\n that will be read on deployed applications, providing documentation for your application's configuration.\n\n\nIt has the configuration values used during testing to inject mock dependencies.\n\n\n\n\nFor example, a production API instance might have the following \nconfig.yaml\n file with connection info for a production database:\n\n\ndatabase\n:\n \npostgres\n://\napp_user\n:\n$\n%\n4\njlkn\n#\nan\n*\n@\nmOZkea2\n@\nsomedns\n.\nname\n.\ncom\n:\n5432\n/\nproduction_db\n\n\n\n\n\n\nWhereas \nconfig.src.yaml\n would have connection info for a local, test database:\n\n\ndatabase\n:\n \npostgres\n://\ntest\n:\ntest\n@\nlocalhost\n:\n5432\n/\ntemporary_db\n\n\n\n\n\n\nThe source configuration file should be checked into version control. Whether or not \nconfig.yaml\n is checked in depends on how you are deploying your code. If you are using environment variables to control application configuration, you should check \nconfig.yaml\n into source control and provide \n$\n-prefixed environment variable values. If you are using managing configuration files on each deployed instance, do not check \nconfig.yaml\n into source control because it'll be a different file for each instance.\n\n\nIt can sometimes makes sense to have a \nlocal.yaml\n with values for running the application locally, e.g. when doing client testing. Use \n--config-path\n with \naqueduct serve\n to use a non-default name.\n\n\nPreventing Resource Leaks\n\n\nWhen an Aqueduct application starts, the application and its \nApplicationChannel\ns will likely create services that they use to respond to requests. In order for application tests to complete successfully, these services must be \"closed\" when the application stops. For built-in services, like \nPostgreSQLPersistentStore\n, this happens automatically when \nApplication.stop()\n is invoked.\n\n\nA \nServiceRegistry\n automatically stops registered services. Registration looks like this:\n\n\nvar\n \nconnection\n \n=\n \nnew\n \nConnectionOfSomeKind\n();\n\n\nawait\n \nconnection\n.\nopen\n();\n\n\nServiceRegistry\n.\ndefaultInstance\n\n  \n.\nregister\nConnectionOfSomeKind\n(\nconnection\n,\n \n(\nc\n)\n \n=\n \nc\n.\nclose\n());\n\n\n\n\n\n\nThis method takes the service to be closed and a closure that closes it. The service is passed as an argument to the closure. If the closure returns a \nFuture\n, \nServiceRegistry.close\n will not complete until the \nFuture\n completes. \nServiceRegistry.defaultInstance\n is closed in \nApplication.stop()\n, any registries created by the programmer must be closed manually.\n\n\nThe return type of \nServiceRegistry.register\n is the object being registered. This makes registration syntax a bit more palatable:\n\n\nvar\n \nconnection\n \n=\n \nServiceRegistry\n.\ndefaultInstance\n\n  \n.\nregister\nConnectionOfSomeKind\n(\n\n    \nnew\n \nConnectionOfSomeKind\n(),\n \n(\nc\n)\n \n=\n \nc\n.\nclose\n());\n\n\n\nawait\n \nconnection\n.\nopen\n();\n\n\n\n\n\n\nConfiguring CORS Headers\n\n\nAll controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), the response is created by evaluating the policy of the \nController\n that will respond to the real request.\n\n\nIn practice, this means that the policy of the last controller in a channel is used. For example, the policy of \nFooController\n generates the preflight response:\n\n\nrouter\n\n  \n.\nroute\n(\n/foo\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n(...))\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nFooController\n());\n\n\n\n\n\n\nEvery \nController\n has a \npolicy\n property (a \nCORSPolicy\n instance). The \npolicy\n has properties for configuring CORS options for that particular endpoint. By having a \npolicy\n, every \nController\n automatically implements logic to respond to preflight requests without any additional code.\n\n\nPolicies can be set at the controller level or at the application level. The static property \nCORSPolicy.defaultPolicy\n can be modified at initialization time to set the CORS options for every controller.\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nCORSPolicy\n.\ndefaultPolicy\n.\nallowedOrigins\n \n=\n \n[\nhttp://mywebsite.com/\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*).\n\n\nEach individual controller can override or replace the default policy by modifying its own \npolicy\n in its constructor.\n\n\nclass\n \nMyResourceController\n \nextends\n \nResourceController\n \n{\n\n  \nMyResourceController\n()\n \n{\n\n    \npolicy\n.\nallowedMethods\n \n=\n \n[\nPOST\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nConfiguring HTTPS\n\n\nBy default, an Aqueduct application does not use HTTPS. In many cases, an Aqueduct application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Aqueduct application unencrypted over HTTP.\n\n\nHowever, Aqueduct may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to \n--ssl-key-path\n \nand\n \n--ssl-certificate-path\n in \naqueduct serve\n, an Aqueduct application will configure itself to only allow HTTPS connections.\n\n\naqueduct serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem\n\n\n\n\n\nBoth the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as \nletsencrypt.org\n.\n\n\nWhen an application is started with these options, the \ncertificateFilePath\n and \nkeyFilePath\n are set on the \nApplicationOptions\n your application is being run with. (If you are not using \naqueduct serve\n, you can set these values directly when instantiating \nApplicationOptions\n.)\n\n\nFor more granular control over setting up an HTTPS server, you may override \nsecurityContext\n in \nApplicationChannel\n. By default, this property will create a \nSecurityContext\n from the \ncertificateFilePath\n and \nkeyFilePath\n in the channels's \noptions\n. A \nSecurityContext\n allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes.\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nSecurityContext\n \nget\n \nsecurityContext\n \n{\n\n    \nreturn\n \nnew\n \nSecurityContext\n()\n\n      \n..\nusePrivateKey\n(\nserver.key\n,\n \npassword:\n \n1234\n)\n\n      \n..\nuseCertificateChain\n(\nserver.crt\n,\n \npassword:\n \n1234\n);\n\n  \n}\n\n\n}", 
            "title": "Configuring an Application and its Environment"
        }, 
        {
            "location": "/application/configure/#configuring-an-application-and-its-environment", 
            "text": "This guide covers configuring an Aqueduct application.", 
            "title": "Configuring an Application and its Environment"
        }, 
        {
            "location": "/application/configure/#configuration-files", 
            "text": "Aqueduct applications use YAML configuration files to provide environment-specific values like database connection information. Use separate configuration files for testing and different deployment environments.  The path of a configuration file is available to an  ApplicationChannel  through its  options  property.  class   TodoAppChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     var   config   =   TodoConfiguration ( options . configurationFilePath ); \n     ... \n   }  }   The default value is  config.yaml .  The best practice for reading a configuration file is to subclass  Configuration . A  Configuration  declares a property for each key in a configuration file. For example, see the following  Configuration  subclass:  class   TodoConfiguration   extends   Configuration   { \n   TodoConfiguration ( String   fileName )   :   super . fromFile ( File ( fileName )); \n\n   DatabaseConnectionConfiguration   database ; \n   String   apiBaseURL ; \n\n   @ optionalConfiguration \n   int   identifier ;  }   This would read a YAML file like this:  database : \n   username :   fred \n   password :   fredspassword \n   host :   db . myapp . com \n   port :   5432 \n   databaseName :   fredsdb  apiBaseURL :   / api  identifier :   2   If required properties are omitted from the YAML file being read, application startup will fail and throw an informative error.", 
            "title": "Configuration Files"
        }, 
        {
            "location": "/application/configure/#environment-variables", 
            "text": "A configuration file can use an environment variable instead of a literal value. In  config.yaml , use a  $ -prefixed environment variable name instead of a value:  database: $DATABASE_CONNECTION_URL\napiBaseURL: /api  If the environment variable  DATABASE_CONNECTION_URL 's value were  \"postgres://user:password@localhost:5432/test\" , the value of  TodoConfiguration.database  will be that string at runtime.  The  safe_config package  has instructions for more additional usages.", 
            "title": "Environment Variables"
        }, 
        {
            "location": "/application/configure/#configuration-conventions-and-deployment-options", 
            "text": "Aqueduct uses two configuration files for a project:  config.yaml  and  config.src.yaml . The latter is the  configuration source file . The configuration source file declares key-value pairs that will be used when running the application tests. Deployed instances use  config.yaml .  This pattern is used for two reasons:   It is the template for the  config.yaml  that will be read on deployed applications, providing documentation for your application's configuration.  It has the configuration values used during testing to inject mock dependencies.   For example, a production API instance might have the following  config.yaml  file with connection info for a production database:  database :   postgres :// app_user : $ % 4 jlkn # an * @ mOZkea2 @ somedns . name . com : 5432 / production_db   Whereas  config.src.yaml  would have connection info for a local, test database:  database :   postgres :// test : test @ localhost : 5432 / temporary_db   The source configuration file should be checked into version control. Whether or not  config.yaml  is checked in depends on how you are deploying your code. If you are using environment variables to control application configuration, you should check  config.yaml  into source control and provide  $ -prefixed environment variable values. If you are using managing configuration files on each deployed instance, do not check  config.yaml  into source control because it'll be a different file for each instance.  It can sometimes makes sense to have a  local.yaml  with values for running the application locally, e.g. when doing client testing. Use  --config-path  with  aqueduct serve  to use a non-default name.", 
            "title": "Configuration Conventions and Deployment Options"
        }, 
        {
            "location": "/application/configure/#preventing-resource-leaks", 
            "text": "When an Aqueduct application starts, the application and its  ApplicationChannel s will likely create services that they use to respond to requests. In order for application tests to complete successfully, these services must be \"closed\" when the application stops. For built-in services, like  PostgreSQLPersistentStore , this happens automatically when  Application.stop()  is invoked.  A  ServiceRegistry  automatically stops registered services. Registration looks like this:  var   connection   =   new   ConnectionOfSomeKind ();  await   connection . open ();  ServiceRegistry . defaultInstance \n   . register ConnectionOfSomeKind ( connection ,   ( c )   =   c . close ());   This method takes the service to be closed and a closure that closes it. The service is passed as an argument to the closure. If the closure returns a  Future ,  ServiceRegistry.close  will not complete until the  Future  completes.  ServiceRegistry.defaultInstance  is closed in  Application.stop() , any registries created by the programmer must be closed manually.  The return type of  ServiceRegistry.register  is the object being registered. This makes registration syntax a bit more palatable:  var   connection   =   ServiceRegistry . defaultInstance \n   . register ConnectionOfSomeKind ( \n     new   ConnectionOfSomeKind (),   ( c )   =   c . close ());  await   connection . open ();", 
            "title": "Preventing Resource Leaks"
        }, 
        {
            "location": "/application/configure/#configuring-cors-headers", 
            "text": "All controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), the response is created by evaluating the policy of the  Controller  that will respond to the real request.  In practice, this means that the policy of the last controller in a channel is used. For example, the policy of  FooController  generates the preflight response:  router \n   . route ( /foo ) \n   . link (()   =   new   Authorizer (...)) \n   . link (()   =   new   FooController ());   Every  Controller  has a  policy  property (a  CORSPolicy  instance). The  policy  has properties for configuring CORS options for that particular endpoint. By having a  policy , every  Controller  automatically implements logic to respond to preflight requests without any additional code.  Policies can be set at the controller level or at the application level. The static property  CORSPolicy.defaultPolicy  can be modified at initialization time to set the CORS options for every controller.  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     CORSPolicy . defaultPolicy . allowedOrigins   =   [ http://mywebsite.com/ ]; \n   }  }   The default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*).  Each individual controller can override or replace the default policy by modifying its own  policy  in its constructor.  class   MyResourceController   extends   ResourceController   { \n   MyResourceController ()   { \n     policy . allowedMethods   =   [ POST ]; \n   }  }", 
            "title": "Configuring CORS Headers"
        }, 
        {
            "location": "/application/configure/#configuring-https", 
            "text": "By default, an Aqueduct application does not use HTTPS. In many cases, an Aqueduct application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Aqueduct application unencrypted over HTTP.  However, Aqueduct may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to  --ssl-key-path   and   --ssl-certificate-path  in  aqueduct serve , an Aqueduct application will configure itself to only allow HTTPS connections.  aqueduct serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem  Both the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as  letsencrypt.org .  When an application is started with these options, the  certificateFilePath  and  keyFilePath  are set on the  ApplicationOptions  your application is being run with. (If you are not using  aqueduct serve , you can set these values directly when instantiating  ApplicationOptions .)  For more granular control over setting up an HTTPS server, you may override  securityContext  in  ApplicationChannel . By default, this property will create a  SecurityContext  from the  certificateFilePath  and  keyFilePath  in the channels's  options . A  SecurityContext  allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes.  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   SecurityContext   get   securityContext   { \n     return   new   SecurityContext () \n       .. usePrivateKey ( server.key ,   password:   1234 ) \n       .. useCertificateChain ( server.crt ,   password:   1234 ); \n   }  }", 
            "title": "Configuring HTTPS"
        }, 
        {
            "location": "/application/structure/", 
            "text": "Application and Project Structure\n\n\nThe purpose of this document is to understand the objects that comprise an Aqueduct application, and how they work with one another to serve HTTP requests. It also discusses the project structure on the filesystem.\n\n\nControllers are Building Blocks\n\n\nThe building blocks of an Aqueduct application are \nControllers\n. Each controller type has logic to handle an HTTP request in some way. Controllers are linked together to form a \nchannel\n; an ordered series of controllers. A channel is a composition of its controllers' behaviors.\n\n\nFor example, consider an \nAuthorizer\n controller that verifies the request's authorization credentials are correct, and a \nSecretController\n that sends a response with secret information. By composing these two controllers together, we have a channel that verifies credentials before sending a secret. The benefit of controllers and channels is that controllers can be reused in multiple channels; the \nAuthorizer\n can protect other types of controllers without any change to its logic.\n\n\n\n\nThe last controller in a channel must always respond to a request. These types of controllers are called \nendpoint controllers\n and implement the business logic for your application's endpoints. For example, an endpoint controller might fetch a list of books from a database and send them in a response.\n\n\nThe other controllers in a channel are called \nmiddleware controllers\n. These types of controllers typically verify something about a request before letting the next controller in the channel handle it. Middleware controllers can respond to a request, but doing so prevents the rest of the controllers in the channel from handling the request.\n\n\nFor example, an \"authorization\" controller could send a \n401 Unauthorized\n response protecting the endpoint controller from unauthorized requests. A \"caching\" controller could send a response with information from a cache, preventing the endpoint controller from performing an expensive query.\n\n\nBoth middleware and endpoint controllers are instances of \nController\n (or a subclass). Middleware controllers are typically reusable, while endpoint controllers are typically not. If a middleware controller is not reusable, its logic might be better suited for the endpoint controller it precedes in the channel.\n\n\nMost endpoint controllers are created by subclassing \nResourceController\n (itself a subclass of \nController\n). This class allows you to implement methods for each HTTP method (like GET or POST) for a given endpoint.\n\n\nThe Application Channel and Entry Point\n\n\nEach application designates one controller as the \nentry point\n of the application. This controller is the first to receive a new request and is the head of the application's channel. In most applications, the entry point is a \nRouter\n; this controller allows multiple channels to be linked, effectively splitting the channel into sub-channels.\n\n\n\n\nThe diagram above looks like this in code:\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentry\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/a\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nAController\n());\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/b\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n(...))\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nBController\n());\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/c\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n(...))\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nCController\n());\n   \n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSee \nthis guide\n for more details on the application channel and entry point.\n\n\nAqueduct Project Structure and Organization\n\n\nAn Aqueduct project is a directory that contains, at minimum, the following file structure:\n\n\npubspec.yaml\nlib/\n  application_name.dart\n\n\n\n\n\nThe name of any Dart application is defined by the \nname\n key in \npubspec.yaml\n. In order for \naqueduct serve\n to run your application, there must be a \n.dart\n file in \nlib/\n with that same name. This is your application library file and it must declare a \nApplicationChannel\n subclass or import a file that does. This is the bare minimum requirement to run an Aqueduct application. (See \nDeploying\n for more details on running applications.)\n\n\nFor organizing applications of reasonable size, we recommend the following structure:\n\n\npubspec.yaml\nconfig.src.yaml\nconfig.yaml\nlib/\n  application_name.dart\n  channel.dart  \n  controller/\n    user_controller.dart\n  model/\n    user.dart\ntest/\n  user_controller_test.dart\n  harness/\n    app.dart\n\n\n\n\n\nThe required \npubspec.yaml\n and \nlib/application_name.dart\n files are present alongside a few others:\n\n\n\n\nconfig.yaml\n: A \nconfiguration file\n for the running application.\n\n\nconfig.src.yaml\n: A \ntemplate for config.yaml\n.\n\n\nchannel.dart\n: A file solely for the \nApplicationChannel\n of an application. This file should be \nexported\n from \napplication_name.dart\n.\n\n\ncontroller/\n: A directory for \nController\n subclass files.\n\n\nmodel/\n: A directory for \nManagedObject\nT\n subclass files.\n\n\ntest/harness/app.dart\n: A \ntest harness\n) for automated testing.\n\n\n\n\nFeel free to create other subdirectories in \nlib/\n for organizing other types of files.\n\n\nAqueduct and dart:io\n\n\nAqueduct runs on top of \ndart:io\n and relies on its \nHttpServer\n implementation. When an Aqueduct application is started, one or more \nHttpServer\n instances are bound to the port specified by \naqueduct serve\n. For each HTTP request, an instance of \nRequest\n is created to wrap the \nHttpRequest\n from \ndart:io\n. The \nRequest\n is added to a \nApplicationChannel\n, sending it through the channel of \nController\ns until it is responded to.\n\n\nIn rare circumstances, you may choose to remove a \nRequest\n from the application channel and manipulate the request with \ndart:io\n only. Once removed, it is your responsibility to respond to the request by setting properties on and closing the \nHttpRequest.response\n. To take a request out of the channel, simply return \nnull\n from a \nController\n:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/bypass_aqueduct\n)\n\n    \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n{\n\n      \nreq\n.\nresponse\n.\nstatusCode\n \n=\n \n200\n;\n\n      \nreq\n.\nresponse\n.\nclose\n();\n\n\n      \nreturn\n \nnull\n;\n\n    \n});\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nThis technique is valuable when Aqueduct can't do something you want it to do or when using \nwebsockets\n.", 
            "title": "Application and Project Structure"
        }, 
        {
            "location": "/application/structure/#application-and-project-structure", 
            "text": "The purpose of this document is to understand the objects that comprise an Aqueduct application, and how they work with one another to serve HTTP requests. It also discusses the project structure on the filesystem.", 
            "title": "Application and Project Structure"
        }, 
        {
            "location": "/application/structure/#controllers-are-building-blocks", 
            "text": "The building blocks of an Aqueduct application are  Controllers . Each controller type has logic to handle an HTTP request in some way. Controllers are linked together to form a  channel ; an ordered series of controllers. A channel is a composition of its controllers' behaviors.  For example, consider an  Authorizer  controller that verifies the request's authorization credentials are correct, and a  SecretController  that sends a response with secret information. By composing these two controllers together, we have a channel that verifies credentials before sending a secret. The benefit of controllers and channels is that controllers can be reused in multiple channels; the  Authorizer  can protect other types of controllers without any change to its logic.   The last controller in a channel must always respond to a request. These types of controllers are called  endpoint controllers  and implement the business logic for your application's endpoints. For example, an endpoint controller might fetch a list of books from a database and send them in a response.  The other controllers in a channel are called  middleware controllers . These types of controllers typically verify something about a request before letting the next controller in the channel handle it. Middleware controllers can respond to a request, but doing so prevents the rest of the controllers in the channel from handling the request.  For example, an \"authorization\" controller could send a  401 Unauthorized  response protecting the endpoint controller from unauthorized requests. A \"caching\" controller could send a response with information from a cache, preventing the endpoint controller from performing an expensive query.  Both middleware and endpoint controllers are instances of  Controller  (or a subclass). Middleware controllers are typically reusable, while endpoint controllers are typically not. If a middleware controller is not reusable, its logic might be better suited for the endpoint controller it precedes in the channel.  Most endpoint controllers are created by subclassing  ResourceController  (itself a subclass of  Controller ). This class allows you to implement methods for each HTTP method (like GET or POST) for a given endpoint.", 
            "title": "Controllers are Building Blocks"
        }, 
        {
            "location": "/application/structure/#the-application-channel-and-entry-point", 
            "text": "Each application designates one controller as the  entry point  of the application. This controller is the first to receive a new request and is the head of the application's channel. In most applications, the entry point is a  Router ; this controller allows multiple channels to be linked, effectively splitting the channel into sub-channels.   The diagram above looks like this in code:  class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entry   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /a ) \n       . link (()   =   new   AController ()); \n\n     router \n       . route ( /b ) \n       . link (()   =   new   Authorizer (...)) \n       . link (()   =   new   BController ()); \n\n     router \n       . route ( /c ) \n       . link (()   =   new   Authorizer (...)) \n       . link (()   =   new   CController ());    \n\n     return   router ; \n   }  }   See  this guide  for more details on the application channel and entry point.", 
            "title": "The Application Channel and Entry Point"
        }, 
        {
            "location": "/application/structure/#aqueduct-project-structure-and-organization", 
            "text": "An Aqueduct project is a directory that contains, at minimum, the following file structure:  pubspec.yaml\nlib/\n  application_name.dart  The name of any Dart application is defined by the  name  key in  pubspec.yaml . In order for  aqueduct serve  to run your application, there must be a  .dart  file in  lib/  with that same name. This is your application library file and it must declare a  ApplicationChannel  subclass or import a file that does. This is the bare minimum requirement to run an Aqueduct application. (See  Deploying  for more details on running applications.)  For organizing applications of reasonable size, we recommend the following structure:  pubspec.yaml\nconfig.src.yaml\nconfig.yaml\nlib/\n  application_name.dart\n  channel.dart  \n  controller/\n    user_controller.dart\n  model/\n    user.dart\ntest/\n  user_controller_test.dart\n  harness/\n    app.dart  The required  pubspec.yaml  and  lib/application_name.dart  files are present alongside a few others:   config.yaml : A  configuration file  for the running application.  config.src.yaml : A  template for config.yaml .  channel.dart : A file solely for the  ApplicationChannel  of an application. This file should be  exported  from  application_name.dart .  controller/ : A directory for  Controller  subclass files.  model/ : A directory for  ManagedObject T  subclass files.  test/harness/app.dart : A  test harness ) for automated testing.   Feel free to create other subdirectories in  lib/  for organizing other types of files.", 
            "title": "Aqueduct Project Structure and Organization"
        }, 
        {
            "location": "/application/structure/#aqueduct-and-dartio", 
            "text": "Aqueduct runs on top of  dart:io  and relies on its  HttpServer  implementation. When an Aqueduct application is started, one or more  HttpServer  instances are bound to the port specified by  aqueduct serve . For each HTTP request, an instance of  Request  is created to wrap the  HttpRequest  from  dart:io . The  Request  is added to a  ApplicationChannel , sending it through the channel of  Controller s until it is responded to.  In rare circumstances, you may choose to remove a  Request  from the application channel and manipulate the request with  dart:io  only. Once removed, it is your responsibility to respond to the request by setting properties on and closing the  HttpRequest.response . To take a request out of the channel, simply return  null  from a  Controller :  @ override  Controller   get   entryPoint   { \n   final   router   =   new   Router (); \n\n   router \n     . route ( /bypass_aqueduct ) \n     . linkFunction (( req )   async   { \n       req . response . statusCode   =   200 ; \n       req . response . close (); \n\n       return   null ; \n     }); \n\n   return   router ;  }   This technique is valuable when Aqueduct can't do something you want it to do or when using  websockets .", 
            "title": "Aqueduct and dart:io"
        }, 
        {
            "location": "/application/threading/", 
            "text": "Multi-threading in Aqueduct\n\n\nOne of the primary differentiators between Aqueduct and other server frameworks is its multi-threaded behavior. When an Aqueduct application starts, it replicates the application logic across a number of threads.\n\n\nIn Dart, threads are called \nisolates\n. The difference in naming isn't just to be cute - an isolate is a little bit different than a thread in that memory is not shared between isolates. Each isolate has its own heap (this is where memory for objects is allocated from) that other isolates can't access.\n\n\nAn isolated thread is very valuable. Many multi-threaded applications share memory across threads, which require difficult design patterns and can easily introduce hard to track bugs that even the most experienced programmer will have a hard time avoiding.\n\n\nHow Aqueduct Uses Isolates\n\n\nAn application is initialized by invoking a series of initialization methods in a \nApplicationChannel\n. Once these methods are finished executing, the application starts sending HTTP requests through the channel created by the \nApplicationChannel\n.\n\n\nBecause an \nApplicationChannel\n is a type - and can be instantiated - Aqueduct simply creates a number of isolates and instantiates \nApplicationChannel\n for each. The initialization code is therefore identical for each isolate, which means that the ongoing behavior of each isolate is also identical.\n\n\nMore importantly, you - the programmer - have to do absolutely nothing to take advantage of Aqueduct's multi-threaded behavior. You simply have to pick the number of isolates you want to run the application on (see \nthis section\n).\n\n\nWhile you don't have to do anything in an Aqueduct application to take advantage of multiple processors, there are things you shouldn't do or should do in another way.\n\n\nFirst, you must be careful of keeping any state in your application. After initialization, any objects created while handling a request should be destroyed once the request is fulfilled. Any data that needs to be persisted must be stored in a database or other data store. This is just good practice for a REST API anyhow, so nothing is really lost here.\n\n\nHowever, there are times where you do need to track state. For example, if you are managing websocket connections, you do need to store some state after initialization - a reference to the websocket. \nThis guide\n covers this topic in detail; the simple explanation is to use the \nApplicationMessageHub\n.\n\n\nAnother thing that is important to consider is initialization. The methods \nprepare()\n and \nentryPoint\n in an application channel will be invoked on each isolate. This behavior is guaranteed to occur for each isolate and there is often little to worry about.\n\n\nHowever, when implementing \nApplicationChannel.initializeApplication\n, code runs on the main isolate. Any changes to static variables or singletons will not be replicated to the isolates running the application logic. The use case for this method is rather minimal, but it is very important that types like \nCodecRegistry\n aren't configured in this method.\n\n\nHow Many Isolates Should I Use\n\n\nTo give you a starting point, the default number of isolates for an application is 3 when started with \naqueduct serve\n. While less than 3 isolates will most certainly degrade performance, more than 3 doesn't necessarily improve performance. (And many more will certainly degrade performance.)\n\n\nThere are a number of variables that factor into the isolate count decision. First, recall a computer essentially does two things: it executes instructions and transmits data. Both of these tasks take time, especially when that data is transmitted to another computer thousands of miles away. (It is a modern marvel that these tasks occur as fast as they do - one that we often take for granted.)\n\n\nWhile a few milliseconds difference in speed to handle a single request isn't all that meaningful, when you start receiving thousands of requests at a time, these milliseconds add up. When your application is struggling to keep up with executing instructions, it is said to be \nCPU-bound\n. (When your application is struggling to transmit data, it is said to be \nIO-bound\n.)\n\n\nA CPU-bound application has two choices: execute less instructions or have more processors (or cores) to execute instructions with. Most computers these days have multiple processors. When only using a single isolate, an Aqueduct application can only use one of those processors at a time. As the number of isolates increases, so too do the number of processors that can be used at a time.\n\n\nThus, more isolates means more processors means more instructions and your application bound less by the CPU. However, there is a limit - creating 100 isolates when there are only two processors doesn't yield any greater performance, because 50 isolates will fight over a single processor. In fact, the amount of work to schedule these instructions and the amount of memory this many isolates will consume will hurt performance.\n\n\nFor example, when running benchmarks with \nwrk\n on my four-core machine, I get significantly better results as I add isolates 1 through 4, but then I get marginal gains and finally less or equal performance as I increase the number of isolates past 4. The blue bar represents the number of requests per second for each isolate count when making a simple HTTP call to Aqueduct.\n\n\n\n\n(Note that benchmarks are a good way of measuring relative performance of an application and identifying bottlenecks, but real world usability performance across a network is the only measurement that matters. The absolute value of these benchmarks should not be taken seriously, as they entirely remove the network portion of the transmission.)\n\n\nBut this isn't the whole story. Server applications are rarely CPU-bound, but instead IO-bound. The red bar represents the number of requests per second when making a database query and returning the results of that query as JSON in the response body. When using Observatory, the measurements indicate that the overwhelming majority of the time is spent transmitting data to and from the database. This is an example of being bound by IO (and the speed of the query).\n\n\nRecall that each isolate has its own database connection. A database connection is a serial queue - it can only handle one query at a time. Increasing the number of database connections means handling more queries at a time. This is no more apparent than when looking at the following graph, which measures the latency of requests with and without a database call.\n\n\n\n\nWhen there is only one database connection (one isolate), the latency is significantly higher per request - the application is entirely bound by the speed of the database serial queue. Adding a second isolate, and therefore a second database connection, drops the latency by more than half.\n\n\nThere are diminishing returns as more database connections are added. That's because the same thing about the number of threads per processor also applies to the number of database connections. Adding more database connections doesn't magically make the database server run any faster.\n\n\nAs a general rule, start with N-1 isolates, where N is the number of processors on the machine. Use \nwrk\n and Observatory to profile your application and tune accordingly. In a multi-instance environment, remember that the total number of database connections is MxN, where M is the number of machines and N is the number of isolates.\n\n\nIf you find yourself in a jam where IO would be better served by less isolates, but CPU would be better served by more isolates, you may consider using a database connection pool isolate.", 
            "title": "Multi-threading"
        }, 
        {
            "location": "/application/threading/#multi-threading-in-aqueduct", 
            "text": "One of the primary differentiators between Aqueduct and other server frameworks is its multi-threaded behavior. When an Aqueduct application starts, it replicates the application logic across a number of threads.  In Dart, threads are called  isolates . The difference in naming isn't just to be cute - an isolate is a little bit different than a thread in that memory is not shared between isolates. Each isolate has its own heap (this is where memory for objects is allocated from) that other isolates can't access.  An isolated thread is very valuable. Many multi-threaded applications share memory across threads, which require difficult design patterns and can easily introduce hard to track bugs that even the most experienced programmer will have a hard time avoiding.", 
            "title": "Multi-threading in Aqueduct"
        }, 
        {
            "location": "/application/threading/#how-aqueduct-uses-isolates", 
            "text": "An application is initialized by invoking a series of initialization methods in a  ApplicationChannel . Once these methods are finished executing, the application starts sending HTTP requests through the channel created by the  ApplicationChannel .  Because an  ApplicationChannel  is a type - and can be instantiated - Aqueduct simply creates a number of isolates and instantiates  ApplicationChannel  for each. The initialization code is therefore identical for each isolate, which means that the ongoing behavior of each isolate is also identical.  More importantly, you - the programmer - have to do absolutely nothing to take advantage of Aqueduct's multi-threaded behavior. You simply have to pick the number of isolates you want to run the application on (see  this section ).  While you don't have to do anything in an Aqueduct application to take advantage of multiple processors, there are things you shouldn't do or should do in another way.  First, you must be careful of keeping any state in your application. After initialization, any objects created while handling a request should be destroyed once the request is fulfilled. Any data that needs to be persisted must be stored in a database or other data store. This is just good practice for a REST API anyhow, so nothing is really lost here.  However, there are times where you do need to track state. For example, if you are managing websocket connections, you do need to store some state after initialization - a reference to the websocket.  This guide  covers this topic in detail; the simple explanation is to use the  ApplicationMessageHub .  Another thing that is important to consider is initialization. The methods  prepare()  and  entryPoint  in an application channel will be invoked on each isolate. This behavior is guaranteed to occur for each isolate and there is often little to worry about.  However, when implementing  ApplicationChannel.initializeApplication , code runs on the main isolate. Any changes to static variables or singletons will not be replicated to the isolates running the application logic. The use case for this method is rather minimal, but it is very important that types like  CodecRegistry  aren't configured in this method.", 
            "title": "How Aqueduct Uses Isolates"
        }, 
        {
            "location": "/application/threading/#how-many-isolates-should-i-use", 
            "text": "To give you a starting point, the default number of isolates for an application is 3 when started with  aqueduct serve . While less than 3 isolates will most certainly degrade performance, more than 3 doesn't necessarily improve performance. (And many more will certainly degrade performance.)  There are a number of variables that factor into the isolate count decision. First, recall a computer essentially does two things: it executes instructions and transmits data. Both of these tasks take time, especially when that data is transmitted to another computer thousands of miles away. (It is a modern marvel that these tasks occur as fast as they do - one that we often take for granted.)  While a few milliseconds difference in speed to handle a single request isn't all that meaningful, when you start receiving thousands of requests at a time, these milliseconds add up. When your application is struggling to keep up with executing instructions, it is said to be  CPU-bound . (When your application is struggling to transmit data, it is said to be  IO-bound .)  A CPU-bound application has two choices: execute less instructions or have more processors (or cores) to execute instructions with. Most computers these days have multiple processors. When only using a single isolate, an Aqueduct application can only use one of those processors at a time. As the number of isolates increases, so too do the number of processors that can be used at a time.  Thus, more isolates means more processors means more instructions and your application bound less by the CPU. However, there is a limit - creating 100 isolates when there are only two processors doesn't yield any greater performance, because 50 isolates will fight over a single processor. In fact, the amount of work to schedule these instructions and the amount of memory this many isolates will consume will hurt performance.  For example, when running benchmarks with  wrk  on my four-core machine, I get significantly better results as I add isolates 1 through 4, but then I get marginal gains and finally less or equal performance as I increase the number of isolates past 4. The blue bar represents the number of requests per second for each isolate count when making a simple HTTP call to Aqueduct.   (Note that benchmarks are a good way of measuring relative performance of an application and identifying bottlenecks, but real world usability performance across a network is the only measurement that matters. The absolute value of these benchmarks should not be taken seriously, as they entirely remove the network portion of the transmission.)  But this isn't the whole story. Server applications are rarely CPU-bound, but instead IO-bound. The red bar represents the number of requests per second when making a database query and returning the results of that query as JSON in the response body. When using Observatory, the measurements indicate that the overwhelming majority of the time is spent transmitting data to and from the database. This is an example of being bound by IO (and the speed of the query).  Recall that each isolate has its own database connection. A database connection is a serial queue - it can only handle one query at a time. Increasing the number of database connections means handling more queries at a time. This is no more apparent than when looking at the following graph, which measures the latency of requests with and without a database call.   When there is only one database connection (one isolate), the latency is significantly higher per request - the application is entirely bound by the speed of the database serial queue. Adding a second isolate, and therefore a second database connection, drops the latency by more than half.  There are diminishing returns as more database connections are added. That's because the same thing about the number of threads per processor also applies to the number of database connections. Adding more database connections doesn't magically make the database server run any faster.  As a general rule, start with N-1 isolates, where N is the number of processors on the machine. Use  wrk  and Observatory to profile your application and tune accordingly. In a multi-instance environment, remember that the total number of database connections is MxN, where M is the number of machines and N is the number of isolates.  If you find yourself in a jam where IO would be better served by less isolates, but CPU would be better served by more isolates, you may consider using a database connection pool isolate.", 
            "title": "How Many Isolates Should I Use"
        }, 
        {
            "location": "/http/", 
            "text": "Tasks\n\n\nAn Aqueduct application serves HTTP clients by sending responses for requests.\n\n\nYou create and link \nController\n objects to handle requests. There are many subclasses of \nController\n that handle common tasks, and you often create your own subclasses of \nController\n to implement application logic. Most of your logic is implemented in subclasses of \nResourceController\n, a controller type geared for REST API endpoints.\n\n\nYou create a subclass of \nApplicationChannel\n to configure controllers used by your application. This subclass also initializes any services your application will use to fulfill requests, like database connections or third party API connections. Most often, you use a \nRouter\n controller at the entry point of your application channel to modularize your application logic.\n\n\nYour application may have many configurable options. This configuration is handled in your application channel. Configuration file management is provided by application-specific \nConfiguration\n subclasses that add type and name safety to your configuration files.\n\n\nYour application is run by using the \naqueduct serve\n command or the \nbin/main.dart\n script. In either case, your application starts by creating multiple, memory-isolated threads that replicate your \nApplicationChannel\n.\n\n\nGuides\n\n\n\n\nHandling Requests and Sending Responsers\n\n\nSerializing Request and Response Bodies\n\n\nRouting\n\n\nRequest Binding with ResourceControllers\n\n\nServing Files and Caching\n\n\nWebsockets\n\n\nUploading Files", 
            "title": "Overview"
        }, 
        {
            "location": "/http/#tasks", 
            "text": "An Aqueduct application serves HTTP clients by sending responses for requests.  You create and link  Controller  objects to handle requests. There are many subclasses of  Controller  that handle common tasks, and you often create your own subclasses of  Controller  to implement application logic. Most of your logic is implemented in subclasses of  ResourceController , a controller type geared for REST API endpoints.  You create a subclass of  ApplicationChannel  to configure controllers used by your application. This subclass also initializes any services your application will use to fulfill requests, like database connections or third party API connections. Most often, you use a  Router  controller at the entry point of your application channel to modularize your application logic.  Your application may have many configurable options. This configuration is handled in your application channel. Configuration file management is provided by application-specific  Configuration  subclasses that add type and name safety to your configuration files.  Your application is run by using the  aqueduct serve  command or the  bin/main.dart  script. In either case, your application starts by creating multiple, memory-isolated threads that replicate your  ApplicationChannel .", 
            "title": "Tasks"
        }, 
        {
            "location": "/http/#guides", 
            "text": "Handling Requests and Sending Responsers  Serializing Request and Response Bodies  Routing  Request Binding with ResourceControllers  Serving Files and Caching  Websockets  Uploading Files", 
            "title": "Guides"
        }, 
        {
            "location": "/http/controller/", 
            "text": "Handling Requests: Fundamentals\n\n\nIn Aqueduct, HTTP requests and responses are instances of \nRequest\ns and \nResponse\ns. For each HTTP request an application receives, an instance of \nRequest\n is created. A \nResponse\n must be created for each request. Responses are created by \ncontroller objects\n. This guide discusses the behavior and initialization of controllers. You can read more about request and response objects \nhere\n.\n\n\nOverview\n\n\nA controller is the basic building block of an Aqueduct application. A controller handles an HTTP request in some way. For example, a controller could return a 200 OK response with a JSON-encoded list of city names. A controller could also check a request to make sure it had the right credentials in its authorization header.\n\n\nControllers are linked together to compose their behaviors into a \nchannel\n. A channel handles a request by performing each of its controllers' behavior in order. For example, a channel might verify the credentials of a request and then return a list of city names by composing two controllers that take each of these actions.\n\n\n\n\nYou subclass controllers to provide their request handling logic, and there are common controller subclasses in Aqueduct for your use.\n\n\nLinking Controllers\n\n\nControllers are linked with their \nlink\n method. This method takes a closure that returns the next controller in the channel. The following shows a channel composed of two controllers:\n\n\nfinal\n \ncontroller\n \n=\n \nVerifyController\n();\n\n\ncontroller\n.\nlink\n(()\n \n=\n \nResponseController\n());\n\n\n\n\n\n\nIn the above, \nVerifyController\n links \nResponseController\n. A request handled by the verifying controller can either respond to the request or let the response controller handle it. If the verifying controller sends a respond, the response controller will never receive the request. Any number of controllers can be linked, but the last controller linked must respond to a request. Controllers that always respond to request are called \nendpoint controllers\n. \nMiddleware controllers\n verify or modify the request, and typically only respond when an error is encountered.\n\n\nLinking occurs in an \napplication channel\n, and is finalized during startup of your application (i.e., once you have set up your controllers, the cannot be changed once the application starts receiving requests).\n\n\nSubclassing Controller to Handle Requests\n\n\nEvery \nController\n implements its \nhandle\n method to handle a request. You override this method in your controllers to provide the logic for your controllers. The following is an example of an endpoint controller, because it always sends a response:\n\n\nclass\n \nNoteController\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nfinal\n \nnotes\n \n=\n \nawait\n \nfetchNotesFromDatabase\n();\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nnotes\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis \nhandle\n method returns a \nResponse\n object. Any time a controller returns a response, Aqueduct sends a response to the client and terminates the request so that no other controllers can handle it.\n\n\nA middleware controller returns a response when it can provide the response or for error conditions. For example, an \nAuthorizer\n controller returns a \n401 Unauthorized\n response if the request's credentials are invalid. To let the request pass to the next controller, you must return the request object.\n\n\nAs an example, the pseudo-code for an \nAuthorizer\n looks like this:\n\n\nclass\n \nAuthorizer\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\nisValid\n(\nrequest\n))\n \n{\n\n      \nreturn\n \nrequest\n;\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nunauthorized\n();\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\n\nEndpoint Controllers\n\n\nIn most cases, endpoint controllers are created by subclassing \nResourceController\n. This controller allows you to declare more than one handler method in a controller to better organize logic. For example, one method might handle POST requests, while another handles GET requests.\n\n\n\n\nModifying a Response with Middleware\n\n\nA middleware controller can add a \nresponse modifier\n to a request. When an endpoint controller eventually creates a response, these modifiers are applied to the response before it is sent. Modifiers are added by invoking \naddResponseModifier\n on a request.\n\n\nclass\n \nVersioner\n \nextends\n \nController\n \n{\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nrequest\n.\naddResponseModifier\n((\nresponse\n)\n \n{\n\n      \nresponse\n.\nheaders\n[\nx-api-version\n]\n \n=\n \n2.1\n;\n\n    \n});\n\n\n    \nreturn\n \nrequest\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAny number of controllers can add a response modifier to a request; they will be processed in the order that they were added. Response modifiers are applied before the response body is encoded, allowing the body object to be manipulated. Response modifiers are invoked regardless of the response generated by the endpoint controller. If an uncaught error is thrown while adding response modifiers, any remaining response modifiers are not called and a 500 Server Error response is sent.\n\n\nLinking Functions\n\n\nFor simple behavior, functions with the same signature as \nhandle\n can be linked to controllers:\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/path\n)\n\n    \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nreq\n);\n\n    \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nResponse\n.\nok\n(\nnull\n));\n\n\n\n\n\n\nLinking a function has all of the same behavior as \nController.handle\n: it can return a request or response, automatically handles exceptions, and can have controllers (and functions) linked to it.\n\n\nController Instantiation and Recycling\n\n\nIt is important to understand why \nlink\n takes a closure, instead of a controller object. Aqueduct is an object oriented framework. Objects have both state and behavior. An application will receive multiple requests that will be handled by the same type of controller. If a mutable controller object were reused to handle multiple requests, it could retain some of its state between requests. This would create problems that are difficult to debug.\n\n\nMost controllers are immutable - in other words, all of their properties are final and they have no setters. This (mostly) ensures that the controller won't change behavior between requests. When a controller is immutable, the \nlink\n closure is invoked once to create and link the controller object, and then the closure is discarded. The same controller object will be reused for every request.\n\n\nControllers can be mutable, with the caveat that they cannot be reused for multiple requests. For example, a \nResourceController\n can have properties that are bound to the values of a request, and therefore these properties will change and a new instance must be created for each request.\n\n\nA mutable \nController\n subclass must implement \nRecyclable\nT\n. The \nlink\n closure will be invoked for each request, creating a new instance of the recyclable controller to handle the request. If a controller has an expensive initialization process, the results of that initialization can be calculated once and reused for each controller instance by implementing the methods from \nRecyclable\nT\n.\n\n\nclass\n \nMyControllerState\n \n{\n\n  \ndynamic\n \nstuff\n;\n\n\n}\n\n\n\nclass\n \nMyController\n \nextends\n \nController\n \nimplements\n \nRecyclable\nMyControllerState\n \n{\n\n  \n@\noverride\n\n  \nMyControllerState\n \nget\n \nrecycledState\n \n=\n \nexpensiveCalculation\n();\n\n\n  \n@\noverride\n\n  \nvoid\n \nrestore\n(\nMyControllerState\n \nstate\n)\n \n{\n\n    \n_restoredState\n \n=\n \nstate\n;\n\n  \n}\n\n\n  \nMyControllerState\n \n_restoredState\n;\n\n\n  \n@\noverride\n\n  \nFutureOr\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \n/* use _restoredState */\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(...);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nrecycledState\n getter is called once, when the controller is first linked. Each new instance of a recyclable controller has its \nrestore\n method invoked prior to handling the request, and the data returned by \nrecycledState\n is passed as an argument. As an example, \nResourceController\n 'compiles' its operation methods. The compiled product is stored as recycled state so that future instances can bind request data more efficiently.\n\n\nException Handling\n\n\nIf an exception or error is thrown during the handling of a request, the controller currently handling the request will catch it. For the majority of values caught, a controller will send a 500 Server Response. The details of the exception or error will be \nlogged\n, and the request is removed from the channel (it will not be passed to a linked controller).\n\n\nThis is the default behavior for all thrown values except \nResponse\n and \nHandlerException\n.\n\n\nThrowing Responses\n\n\nA \nResponse\n can be thrown at any time; the controller handling the request will catch it and send it to the client. This completes the request. This might not seem useful, for example, the following shows a silly use of this behavior:\n\n\nclass\n \nThrower\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\n!\nisForbidden\n(\nrequest\n))\n \n{\n\n      \nthrow\n \nnew\n \nResponse\n.\nforbidden\n();\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nnull\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThrowing HandlerExceptions\n\n\nExceptions can implement \nHandlerException\n to provide a response other than the default when thrown. For example, an application that handles bank transactions might declare an exception for invalid withdrawals:\n\n\nenum\n \nWithdrawalProblem\n \n{\n\n  \ninsufficientFunds\n,\n\n  \nbankClosed\n\n\n}\n\n\nclass\n \nWithdrawalException\n \nimplements\n \nException\n \n{\n\n  \nWithdrawalException\n(\nthis\n.\nproblem\n);\n\n\n  \nfinal\n \nWithdrawalProblem\n \nproblem\n;\n\n\n}\n\n\n\n\n\n\nController code can catch this exception to return a different status code depending on the exact problem with a withdrawal. If this code has to be written in multiple places, it is useful for \nWithdrawalException\n to implement \nHandlerException\n. An implementor must provide an implementation for \nresponse\n:\n\n\nclass\n \nWithdrawalException\n \nimplements\n \nHandlerException\n \n{\n\n  \nWithdrawalException\n(\nthis\n.\nproblem\n);\n\n\n  \nfinal\n \nWithdrawalProblem\n \nproblem\n;\n\n\n  \n@\noverride\n\n  \nResponse\n \nget\n \nresponse\n \n{\n\n    \nswitch\n \n(\nproblem\n)\n \n{\n\n      \ncase\n \nWithdrawalProblem\n.\ninsufficientFunds:\n\n        \nreturn\n \nnew\n \nResponse\n.\nbadRequest\n(\nbody:\n \n{\nerror\n:\n \ninsufficient_funds\n});\n\n      \ncase\n \nWithdrawalProblem\n.\nbankClosed:\n\n        \nreturn\n \nnew\n \nResponse\n.\nbadRequest\n(\nbody:\n \n{\nerror\n:\n \nbank_closed\n});\n\n    \n}\n\n  \n}\n\n\n}\n\n\n\n\n\n\nCORS Headers and Preflight Requests\n\n\nController\ns have built-in behavior for handling CORS requests. They will automatically respond to \nOPTIONS\n preflight requests and attach CORS headers to any other response. See \nthe chapter on CORS\n for more details.", 
            "title": "Handling Requests and Sending Response"
        }, 
        {
            "location": "/http/controller/#handling-requests-fundamentals", 
            "text": "In Aqueduct, HTTP requests and responses are instances of  Request s and  Response s. For each HTTP request an application receives, an instance of  Request  is created. A  Response  must be created for each request. Responses are created by  controller objects . This guide discusses the behavior and initialization of controllers. You can read more about request and response objects  here .", 
            "title": "Handling Requests: Fundamentals"
        }, 
        {
            "location": "/http/controller/#overview", 
            "text": "A controller is the basic building block of an Aqueduct application. A controller handles an HTTP request in some way. For example, a controller could return a 200 OK response with a JSON-encoded list of city names. A controller could also check a request to make sure it had the right credentials in its authorization header.  Controllers are linked together to compose their behaviors into a  channel . A channel handles a request by performing each of its controllers' behavior in order. For example, a channel might verify the credentials of a request and then return a list of city names by composing two controllers that take each of these actions.   You subclass controllers to provide their request handling logic, and there are common controller subclasses in Aqueduct for your use.", 
            "title": "Overview"
        }, 
        {
            "location": "/http/controller/#linking-controllers", 
            "text": "Controllers are linked with their  link  method. This method takes a closure that returns the next controller in the channel. The following shows a channel composed of two controllers:  final   controller   =   VerifyController ();  controller . link (()   =   ResponseController ());   In the above,  VerifyController  links  ResponseController . A request handled by the verifying controller can either respond to the request or let the response controller handle it. If the verifying controller sends a respond, the response controller will never receive the request. Any number of controllers can be linked, but the last controller linked must respond to a request. Controllers that always respond to request are called  endpoint controllers .  Middleware controllers  verify or modify the request, and typically only respond when an error is encountered.  Linking occurs in an  application channel , and is finalized during startup of your application (i.e., once you have set up your controllers, the cannot be changed once the application starts receiving requests).", 
            "title": "Linking Controllers"
        }, 
        {
            "location": "/http/controller/#subclassing-controller-to-handle-requests", 
            "text": "Every  Controller  implements its  handle  method to handle a request. You override this method in your controllers to provide the logic for your controllers. The following is an example of an endpoint controller, because it always sends a response:  class   NoteController   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     final   notes   =   await   fetchNotesFromDatabase (); \n\n     return   Response . ok ( notes ); \n   }  }   This  handle  method returns a  Response  object. Any time a controller returns a response, Aqueduct sends a response to the client and terminates the request so that no other controllers can handle it.  A middleware controller returns a response when it can provide the response or for error conditions. For example, an  Authorizer  controller returns a  401 Unauthorized  response if the request's credentials are invalid. To let the request pass to the next controller, you must return the request object.  As an example, the pseudo-code for an  Authorizer  looks like this:  class   Authorizer   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     if   ( isValid ( request ))   { \n       return   request ; \n     } \n\n     return   Response . unauthorized (); \n   }  }    Endpoint Controllers  In most cases, endpoint controllers are created by subclassing  ResourceController . This controller allows you to declare more than one handler method in a controller to better organize logic. For example, one method might handle POST requests, while another handles GET requests.", 
            "title": "Subclassing Controller to Handle Requests"
        }, 
        {
            "location": "/http/controller/#modifying-a-response-with-middleware", 
            "text": "A middleware controller can add a  response modifier  to a request. When an endpoint controller eventually creates a response, these modifiers are applied to the response before it is sent. Modifiers are added by invoking  addResponseModifier  on a request.  class   Versioner   extends   Controller   { \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     request . addResponseModifier (( response )   { \n       response . headers [ x-api-version ]   =   2.1 ; \n     }); \n\n     return   request ; \n   }  }   Any number of controllers can add a response modifier to a request; they will be processed in the order that they were added. Response modifiers are applied before the response body is encoded, allowing the body object to be manipulated. Response modifiers are invoked regardless of the response generated by the endpoint controller. If an uncaught error is thrown while adding response modifiers, any remaining response modifiers are not called and a 500 Server Error response is sent.", 
            "title": "Modifying a Response with Middleware"
        }, 
        {
            "location": "/http/controller/#linking-functions", 
            "text": "For simple behavior, functions with the same signature as  handle  can be linked to controllers:     router \n     . route ( /path ) \n     . linkFunction (( req )   async   =   req ); \n     . linkFunction (( req )   async   =   Response . ok ( null ));   Linking a function has all of the same behavior as  Controller.handle : it can return a request or response, automatically handles exceptions, and can have controllers (and functions) linked to it.", 
            "title": "Linking Functions"
        }, 
        {
            "location": "/http/controller/#controller-instantiation-and-recycling", 
            "text": "It is important to understand why  link  takes a closure, instead of a controller object. Aqueduct is an object oriented framework. Objects have both state and behavior. An application will receive multiple requests that will be handled by the same type of controller. If a mutable controller object were reused to handle multiple requests, it could retain some of its state between requests. This would create problems that are difficult to debug.  Most controllers are immutable - in other words, all of their properties are final and they have no setters. This (mostly) ensures that the controller won't change behavior between requests. When a controller is immutable, the  link  closure is invoked once to create and link the controller object, and then the closure is discarded. The same controller object will be reused for every request.  Controllers can be mutable, with the caveat that they cannot be reused for multiple requests. For example, a  ResourceController  can have properties that are bound to the values of a request, and therefore these properties will change and a new instance must be created for each request.  A mutable  Controller  subclass must implement  Recyclable T . The  link  closure will be invoked for each request, creating a new instance of the recyclable controller to handle the request. If a controller has an expensive initialization process, the results of that initialization can be calculated once and reused for each controller instance by implementing the methods from  Recyclable T .  class   MyControllerState   { \n   dynamic   stuff ;  }  class   MyController   extends   Controller   implements   Recyclable MyControllerState   { \n   @ override \n   MyControllerState   get   recycledState   =   expensiveCalculation (); \n\n   @ override \n   void   restore ( MyControllerState   state )   { \n     _restoredState   =   state ; \n   } \n\n   MyControllerState   _restoredState ; \n\n   @ override \n   FutureOr RequestOrResponse   handle ( Request   request )   async   { \n     /* use _restoredState */ \n     return   new   Response . ok (...); \n   }  }   The  recycledState  getter is called once, when the controller is first linked. Each new instance of a recyclable controller has its  restore  method invoked prior to handling the request, and the data returned by  recycledState  is passed as an argument. As an example,  ResourceController  'compiles' its operation methods. The compiled product is stored as recycled state so that future instances can bind request data more efficiently.", 
            "title": "Controller Instantiation and Recycling"
        }, 
        {
            "location": "/http/controller/#exception-handling", 
            "text": "If an exception or error is thrown during the handling of a request, the controller currently handling the request will catch it. For the majority of values caught, a controller will send a 500 Server Response. The details of the exception or error will be  logged , and the request is removed from the channel (it will not be passed to a linked controller).  This is the default behavior for all thrown values except  Response  and  HandlerException .", 
            "title": "Exception Handling"
        }, 
        {
            "location": "/http/controller/#throwing-responses", 
            "text": "A  Response  can be thrown at any time; the controller handling the request will catch it and send it to the client. This completes the request. This might not seem useful, for example, the following shows a silly use of this behavior:  class   Thrower   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     if   ( ! isForbidden ( request ))   { \n       throw   new   Response . forbidden (); \n     } \n\n     return   Response . ok ( null ); \n   }  }", 
            "title": "Throwing Responses"
        }, 
        {
            "location": "/http/controller/#throwing-handlerexceptions", 
            "text": "Exceptions can implement  HandlerException  to provide a response other than the default when thrown. For example, an application that handles bank transactions might declare an exception for invalid withdrawals:  enum   WithdrawalProblem   { \n   insufficientFunds , \n   bankClosed  }  class   WithdrawalException   implements   Exception   { \n   WithdrawalException ( this . problem ); \n\n   final   WithdrawalProblem   problem ;  }   Controller code can catch this exception to return a different status code depending on the exact problem with a withdrawal. If this code has to be written in multiple places, it is useful for  WithdrawalException  to implement  HandlerException . An implementor must provide an implementation for  response :  class   WithdrawalException   implements   HandlerException   { \n   WithdrawalException ( this . problem ); \n\n   final   WithdrawalProblem   problem ; \n\n   @ override \n   Response   get   response   { \n     switch   ( problem )   { \n       case   WithdrawalProblem . insufficientFunds: \n         return   new   Response . badRequest ( body:   { error :   insufficient_funds }); \n       case   WithdrawalProblem . bankClosed: \n         return   new   Response . badRequest ( body:   { error :   bank_closed }); \n     } \n   }  }", 
            "title": "Throwing HandlerExceptions"
        }, 
        {
            "location": "/http/controller/#cors-headers-and-preflight-requests", 
            "text": "Controller s have built-in behavior for handling CORS requests. They will automatically respond to  OPTIONS  preflight requests and attach CORS headers to any other response. See  the chapter on CORS  for more details.", 
            "title": "CORS Headers and Preflight Requests"
        }, 
        {
            "location": "/http/request_and_response/", 
            "text": "Serializing Request and Response Bodies\n\n\nIn Aqueduct, HTTP requests and responses are instances of \nRequest\ns and \nResponse\ns. For each HTTP request an application receives, an instance of \nRequest\n is created. A \nResponse\n must be created for each request. Responses are created by \ncontroller objects\n. This guide discusses the behavior of request and response objects.\n\n\nThe Request Object\n\n\nA \nRequest\n is created for each HTTP request to your application. A \nRequest\n stores everything about the HTTP request and has some additional behavior that makes reading from them easier. You handle requests by writing code in a \ncontroller object\n or closures.\n\n\nAll properties of a request are available in its \nraw\n property (a Dart standard library \nHttpRequest\n). A \nRequest\n has \nattachments\n that data can be attached to in a controller for use by a linked controller:\n\n\nrouter\n.\nroute\n(\n/path\n).\nlinkFunction\n((\nreq\n)\n \n{\n\n  \nreq\n.\nattachments\n[\nkey\n]\n \n=\n \nvalue\n;\n\n\n}).\nlinkFunction\n((\nreq\n)\n \n{\n\n  \nreturn\n \nResponse\n.\nok\n({\nkey\n:\n \nreq\n.\nattachments\n[\nvalue\n]});\n\n\n});\n\n\n\n\n\n\nA \nRequest\n also has two built-in attachments, \nauthorization\n and \npath\n. \nauthorization\n contains authorization information from an \nAuthorizer\n and \npath\n has request path information from a \nRouter\n.\n\n\nThe Response Object\n\n\nAn \nResponse\n has a status code, headers and body. The default constructor takes a status code, header map and body object. There are many named constructors for common response types:\n\n\nResponse\n(\n200\n,\n \n{\nx-header\n:\n \nvalue\n},\n \nbody:\n \n[\n1\n,\n \n2\n,\n \n3\n]);\n\n\nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n\nResponse\n.\ncreated\n();\n\n\nResponse\n.\nbadRequest\n(\nbody:\n \n{\nerror\n:\n \nreason\n});\n\n\n\n\n\n\nHeaders are encoded according to \ndart:io.HttpHeaders.add\n. For body encoding behavior, see the following sections.\n\n\nEncoding and Decoding the HTTP Body\n\n\nRequest\n and \nResponse\n objects have behavior for handling the HTTP body. You decode the contents of a \nRequest\n body into Dart objects that are used in your code. You provide a Dart object to a \nResponse\n and it is automatically encoded according to the content-type of the response.\n\n\nDecoding Request Bodies\n\n\nEvery \nRequest\n has a \nbody\n property. This object decodes the bytes from the request body into Dart objects. The behavior for decoding is determined by the content-type header of the request (see the section on \nCodecRegistry\n later in this guide). When you decode a body, you can specify the Dart object type you expect it to be. If the decoded body object is not the expected type, an exception that sends a 400 Bad Request error is thrown.\n\n\n// Ensures that the decoded body is a Map\nString, dynamic\n\n\nfinal\n \nmap\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\nMap\nString\n,\n \ndynamic\n();\n\n\n\n// Takes whatever object the body is decoded into\n\n\nfinal\n \nanyObject\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\n();\n\n\n\n\n\n\nOnce a request's body has been decoded, it can be accessed through a synchronous \nas\n method. This method also takes a type argument to enforce the type of the decoded body object.\n\n\nfinal\n \nmap\n \n=\n \nrequest\n.\nbody\n.\nas\nMap\nString\n,\n \ndynamic\n();\n\n\n\n\n\n\n\n\nInferred Types\n\n\nYou don't need to provide a type argument to \nas\n or \ndecode\n if the type can be inferred. For example, \nobject.read(await request.body.decode())\n will infer the type of the decoded body as a \nMap\nString, dynamic\n without having to provide type parameters.\n\n\n\n\nIf a body cannot be decoded according to its content-type (the data is malformed), an error is thrown that sends the appropriate error response to the client.\n\n\nFor more request body behavior, see the API reference for \nRequestBody\n, the \nsection on body binding for ResourceControllers\n and a later section in this guide on \nSerializable\n.\n\n\n\n\nMax Body Size\n\n\nThe size of a request body is limited to 10MB by default and can be changed by setting the value of \nRequestBody.maxSize\n during application initialization.\n\n\n\n\nEncoding Response Body Objects\n\n\nAn HTTP response often contains a \nbody\n. For example, the body in response to \nGET /users/1\n might be JSON object that represents a user. To ensure the client understands that the body is a JSON object, it includes the header \nContent-Type: application/json; charset=utf-8\n.\n\n\nWhen creating a \nResponse\n that has a body, you provide a \nbody object\n and a \ncontentType\n. For example:\n\n\nvar\n \nmap\n \n=\n \n{\nkey\n:\n \nvalue\n};\n\n\n\n// ContentType.json is the default, setting it may be omitted.\n\n\n// ContentType.json == `application/json; charset=utf-8\n\n\nfinal\n \nresponse\n \n=\n \nResponse\n.\nok\n(\nmap\n)\n\n  \n..\ncontentType\n \n=\n \nContentType\n.\njson\n;\n\n\n\n\n\n\nBody objects are encoded according to their content-type. In the above, \nmap\n is first encoded as a JSON string and then to a list of UTF8 bytes.\n\n\n\n\nA \nContentType\n is made up of three components: a primary type, a subtype and an optional character set.\n\n\n\n\nThe primary and subtype determine the first conversion step and the charset determines the next. Each step is performed by an instance of \nCodec\n (from \ndart:convert\n). For example, the content type \napplication/json\n selects \nJsonCodec\n, while charset \nutf-8\n selects \nUtf8Codec\n. These two codecs are run in succession to convert the \nMap\n to a list of bytes. The codec is selected by your application's \nCodecRegistry\n; this is covered in later section.\n\n\nThe body object must be valid for the selected codec. In the above example, a \nMap\nString, dynamic\n can be encoded by a \nJsonCodec\n. But if the body object cannot be encoded, a 500 Server Error response is sent. A valid input for one \nCodec\n may not be valid for another; it is up to you to ensure that the body object is valid for the \ncontentType\n of the response.\n\n\nNot all content types require two conversion steps. For example, when serving an HTML file, the body object is already an HTML \nString\n. It will only be converted by a charset encoder:\n\n\nvar\n \nhtml\n \n=\n \nhtml\n/html\n;\n\n\nvar\n \nresponse\n \n=\n \nResponse\n.\nok\n(\nhtml\n)\n\n  \n..\ncontentType\n \n=\n \nContentType\n.\nhtml\n;\n\n\n\n\n\n\nAnd an image body object needs no conversion at all, since it is already a list of bytes. If there is no registered codec for a content-type, the body object must be a byte array (\nList\nint\n where each value is between 0-255).\n\n\nfinal\n \nimageFile\n \n=\n \nFile\n(\nimage.jpg\n);\n\n\nfinal\n \nimageBytes\n \n=\n \nawait\n \nimageFile\n.\nreadAsBytes\n();\n\n\nfinal\n \nresponse\n \n=\n \nResponse\n.\nok\n(\nimageBytes\n)\n\n  \n..\ncontentType\n \n=\n \nContentType\n(\nimage\n,\n \njpeg\n);\n\n\n\n\n\n\nYou may disable the automatic encoding of a body as long as the body object is a byte array:\n\n\nfinal\n \njsonBytes\n \n=\n \nutf8\n.\nencode\n(\njson\n.\nencode\n({\nkey\n:\n \nvalue\n}));\n\n\nfinal\n \nresponse\n \n=\n \nResponse\n.\nok\n(\njsonBytes\n)..\nencodeBody\n \n=\n \nfalse\n;\n\n\n\n\n\n\nSee a later section for more details on content type to codec mappings. Also, see the documentation for \nCodecRegistry\n for details on built-in codecs and adding codecs.\n\n\nStreaming Response Bodies\n\n\nA body object may also be a \nStream\nT\n. \nStream\nT\n body objects are most often used when serving files. This allows the contents of the file to be streamed from disk to the HTTP client without having to load the whole file into memory first. (See also \nFileController\n.)\n\n\nfinal\n \nimageFile\n \n=\n \nFile\n(\nimage.jpg\n);\n\n\nfinal\n \nimageByteStream\n \n=\n \nimageFile\n.\nopenRead\n();\n\n\nfinal\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nimageByteStream\n)\n\n  \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\nimage\n,\n \njpeg\n);\n\n\n\n\n\n\nWhen a body object is a \nStream\nT\n, the response will not be sent until the stream is closed. For finite streams - like those from opened filed - this happens as soon as the entire file is read. For streams that you construct yourself, you must close the stream some time after the response has been returned.\n\n\nCodecs and Content Types\n\n\nIn the above sections, we glossed over how a codec gets selected when preparing the response body. The common case of \nManagedObject\nT\n body objects that are sent as UTF8 encoded JSON 'just works' and is suitable for most applications. When serving assets for a web application or different data formats like XML, it becomes important to understand how Aqueduct's codec registry works.\n\n\nCodecRegistry\n contains mappings from content types to \nCodec\ns. These codecs encode response bodies and decode request bodies. There are three built-in codecs for \napplication/json\n, \napplication/x-www-form-urlencoded\n and \ntext/*\n. When a response is being sent, the repository is searched for an entry that exactly matches the primary and subtype of the \nResponse.contentType\n. If an entry exists, the associated \nCodec\n starts the conversion. For example, if the content type is \napplication/json; charset=utf-8\n, the built-in \napplication/json\n codec encodes the body object.\n\n\nIf there isn't an exact match, but there is an entry for the primary type with the wildcard (\n*\n) subtype, that codec is used. For example, the built-in codec for \ntext/*\n will be selected for both \ntext/plain\n and \ntext/html\n. If there was something special that had to be done for \ntext/html\n, a more specific codec may be added for that type:\n\n\nclass\n \nMyChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nCodecRegistry\n.\ndefaultInstance\n.\nadd\n(\nContentType\n(\napplication\n,\n \nhtml\n),\n \nHTMLCodec\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nCodecs must be added in your \nApplicationChannel.prepare\n method. The codec must implement \nCodec\n from \ndart:convert\n. In the above example, when a response's content type is \ntext/html\n, the \nHTMLCodec\n will encode the body object. This codec takes precedence over \ntext/*\n because it is more specific.\n\n\nWhen selecting a codec for a response body, the \nContentType.charset\n doesn't impact which codec is selected. If a response's content-type has a charset, then a charset encoder like \nUTF8\n will be applied as a last encoding step. For example, a response with content-type \napplication/json; charset=utf-8\n will encode the body object as a JSON string, which is then encoded as a list of UTF8 bytes. It is required that a response body's eventually encoded type is a list of bytes, so it follows that a codec that produces a string must have a charset.\n\n\nIf there is no codec in the repository for the content type of a \nResponse\n, the body object must be a \nList\nint\n or \nStream\nList\nint\n. If you find yourself converting data prior to setting it as a body object, it may make sense to add your own codec to \nCodecRegistry\n.\n\n\nA request's body always starts as a list of bytes and is decoded into Dart objects. To decode a JSON request body, it first must be decoded from the list of UTF8 bytes into a string. It is possible that a client could omit the charset in its content-type header. Codecs added to \nCodecRegistry\n may specify a default charset to interpret a charset-less content-type. When a codec is added to the repository, if content-type's charset is non-null, that is the default. For example, the JSON codec is added like this:\n\n\nCodecRegistry\n.\ndefaultInstance\n.\nadd\n(\n\n  \nContentType\n(\napplication\n,\n \njson\n,\n \ncharset:\n \nutf-8\n),\n\n  \nconst\n \nJsonCodec\n(),\n\n  \nallowCompression:\n \ntrue\n);\n\n\n\n\n\n\nIf no charset is specified when registering a codec, no charset decoding occurs on a request body if one doesn't exist. Content-types that are decoded from a \nString\n should not use a default charset because the repository would always attempt to decode the body as a string first.\n\n\nCompression with gzip\n\n\nBody objects may be compressed with \ngzip\n if the HTTP client allows it \nand\n the \nCodecRegistry\n has been configured to compress the content type of the response. The three built-in codecs - \napplication/json\n, \napplication/x-www-form-urlencoded\n and \ntext/*\n - are all configured to allow compression. Compression occurs as the last step of conversion and only if the HTTP client sends the \nAccept-Encoding: gzip\n header.\n\n\nContent types that are not in the codec repository will not trigger compression, even if the HTTP client allows compression with the \nAccept-Encoding\n header. This is to prevent binary contents like images from being 'compressed', since they are likely already compressed by a content-specific algorithm. In order for Aqueduct to compress a content type other than the built-in types, you may add a codec to the repository with the \nallowCompression\n flag. (The default value is \ntrue\n.)\n\n\nCodecRegistry\n.\nadd\n(\n\n  \nContentType\n(\napplication\n,\n \nx-special\n),\n\n   \nMyCodec\n(),\n\n  \nallowCompression:\n \ntrue\n);\n\n\n\n\n\n\nYou may also set whether or not a content type uses compression without having to specify a codec if no conversion step needs to occur:\n\n\nCodecRegistry\n.\nsetAllowsCompression\n(\nnew\n \nContentType\n(\napplication\n,\n \nx-special\n),\n \ntrue\n);\n\n\n\n\n\n\nSerializable Objects\n\n\nMost request and response bodies are JSON objects and lists of objects. In Dart, JSON objects are maps. A \nSerializable\n object can be read from a map and converted back into a map. You subclass \nSerializable\n to assign keys from a map to properties of a your subclass, and to write its properties back to a map. This allows static types you declare in your application to represent expected request and response bodies. Aqueduct's ORM type \nManagedObject\n is a \nSerializable\n, for example.\n\n\nSending Serializable Objects as Response Bodies\n\n\nThe body object of a response can be a \nSerializable\n. Before the response is sent, \nasMap()\n is called before the body object is encoded into JSON (or some other transmission format).\n\n\nFor example, a single serializable object returned in a 200 OK response:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nPerson\n(\ncontext\n)..\nwhere\n((\np\n)\n \n=\n \np\n.\nid\n).\nequalTo\n(\n1\n);\n\n\nfinal\n \nperson\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\nfinal\n \nresponse\n \n=\n \nResponse\n.\nok\n(\nperson\n);\n\n\n\n\n\n\nA response body object can also be a list of \nSerializable\n objects.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nPerson\n(\ncontext\n);\n\n\nfinal\n \npeople\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\nfinal\n \nresponse\n \n=\n \nResponse\n.\nok\n(\npeople\n);\n\n\n\n\n\n\nThe flow of a body object is shown in the following diagram. Each orange item is an allowed body object type and shows the steps it will go through when being encoded to the HTTP response body. For example, a \nSerializable\n goes through three steps, whereas a \nList\nint\n goes through zero steps and is added as-is to the HTTP response.\n\n\n\n\nReading Serializable Objects from Request Bodies\n\n\nA serializable object can be read from a request body:\n\n\nfinal\n \nperson\n \n=\n \nPerson\n()..\nread\n(\nawait\n \nrequest\n.\nbody\n.\ndecode\n());\n\n\n\n\n\n\nA list of serializable objects as well:\n\n\nList\nMap\nString\n,\n \ndynamic\n \nobjects\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\n();\n\n\nfinal\n \npeople\n \n=\n \nobjects\n.\nmap\n((\no\n)\n \n=\n \nPerson\n()..\nread\n(\no\n)).\ntoList\n();\n\n\n\n\n\n\nBoth serializable and a list of serializable can be \nbound to a operation method parameter in a ResourceController\n.\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \naddPerson\n(\n@\nBind\n.\nbody\n()\n \nPerson\n \nperson\n)\n \nasync\n \n{\n\n  \nfinal\n \ninsertedPerson\n \n=\n \nawait\n \ncontext\n.\ninsertObject\n(\nperson\n);\n\n  \nreturn\n \nResponse\n.\nok\n(\ninsertedPerson\n);\n\n\n}\n\n\n\n\n\n\nKey Filtering\n\n\nBoth \nread\n and \nBind.body\n (when binding a \nSerializable\n) support key filtering. A key filter is a list of keys that either discard keys from the body, requires keys in the body, or throws an error if a key exists in the body. Example:\n\n\nfinal\n \nperson\n \n=\n \nPerson\n()\n\n  \n..\nread\n(\nawait\n \nrequest\n.\nbody\n.\ndecode\n(),\n\n         \nignore:\n \n[\nid\n],\n\n         \nreject:\n \n[\npassword\n],\n\n         \nrequire:\n \n[\nname\n,\n \nheight\n,\n \nweight\n]);\n\n\n\n\n\n\nIn the above: if the body contains 'id', the value is discarded immediately; if the body contains 'password', a 400 status code exception is thrown; and if the body doesn't contain all of name, height and weight, a 400 status code exception is thrown.\n\n\nWhen binding a list of serializables, filters are applied to each element of the list.\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \naddPerson\n(\n@\nBind\n.\nbody\n(\nreject:\n \n[\nprivateInfo\n])\n \nList\nPerson\n \npeople\n)\n \nasync\n \n{\n\n  \n// if any Person in the body contains the privateInfo key, a 400 Bad Request is sent and this method\n\n  \n// is not called\n\n\n}\n\n\n\n\n\n\nSubclassing Serializable\n\n\nA \nSerializable\n object must implement a \nreadFromMap()\n and \nasMap()\n.\n\n\nAn object that extends \nSerializable\n may be used as a response body object directly:\n\n\nclass\n \nPerson\n \nextends\n \nSerializable\n \n{\n\n  \nString\n \nname\n;\n\n  \nString\n \nemail\n;\n\n\n  \nMap\nString\n,\n \ndynamic\n \nasMap\n()\n \n{\n\n    \nreturn\n \n{\n\n      \nname\n:\n \nname\n,\n\n      \nemail\n:\n \nemail\n\n    \n};\n\n  \n}\n\n\n  \nvoid\n \nreadFromMap\n(\nMap\nString\n,\n \ndynamic\n \ninputMap\n)\n \n{\n\n    \nname\n \n=\n \ninputMap\n[\nname\n];\n\n    \nemail\n \n=\n \ninputMap\n[\nemail\n];\n\n  \n}\n\n\n}\n\n\n\nfinal\n \nperson\n \n=\n \nPerson\n();\n\n\nfinal\n \nresponse\n \n=\n \nResponse\n.\nok\n(\nperson\n);\n\n\n\n\n\n\nreadFromMap\n is invoked by \nread\n, after all filters have been applied.\n\n\nSerializable and OpenAPI Generation\n\n\nSee the section on how \nSerializable\n types work with OpenAPI documentation generation \nhere\n.", 
            "title": "Serializing Request and Response Bodies"
        }, 
        {
            "location": "/http/request_and_response/#serializing-request-and-response-bodies", 
            "text": "In Aqueduct, HTTP requests and responses are instances of  Request s and  Response s. For each HTTP request an application receives, an instance of  Request  is created. A  Response  must be created for each request. Responses are created by  controller objects . This guide discusses the behavior of request and response objects.", 
            "title": "Serializing Request and Response Bodies"
        }, 
        {
            "location": "/http/request_and_response/#the-request-object", 
            "text": "A  Request  is created for each HTTP request to your application. A  Request  stores everything about the HTTP request and has some additional behavior that makes reading from them easier. You handle requests by writing code in a  controller object  or closures.  All properties of a request are available in its  raw  property (a Dart standard library  HttpRequest ). A  Request  has  attachments  that data can be attached to in a controller for use by a linked controller:  router . route ( /path ). linkFunction (( req )   { \n   req . attachments [ key ]   =   value ;  }). linkFunction (( req )   { \n   return   Response . ok ({ key :   req . attachments [ value ]});  });   A  Request  also has two built-in attachments,  authorization  and  path .  authorization  contains authorization information from an  Authorizer  and  path  has request path information from a  Router .", 
            "title": "The Request Object"
        }, 
        {
            "location": "/http/request_and_response/#the-response-object", 
            "text": "An  Response  has a status code, headers and body. The default constructor takes a status code, header map and body object. There are many named constructors for common response types:  Response ( 200 ,   { x-header :   value },   body:   [ 1 ,   2 ,   3 ]);  Response . ok ({ key :   value });  Response . created ();  Response . badRequest ( body:   { error :   reason });   Headers are encoded according to  dart:io.HttpHeaders.add . For body encoding behavior, see the following sections.", 
            "title": "The Response Object"
        }, 
        {
            "location": "/http/request_and_response/#encoding-and-decoding-the-http-body", 
            "text": "Request  and  Response  objects have behavior for handling the HTTP body. You decode the contents of a  Request  body into Dart objects that are used in your code. You provide a Dart object to a  Response  and it is automatically encoded according to the content-type of the response.", 
            "title": "Encoding and Decoding the HTTP Body"
        }, 
        {
            "location": "/http/request_and_response/#decoding-request-bodies", 
            "text": "Every  Request  has a  body  property. This object decodes the bytes from the request body into Dart objects. The behavior for decoding is determined by the content-type header of the request (see the section on  CodecRegistry  later in this guide). When you decode a body, you can specify the Dart object type you expect it to be. If the decoded body object is not the expected type, an exception that sends a 400 Bad Request error is thrown.  // Ensures that the decoded body is a Map String, dynamic  final   map   =   await   request . body . decode Map String ,   dynamic ();  // Takes whatever object the body is decoded into  final   anyObject   =   await   request . body . decode ();   Once a request's body has been decoded, it can be accessed through a synchronous  as  method. This method also takes a type argument to enforce the type of the decoded body object.  final   map   =   request . body . as Map String ,   dynamic ();    Inferred Types  You don't need to provide a type argument to  as  or  decode  if the type can be inferred. For example,  object.read(await request.body.decode())  will infer the type of the decoded body as a  Map String, dynamic  without having to provide type parameters.   If a body cannot be decoded according to its content-type (the data is malformed), an error is thrown that sends the appropriate error response to the client.  For more request body behavior, see the API reference for  RequestBody , the  section on body binding for ResourceControllers  and a later section in this guide on  Serializable .   Max Body Size  The size of a request body is limited to 10MB by default and can be changed by setting the value of  RequestBody.maxSize  during application initialization.", 
            "title": "Decoding Request Bodies"
        }, 
        {
            "location": "/http/request_and_response/#encoding-response-body-objects", 
            "text": "An HTTP response often contains a  body . For example, the body in response to  GET /users/1  might be JSON object that represents a user. To ensure the client understands that the body is a JSON object, it includes the header  Content-Type: application/json; charset=utf-8 .  When creating a  Response  that has a body, you provide a  body object  and a  contentType . For example:  var   map   =   { key :   value };  // ContentType.json is the default, setting it may be omitted.  // ContentType.json == `application/json; charset=utf-8  final   response   =   Response . ok ( map ) \n   .. contentType   =   ContentType . json ;   Body objects are encoded according to their content-type. In the above,  map  is first encoded as a JSON string and then to a list of UTF8 bytes.   A  ContentType  is made up of three components: a primary type, a subtype and an optional character set.   The primary and subtype determine the first conversion step and the charset determines the next. Each step is performed by an instance of  Codec  (from  dart:convert ). For example, the content type  application/json  selects  JsonCodec , while charset  utf-8  selects  Utf8Codec . These two codecs are run in succession to convert the  Map  to a list of bytes. The codec is selected by your application's  CodecRegistry ; this is covered in later section.  The body object must be valid for the selected codec. In the above example, a  Map String, dynamic  can be encoded by a  JsonCodec . But if the body object cannot be encoded, a 500 Server Error response is sent. A valid input for one  Codec  may not be valid for another; it is up to you to ensure that the body object is valid for the  contentType  of the response.  Not all content types require two conversion steps. For example, when serving an HTML file, the body object is already an HTML  String . It will only be converted by a charset encoder:  var   html   =   html /html ;  var   response   =   Response . ok ( html ) \n   .. contentType   =   ContentType . html ;   And an image body object needs no conversion at all, since it is already a list of bytes. If there is no registered codec for a content-type, the body object must be a byte array ( List int  where each value is between 0-255).  final   imageFile   =   File ( image.jpg );  final   imageBytes   =   await   imageFile . readAsBytes ();  final   response   =   Response . ok ( imageBytes ) \n   .. contentType   =   ContentType ( image ,   jpeg );   You may disable the automatic encoding of a body as long as the body object is a byte array:  final   jsonBytes   =   utf8 . encode ( json . encode ({ key :   value }));  final   response   =   Response . ok ( jsonBytes ).. encodeBody   =   false ;   See a later section for more details on content type to codec mappings. Also, see the documentation for  CodecRegistry  for details on built-in codecs and adding codecs.", 
            "title": "Encoding Response Body Objects"
        }, 
        {
            "location": "/http/request_and_response/#streaming-response-bodies", 
            "text": "A body object may also be a  Stream T .  Stream T  body objects are most often used when serving files. This allows the contents of the file to be streamed from disk to the HTTP client without having to load the whole file into memory first. (See also  FileController .)  final   imageFile   =   File ( image.jpg );  final   imageByteStream   =   imageFile . openRead ();  final   response   =   new   Response . ok ( imageByteStream ) \n   .. contentType   =   new   ContentType ( image ,   jpeg );   When a body object is a  Stream T , the response will not be sent until the stream is closed. For finite streams - like those from opened filed - this happens as soon as the entire file is read. For streams that you construct yourself, you must close the stream some time after the response has been returned.", 
            "title": "Streaming Response Bodies"
        }, 
        {
            "location": "/http/request_and_response/#codecs-and-content-types", 
            "text": "In the above sections, we glossed over how a codec gets selected when preparing the response body. The common case of  ManagedObject T  body objects that are sent as UTF8 encoded JSON 'just works' and is suitable for most applications. When serving assets for a web application or different data formats like XML, it becomes important to understand how Aqueduct's codec registry works.  CodecRegistry  contains mappings from content types to  Codec s. These codecs encode response bodies and decode request bodies. There are three built-in codecs for  application/json ,  application/x-www-form-urlencoded  and  text/* . When a response is being sent, the repository is searched for an entry that exactly matches the primary and subtype of the  Response.contentType . If an entry exists, the associated  Codec  starts the conversion. For example, if the content type is  application/json; charset=utf-8 , the built-in  application/json  codec encodes the body object.  If there isn't an exact match, but there is an entry for the primary type with the wildcard ( * ) subtype, that codec is used. For example, the built-in codec for  text/*  will be selected for both  text/plain  and  text/html . If there was something special that had to be done for  text/html , a more specific codec may be added for that type:  class   MyChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     CodecRegistry . defaultInstance . add ( ContentType ( application ,   html ),   HTMLCodec ()); \n   }  }   Codecs must be added in your  ApplicationChannel.prepare  method. The codec must implement  Codec  from  dart:convert . In the above example, when a response's content type is  text/html , the  HTMLCodec  will encode the body object. This codec takes precedence over  text/*  because it is more specific.  When selecting a codec for a response body, the  ContentType.charset  doesn't impact which codec is selected. If a response's content-type has a charset, then a charset encoder like  UTF8  will be applied as a last encoding step. For example, a response with content-type  application/json; charset=utf-8  will encode the body object as a JSON string, which is then encoded as a list of UTF8 bytes. It is required that a response body's eventually encoded type is a list of bytes, so it follows that a codec that produces a string must have a charset.  If there is no codec in the repository for the content type of a  Response , the body object must be a  List int  or  Stream List int . If you find yourself converting data prior to setting it as a body object, it may make sense to add your own codec to  CodecRegistry .  A request's body always starts as a list of bytes and is decoded into Dart objects. To decode a JSON request body, it first must be decoded from the list of UTF8 bytes into a string. It is possible that a client could omit the charset in its content-type header. Codecs added to  CodecRegistry  may specify a default charset to interpret a charset-less content-type. When a codec is added to the repository, if content-type's charset is non-null, that is the default. For example, the JSON codec is added like this:  CodecRegistry . defaultInstance . add ( \n   ContentType ( application ,   json ,   charset:   utf-8 ), \n   const   JsonCodec (), \n   allowCompression:   true );   If no charset is specified when registering a codec, no charset decoding occurs on a request body if one doesn't exist. Content-types that are decoded from a  String  should not use a default charset because the repository would always attempt to decode the body as a string first.", 
            "title": "Codecs and Content Types"
        }, 
        {
            "location": "/http/request_and_response/#compression-with-gzip", 
            "text": "Body objects may be compressed with  gzip  if the HTTP client allows it  and  the  CodecRegistry  has been configured to compress the content type of the response. The three built-in codecs -  application/json ,  application/x-www-form-urlencoded  and  text/*  - are all configured to allow compression. Compression occurs as the last step of conversion and only if the HTTP client sends the  Accept-Encoding: gzip  header.  Content types that are not in the codec repository will not trigger compression, even if the HTTP client allows compression with the  Accept-Encoding  header. This is to prevent binary contents like images from being 'compressed', since they are likely already compressed by a content-specific algorithm. In order for Aqueduct to compress a content type other than the built-in types, you may add a codec to the repository with the  allowCompression  flag. (The default value is  true .)  CodecRegistry . add ( \n   ContentType ( application ,   x-special ), \n    MyCodec (), \n   allowCompression:   true );   You may also set whether or not a content type uses compression without having to specify a codec if no conversion step needs to occur:  CodecRegistry . setAllowsCompression ( new   ContentType ( application ,   x-special ),   true );", 
            "title": "Compression with gzip"
        }, 
        {
            "location": "/http/request_and_response/#serializable-objects", 
            "text": "Most request and response bodies are JSON objects and lists of objects. In Dart, JSON objects are maps. A  Serializable  object can be read from a map and converted back into a map. You subclass  Serializable  to assign keys from a map to properties of a your subclass, and to write its properties back to a map. This allows static types you declare in your application to represent expected request and response bodies. Aqueduct's ORM type  ManagedObject  is a  Serializable , for example.", 
            "title": "Serializable Objects"
        }, 
        {
            "location": "/http/request_and_response/#sending-serializable-objects-as-response-bodies", 
            "text": "The body object of a response can be a  Serializable . Before the response is sent,  asMap()  is called before the body object is encoded into JSON (or some other transmission format).  For example, a single serializable object returned in a 200 OK response:  final   query   =   Query Person ( context ).. where (( p )   =   p . id ). equalTo ( 1 );  final   person   =   await   query . fetchOne ();  final   response   =   Response . ok ( person );   A response body object can also be a list of  Serializable  objects.  final   query   =   Query Person ( context );  final   people   =   await   query . fetch ();  final   response   =   Response . ok ( people );   The flow of a body object is shown in the following diagram. Each orange item is an allowed body object type and shows the steps it will go through when being encoded to the HTTP response body. For example, a  Serializable  goes through three steps, whereas a  List int  goes through zero steps and is added as-is to the HTTP response.", 
            "title": "Sending Serializable Objects as Response Bodies"
        }, 
        {
            "location": "/http/request_and_response/#reading-serializable-objects-from-request-bodies", 
            "text": "A serializable object can be read from a request body:  final   person   =   Person ().. read ( await   request . body . decode ());   A list of serializable objects as well:  List Map String ,   dynamic   objects   =   await   request . body . decode ();  final   people   =   objects . map (( o )   =   Person ().. read ( o )). toList ();   Both serializable and a list of serializable can be  bound to a operation method parameter in a ResourceController .  @ Operation . post ()  Future Response   addPerson ( @ Bind . body ()   Person   person )   async   { \n   final   insertedPerson   =   await   context . insertObject ( person ); \n   return   Response . ok ( insertedPerson );  }", 
            "title": "Reading Serializable Objects from Request Bodies"
        }, 
        {
            "location": "/http/request_and_response/#key-filtering", 
            "text": "Both  read  and  Bind.body  (when binding a  Serializable ) support key filtering. A key filter is a list of keys that either discard keys from the body, requires keys in the body, or throws an error if a key exists in the body. Example:  final   person   =   Person () \n   .. read ( await   request . body . decode (), \n          ignore:   [ id ], \n          reject:   [ password ], \n          require:   [ name ,   height ,   weight ]);   In the above: if the body contains 'id', the value is discarded immediately; if the body contains 'password', a 400 status code exception is thrown; and if the body doesn't contain all of name, height and weight, a 400 status code exception is thrown.  When binding a list of serializables, filters are applied to each element of the list.  @ Operation . post ()  Future Response   addPerson ( @ Bind . body ( reject:   [ privateInfo ])   List Person   people )   async   { \n   // if any Person in the body contains the privateInfo key, a 400 Bad Request is sent and this method \n   // is not called  }", 
            "title": "Key Filtering"
        }, 
        {
            "location": "/http/request_and_response/#subclassing-serializable", 
            "text": "A  Serializable  object must implement a  readFromMap()  and  asMap() .  An object that extends  Serializable  may be used as a response body object directly:  class   Person   extends   Serializable   { \n   String   name ; \n   String   email ; \n\n   Map String ,   dynamic   asMap ()   { \n     return   { \n       name :   name , \n       email :   email \n     }; \n   } \n\n   void   readFromMap ( Map String ,   dynamic   inputMap )   { \n     name   =   inputMap [ name ]; \n     email   =   inputMap [ email ]; \n   }  }  final   person   =   Person ();  final   response   =   Response . ok ( person );   readFromMap  is invoked by  read , after all filters have been applied.", 
            "title": "Subclassing Serializable"
        }, 
        {
            "location": "/http/request_and_response/#serializable-and-openapi-generation", 
            "text": "See the section on how  Serializable  types work with OpenAPI documentation generation  here .", 
            "title": "Serializable and OpenAPI Generation"
        }, 
        {
            "location": "/http/routing/", 
            "text": "Routing\n\n\nWhat is routing?\n\n\nEvery HTTP request has a URL. A URL identifies a \nresource\n. In the early days of the Internet, a resource was a file. For example, the URL \nhttp://www.geocities.com/my_page/image.jpg\n would return the file \nimage.jpg\n from the folder \nmy_page\n on the webserver located at \nwww.geocities.com\n. In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide, create or modify a resource for a URL, wherever that resource might come from.\n\n\nA URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this: \nhttp://stablekernel.com/about\n. Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it.\n\n\nMore generally, the \"About\" page URL has the three required components of a URL: a \nscheme\n (\nhttp\n), a \nhost\n (\nstablekernel.com\n) and a \npath\n (\n/about\n). The host specifies the computer responsible for providing the resource, the path identifies the resource and the scheme lets both the requester and the host know how they should exchange information.\n\n\nAn Aqueduct application receives requests when the scheme is \nhttp\n (or \nhttps\n) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path.\n\n\nIn Aqueduct, a \nRouter\n routes \nRequest\ns to a \nController\n based on the request path. This process is known as \nrouting\n. When an application starts up, routes are registered in a subclass of \nApplicationChannel\n. Each registered route creates a new \nchannel\n of \nController\ns that will handle the request.\n\n\nRoute Specifications Match HTTP Request Paths\n\n\nA route is registered by invoking \nRouter.route\n. This method takes a \nroute specification\n - a \nString\n with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding \nApplicationChannel.entryPoint\n. For example:\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/users\n)\n\n      \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nnew\n \nResponse\n.\nok\n(\nawait\n \ngetAllUsers\n());\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe argument to \nroute\n is the route specification string. This particular route matches the path \n/users\n. That is, a request for the URL \nhttp://myserver.com/users\n will be handled by the \nlinkFunction\n closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.)\n\n\nA path can have multiple segments (the characters between slashes). For example, the path \n/users/foo\n has two path segments: \nusers\n and \nfoo\n. A route specification matches each segment of a path against each of its segments. The path and the route must also have the same number of segments. Thus, the route specification \n/users/foo\n would match the path \n/users/foo\n, but it would not match the paths \n/users\n, \n/users/7\n or \n/users/foo/1\n.\n\n\nPath Variables\n\n\nA route specification may have \npath variables\n. A path variable captures the value from a path segment, so that your code can use it. A path variable is most often used to uniquely identify a resource by some identifier, like \n/users/1\n and \n/users/2\n.\n\n\nIn a route specification, a path variable starts with a colon (\n:\n). The name of the variable follows this colon. For example, consider the following route that declares a path variable named \nuserID\n:\n\n\nrouter\n.\nroute\n(\n/users/:userID\n)\n\n\n\n\n\n\nThis route specification will match \n/users/1\n, \n/users/2\n, \n/users/foo\n, etc. The value of \nuserID\n is \n1\n, \n2\n and \nfoo\n, respectively. This route won't match \n/users\n or \n/users/1/2\n.\n\n\nOptional Path Segments\n\n\nRoutes may have optional path segments. This allows a group of routes that all refer to a resource collection and its individual resources to go to the same controller. For example, the requests \n/users\n and \n/users/1\n can both be covered by a single route specification.\n\n\nAn optional path segment has square brackets (\n[]\n) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both \n/users\n and \n/users/:userID\n:\n\n\nroute\n(\n/users/[:userID]\n)\n\n\nroute\n(\n/users[/:userID]\n)\n\n\n\n\n\n\nConceptually, a request with a path of \n/users/1\n identifies a single user, where \n/users\n identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same controller. Therefore, the code to handle one user or multiple users is written in the same place.\n\n\nYou may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match \n/a\n, \n/a/b\n and \n/a/b/c\n. It would not match \n/a/c\n.\n\n\nroute\n(\n/a/[b/[c]]\n)\n\n\n\n\n\n\nIt's pretty rare to have more than one optional segment in a route. For example, consider the route:\n\n\nroute\n(\n/users/[:id/[:subresource/[:subresourceid]]]\n);\n\n\n\n\n\n\nThe code to handle one or more users is likely very different than the code to handle one of its subresources - different database tables will be queried and different authorization may be needed. Thus, a better approach is to split subresources into their own routes to keep controller logic modular:\n\n\n// Matches /users and /users/:id\n\n\nroute\n(\n/users/[:id]\n)...;\n\n\n\n// Matches /users/:userId/posts and /users/:userId/posts/:postId\n\n\nroute\n(\n/users/:userId/posts/[:postId]\n)...;\n\n\n\n// Matches /users/:userId/notes and /users/:userId/notes/:noteId\n\n\nroute\n(\n/users/:userId/notes/[:noteId]\n)...;\n\n\n\n\n\n\nRestricting Path Variable Values\n\n\nPath variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits \nuserID\n to numbers only:\n\n\nroute\n(\n/users/:userID([0-9]+)\n)\n\n\n\n\n\n\nThis regular expression would only apply to the \n:userID\n segment. Note that capture groups and parentheses in general can't be included in a route's regular expression.\n\n\nEverything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression.\n\n\nMatching the Remaining Path\n\n\nFinally, a route specification may have a special 'match-all' token, the asterisk (\n*\n). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification \n/users/*\n would match the following paths:\n\n\n/users\n/users/1\n/users/foo\n/users/foo/bar\n/users/foo/bar/something/else/and/this/goes/on/forever\n\n\n\n\n\nThis token is used when another medium is going to interpret the URL. For example, \nFileController\n - which reads a file from the filesystem - might have a route \n/file/*\n. It uses everything after \n/file\n to figure out the path on the filesystem.\n\n\nAccessing Path Variables\n\n\nInformation that a router parses from a request path - like path variables - are stored in \nRequest.path\n. When a \nRequest\n is handled by a router, its \npath\n is set to an instance of this type. Controllers deeper in the channel access \nRequest.path\n to help determine which resource the request is identifying. The \npath\n is an instance of \nRequestPath\n.\n\n\nA \nRequestPath\n contains an map of \nvariables\n, where the key is path variable name and the value is the value of that variable in the request. For example, consider a route specification \n/users/:id\n. When a request with path \n/users/1\n is routed, the value \n1\n is stored in this map for the key \nid\n:\n\n\nfinal\n \nidentifier\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nid\n];\n\n\n// identifier = \n1\n\n\n\n\n\n\nThe values in \nvariables\n are always \nString\ns, since a request path is a \nString\n. \nController\ns may parse path variables into types like \nint\n.\n\n\nResourceController\n uses path variables to select a operation method to handle a request.\n\n\nFailed Matches Return 404\n\n\nA \nRouter\n will return a \n404 Not Found\n if there is no matching route for the request. No linked controllers will handle the request. This behavior may be overridden by providing a closure to \nRouter\n's constructor.", 
            "title": "Routing"
        }, 
        {
            "location": "/http/routing/#routing", 
            "text": "", 
            "title": "Routing"
        }, 
        {
            "location": "/http/routing/#what-is-routing", 
            "text": "Every HTTP request has a URL. A URL identifies a  resource . In the early days of the Internet, a resource was a file. For example, the URL  http://www.geocities.com/my_page/image.jpg  would return the file  image.jpg  from the folder  my_page  on the webserver located at  www.geocities.com . In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide, create or modify a resource for a URL, wherever that resource might come from.  A URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this:  http://stablekernel.com/about . Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it.  More generally, the \"About\" page URL has the three required components of a URL: a  scheme  ( http ), a  host  ( stablekernel.com ) and a  path  ( /about ). The host specifies the computer responsible for providing the resource, the path identifies the resource and the scheme lets both the requester and the host know how they should exchange information.  An Aqueduct application receives requests when the scheme is  http  (or  https ) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path.  In Aqueduct, a  Router  routes  Request s to a  Controller  based on the request path. This process is known as  routing . When an application starts up, routes are registered in a subclass of  ApplicationChannel . Each registered route creates a new  channel  of  Controller s that will handle the request.", 
            "title": "What is routing?"
        }, 
        {
            "location": "/http/routing/#route-specifications-match-http-request-paths", 
            "text": "A route is registered by invoking  Router.route . This method takes a  route specification  - a  String  with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding  ApplicationChannel.entryPoint . For example:  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /users ) \n       . linkFunction (( req )   async   =   new   Response . ok ( await   getAllUsers ()); \n\n     return   router ; \n   }  }   The argument to  route  is the route specification string. This particular route matches the path  /users . That is, a request for the URL  http://myserver.com/users  will be handled by the  linkFunction  closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.)  A path can have multiple segments (the characters between slashes). For example, the path  /users/foo  has two path segments:  users  and  foo . A route specification matches each segment of a path against each of its segments. The path and the route must also have the same number of segments. Thus, the route specification  /users/foo  would match the path  /users/foo , but it would not match the paths  /users ,  /users/7  or  /users/foo/1 .", 
            "title": "Route Specifications Match HTTP Request Paths"
        }, 
        {
            "location": "/http/routing/#path-variables", 
            "text": "A route specification may have  path variables . A path variable captures the value from a path segment, so that your code can use it. A path variable is most often used to uniquely identify a resource by some identifier, like  /users/1  and  /users/2 .  In a route specification, a path variable starts with a colon ( : ). The name of the variable follows this colon. For example, consider the following route that declares a path variable named  userID :  router . route ( /users/:userID )   This route specification will match  /users/1 ,  /users/2 ,  /users/foo , etc. The value of  userID  is  1 ,  2  and  foo , respectively. This route won't match  /users  or  /users/1/2 .", 
            "title": "Path Variables"
        }, 
        {
            "location": "/http/routing/#optional-path-segments", 
            "text": "Routes may have optional path segments. This allows a group of routes that all refer to a resource collection and its individual resources to go to the same controller. For example, the requests  /users  and  /users/1  can both be covered by a single route specification.  An optional path segment has square brackets ( [] ) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both  /users  and  /users/:userID :  route ( /users/[:userID] )  route ( /users[/:userID] )   Conceptually, a request with a path of  /users/1  identifies a single user, where  /users  identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same controller. Therefore, the code to handle one user or multiple users is written in the same place.  You may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match  /a ,  /a/b  and  /a/b/c . It would not match  /a/c .  route ( /a/[b/[c]] )   It's pretty rare to have more than one optional segment in a route. For example, consider the route:  route ( /users/[:id/[:subresource/[:subresourceid]]] );   The code to handle one or more users is likely very different than the code to handle one of its subresources - different database tables will be queried and different authorization may be needed. Thus, a better approach is to split subresources into their own routes to keep controller logic modular:  // Matches /users and /users/:id  route ( /users/[:id] )...;  // Matches /users/:userId/posts and /users/:userId/posts/:postId  route ( /users/:userId/posts/[:postId] )...;  // Matches /users/:userId/notes and /users/:userId/notes/:noteId  route ( /users/:userId/notes/[:noteId] )...;", 
            "title": "Optional Path Segments"
        }, 
        {
            "location": "/http/routing/#restricting-path-variable-values", 
            "text": "Path variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits  userID  to numbers only:  route ( /users/:userID([0-9]+) )   This regular expression would only apply to the  :userID  segment. Note that capture groups and parentheses in general can't be included in a route's regular expression.  Everything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression.", 
            "title": "Restricting Path Variable Values"
        }, 
        {
            "location": "/http/routing/#matching-the-remaining-path", 
            "text": "Finally, a route specification may have a special 'match-all' token, the asterisk ( * ). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification  /users/*  would match the following paths:  /users\n/users/1\n/users/foo\n/users/foo/bar\n/users/foo/bar/something/else/and/this/goes/on/forever  This token is used when another medium is going to interpret the URL. For example,  FileController  - which reads a file from the filesystem - might have a route  /file/* . It uses everything after  /file  to figure out the path on the filesystem.", 
            "title": "Matching the Remaining Path"
        }, 
        {
            "location": "/http/routing/#accessing-path-variables", 
            "text": "Information that a router parses from a request path - like path variables - are stored in  Request.path . When a  Request  is handled by a router, its  path  is set to an instance of this type. Controllers deeper in the channel access  Request.path  to help determine which resource the request is identifying. The  path  is an instance of  RequestPath .  A  RequestPath  contains an map of  variables , where the key is path variable name and the value is the value of that variable in the request. For example, consider a route specification  /users/:id . When a request with path  /users/1  is routed, the value  1  is stored in this map for the key  id :  final   identifier   =   request . path . variables [ id ];  // identifier =  1   The values in  variables  are always  String s, since a request path is a  String .  Controller s may parse path variables into types like  int .  ResourceController  uses path variables to select a operation method to handle a request.", 
            "title": "Accessing Path Variables"
        }, 
        {
            "location": "/http/routing/#failed-matches-return-404", 
            "text": "A  Router  will return a  404 Not Found  if there is no matching route for the request. No linked controllers will handle the request. This behavior may be overridden by providing a closure to  Router 's constructor.", 
            "title": "Failed Matches Return 404"
        }, 
        {
            "location": "/http/resource_controller/", 
            "text": "ResourceController\n\n\nA \nResourceController\n is a \ncontroller\n that provide conveniences for implementing endpoint controllers. A \nResourceController\n must be subclassed, and in that subclass, you write a method for each operation on that type of resource. For example, a \nUserController\n might handle the following operations:\n\n\n\n\ncreating a new user (\nPOST /users\n)\n\n\ngetting all users (\nGET /users\n)\n\n\ngetting an individual user (\nGET /users/:id\n)\n\n\nupdating an individual user (\nPUT /users/:id\n)\n\n\ndeleting an individual user (\nDELETE /users/:id\n)\n\n\n\n\nThese methods that are invoked for an operation are called \noperation methods\n.\n\n\nOperation Methods\n\n\nAn operation method is an instance method of a \nResourceController\n subclass that has an \n@Operation\n annotation. It must return an instance of \nFuture\nResponse\n. Here's an example:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllCities\n()\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n([\nAtlanta\n,\n \nMadison\n,\n \nMountain View\n]);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe above operation method will be invoked when \nCityController\n handles \nGET\n requests without path variables. To handle operation methods with path variables, the name of the path variable is added to the \n@Operation\n annotation:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllCities\n()\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n([\nAtlanta\n,\n \nMadison\n,\n \nMountain View\n]);\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nname\n)\n\n  \nFuture\nResponse\n \ngetCityByName\n()\n \nasync\n \n{\n\n    \nfinal\n \nid\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nname\n];\n\n    \nreturn\n \nResponse\n.\nok\n(\nfetchCityWithName\n(\nname\n));\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\n\nPath Variables\n\n\nThis controller would be linked to the route specification \n/cities/[:name]\n, so that it can handle both of these operations. Read more about path variables in \nRouting\n.\n\n\n\n\nThe named constructor of \nOperation\n tells us which HTTP method the operation method handles. The following named constructors exist:\n\n\n\n\nOperation.post()\n\n\nOperation.get()\n\n\nOperation.put()\n\n\nOperation.delete()\n\n\n\n\nThe canonical \nOperation()\n constructor takes the HTTP method as its first argument for non-standard operations, e.g.:\n\n\n@\nOperation\n(\nPATCH\n,\n \nid\n)\n\n\nFuture\nResponse\n \npatchObjectWithID\n()\n \nasync\n \n=\n \n...;\n\n\n\n\n\n\nAll \nOperation\n constructors take a variable list of path variables. There can be multiple path variables for an operation. An operation method will only be invoked if all of its path variables are present in the request path. There can be multiple operation methods for a given HTTP method, as long as each expects a different set of path variables.\n\n\nHere's an example of an operation that requires two path variables:\n\n\n@\nOperation\n.\nget\n(\nuserID\n,\n \nitemID\n)\n\n\nFuture\nResponse\n \ngetUserItem\n()\n \nasync\n \n{\n\n  \nfinal\n \nuserID\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nuserID\n];\n\n  \nfinal\n \nitemID\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nitemID\n];\n\n  \nreturn\n \nResponse\n.\nok\n(...);\n\n\n}\n\n\n\n\n\n\nIf no operation method exists for a request, a 405 Method Not Allowed response is automatically sent and no operation method is invoked.\n\n\nRouting to a ResourceController\n\n\nA \nResourceController\n subclass must be preceded by a \nRouter\n in the application channel. The \nRouter\n will parse path variables so that the controller can use them to determine which operation method should be invoked. A typical route to a \nResourceController\n contains an optional identifying path variable:\n\n\nrouter\n\n  \n.\nroute\n(\n/cities/[:name]\n)\n\n  \n.\nlink\n(()\n \n=\n \nCityController\n());\n\n\n\n\n\n\nThis route would allow \nCityController\n to implement operation methods for all HTTP methods with both no path variables and the 'name' path variable.\n\n\nIt is considered good practice to break sub-resources into their own controller. For example, the following is preferred:\n\n\nrouter\n\n  \n.\nroute\n(\n/cities/[:name]\n)\n\n  \n.\nlink\n(()\n \n=\n \nCityController\n());\n\n\n\nrouter\n\n  \n.\nroute\n(\n/cities/:name/attractions/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nCityAttractionController\n());\n\n\n\n\n\n\nBy contrast, the route \n/cities/[:name/[attractions/[:id]]]\n, while valid, makes controller logic much more unwieldy.\n\n\nRequest Bindings\n\n\nOperation methods may \nbind\n properties of an HTTP request to its parameters. When the operation method is invoked, the value of that property is passed as an argument to the operation method. For example, the following binds the header named 'X-API-Key' to the argument \napiKey\n:\n\n\n@\nOperation\n.\nget\n(\nname\n)\n\n\nFuture\nResponse\n \ngetCityByName\n(\n@\nBind\n.\nheader\n(\nx-api-key\n)\n \nString\n \napiKey\n)\n \nasync\n \n{\n\n  \nif\n \n(\n!\nisValid\n(\napiKey\n))\n \n{\n\n    \nreturn\n \nResponse\n.\nunauthorized\n();\n\n  \n}\n\n\n  \nreturn\n \nResponse\n.\nok\n(...);\n\n\n}\n\n\n\n\n\n\nThe following table shows the possible types of bindings:\n\n\n\n\n\n\n\n\nProperty\n\n\nBinding\n\n\n\n\n\n\n\n\n\n\nPath Variable\n\n\n@Bind.path(pathVariableName)\n\n\n\n\n\n\nURL Query Parameter\n\n\n@Bind.query(queryParameterName)\n\n\n\n\n\n\nHeader\n\n\n@Bind.header(headerName)\n\n\n\n\n\n\nRequest Body\n\n\n@Bind.body()\n\n\n\n\n\n\n\n\nYou may bind any number of HTTP request properties to a single operation method.\n\n\nOptional Bindings\n\n\nBindings can be made optional. If a binding is optional, the operation method will still be called even if the binding isn't in a request. To make a binding optional, wrap it in curly brackets.\n\n\n@\nOperation\n.\nget\n()\n\n\nFuture\nResponse\n \ngetAllCities\n({\n@\nBind\n.\nheader\n(\nx-api-key\n)\n \nString\n \napiKey\n})\n \nasync\n \n{\n\n  \nif\n \n(\napiKey\n \n==\n \nnull\n)\n \n{\n\n    \n// No X-API-Key in request\n\n    \n...\n\n  \n}\n\n  \n...\n\n\n}\n\n\n\n\n\n\nThe curly bracket syntax is a Dart language feature for optional method parameters (\nsee more here\n). If there are multiple optional parameters, use only one pair of curly brackets and list each optional parameter in those brackets.\n\n\nA bound parameter will be null if is not present in the request. You can provide a default value for optional parameters.\n\n\n@\nOperation\n.\nget\n()\n\n\nFuture\nResponse\n \ngetAllCities\n({\n@\nBind\n.\nheader\n(\nx-api-key\n)\n \nString\n \napiKey:\n \npublic\n})\n \nasync\n \n{\n\n  \n...\n\n\n}\n\n\n\n\n\n\nAutomatically Parsing Bindings\n\n\nQuery, header and path bindings can automatically be parsed into other types, such as \nint\n or \nDateTime\n. Simply declare the bound parameter's type to the desired type:\n\n\nFuture\nResponse\n \ngetCityByID\n(\n@\nBind\n.\nquery\n(\nid\n)\n \nint\n \ncityID\n)\n\n\n\n\n\n\nThe type of a bound parameter may be \nString\n or any type that implements \nparse\n (e.g., \nint\n, \nDateTime\n). Query parameters may also be bound to \nbool\n parameters; a boolean query parameter will be true if the query parameter has no value (e.g. \n/path?boolean\n).\n\n\nIf parsing fails for any reason, an error response is sent and the operation method is not called. For example, the above example binds \nint cityID\n - if the path variable 'id' can't be parsed into an \nint\n, a 404 Not Found response is sent. If a query parameter or header value cannot be parsed, a 400 Bad Request response is sent.\n\n\nYou may also bind \nList\nT\n parameters to headers and query parameters, where \nT\n must meet the same criteria as above. Query parameters and headers may appear more than once in a request. For example, the value of \nids\n is \n[1, 2]\n if the request URL ends with \n/path?id=1\nid=2\n and the operation method looks like this:\n\n\nFuture\nResponse\n \ngetCitiesByIDs\n(\n@\nBind\n.\nquery\n(\nid\n)\n \nList\nint\n \nids\n)\n\n\n\n\n\n\nNote that if a parameter is \nnot\n bound to a list and there are multiple occurrences of that property in the request, a 400 Bad Request response will be sent. If you want to allow multiple values, you must bind to a \nList\nT\n.\n\n\nHeader Bindings\n\n\nThe following operation method binds the header named \nX-API-Key\n to the \napiKey\n parameter:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllCities\n(\n@\nBind\n.\nheader\n(\nx-api-key\n)\n \nString\n \napiKey\n)\n \nasync\n \n{\n\n    \nif\n \n(\n!\nisValid\n(\napiKey\n))\n \n{\n\n      \nreturn\n \nResponse\n.\nunauthorized\n();\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nok\n([\nAtlanta\n,\n \nMadison\n,\n \nMountain View\n]);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIf an \nX-API-Key\n header is present in the request, its value will be available in \napiKey\n. If it is not, \ngetAllCities(apiKey)\n would not be called and a 400 Bad Request response will be sent. If \napiKey\n were optional, the method is called as normal and \napiKey\n is null or a default value.\n\n\nHeader names are case-insensitive per the HTTP specification. Therefore, the header name may be 'X-API-KEY', 'X-Api-Key' 'x-api-key', etc. and \napiKey\n will be bound in all cases.\n\n\nQuery Parameter Bindings\n\n\nThe following operation methods binds the query parameter named 'name' to the parameter \ncityName\n:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllCities\n(\n@\nBind\n.\nquery\n(\nname\n)\n \nString\n \ncityName\n)\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n(\ncities\n.\nwhere\n((\nc\n)\n \n=\n \nc\n.\nname\n \n==\n \ncityName\n).\ntoList\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nQuery parameters can be required or optional. If required, a 400 Bad Request response is sent and no operation method is called if the query parameter is not present in the request URL. If optional, the bound variable is null or a default value.\n\n\nQuery parameters are case-sensitive; this binding will only match the query parameter 'name', but not 'Name' or 'NAME'.\n\n\nQuery parameters may also bound for query strings in the request body when the content-type is 'application/x-www-form-urlencoded'.\n\n\nPath Variable Bindings\n\n\nThe following operation method binds the path variable 'id' to the parameter \ncityID\n:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetCityByID\n(\n@\nBind\n.\npath\n(\nid\n)\n \nString\n \ncityID\n)\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n(\ncities\n.\nwhere\n((\nc\n)\n \n=\n \nc\n.\nid\n \n==\n \ncityID\n).\ntoList\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nPath variables are made available when creating \nroutes\n. A \nRouter\n must have a route that includes a path variable and that path variable must be listed in the \nOperation\n annotation. Path variables are case-sensitive and may not be optional.\n\n\nIf you attempt to bind a path variable that is not present in the \nOperation\n, you will get a runtime exception at startup. You do not have to bind path variables for an operation method to be invoked.\n\n\nHTTP Request Body Bindings\n\n\nThe body of an HTTP request can also be bound to a parameter:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \nCityController\n(\nthis\n.\ncontext\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \naddCity\n(\n@\nBind\n.\nbody\n()\n \nCity\n \ncity\n)\n \nasync\n \n{\n\n    \nfinal\n \ninsertedCity\n \n=\n \nawait\n \ncontext\n.\ninsertObject\n(\ncity\n);\n\n\n    \nreturn\n \nResponse\n.\nok\n(\ninsertedCity\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSince there is only one request body, \nBind.body()\n doesn't take any identifying arguments (however, it does take optional arguments for ignoring, requiring or rejecting keys; this matches the behavior of \nSerializable.read\n and only works when the bound type is a \nSerializable\n or list of).\n\n\nThe bound parameter type (\nCity\n in this example) must implement \nSerializable\n. Aqueduct will automatically decode the request body from it's content-type, create a new instance of the bound parameter type, and invoke its \nread\n method. In the above example, a valid request body would be the following JSON:\n\n\n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nAtlanta\n\n\n}\n\n\n\n\n\n\n\n\nHTTP Body Decoding\n\n\nRequest bodies are decoded according to their content-type prior to being deserialized. For more information on request body decoding, including decoding content-types other than JSON, see \nthis guide\n.\n\n\n\n\nIf parsing fails or \nread\n throws an exception, a 400 Bad Request response will be sent and the operation method won't be called.\n\n\nYou may also bind \nList\nSerializable\n parameters to the request body. Consider the following JSON that contains a list of cities:\n\n\n[\n\n  \n{\nid\n:\n \n1\n,\n \nname\n:\n \nAtlanta\n},\n\n  \n{\nid\n:\n \n2\n,\n \nname\n:\n \nMadison\n}\n\n\n]\n\n\n\n\n\n\nThis body can be bound by declaring the bound parameter to be a \nList\n of the desired type:\n\n\nFuture\nResponse\n \naddCity\n(\n@\nBind\n.\nbody\n()\n \nList\nCity\n \ncities\n)\n\n\n\n\n\n\n\n\nList vs Object\n\n\nAn endpoint should either take a single object or a list of objects, but not both. If the request body is a JSON list and the bound variable is not a list, a 400 Bad Request response will be sent (and vice versa). Declaring a body binding of the appropriate type validates the expected value and aids in automatically generating an OpenAPI specification for your application.\n\n\n\n\nNote that if the request's \nContent-Type\n is 'x-www-form-urlencoded', its must be bound with \nBind.query\n and not \nBind.body\n.\n\n\n\n\nKey Filters in Bind.body()\n\n\nFilters can be applied to keys of the object being read. Filters can ignore keys, require keys or throw an error if a key is found. See more \nhere\n.\n\n\n\n\nProperty Binding\n\n\nThe properties of an \nResourceController\ns may also have \nBind.query\n and \nBind.header\n metadata. This binds values from the request to the \nResourceController\n instance itself, making them accessible from \nall\n operation methods.\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nrequiredBinding\n\n  \n@\nBind\n.\nheader\n(\nx-timestamp\n)\n\n  \nDateTime\n \ntimestamp\n;\n\n\n  \n@\nBind\n.\nquery\n(\nlimit\n)\n\n  \nint\n \nlimit\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetCities\n()\n \nasync\n \n{\n\n      \n// can use both limit and timestamp\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIn the above, both \ntimestamp\n and \nlimit\n are bound prior to \ngetCities\n being invoked. By default, a bound property is optional. Adding an \nrequiredBinding\n annotation changes a property to required. If required, any request without the required property fails with a 400 Bad Request status code and none of the operation methods are invoked.\n\n\nOther ResourceController Behavior\n\n\nBesides binding, \nResourceController\ns have some other behavior that is important to understand.\n\n\nRequest and Response Bodies\n\n\nA \nResourceController\n can limit the content type of HTTP request bodies it accepts. By default, a \nResourceController\n will accept only \napplication/json\n request bodies for its \nPOST\n and \nPUT\n methods. This can be modified by setting the \nacceptedContentTypes\n property in the constructor.\n\n\nclass\n \nUserController\n \nextends\n \nResourceController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nacceptedContentTypes\n \n=\n \n[\nContentType\n.\nJSON\n,\n \nContentType\n.\nXML\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIf a request is made with a content type other than the accepted content types, the controller automatically responds with a 415 Unsupported Media Type response.\n\n\nThe body of an HTTP request is decoded if the content type is accepted and there exists a operation method to handle the request. The body is not decoded if there is not a matching operation method for the request. The body is decoded by \nResourceController\n prior to your operation method being invoked. Therefore, you can always use the synchronous \nRequestBody.as\n method to access the body from within an operation method:\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \ncreateThing\n()\n \nasync\n \n{\n\n  \n// do this:\n\n  \nMap\nString\n,\n \ndynamic\n \nbodyMap\n \n=\n \nrequest\n.\nbody\n.\nas\n();\n\n\n  \n// no need to do this:\n\n  \nMap\nString\n,\n \ndynamic\n \nbodyMap\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\n();\n\n\n  \nreturn\n \n...;\n\n\n}\n\n\n\n\n\n\nA \nResourceController\n can also have a default content type for its responses. By default, this is \napplication/json\n. This default can be changed by changing \nresponseContentType\n in the constructor:\n\n\nclass\n \nUserController\n \nextends\n \nResourceController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nresponseContentType\n \n=\n \nContentType\n.\nXML\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nresponseContentType\n is the \ndefault\n response content type. An individual \nResponse\n may set its own \ncontentType\n, which takes precedence over the \nresponseContentType\n. For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return:\n\n\nclass\n \nUserController\n \nextends\n \nResourceController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nresponseContentType\n \n=\n \nContentType\n.\nJSON\n;\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetUserByID\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nResponse\n.\nok\n(...);\n\n\n    \nif\n \n(\nrequest\n.\nheaders\n.\nvalue\n(\nBind\n.\nheaders\n.\nACCEPT\n).\nstartsWith\n(\napplication/xml\n))\n \n{\n\n      \nresponse\n.\ncontentType\n \n=\n \nContentType\n.\nXML\n;\n\n    \n}\n\n\n    \nreturn\n \nresponse\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nMore Specialized ResourceControllers\n\n\nMany \nResourceController\n subclasses will execute \nqueries\n. There are helpful \nResourceController\n subclasses for reducing boilerplate code.\n\n\nA \nQueryController\nT\n builds a \nQuery\nT\n based on the incoming request. If the request has a body, this \nQuery\nT\n's \nvalues\n property is read from that body. If the request has a path variable, the \nQuery\nT\n assigns an expression to the primary key value. For example, in a normal \nResourceController\n that responds to a PUT request, you might write the following:\n\n\n@\nOperation\n.\nput\n(\nid\n)\n\n\nFuture\nResponse\n \nupdateUser\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n,\n \n@\nBind\n.\nbody\n()\n \nUser\n \nuser\n)\n \nasync\n \n{\n\n  \nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n    \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\nid\n)\n\n    \n..\nvalues\n \n=\n \nuser\n;\n\n\n  \nreturn\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nupdateOne\n());\n\n\n}\n\n\n\n\n\n\nA \nQueryController\nT\n builds this query before a operation method is invoked, storing it in the inherited \nquery\n property. A \nManagedObject\nT\n subclass is the type argument to \nQueryController\nT\n.\n\n\nclass\n \nUserController\n \nextends\n \nQueryController\nUser\n \n{\n\n  \nUserController\n(\nManagedContext\n \ncontext\n)\n \n:\n \nsuper\n(\ncontext\n);\n\n\n  \n@\nOperation\n.\nput\n(\nid\n)\n\n  \nFuture\nResponse\n \nupdateUser\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \n// query already exists and is identical to the snippet above\n\n    \nvar\n \nresult\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n    \nreturn\n \nResponse\n.\nok\n(\nresult\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nA \nManagedObjectController\nT\n is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage:\n\n\nrouter\n\n  \n.\nroute\n(\n/users/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nManagedObjectController\nUser\n(\ncontext\n));\n\n\n\n\n\n\nThis controller has the following behavior:\n\n\n\n\n\n\n\n\nRequest\n\n\nAction\n\n\n\n\n\n\n\n\n\n\nPOST /users\n\n\nInserts a user into the database with values from the request body\n\n\n\n\n\n\nGET /users\n\n\nFetches all users in the database\n\n\n\n\n\n\nGET /users/:id\n\n\nFetches a single user by id\n\n\n\n\n\n\nDELETE /users/:id\n\n\nDeletes a single user by id\n\n\n\n\n\n\nPUT /users/:id\n\n\nUpdated a single user by id, using values from the request body\n\n\n\n\n\n\n\n\nThe objects returned from getting the collection - e.g, \nGET /users\n - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order:\n\n\nGET /users?sortBy=name,asc\n\n\n\n\n\n\nThe results can be paged (see \nPaging in Advanced Queries\n) with query parameters \noffset\n, \ncount\n, \npageBy\n, \npageAfter\n and \npagePrior\n.\n\n\nA \nManagedObjectController\nT\n can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via \nPUT\n:\n\n\nclass\n \nUserController\n \nextends\n \nManagedObjectController\nUser\n \n{\n\n  \nUserController\n(\nManagedContext\n \ncontext\n)\n \n:\n \nsuper\n(\ncontext\n);\n\n\n  \nFuture\nQuery\nUser\n \nwillUpdateObjectWithQuery\n(\n\n      \nQuery\nUser\n \nquery\n)\n \nasync\n \n{\n\n    \nquery\n.\nvalues\n.\nlastUpdatedAt\n \n=\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n    \nreturn\n \nquery\n;\n\n  \n}\n\n\n  \nFuture\nResponse\n \ndidUpdateObject\n(\nUser\n \nobject\n)\n \nasync\n \n{\n\n    \nobject\n.\nremovePropertyFromBackingMap\n(\nprivate\n);\n\n    \nreturn\n \nResponse\n.\nok\n(\nobject\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSee the chapter on \nvalidations\n, which are powerful when combined with \nManagedObjectController\nT\n.", 
            "title": "Request Binding with Resource Controllers"
        }, 
        {
            "location": "/http/resource_controller/#resourcecontroller", 
            "text": "A  ResourceController  is a  controller  that provide conveniences for implementing endpoint controllers. A  ResourceController  must be subclassed, and in that subclass, you write a method for each operation on that type of resource. For example, a  UserController  might handle the following operations:   creating a new user ( POST /users )  getting all users ( GET /users )  getting an individual user ( GET /users/:id )  updating an individual user ( PUT /users/:id )  deleting an individual user ( DELETE /users/:id )   These methods that are invoked for an operation are called  operation methods .", 
            "title": "ResourceController"
        }, 
        {
            "location": "/http/resource_controller/#operation-methods", 
            "text": "An operation method is an instance method of a  ResourceController  subclass that has an  @Operation  annotation. It must return an instance of  Future Response . Here's an example:  class   CityController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllCities ()   async   { \n     return   Response . ok ([ Atlanta ,   Madison ,   Mountain View ]); \n   }  }   The above operation method will be invoked when  CityController  handles  GET  requests without path variables. To handle operation methods with path variables, the name of the path variable is added to the  @Operation  annotation:  class   CityController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllCities ()   async   { \n     return   Response . ok ([ Atlanta ,   Madison ,   Mountain View ]); \n   } \n\n   @ Operation . get ( name ) \n   Future Response   getCityByName ()   async   { \n     final   id   =   request . path . variables [ name ]; \n     return   Response . ok ( fetchCityWithName ( name )); \n   }  }    Path Variables  This controller would be linked to the route specification  /cities/[:name] , so that it can handle both of these operations. Read more about path variables in  Routing .   The named constructor of  Operation  tells us which HTTP method the operation method handles. The following named constructors exist:   Operation.post()  Operation.get()  Operation.put()  Operation.delete()   The canonical  Operation()  constructor takes the HTTP method as its first argument for non-standard operations, e.g.:  @ Operation ( PATCH ,   id )  Future Response   patchObjectWithID ()   async   =   ...;   All  Operation  constructors take a variable list of path variables. There can be multiple path variables for an operation. An operation method will only be invoked if all of its path variables are present in the request path. There can be multiple operation methods for a given HTTP method, as long as each expects a different set of path variables.  Here's an example of an operation that requires two path variables:  @ Operation . get ( userID ,   itemID )  Future Response   getUserItem ()   async   { \n   final   userID   =   request . path . variables [ userID ]; \n   final   itemID   =   request . path . variables [ itemID ]; \n   return   Response . ok (...);  }   If no operation method exists for a request, a 405 Method Not Allowed response is automatically sent and no operation method is invoked.", 
            "title": "Operation Methods"
        }, 
        {
            "location": "/http/resource_controller/#routing-to-a-resourcecontroller", 
            "text": "A  ResourceController  subclass must be preceded by a  Router  in the application channel. The  Router  will parse path variables so that the controller can use them to determine which operation method should be invoked. A typical route to a  ResourceController  contains an optional identifying path variable:  router \n   . route ( /cities/[:name] ) \n   . link (()   =   CityController ());   This route would allow  CityController  to implement operation methods for all HTTP methods with both no path variables and the 'name' path variable.  It is considered good practice to break sub-resources into their own controller. For example, the following is preferred:  router \n   . route ( /cities/[:name] ) \n   . link (()   =   CityController ());  router \n   . route ( /cities/:name/attractions/[:id] ) \n   . link (()   =   CityAttractionController ());   By contrast, the route  /cities/[:name/[attractions/[:id]]] , while valid, makes controller logic much more unwieldy.", 
            "title": "Routing to a ResourceController"
        }, 
        {
            "location": "/http/resource_controller/#request-bindings", 
            "text": "Operation methods may  bind  properties of an HTTP request to its parameters. When the operation method is invoked, the value of that property is passed as an argument to the operation method. For example, the following binds the header named 'X-API-Key' to the argument  apiKey :  @ Operation . get ( name )  Future Response   getCityByName ( @ Bind . header ( x-api-key )   String   apiKey )   async   { \n   if   ( ! isValid ( apiKey ))   { \n     return   Response . unauthorized (); \n   } \n\n   return   Response . ok (...);  }   The following table shows the possible types of bindings:     Property  Binding      Path Variable  @Bind.path(pathVariableName)    URL Query Parameter  @Bind.query(queryParameterName)    Header  @Bind.header(headerName)    Request Body  @Bind.body()     You may bind any number of HTTP request properties to a single operation method.", 
            "title": "Request Bindings"
        }, 
        {
            "location": "/http/resource_controller/#optional-bindings", 
            "text": "Bindings can be made optional. If a binding is optional, the operation method will still be called even if the binding isn't in a request. To make a binding optional, wrap it in curly brackets.  @ Operation . get ()  Future Response   getAllCities ({ @ Bind . header ( x-api-key )   String   apiKey })   async   { \n   if   ( apiKey   ==   null )   { \n     // No X-API-Key in request \n     ... \n   } \n   ...  }   The curly bracket syntax is a Dart language feature for optional method parameters ( see more here ). If there are multiple optional parameters, use only one pair of curly brackets and list each optional parameter in those brackets.  A bound parameter will be null if is not present in the request. You can provide a default value for optional parameters.  @ Operation . get ()  Future Response   getAllCities ({ @ Bind . header ( x-api-key )   String   apiKey:   public })   async   { \n   ...  }", 
            "title": "Optional Bindings"
        }, 
        {
            "location": "/http/resource_controller/#automatically-parsing-bindings", 
            "text": "Query, header and path bindings can automatically be parsed into other types, such as  int  or  DateTime . Simply declare the bound parameter's type to the desired type:  Future Response   getCityByID ( @ Bind . query ( id )   int   cityID )   The type of a bound parameter may be  String  or any type that implements  parse  (e.g.,  int ,  DateTime ). Query parameters may also be bound to  bool  parameters; a boolean query parameter will be true if the query parameter has no value (e.g.  /path?boolean ).  If parsing fails for any reason, an error response is sent and the operation method is not called. For example, the above example binds  int cityID  - if the path variable 'id' can't be parsed into an  int , a 404 Not Found response is sent. If a query parameter or header value cannot be parsed, a 400 Bad Request response is sent.  You may also bind  List T  parameters to headers and query parameters, where  T  must meet the same criteria as above. Query parameters and headers may appear more than once in a request. For example, the value of  ids  is  [1, 2]  if the request URL ends with  /path?id=1 id=2  and the operation method looks like this:  Future Response   getCitiesByIDs ( @ Bind . query ( id )   List int   ids )   Note that if a parameter is  not  bound to a list and there are multiple occurrences of that property in the request, a 400 Bad Request response will be sent. If you want to allow multiple values, you must bind to a  List T .", 
            "title": "Automatically Parsing Bindings"
        }, 
        {
            "location": "/http/resource_controller/#header-bindings", 
            "text": "The following operation method binds the header named  X-API-Key  to the  apiKey  parameter:  class   CityController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllCities ( @ Bind . header ( x-api-key )   String   apiKey )   async   { \n     if   ( ! isValid ( apiKey ))   { \n       return   Response . unauthorized (); \n     } \n\n     return   Response . ok ([ Atlanta ,   Madison ,   Mountain View ]); \n   }  }   If an  X-API-Key  header is present in the request, its value will be available in  apiKey . If it is not,  getAllCities(apiKey)  would not be called and a 400 Bad Request response will be sent. If  apiKey  were optional, the method is called as normal and  apiKey  is null or a default value.  Header names are case-insensitive per the HTTP specification. Therefore, the header name may be 'X-API-KEY', 'X-Api-Key' 'x-api-key', etc. and  apiKey  will be bound in all cases.", 
            "title": "Header Bindings"
        }, 
        {
            "location": "/http/resource_controller/#query-parameter-bindings", 
            "text": "The following operation methods binds the query parameter named 'name' to the parameter  cityName :  class   CityController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllCities ( @ Bind . query ( name )   String   cityName )   async   { \n     return   Response . ok ( cities . where (( c )   =   c . name   ==   cityName ). toList ()); \n   }  }   Query parameters can be required or optional. If required, a 400 Bad Request response is sent and no operation method is called if the query parameter is not present in the request URL. If optional, the bound variable is null or a default value.  Query parameters are case-sensitive; this binding will only match the query parameter 'name', but not 'Name' or 'NAME'.  Query parameters may also bound for query strings in the request body when the content-type is 'application/x-www-form-urlencoded'.", 
            "title": "Query Parameter Bindings"
        }, 
        {
            "location": "/http/resource_controller/#path-variable-bindings", 
            "text": "The following operation method binds the path variable 'id' to the parameter  cityID :  class   CityController   extends   ResourceController   { \n   @ Operation . get ( id ) \n   Future Response   getCityByID ( @ Bind . path ( id )   String   cityID )   async   { \n     return   Response . ok ( cities . where (( c )   =   c . id   ==   cityID ). toList ()); \n   }  }   Path variables are made available when creating  routes . A  Router  must have a route that includes a path variable and that path variable must be listed in the  Operation  annotation. Path variables are case-sensitive and may not be optional.  If you attempt to bind a path variable that is not present in the  Operation , you will get a runtime exception at startup. You do not have to bind path variables for an operation method to be invoked.", 
            "title": "Path Variable Bindings"
        }, 
        {
            "location": "/http/resource_controller/#http-request-body-bindings", 
            "text": "The body of an HTTP request can also be bound to a parameter:  class   CityController   extends   ResourceController   { \n   CityController ( this . context ); \n\n   final   ManagedContext   context ; \n\n   @ Operation . post () \n   Future Response   addCity ( @ Bind . body ()   City   city )   async   { \n     final   insertedCity   =   await   context . insertObject ( city ); \n\n     return   Response . ok ( insertedCity ); \n   }  }   Since there is only one request body,  Bind.body()  doesn't take any identifying arguments (however, it does take optional arguments for ignoring, requiring or rejecting keys; this matches the behavior of  Serializable.read  and only works when the bound type is a  Serializable  or list of).  The bound parameter type ( City  in this example) must implement  Serializable . Aqueduct will automatically decode the request body from it's content-type, create a new instance of the bound parameter type, and invoke its  read  method. In the above example, a valid request body would be the following JSON:  { \n   id :   1 , \n   name :   Atlanta  }    HTTP Body Decoding  Request bodies are decoded according to their content-type prior to being deserialized. For more information on request body decoding, including decoding content-types other than JSON, see  this guide .   If parsing fails or  read  throws an exception, a 400 Bad Request response will be sent and the operation method won't be called.  You may also bind  List Serializable  parameters to the request body. Consider the following JSON that contains a list of cities:  [ \n   { id :   1 ,   name :   Atlanta }, \n   { id :   2 ,   name :   Madison }  ]   This body can be bound by declaring the bound parameter to be a  List  of the desired type:  Future Response   addCity ( @ Bind . body ()   List City   cities )    List vs Object  An endpoint should either take a single object or a list of objects, but not both. If the request body is a JSON list and the bound variable is not a list, a 400 Bad Request response will be sent (and vice versa). Declaring a body binding of the appropriate type validates the expected value and aids in automatically generating an OpenAPI specification for your application.   Note that if the request's  Content-Type  is 'x-www-form-urlencoded', its must be bound with  Bind.query  and not  Bind.body .   Key Filters in Bind.body()  Filters can be applied to keys of the object being read. Filters can ignore keys, require keys or throw an error if a key is found. See more  here .", 
            "title": "HTTP Request Body Bindings"
        }, 
        {
            "location": "/http/resource_controller/#property-binding", 
            "text": "The properties of an  ResourceController s may also have  Bind.query  and  Bind.header  metadata. This binds values from the request to the  ResourceController  instance itself, making them accessible from  all  operation methods.  class   CityController   extends   ResourceController   { \n   @ requiredBinding \n   @ Bind . header ( x-timestamp ) \n   DateTime   timestamp ; \n\n   @ Bind . query ( limit ) \n   int   limit ; \n\n   @ Operation . get () \n   Future Response   getCities ()   async   { \n       // can use both limit and timestamp \n   }  }   In the above, both  timestamp  and  limit  are bound prior to  getCities  being invoked. By default, a bound property is optional. Adding an  requiredBinding  annotation changes a property to required. If required, any request without the required property fails with a 400 Bad Request status code and none of the operation methods are invoked.", 
            "title": "Property Binding"
        }, 
        {
            "location": "/http/resource_controller/#other-resourcecontroller-behavior", 
            "text": "Besides binding,  ResourceController s have some other behavior that is important to understand.", 
            "title": "Other ResourceController Behavior"
        }, 
        {
            "location": "/http/resource_controller/#request-and-response-bodies", 
            "text": "A  ResourceController  can limit the content type of HTTP request bodies it accepts. By default, a  ResourceController  will accept only  application/json  request bodies for its  POST  and  PUT  methods. This can be modified by setting the  acceptedContentTypes  property in the constructor.  class   UserController   extends   ResourceController   { \n   UserController ()   { \n     acceptedContentTypes   =   [ ContentType . JSON ,   ContentType . XML ]; \n   }  }   If a request is made with a content type other than the accepted content types, the controller automatically responds with a 415 Unsupported Media Type response.  The body of an HTTP request is decoded if the content type is accepted and there exists a operation method to handle the request. The body is not decoded if there is not a matching operation method for the request. The body is decoded by  ResourceController  prior to your operation method being invoked. Therefore, you can always use the synchronous  RequestBody.as  method to access the body from within an operation method:  @ Operation . post ()  Future Response   createThing ()   async   { \n   // do this: \n   Map String ,   dynamic   bodyMap   =   request . body . as (); \n\n   // no need to do this: \n   Map String ,   dynamic   bodyMap   =   await   request . body . decode (); \n\n   return   ...;  }   A  ResourceController  can also have a default content type for its responses. By default, this is  application/json . This default can be changed by changing  responseContentType  in the constructor:  class   UserController   extends   ResourceController   { \n   UserController ()   { \n     responseContentType   =   ContentType . XML ; \n   }  }   The  responseContentType  is the  default  response content type. An individual  Response  may set its own  contentType , which takes precedence over the  responseContentType . For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return:  class   UserController   extends   ResourceController   { \n   UserController ()   { \n     responseContentType   =   ContentType . JSON ; \n   } \n\n   @ Operation . get ( id ) \n   Future Response   getUserByID ( @ Bind . path ( id )   int   id )   async   { \n     var   response   =   Response . ok (...); \n\n     if   ( request . headers . value ( Bind . headers . ACCEPT ). startsWith ( application/xml ))   { \n       response . contentType   =   ContentType . XML ; \n     } \n\n     return   response ; \n   }  }", 
            "title": "Request and Response Bodies"
        }, 
        {
            "location": "/http/resource_controller/#more-specialized-resourcecontrollers", 
            "text": "Many  ResourceController  subclasses will execute  queries . There are helpful  ResourceController  subclasses for reducing boilerplate code.  A  QueryController T  builds a  Query T  based on the incoming request. If the request has a body, this  Query T 's  values  property is read from that body. If the request has a path variable, the  Query T  assigns an expression to the primary key value. For example, in a normal  ResourceController  that responds to a PUT request, you might write the following:  @ Operation . put ( id )  Future Response   updateUser ( @ Bind . path ( id )   int   id ,   @ Bind . body ()   User   user )   async   { \n   var   query   =   Query User ( context ) \n     .. where (( u )   =   u . id ). equalTo ( id ) \n     .. values   =   user ; \n\n   return   Response . ok ( await   query . updateOne ());  }   A  QueryController T  builds this query before a operation method is invoked, storing it in the inherited  query  property. A  ManagedObject T  subclass is the type argument to  QueryController T .  class   UserController   extends   QueryController User   { \n   UserController ( ManagedContext   context )   :   super ( context ); \n\n   @ Operation . put ( id ) \n   Future Response   updateUser ( @ Bind . path ( id )   int   id )   async   { \n     // query already exists and is identical to the snippet above \n     var   result   =   await   query . updateOne (); \n     return   Response . ok ( result ); \n   }  }   A  ManagedObjectController T  is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage:  router \n   . route ( /users/[:id] ) \n   . link (()   =   ManagedObjectController User ( context ));   This controller has the following behavior:     Request  Action      POST /users  Inserts a user into the database with values from the request body    GET /users  Fetches all users in the database    GET /users/:id  Fetches a single user by id    DELETE /users/:id  Deletes a single user by id    PUT /users/:id  Updated a single user by id, using values from the request body     The objects returned from getting the collection - e.g,  GET /users  - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order:  GET /users?sortBy=name,asc   The results can be paged (see  Paging in Advanced Queries ) with query parameters  offset ,  count ,  pageBy ,  pageAfter  and  pagePrior .  A  ManagedObjectController T  can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via  PUT :  class   UserController   extends   ManagedObjectController User   { \n   UserController ( ManagedContext   context )   :   super ( context ); \n\n   Future Query User   willUpdateObjectWithQuery ( \n       Query User   query )   async   { \n     query . values . lastUpdatedAt   =   DateTime . now (). toUtc (); \n     return   query ; \n   } \n\n   Future Response   didUpdateObject ( User   object )   async   { \n     object . removePropertyFromBackingMap ( private ); \n     return   Response . ok ( object ); \n   }  }   See the chapter on  validations , which are powerful when combined with  ManagedObjectController T .", 
            "title": "More Specialized ResourceControllers"
        }, 
        {
            "location": "/http/serving_files/", 
            "text": "Serving Files and Caching\n\n\nAqueduct can serve files by returning the contents of a file as an HTTP response body.\n\n\nFileController\n\n\nInstances of \nFileController\n serve a directory from the filesystem through an HTTP interface. Any route that channels requests to an \nFileController\n \nmust\n contain a \n*\n match-all token.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n.\nroute\n(\n/files/*\n).\nlink\n(()\n \n=\n \nFileController\n(\npublic/\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nThe argument to \nFileController\n is the directory on the filesystem in which request paths will be resolved against. In the above example, an HTTP request with the path \n/files/image.jpg\n would return the contents of the file \npublic/image.jpg\n.\n\n\nNote that \npublic/\n does not have a leading slash - therefore, the directory \npublic\n must be relative to the directory that the Aqueduct application was served from. In practice, this means you might have a directory structure like:\n\n\nproject/\n  pubspec.yaml  \n  lib/\n    channel.dart\n    ...\n  test/\n    ...\n  public/\n    image.jpg\n\n\n\n\n\nAdding a leading slash to the directory served by \nFileController\n will resolve it relative to the filesystem root.\n\n\nIf the requested path was a directory, the filename \nindex.html\n will be appended to the path when searching for a file to return.\n\n\nIf a file does not exist, an \nFileController\n returns a 404 Not Found response.\n\n\nContent-Type of Files\n\n\nAn \nFileController\n will set the content-type of the HTTP response based on the served files path extension. By default, it recognizes many common extensions like \n.html\n, \n.css\n, \n.jpg\n, \n.js\n. You may add content-types for extensions to an instance:\n\n\nvar\n \ncontroller\n \n=\n \nFileController\n(\npublic/\n)\n\n  \n..\nsetContentTypeForExtension\n(\nxml\n,\n \nContentType\n(\napplication\n,\n \nxml\n));\n\n\n\n\n\n\nIf there is no entry for an extension of a file being served, the content-type defaults to \napplication/octet-stream\n. An \nFileController\n will never invoke any encoders from \nCodecRegistry\n, but it will GZIP data if the repository allows compression for the content-type of the file (see \nCodecRegistry.add\n and \nCodecRegistry.setAllowsCompression\n).\n\n\nCaching\n\n\nAn \nFileController\n always sets the the Last-Modified header of the response to the last modified date according to the filesystem. If a request sends an If-Modified-Since header and the file has not been modified since that date, a 304 Not Modified response is sent with the appropriate headers.\n\n\nYou may provide Cache-Control headers depending on the path of the file being served. Here's an example that adds \nCache-Control: public, max-age=31536000\n\n\nvar\n \npolicy\n \n=\n \nCachePolicy\n(\nexpirationFromNow:\n \nDuration\n(\ndays:\n \n365\n));\n\n\nvar\n \ncontroller\n \n=\n \nFileController\n(\npublic/\n)\n\n  \n..\naddCachePolicy\n(\npolicy\n,\n \n(\npath\n)\n \n=\n \npath\n.\nendsWith\n(\n.css\n));\n\n\n\n\n\n\nFile Serving and Caching Outside of FileController\n\n\nA file can be served by any controller by setting the body object of a \nResponse\n with its contents:\n\n\nvar\n \nfile\n \n=\n \nFile\n(\nindex.html\n);\n\n\n\n// By loading contents into memory first...\n\n\nvar\n \nresponse\n \n=\n \nResponse\n.\nok\n(\nfile\n.\nreadAsStringSync\n())\n\n  \n..\ncontentType\n \n=\n \nContentType\n(\napplication\n,\n \nhtml\n);\n\n\n\n// Or by streaming the contents from disk\n\n\nvar\n \nresponse\n \n=\n \nResponse\n.\nok\n(\nfile\n.\nopenRead\n())\n\n  \n..\nencodeBody\n \n=\n \nfalse\n\n  \n..\ncontentType\n \n=\n \nContentType\n(\napplication\n,\n \nhtml\n);\n\n\n\n\n\n\nIt is important to understand the how Aqueduct \nuses content-types to manipulate response bodies\n to serve file contents.\n\n\nYou may set the \nCachePolicy\n of any \nResponse\n. Note that \nCachePolicy\n only modifies the Cache-Control header of a response. Headers like Last-Modified and ETag are not added.\n\n\nvar\n \nresponse\n \n=\n \nResponse\n.\nok\n(\ncontents\n)\n\n  \n..\ncachePolicy\n \n=\n \nCachePolicy\n();", 
            "title": "Serving Files and Caching"
        }, 
        {
            "location": "/http/serving_files/#serving-files-and-caching", 
            "text": "Aqueduct can serve files by returning the contents of a file as an HTTP response body.", 
            "title": "Serving Files and Caching"
        }, 
        {
            "location": "/http/serving_files/#filecontroller", 
            "text": "Instances of  FileController  serve a directory from the filesystem through an HTTP interface. Any route that channels requests to an  FileController   must  contain a  *  match-all token.  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router . route ( /files/* ). link (()   =   FileController ( public/ )); \n\n   return   router ;  }   The argument to  FileController  is the directory on the filesystem in which request paths will be resolved against. In the above example, an HTTP request with the path  /files/image.jpg  would return the contents of the file  public/image.jpg .  Note that  public/  does not have a leading slash - therefore, the directory  public  must be relative to the directory that the Aqueduct application was served from. In practice, this means you might have a directory structure like:  project/\n  pubspec.yaml  \n  lib/\n    channel.dart\n    ...\n  test/\n    ...\n  public/\n    image.jpg  Adding a leading slash to the directory served by  FileController  will resolve it relative to the filesystem root.  If the requested path was a directory, the filename  index.html  will be appended to the path when searching for a file to return.  If a file does not exist, an  FileController  returns a 404 Not Found response.", 
            "title": "FileController"
        }, 
        {
            "location": "/http/serving_files/#content-type-of-files", 
            "text": "An  FileController  will set the content-type of the HTTP response based on the served files path extension. By default, it recognizes many common extensions like  .html ,  .css ,  .jpg ,  .js . You may add content-types for extensions to an instance:  var   controller   =   FileController ( public/ ) \n   .. setContentTypeForExtension ( xml ,   ContentType ( application ,   xml ));   If there is no entry for an extension of a file being served, the content-type defaults to  application/octet-stream . An  FileController  will never invoke any encoders from  CodecRegistry , but it will GZIP data if the repository allows compression for the content-type of the file (see  CodecRegistry.add  and  CodecRegistry.setAllowsCompression ).", 
            "title": "Content-Type of Files"
        }, 
        {
            "location": "/http/serving_files/#caching", 
            "text": "An  FileController  always sets the the Last-Modified header of the response to the last modified date according to the filesystem. If a request sends an If-Modified-Since header and the file has not been modified since that date, a 304 Not Modified response is sent with the appropriate headers.  You may provide Cache-Control headers depending on the path of the file being served. Here's an example that adds  Cache-Control: public, max-age=31536000  var   policy   =   CachePolicy ( expirationFromNow:   Duration ( days:   365 ));  var   controller   =   FileController ( public/ ) \n   .. addCachePolicy ( policy ,   ( path )   =   path . endsWith ( .css ));", 
            "title": "Caching"
        }, 
        {
            "location": "/http/serving_files/#file-serving-and-caching-outside-of-filecontroller", 
            "text": "A file can be served by any controller by setting the body object of a  Response  with its contents:  var   file   =   File ( index.html );  // By loading contents into memory first...  var   response   =   Response . ok ( file . readAsStringSync ()) \n   .. contentType   =   ContentType ( application ,   html );  // Or by streaming the contents from disk  var   response   =   Response . ok ( file . openRead ()) \n   .. encodeBody   =   false \n   .. contentType   =   ContentType ( application ,   html );   It is important to understand the how Aqueduct  uses content-types to manipulate response bodies  to serve file contents.  You may set the  CachePolicy  of any  Response . Note that  CachePolicy  only modifies the Cache-Control header of a response. Headers like Last-Modified and ETag are not added.  var   response   =   Response . ok ( contents ) \n   .. cachePolicy   =   CachePolicy ();", 
            "title": "File Serving and Caching Outside of FileController"
        }, 
        {
            "location": "/http/websockets/", 
            "text": "Using Websockets in Aqueduct\n\n\nA standard HTTP request will yield an HTTP response from a web server. In order for the server to send data to a client, the client must have sent a request for that data. A \nwebsocket\n is a special type of HTTP request that stays open, and both the server and client can send data to one another whenever they please.\n\n\nFor example, a chat application might use websockets to send messages to everyone in a chatroom. In this scenario, the chat client application opens a websocket connection to the server application. When the user types a message, their chat client sends that message on its websocket. The payload might be JSON data that looks like this:\n\n\n{\n\n  \naction\n:\n \nsend_message\n,\n\n  \nroom\n:\n \ngeneral\n,\n\n  \ntext\n:\n \nHi everyone\n\n\n}\n\n\n\n\n\n\nThe server will receive this data, then turn around and send a modified version to \nevery\n websocket connection it has. That data might look like this:\n\n\n{\n\n  \naction\n:\n \nreceive_message\n,\n\n  \nroom\n:\n \ngeneral\n,\n\n  \nfrom\n:\n \nBob\n,\n\n  \ntext\n:\n \nHi everyone\n\n\n}\n\n\n\n\n\n\nEvery connected user will receive this data and draw \nBob: Hi everyone\n to the screen.\n\n\nNote that there's nothing about websockets that says you have to use JSON data - you can use any data format you like.\n\n\nUpgrading an HTTP Request to a WebSocket\n\n\nIn Aqueduct, websockets are handled by Dart's standard library \nWebSocket\n type. Here's an example:\n\n\nrouter\n\n  \n.\nroute\n(\n/connect\n)\n\n  \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n    \nvar\n \nsocket\n \n=\n \nawait\n \nWebSocketTransformer\n.\nupgrade\n(\nrequest\n.\nraw\n);\n\n    \nsocket\n.\nlisten\n(\nlistener\n);\n\n\n    \nreturn\n \nnull\n;\n\n  \n});\n\n\n\n\n\n\nIt's important that a request that is upgraded to a websocket is removed from the channel by returning null from the controller. (See the section on \nAqueduct and dart:io\n \nin this guide\n for more details.)\n\n\nA client application can connect to the URL \nws://localhost:8888/connect\n. A Dart application would make this connection like so:\n\n\nvar\n \nsocket\n \n=\n \nawait\n \nWebSocket\n.\nconnect\n(\nws://localhost:8888/connect\n);\n\n\nsocket\n.\nlisten\n(...);\n\n\n\n\n\n\nBi-directional Communication\n\n\nIn the simple example above, the server only listens for data from the client. For data to be sent to the client, a reference must be kept to the \nWebSocket\n so that data can be added to it. How an Aqueduct application manages its websocket connections depends greatly on the behavior of the application, the number of isolates the application is running on and the infrastructure of the system as a whole.\n\n\nA simple application might keep track of websocket connections in a \nMap\n, where the key is a user identifier acquired from the authorization of the request:\n\n\nrouter\n\n  \n.\nroute\n(\n/connect\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n(\nauthServer\n));\n\n  \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n    \nvar\n \nuserID\n \n=\n \nrequest\n.\nauthorization\n.\nownerID\n;\n\n    \nvar\n \nsocket\n \n=\n \nawait\n \nWebSocketTransformer\n.\nupgrade\n(\nrequest\n.\nraw\n);\n\n    \nsocket\n.\nlisten\n((\nevent\n)\n \n=\n \nhandleEvent\n(\nevent\n,\n \nfromUserID:\n \nuserID\n));\n\n\n    \nconnections\n[\nuserID\n]\n \n=\n \nsocket\n;\n\n\n    \nreturn\n \nnull\n;\n\n  \n});\n\n\n\n\n\n\nIf we continue with the 'chat application' example, the code for \nhandleEvent\n may be something like:\n\n\nvoid\n \nhandleEvent\n(\ndynamic\n \nevent\n,\n \n{\nint\n \nfromUserID\n})\n \n{\n\n  \nvar\n \nincoming\n \n=\n \njson\n.\ndecode\n(\nUTF8\n.\ndecode\n(\nevent\n));\n\n  \nvar\n \noutgoing\n \n=\n \nutf8\n.\nencode\n(\njson\n.\nencode\n({\n\n    \ntext\n:\n \nincoming\n[\ntext\n],\n\n    \n...\n\n  \n}));\n\n\n  \nconnections\n.\nkeys\n\n    \n.\nwhere\n((\nuserID\n)\n \n=\n \nuserID\n \n!=\n \nfromUserID\n)\n\n    \n.\nforEach\n((\nuserID\n)\n \n{\n\n      \nvar\n \nconnection\n \n=\n \nconnections\n[\nuserID\n];\n\n      \nconnection\n.\nadd\n(\noutgoing\n);\n\n    \n});\n\n\n}\n\n\n\n\n\n\nNote that this simple implementation doesn't account for multiple connections from the same user or multi-isolate applications.\n\n\nConsiderations for Multi-Isolate and Multi-Instance Applications\n\n\nBy default, an Aqueduct application runs on multiple isolates. Since each isolate has its own heap, a websocket created on one isolate is not directly accessible by another isolate. In the example above, each isolate would have its own map of connections - therefore, a message is only sent to connections that were opened on the same isolate that the chat message originated from.\n\n\nA simple solution is to only run the application on a single isolate, ensuring that all websockets are on a single isolate and accessible to one another:\n\n\naqueduct\n \nserve\n \n-\nn\n \n1\n\n\n\n\n\n\nFor many applications, this is a fine solution. For others, it may not be.\n\n\nRecall that one of the benefits of Aqueduct's multi-isolate architecture is that code tested on a single instance will scale to multiple instances behind a load balancer. If an Aqueduct application runs correctly on a single, multi-isolate instance, it will run correctly on multiple instances. This (somewhat) enforced structure prevents us from naively keeping track of websocket connections on a single isolate, which would cause issues when we scale out to a multi-instance system.\n\n\nIf you find yourself in a situation where your application is so popular you need multiple servers to efficiently serve requests, you'll have a good idea on how to architect an appropriate solution (or you'll have the money to hire someone that does). In many situations, the REST API and websocket server are separate instances anyhow - they have different lifecycles and deployment behavior. It may make sense to run a websocket server on a single isolate, since you are likely IO-bound instead of CPU bound.\n\n\nIf you still prefer to have a multi-isolate server with websockets, the \nApplicationMessageHub\n will come in handy. When broadcasting messages to connected websockets across the application, you first send the data to each websocket connected to the isolate that is originating the message. Then, the message is added to the \nApplicationMessageHub\n:\n\n\nvoid\n \nonChatMessage\n(\nString\n \nmessage\n)\n \n{\n\n  \nconnectedSockets\n.\nforEach\n((\nsocket\n)\n \n{\n\n    \nsocket\n.\nadd\n(\nmessage\n);\n\n  \n});\n\n\n  \nApplicationChannel\n.\nmessageHub\n.\nadd\n({\nevent\n:\n \nwebsocket_broadcast\n,\n \nmessage\n:\n \nmessage\n});\n\n\n}\n\n\n\n\n\n\nAnything added to the \nmessageHub\n will be delivered to the listener for every other message hub - i.e., every other isolate will receive this data. The other isolates then send the message to each of their connected websockets:\n\n\nclass\n \nChatChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nmessageHub\n.\nlisten\n((\nevent\n)\n \n{\n\n      \nif\n \n(\nevent\n \nis\n \nMap\n \n \nevent\n[\nevent\n]\n \n==\n \nwebsocket_broadcast\n)\n \n{\n\n        \nconnectedSockets\n.\nforEach\n((\nsocket\n)\n \n{\n\n          \nsocket\n.\nadd\n(\nevent\n[\nmessage\n]);\n\n        \n});\n\n      \n}\n\n    \n});\n\n  \n}\n\n\n}", 
            "title": "Websockets"
        }, 
        {
            "location": "/http/websockets/#using-websockets-in-aqueduct", 
            "text": "A standard HTTP request will yield an HTTP response from a web server. In order for the server to send data to a client, the client must have sent a request for that data. A  websocket  is a special type of HTTP request that stays open, and both the server and client can send data to one another whenever they please.  For example, a chat application might use websockets to send messages to everyone in a chatroom. In this scenario, the chat client application opens a websocket connection to the server application. When the user types a message, their chat client sends that message on its websocket. The payload might be JSON data that looks like this:  { \n   action :   send_message , \n   room :   general , \n   text :   Hi everyone  }   The server will receive this data, then turn around and send a modified version to  every  websocket connection it has. That data might look like this:  { \n   action :   receive_message , \n   room :   general , \n   from :   Bob , \n   text :   Hi everyone  }   Every connected user will receive this data and draw  Bob: Hi everyone  to the screen.  Note that there's nothing about websockets that says you have to use JSON data - you can use any data format you like.", 
            "title": "Using Websockets in Aqueduct"
        }, 
        {
            "location": "/http/websockets/#upgrading-an-http-request-to-a-websocket", 
            "text": "In Aqueduct, websockets are handled by Dart's standard library  WebSocket  type. Here's an example:  router \n   . route ( /connect ) \n   . linkFunction (( request )   async   { \n     var   socket   =   await   WebSocketTransformer . upgrade ( request . raw ); \n     socket . listen ( listener ); \n\n     return   null ; \n   });   It's important that a request that is upgraded to a websocket is removed from the channel by returning null from the controller. (See the section on  Aqueduct and dart:io   in this guide  for more details.)  A client application can connect to the URL  ws://localhost:8888/connect . A Dart application would make this connection like so:  var   socket   =   await   WebSocket . connect ( ws://localhost:8888/connect );  socket . listen (...);", 
            "title": "Upgrading an HTTP Request to a WebSocket"
        }, 
        {
            "location": "/http/websockets/#bi-directional-communication", 
            "text": "In the simple example above, the server only listens for data from the client. For data to be sent to the client, a reference must be kept to the  WebSocket  so that data can be added to it. How an Aqueduct application manages its websocket connections depends greatly on the behavior of the application, the number of isolates the application is running on and the infrastructure of the system as a whole.  A simple application might keep track of websocket connections in a  Map , where the key is a user identifier acquired from the authorization of the request:  router \n   . route ( /connect ) \n   . link (()   =   new   Authorizer ( authServer )); \n   . linkFunction (( request )   async   { \n     var   userID   =   request . authorization . ownerID ; \n     var   socket   =   await   WebSocketTransformer . upgrade ( request . raw ); \n     socket . listen (( event )   =   handleEvent ( event ,   fromUserID:   userID )); \n\n     connections [ userID ]   =   socket ; \n\n     return   null ; \n   });   If we continue with the 'chat application' example, the code for  handleEvent  may be something like:  void   handleEvent ( dynamic   event ,   { int   fromUserID })   { \n   var   incoming   =   json . decode ( UTF8 . decode ( event )); \n   var   outgoing   =   utf8 . encode ( json . encode ({ \n     text :   incoming [ text ], \n     ... \n   })); \n\n   connections . keys \n     . where (( userID )   =   userID   !=   fromUserID ) \n     . forEach (( userID )   { \n       var   connection   =   connections [ userID ]; \n       connection . add ( outgoing ); \n     });  }   Note that this simple implementation doesn't account for multiple connections from the same user or multi-isolate applications.", 
            "title": "Bi-directional Communication"
        }, 
        {
            "location": "/http/websockets/#considerations-for-multi-isolate-and-multi-instance-applications", 
            "text": "By default, an Aqueduct application runs on multiple isolates. Since each isolate has its own heap, a websocket created on one isolate is not directly accessible by another isolate. In the example above, each isolate would have its own map of connections - therefore, a message is only sent to connections that were opened on the same isolate that the chat message originated from.  A simple solution is to only run the application on a single isolate, ensuring that all websockets are on a single isolate and accessible to one another:  aqueduct   serve   - n   1   For many applications, this is a fine solution. For others, it may not be.  Recall that one of the benefits of Aqueduct's multi-isolate architecture is that code tested on a single instance will scale to multiple instances behind a load balancer. If an Aqueduct application runs correctly on a single, multi-isolate instance, it will run correctly on multiple instances. This (somewhat) enforced structure prevents us from naively keeping track of websocket connections on a single isolate, which would cause issues when we scale out to a multi-instance system.  If you find yourself in a situation where your application is so popular you need multiple servers to efficiently serve requests, you'll have a good idea on how to architect an appropriate solution (or you'll have the money to hire someone that does). In many situations, the REST API and websocket server are separate instances anyhow - they have different lifecycles and deployment behavior. It may make sense to run a websocket server on a single isolate, since you are likely IO-bound instead of CPU bound.  If you still prefer to have a multi-isolate server with websockets, the  ApplicationMessageHub  will come in handy. When broadcasting messages to connected websockets across the application, you first send the data to each websocket connected to the isolate that is originating the message. Then, the message is added to the  ApplicationMessageHub :  void   onChatMessage ( String   message )   { \n   connectedSockets . forEach (( socket )   { \n     socket . add ( message ); \n   }); \n\n   ApplicationChannel . messageHub . add ({ event :   websocket_broadcast ,   message :   message });  }   Anything added to the  messageHub  will be delivered to the listener for every other message hub - i.e., every other isolate will receive this data. The other isolates then send the message to each of their connected websockets:  class   ChatChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     messageHub . listen (( event )   { \n       if   ( event   is   Map     event [ event ]   ==   websocket_broadcast )   { \n         connectedSockets . forEach (( socket )   { \n           socket . add ( event [ message ]); \n         }); \n       } \n     }); \n   }  }", 
            "title": "Considerations for Multi-Isolate and Multi-Instance Applications"
        }, 
        {
            "location": "/http/file_upload/", 
            "text": "Uploading Files\n\n\nFiles are often uploaded as part of a multipart form request. A request of this type has the content-type \nmultipart/form-data\n and is body is made up of multiple data \nparts\n. These segments are typically the base64 encoded contents of a file and accompanying metadata for the upload.\n\n\nMultipart data is decoded using objects from \npackage:mime\n. You must add this package your application's \npubspec.yaml\n file:\n\n\ndependencies\n:\n\n  \nmime\n:\n \nany\n \n# prefer a better constraint than this\n\n\n\n\n\n\nBy default, resource controllers only accept \napplication/json\n requests and must be configured to accept \nmultipart/form-data\n requests. To read each part, create a \nMimeMultipartTransformer\n and stream the body into it. The following shows an example:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:mime/mime.dart\n;\n\n\n\nclass\n \nMyController\n \nextends\n \nResourceController\n \n{\n\n  \nMyController\n()\n \n{\n\n    \nacceptedContentTypes\n \n=\n \n[\nContentType\n(\nmultipart\n,\n \nform-data\n)];\n\n  \n}\n\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \npostForm\n()\n \nasync\n \n{}\n\n    \nfinal\n \nboundary\n \n=\n \nrequest\n.\nraw\n.\nheaders\n.\ncontentType\n.\nparameters\n[\nboundary\n];\n\n    \nfinal\n \ntransformer\n \n=\n \nMimeMultipartTransformer\n(\nboundary\n);\n\n    \nfinal\n \nbodyBytes\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\nList\nint\n();\n\n\n    \n// Pay special attention to the square brackets in the argument:\n\n    \nfinal\n \nbodyStream\n \n=\n \nStream\n.\nfromIterable\n([\nbodyBytes\n]);\n\n    \nfinal\n \nparts\n \n=\n \nawait\n \ntransformer\n.\nbind\n(\nbodyStream\n).\ntoList\n();\n\n\n    \nfor\n \n(\nvar\n \npart\n \nin\n \nparts\n)\n \n{\n\n      \nfinal\n \nheaders\n \n=\n \npart\n.\nheaders\n;\n\n      \nfinal\n \ncontent\n \n=\n \nawait\n \npart\n.\ntoList\n();\n\n\n      \n// Use headers[\ncontent-disposition\n] to identify the part\n\n      \n// The byte content of the part is available in \ncontent\n.\n\n    \n}\n    \n  \n}\n\n\n}", 
            "title": "Uploading Files"
        }, 
        {
            "location": "/http/file_upload/#uploading-files", 
            "text": "Files are often uploaded as part of a multipart form request. A request of this type has the content-type  multipart/form-data  and is body is made up of multiple data  parts . These segments are typically the base64 encoded contents of a file and accompanying metadata for the upload.  Multipart data is decoded using objects from  package:mime . You must add this package your application's  pubspec.yaml  file:  dependencies : \n   mime :   any   # prefer a better constraint than this   By default, resource controllers only accept  application/json  requests and must be configured to accept  multipart/form-data  requests. To read each part, create a  MimeMultipartTransformer  and stream the body into it. The following shows an example:  import   package:aqueduct/aqueduct.dart ;  import   package:mime/mime.dart ;  class   MyController   extends   ResourceController   { \n   MyController ()   { \n     acceptedContentTypes   =   [ ContentType ( multipart ,   form-data )]; \n   } \n\n   @ Operation . post () \n   Future Response   postForm ()   async   {} \n     final   boundary   =   request . raw . headers . contentType . parameters [ boundary ]; \n     final   transformer   =   MimeMultipartTransformer ( boundary ); \n     final   bodyBytes   =   await   request . body . decode List int (); \n\n     // Pay special attention to the square brackets in the argument: \n     final   bodyStream   =   Stream . fromIterable ([ bodyBytes ]); \n     final   parts   =   await   transformer . bind ( bodyStream ). toList (); \n\n     for   ( var   part   in   parts )   { \n       final   headers   =   part . headers ; \n       final   content   =   await   part . toList (); \n\n       // Use headers[ content-disposition ] to identify the part \n       // The byte content of the part is available in  content . \n     }     \n   }  }", 
            "title": "Uploading Files"
        }, 
        {
            "location": "/db/", 
            "text": "Tasks\n\n\nAqueduct's ORM stores data in database tables and maps table rows to Dart objects.\n\n\nYou declare subclasses of \nManagedObject\nT\n in your application code to define the database tables your application uses. The properties of these types have annotations like \nColumn\n and \nValidate\n to customize the behavior of tables in your database.\n\n\nYour application creates a \nManagedContext\n service object during initialization that manages database access for your application. This service is injected into controllers that make database queries.\n\n\nInstances of \nQuery\nT\n are created to insert, update, read and delete data from a database. A \nQuery\nT\n has many configurable options for filtering, joining, paging, sorting and performing aggregate functions on database rows.\n\n\nThe \naqueduct db\n command-line tool manages databases that your application connects. This tool creates and executes migration scripts that update the schema of a database to match the requirements of your application.\n\n\nThe minimum version of PostgreSQL needed to work with Aqueduct is 9.6.\n\n\nGuides\n\n\n\n\nConnecting to a Database\n\n\nModeling Data\n\n\nStorage, Serialization and Deserialization\n\n\nExecuting Queries\n\n\nJoins, Filtering and Paging\n\n\nExecuting Queries in a Transaction\n\n\nAdding Validations and Callbacks to ManagedObject\n\n\nAqueduct Database Tool\n\n\nJSON Document Columns and Operations", 
            "title": "Overview"
        }, 
        {
            "location": "/db/#tasks", 
            "text": "Aqueduct's ORM stores data in database tables and maps table rows to Dart objects.  You declare subclasses of  ManagedObject T  in your application code to define the database tables your application uses. The properties of these types have annotations like  Column  and  Validate  to customize the behavior of tables in your database.  Your application creates a  ManagedContext  service object during initialization that manages database access for your application. This service is injected into controllers that make database queries.  Instances of  Query T  are created to insert, update, read and delete data from a database. A  Query T  has many configurable options for filtering, joining, paging, sorting and performing aggregate functions on database rows.  The  aqueduct db  command-line tool manages databases that your application connects. This tool creates and executes migration scripts that update the schema of a database to match the requirements of your application.  The minimum version of PostgreSQL needed to work with Aqueduct is 9.6.", 
            "title": "Tasks"
        }, 
        {
            "location": "/db/#guides", 
            "text": "Connecting to a Database  Modeling Data  Storage, Serialization and Deserialization  Executing Queries  Joins, Filtering and Paging  Executing Queries in a Transaction  Adding Validations and Callbacks to ManagedObject  Aqueduct Database Tool  JSON Document Columns and Operations", 
            "title": "Guides"
        }, 
        {
            "location": "/db/connecting/", 
            "text": "Connecting to a Database from Aqueduct\n\n\nThe purpose of this document is to guide you through creating a new PostgreSQL database and setting up an Aqueduct application that connects to it.\n\n\nCreating a Database\n\n\nTo use the Aqueduct ORM, you must have a PostgreSQL database server and create a database for your application. When developing locally, use \nPostgres.app\n to set up a development database server quickly. After running this application, create or select a new database server from the left-hand menu, and then double-click any of the database icons to open the \npsql\n command-line tool. (If you are not using \nPostgres.app\n, make sure \npsql\n is in your \n$PATH\n and run it from the command-line.)\n\n\nInside \npsql\n, enter the following commands to create a database and a database user for your application:\n\n\nCREATE\n \nDATABASE\n \nmy_app_name\n;\n\n\nCREATE\n \nUSER\n \nmy_app_name_user\n \nWITH\n \nPASSWORD\n \npassword\n;\n\n\nGRANT\n \nALL\n \nON\n \nDATABASE\n \nmy_app_name\n \nTO\n \nmy_app_name_user\n;\n\n\n\n\n\n\nUsing ManagedContext to Connect to a Database\n\n\nThe interface to a database from Aqueduct is an instance of \nManagedContext\n that contains the following two objects:\n\n\n\n\na \nManagedDataModel\n that describes your application's data model\n\n\na \nPersistentStore\n that manages a connection to a single database\n\n\n\n\nA \nManagedContext\n uses these two objects to coordinate moving data to and from your application and a database. A \nQuery\nT\n object uses a context's persistent store to determine which database to send commands to, and a data model to map database rows to objects and vice versa.\n\n\nA context, like all service objects, is created in \nApplicationChannel.prepare\n.\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nvar\n \npsc\n \n=\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n        \nmy_app_name_user\n,\n \npassword\n,\n \nlocalhost\n,\n \n5432\n,\n \nmy_app_name\n);\n\n\n    \ncontext\n \n=\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nManagedDataModel.fromCurrentMirrorSystem\n finds every \nManagedObject\nT\n subclass in your application's code. Optionally, you may specify an exact list:\n\n\nvar\n \ndataModel\n \n=\n \nManagedDataModel\n([\nUser\n,\n \nPost\n,\n \nFriendship\n]);\n\n\n\n\n\n\n\n\nFinding ManagedObjects\nA managed object subclass must be directly or transitively imported into your application channel file. A file in your project directory that is not imported will not be found. There is typically no need to import a managed object subclass file directly: your application is initialized in your channel, which imports all of your controllers and services, which in turn import the managed object subclasses they use. As long as you are using your managed object declarations in your application, they'll be found.\n\n\n\n\n\n\nControllers that need to execute database queries must have a reference to a context; this is typically accomplished by passing the context to a controller's constructor:\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ncontext\n \n=\n \nManagedContext\n(...);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nreturn\n \nRouter\n()\n\n      \n..\nroute\n(\n/users/[:id]\n).\nlink\n(()\n \n=\n \nUserController\n(\ncontext\n));\n\n  \n}\n\n\n}\n\n\n\n\n\n\nUsing a Configuration File\n\n\nConnection information for a database is most often read from a configuration file. This allows you to create configurations for different environments (production, development, etc.), without having to modify code. This is very important for testing, because you will want to run your automated tests against an empty database. (\nSee more on configuration files.\n.)\n\n\nclass\n \nMyConfiguration\n \nextends\n \nConfiguration\n \n{\n\n  \nMyConfiguration\n(\nString\n \nconfigPath\n)\n \n:\n \nsuper\n.\nfromFile\n(\nconfigPath\n);\n\n\n  \nDatabaseConfiguration\n \ndatabase\n;\n\n\n}\n\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \nconfig\n \n=\n \nMyConfiguration\n(\noptions\n.\nconfigurationFilePath\n);\n\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npsc\n \n=\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n        \nconfig\n.\ndatabase\n.\nusername\n,\n\n        \nconfig\n.\ndatabase\n.\npassword\n,\n\n        \nconfig\n.\ndatabase\n.\nhost\n,\n\n        \nconfig\n.\ndatabase\n.\nport\n,\n\n        \nconfig\n.\ndatabase\n.\ndatabaseName\n);\n        \n\n    \ncontext\n \n=\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe declaration of \nMyConfiguration\n requires that a YAML file must have the following structure:\n\n\ndatabase\n:\n\n  \nusername\n:\n \nbob\n\n  \npassword\n:\n \nbobspassword\n\n  \nhost\n:\n \nlocalhost\n\n  \nport\n:\n \n5432\n\n  \ndatabaseName\n:\n \nmy_app\n\n\n\n\n\n\nConnection Behavior\n\n\nA persistent store manages one database connection. This connection is automatically maintained - the first time a query is executed, the connection is opened. If the connection is lost, the next query will reopen the connection. If a connection fails to open, an exception is thrown when trying to execute a query. This connection will return a 503 response if left uncaught.", 
            "title": "Connecting to a Database"
        }, 
        {
            "location": "/db/connecting/#connecting-to-a-database-from-aqueduct", 
            "text": "The purpose of this document is to guide you through creating a new PostgreSQL database and setting up an Aqueduct application that connects to it.", 
            "title": "Connecting to a Database from Aqueduct"
        }, 
        {
            "location": "/db/connecting/#creating-a-database", 
            "text": "To use the Aqueduct ORM, you must have a PostgreSQL database server and create a database for your application. When developing locally, use  Postgres.app  to set up a development database server quickly. After running this application, create or select a new database server from the left-hand menu, and then double-click any of the database icons to open the  psql  command-line tool. (If you are not using  Postgres.app , make sure  psql  is in your  $PATH  and run it from the command-line.)  Inside  psql , enter the following commands to create a database and a database user for your application:  CREATE   DATABASE   my_app_name ;  CREATE   USER   my_app_name_user   WITH   PASSWORD   password ;  GRANT   ALL   ON   DATABASE   my_app_name   TO   my_app_name_user ;", 
            "title": "Creating a Database"
        }, 
        {
            "location": "/db/connecting/#using-managedcontext-to-connect-to-a-database", 
            "text": "The interface to a database from Aqueduct is an instance of  ManagedContext  that contains the following two objects:   a  ManagedDataModel  that describes your application's data model  a  PersistentStore  that manages a connection to a single database   A  ManagedContext  uses these two objects to coordinate moving data to and from your application and a database. A  Query T  object uses a context's persistent store to determine which database to send commands to, and a data model to map database rows to objects and vice versa.  A context, like all service objects, is created in  ApplicationChannel.prepare .  class   MyApplicationChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     var   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     var   psc   =   PostgreSQLPersistentStore . fromConnectionInfo ( \n         my_app_name_user ,   password ,   localhost ,   5432 ,   my_app_name ); \n\n     context   =   ManagedContext ( dataModel ,   psc ); \n   }  }   The  ManagedDataModel.fromCurrentMirrorSystem  finds every  ManagedObject T  subclass in your application's code. Optionally, you may specify an exact list:  var   dataModel   =   ManagedDataModel ([ User ,   Post ,   Friendship ]);    Finding ManagedObjects A managed object subclass must be directly or transitively imported into your application channel file. A file in your project directory that is not imported will not be found. There is typically no need to import a managed object subclass file directly: your application is initialized in your channel, which imports all of your controllers and services, which in turn import the managed object subclasses they use. As long as you are using your managed object declarations in your application, they'll be found.    Controllers that need to execute database queries must have a reference to a context; this is typically accomplished by passing the context to a controller's constructor:  class   MyApplicationChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     context   =   ManagedContext (...); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     return   Router () \n       .. route ( /users/[:id] ). link (()   =   UserController ( context )); \n   }  }", 
            "title": "Using ManagedContext to Connect to a Database"
        }, 
        {
            "location": "/db/connecting/#using-a-configuration-file", 
            "text": "Connection information for a database is most often read from a configuration file. This allows you to create configurations for different environments (production, development, etc.), without having to modify code. This is very important for testing, because you will want to run your automated tests against an empty database. ( See more on configuration files. .)  class   MyConfiguration   extends   Configuration   { \n   MyConfiguration ( String   configPath )   :   super . fromFile ( configPath ); \n\n   DatabaseConfiguration   database ;  }  class   MyApplicationChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   config   =   MyConfiguration ( options . configurationFilePath ); \n\n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   psc   =   PostgreSQLPersistentStore . fromConnectionInfo ( \n         config . database . username , \n         config . database . password , \n         config . database . host , \n         config . database . port , \n         config . database . databaseName );         \n\n     context   =   ManagedContext ( dataModel ,   psc ); \n   }  }   The declaration of  MyConfiguration  requires that a YAML file must have the following structure:  database : \n   username :   bob \n   password :   bobspassword \n   host :   localhost \n   port :   5432 \n   databaseName :   my_app", 
            "title": "Using a Configuration File"
        }, 
        {
            "location": "/db/connecting/#connection-behavior", 
            "text": "A persistent store manages one database connection. This connection is automatically maintained - the first time a query is executed, the connection is opened. If the connection is lost, the next query will reopen the connection. If a connection fails to open, an exception is thrown when trying to execute a query. This connection will return a 503 response if left uncaught.", 
            "title": "Connection Behavior"
        }, 
        {
            "location": "/db/modeling_data/", 
            "text": "Modeling Data\n\n\nIn this guide, you will learn how to create types that are mapped to database tables. At the end of this guide are additional examples of data model types.\n\n\nDefining a Table\n\n\nIn your application, you declare types whose instances are stored in a database. Each of these types is mapped to a database table, where each property of the type is a column of the table. For example, consider modeling newspaper articles, where each article has a unique identifier, text contents and published date:\n\n\n// This is a table definition of an \narticle\n\n\nclass\n \n_Article\n \n{\n\n  \n@\nColumn\n(\nprimaryKey:\n \ntrue\n)\n\n  \nint\n \nid\n;\n\n\n  \nString\n \ncontents\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nDateTime\n \npublishedDate\n;\n\n\n}\n\n\n\n\n\n\nThis plain Dart class is called a \ntable definition\n because it defines a database table named \n_Article\n. The table has three columns, \nid\n, \ncontents\n, \npublishedDate\n. An example of the data stored in this table might look like this:\n\n\n\n\n\n\n\n\nid\n\n\ncontents\n\n\npublishedDate\n\n\n\n\n\n\n\n\n\n\n1\n\n\nToday, the local...\n\n\n2018-02-01 00:00:00.000\n\n\n\n\n\n\n2\n\n\nIn other news, ...\n\n\n2018-03-01 04:30:00.000\n\n\n\n\n\n\n\n\nA property in a table definition can optionally have a \nColumn\n annotation. This annotation configures the behavior of the associated database column. If a property doesn't have an annotation, the column has default behavior. These behaviors are shown in the table below:\n\n\n\n\n\n\n\n\nOption\n\n\nType\n\n\nBehavior\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\nprimaryKey\n\n\nbool\n\n\nsets primary key column\n\n\nfalse (not primary key)\n\n\n\n\n\n\ndatabaseType\n\n\nManagedPropertyType\n\n\nsets underlying column type\n\n\ninferred from Dart type\n\n\n\n\n\n\nnullable\n\n\nbool\n\n\ntoggles whether column can be null\n\n\nfalse (not nullable)\n\n\n\n\n\n\nunique\n\n\nbool\n\n\ntoggles whether column is unique across all rows\n\n\nfalse (not unique)\n\n\n\n\n\n\ndefaultValue\n\n\nString\n\n\nprovides default value for new rows when value is undefined\n\n\nnull\n\n\n\n\n\n\nindexed\n\n\nbool\n\n\nwhether an index should be created for the column\n\n\nfalse (no index)\n\n\n\n\n\n\nomitByDefault\n\n\nbool\n\n\nwhether this column should be left out by default\n\n\nfalse (fetch column value)\n\n\n\n\n\n\nautoincrement\n\n\nbool\n\n\nwhether this column's value is automatically generated from a series\n\n\nfalse (not generated)\n\n\n\n\n\n\n\n\nYou must use either zero or one \nColumn\n annotation per property, and you must set all behaviors in one annotation, e.g.:\n\n\n@\nColumn\n(\nnullable:\n \ntrue\n,\n \nunique:\n \ntrue\n,\n \nindexed:\n \ntrue\n)\n\n\nint\n \nfield\n;\n\n\n\n\n\n\nThe data type of a column is inferred from the Dart type of the property as shown by the following table.\n\n\n\n\n\n\n\n\nDart Type\n\n\nGeneral Column Type\n\n\nPostgreSQL Column Type\n\n\n\n\n\n\n\n\n\n\nint\n\n\ninteger number\n\n\nINT\n or \nSERIAL\n\n\n\n\n\n\ndouble\n\n\nfloating point number\n\n\nDOUBLE PRECISION\n\n\n\n\n\n\nString\n\n\ntext\n\n\nTEXT\n\n\n\n\n\n\nDateTime\n\n\ntimestamp\n\n\nTIMESTAMP\n\n\n\n\n\n\nbool\n\n\nboolean\n\n\nBOOLEAN\n\n\n\n\n\n\nDocument\n\n\na JSON object or array\n\n\nJSONB\n\n\n\n\n\n\nAny \nenum\n\n\ntext, restricted to enum cases\n\n\nTEXT\n\n\n\n\n\n\n\n\nSome types can be represented by many database types; for example, an integer can be stored as 2, 4 or 8 bytes. Use the \ndatabaseType\n of a \nColumn\n annotation to specify:\n\n\n@\nColumn\n(\ndatabaseType:\n \nManagedPropertyType\n.\nbigInteger\n)\n\n\nint\n \nbigNumber\n;\n\n\n\n\n\n\nThe only requirement of a table definition type is that it has exactly one primary key property. A primary key is an indexed, unique identifier for a database row and is set through the \nColumn\n annotation.\n\n\n@\nColumn\n(\nprimaryKey:\n \ntrue\n)\n\n\nint\n \nid\n;\n\n\n\n\n\n\nA primary key can be any supported data type, and it is always unique and indexed. It is common for primary keys to be 64-bit, auto-incrementing integers. The \nprimaryKey\n constant exists as a convenience for a \nColumn\n with these behaviors.\n\n\nclass\n \n_Article\n \n{\n\n  \n@\nprimaryKey\n \n// equivalent to @Column(primaryKey: true, databaseType: ManagedPropertyType.bigInteger, autoincrement: true)\n\n  \nint\n \nid\n;\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\n\n\nCreating Tables\n\n\nTables are created in a database by using the \naqueduct\n command line tool to generate and execute migration scripts. The tool inspects your database types and automatically synchronizes a databases schema to match your them.\n\n\n\n\nBy default, the name of the table definition is the name of the database table. You can configure this with the \nTable\n annotation.\n\n\n@\nTable\n(\nname:\n \nArticleTable\n)\n\n\nclass\n \n_Article\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \ncontents\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nDateTime\n \npublishedDate\n;\n\n\n}\n\n\n\n\n\n\nIt is convention that table definitions are \nprivate classes\n, that is, their name is prefixed with an underscore (\n_\n). This convention is discussed later in this guide.\n\n\nDefining a Managed Object Subclass\n\n\nA table definition by itself is just a plain Dart class. You must also declare a \nManagedObject\n subclass to bring your table definition to life. Here's an example:\n\n\nclass\n \nArticle\n \nextends\n \nManagedObject\n_Article\n \nimplements\n \n_Article\n \n{}\n\n\n\n\n\n\nA managed object subclass, also called the \ninstance type\n, is the object type that you work with in your application code. For example, when you fetch rows from a database, you will get a list of managed objects. A managed object subclass declares its table definition in two places: once as the type argument of its superclass, and again as an interface it implements.\n\n\nA managed object subclass inherits all of the properties from its table definition; i.e., an \nArticle\n has an \nid\n, \ncontents\n and \npublishedDate\n because \n_Article\n declares those properties. You create and use instances of a managed object subclass like any other object:\n\n\nfinal\n \narticle\n \n=\n \nnew\n \nArticle\n();\n\n\narticle\n.\ntext\n \n=\n \nToday, ...\n;\n\n\narticle\n.\npublishedDate\n \n=\n \nDateTime\n.\nnow\n();\n\n\n\n\n\n\n\n\nManaged Object Constructors\n\n\nYou can add new constructors to a managed object subclass, but you must always have a default, no-argument constructor. This default constructor is used when the ORM creates instances from rows in your database.\n\n\n\n\nModeling Relationships\n\n\nA managed object can have \nrelationships\n to other managed objects. For example, an author can have many books, an article can belong to a newspaper, and an employee can have a manager. In a relational database, relationships between tables are established by storing the primary key of a table row in a column of the related table. This column is a \nforeign key reference\n to the related table.\n\n\nWhen a table has a foreign key reference, it is said to \nbelong to\n the related table. In the example of an employee and manager, the employee \nbelongs to\n the manager and therefore the employee table has a foreign key reference to the manager table. The inverse of this statement is also true: a manager \nhas\n employees. A manager has-many employees - this is called a \nhas-many relationship\n. There are also \nhas-one relationships\n - for example, a country has-one capital.\n\n\nThe following is an example of a country and a has-one relationship to a capital city:\n\n\nclass\n \nCity\n \nextends\n \nManagedObject\n_City\n \nimplements\n \n_City\n \n{}\n\n\nclass\n \n_City\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nRelate\n(\n#\ncapital\n)\n\n  \nCountry\n \ncountry\n;\n\n\n}\n\n\n\nclass\n \nCountry\n \nextends\n \nManagedObject\n_Country\n \nimplements\n \n_Country\n \n{}\n\n\nclass\n \n_Country\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nCity\n \ncapital\n;\n\n\n}\n\n\n\n\n\n\nA relationship is formed between two tables by declaring properties in both table definition types. The type of those properties is the related managed object subclass - so a \nCountry\n has a property of type \nCity\n, and a \nCity\n has a property of type \nCountry\n.\n\n\nExactly one of those properties must have a \nRelate\n annotation. The \nRelate\n annotation designates the underlying column as a foreign key column. In this example, the city table has a foreign key column to the country table. Conceptually, then, a city \nbelongs to\n a country and a country has-one capital city. A city can only belong to one country through this relationship, and that is true of all belongs-to relationship properties.\n\n\n\n\nForeign Key Column Names\n\n\nA foreign key column in the database is named by joining the name of the relationship property and the primary key of the related table with an underscore. For example, the column in the city table is named \ncountry_id\n.\n\n\n\n\nThe property without \nRelate\n is the \ninverse\n of the relationship and is conceptually either a has-one or has-many relationship property. In this example, a country's relationship to its capital is has-one. A relationship is has-many when the type of the inverse property is a \nManagedSet\n. For example, if we wanted to model a relationship between a country and all of its cities, we'd declare a \nManagedSet\nCity\n property in the country:\n\n\nclass\n \nCity\n \nextends\n \nManagedObject\n_City\n \nimplements\n \n_City\n \n{}\n\n\nclass\n \n_City\n \n{\n\n  \n...\n\n\n  \n@\nRelate\n(\n#\ncities\n)\n\n  \nCountry\n \ncountry\n;\n\n\n}\n\n\n\nclass\n \nCountry\n \nextends\n \nManagedObject\n_Country\n \nimplements\n \n_Country\n \n{}\n\n\nclass\n \n_Country\n \n{\n\n  \n...\n\n\n  \nManagedSet\nCity\n \ncities\n;\n\n\n}\n\n\n\n\n\n\n\n\nManagedSet Behavior\n\n\nA \nRelate\n property can never be a \nManagedSet\n. A \nManagedSet\n is a \nList\n, and therefore can be used in the same way a list is used.\n\n\n\n\nNotice that the \nRelate\n annotation takes at least one argument: a symbol that matches the name of the inverse property. This is what links two relationship properties to each other. In the first example, this argument was \n#capital\n because the name of the inverse property is \ncapital\n; likewise, \n#cities\n and \ncities\n. This pairing name must match or an error will be thrown.\n\n\n\n\nSymbols\n\n\nA symbol is a name identifier in Dart; a symbol can refer to a class, method, or property. The \n#name\n syntax is a \nsymbol literal\n.\n\n\n\n\nThe \nRelate\n annotation has optional arguments to further define the relationship. Like \nColumn\n, these are optional arguments, e.g.:\n\n\n@\nRelate\n(\n#\ncities\n,\n \nisRequired:\n \ntrue\n,\n \nonDelete:\n \nDeleteRule\n.\ncascade\n)\n\n\n\n\n\n\nA relationship may be be required or optional. For example, if \nCity.country\n were required, then a \nCity\n must always have a \nCountry\n. By default, relationships are optional.\n\n\nA relationship has a delete rule. When an object is deleted, any objects that belong to its relationships are subject to this rule. The following table shows the rules and their behavior:\n\n\n\n\n\n\n\n\nRule\n\n\nBehavior\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nnullify (default)\n\n\ninverse is set to null\n\n\nWhen deleting an author, its articles' author becomes null\n\n\n\n\n\n\ncascade\n\n\nrelated objects are also deleted\n\n\nWhen deleting an author, its articles are deleted\n\n\n\n\n\n\nrestrict\n\n\ndelete fails\n\n\nWhen attempting to delete an author with articles, the delete operation fails\n\n\n\n\n\n\ndefault\n\n\ninverse set to a default value\n\n\nWhen deleting an author, its articles author is set to the default value of the column\n\n\n\n\n\n\n\n\nSpecial Behaviors\n\n\nEnum Types\n\n\nEnums types can be used to declare properties in a table definition. The database will store the column as a string representation of the enumeration. Here's an example where a user can be an administrator or a normal user:\n\n\nenum\n \nUserType\n \n{\n\n  \nadmin\n,\n \nuser\n\n\n}\n\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \nUserType\n \nrole\n;\n\n\n}\n\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n\n  \n..\nvalues\n.\nrole\n \n=\n \nUserType\n.\nadmin\n;\n\n\nfinal\n \nbob\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n\n\n\nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nrole\n).\nequalTo\n(\nUserType\n.\nadmin\n);\n\n\nfinal\n \nallAdmins\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nIn the database, the \nrole\n column is stored as a string. Its value is either \"admin\" or \"user\".\n\n\nPrivate Variables\n\n\nA private variable in a table definition removes it from the serialized representation of an object. A private variable is always fetched when making a database query, but it is not read when invoking \nread\n and is not written when invoking \nasMap\n. Both of these methods are invoked when reading a managed object from a request body, or writing it to a response body.\n\n\nTransient Properties\n\n\nProperties declared in a managed object subclass are called \ntransient\n because they are not stored in a database. For example, consider an \nAuthor\n type that stores first and last name as separate columns. Instead of redundantly storing a 'full name' in the database, a transient property can combine the first and last name:\n\n\nclass\n \nAuthor\n \nextends\n \nManagedObject\n_Author\n \nimplements\n \n_Author\n \n{\n\n  \nString\n \nget\n \nname\n \n=\n \n$\nfirstName\n \n$\nlastName\n;\n\n  \nset\n \nname\n(\nString\n \nfullName\n)\n \n{\n\n    \nfirstName\n \n=\n \nfullName\n.\nsplit\n(\n \n).\nfirst\n;\n\n    \nlastName\n \n=\n \nfullName\n.\nsplit\n(\n \n).\nlast\n;\n\n  \n}\n\n\n}\n\n\nclass\n \n_Author\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nfirstName\n;\n\n  \nString\n \nlastName\n;\n\n\n}\n\n\n\n\n\n\nBy default, a transient property is ignored when reading an object from a request body or writing the object to a response body (see the guide on \nserialization\n for more details). You can annotate a transient property with \nSerialize\n so that it is able to be read from a request body, written to a response body, or both. For example:\n\n\nclass\n \nAuthor\n \nextends\n \nManagedObject\n_Author\n \nimplements\n \n_Author\n \n{\n\n  \n@\nSerialize\n()\n\n  \nString\n \nget\n \nname\n \n=\n \n$\nfirstName\n \n$\nlastName\n;\n\n\n  \n@\nSerialize\n()\n\n  \nset\n \nname\n(\nString\n \nfullName\n)\n \n{\n\n    \nfirstName\n \n=\n \nfullName\n.\nsplit\n(\n \n).\nfirst\n;\n\n    \nlastName\n \n=\n \nfullName\n.\nsplit\n(\n \n).\nlast\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nYou may declare getters, setters and properties to be serialized in this way. When declaring a property, you can control it with arguments to \nSerialize\n:\n\n\nclass\n \nAuthor\n \nextends\n \nManagedObject\n_Author\n \nimplements\n \n_Author\n \n{\n\n  \n@\nSerialize\n(\ninput:\n \nfalse\n,\n \noutput:\n \ntrue\n)\n\n  \nbool\n \nisCurrentlyPromoted\n;\n\n\n}\n\n\n\n\n\n\nProject File Structure\n\n\nA managed object subclass and its table definition together are called an \nentity\n. Each entity should be declared in the same file, and the table definition should be prefixed with an \n_\n to prevent it from being used elsewhere in the project. It is preferable to declare one entity per file, and store all entities in the \nlib/model/\n directory of your project.\n\n\nThe files your model definitions are declared in must be visible to Aqueduct tooling. In normal circumstances, this happens automatically because of the following:\n\n\n\n\nAqueduct tooling can find any file that is imported (directly or transitively) from your library file.\n\n\nYour library file, by default, can see the file your \nApplicationChannel\n is declared in.\n\n\nYour application channel file must import any controller that it links.\n\n\nYour controllers must import any model file they use.\n\n\n\n\nWhen you use the \naqueduct\n CLI to generate database migration scripts, it will report all of the \nManagedObject\ns in your application that it was able to find. If a particular type is not listed, it may reveal that you aren't using that type. If you need to ensure that the tooling can see a particular model file that it is not locating, you may import it in your \nchannel.dart\n file.\n\n\nExamples\n\n\nExample: One-to-Many Relationship\n\n\nAn author has many books:\n\n\nclass\n \nAuthor\n \nextends\n \nManagedObject\n_Author\n \nimplements\n \n_Author\n \n{}\n\n\nclass\n \n_Author\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \nManagedSet\nBook\n \nbooks\n;\n\n\n}\n\n\n\nclass\n \nBook\n \nextends\n \nManagedObject\n_Book\n \nimplements\n \n_Book\n \n{}\n\n\nclass\n \n_Book\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \n@\nRelate\n(\n#\nbooks\n)\n\n  \nAuthor\n \nauthor\n;\n\n\n}\n\n\n\n\n\n\nTo insert an author and a book associated with that author:\n\n\nfinal\n \nauthorQuery\n \n=\n \nQuery\nAuthor\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nFred\n;\n\n\nfinal\n \nauthor\n \n=\n \nawait\n \nauthorQuery\n.\ninsert\n();\n\n\n\nfinal\n \nbookQuery\n \n=\n \nQuery\nBook\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nTitle\n\n  \n..\nvalues\n.\nauthor\n.\nid\n \n=\n \nauthor\n.\nid\n;\n\n\nfinal\n \nbook\n \n=\n \nawait\n \nbookQuery\n.\ninsert\n();\n  \n\n\n\n\n\nTo fetch authors and their books:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nAuthor\n(\ncontext\n)\n\n  \n..\njoin\n(\nset\n:\n \n(\na\n)\n \n=\n \na\n.\nbooks\n);\n\n\nfinal\n \nauthors\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nTo fetch a book and their full author object:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nBook\n(\ncontext\n)\n\n  \n..\nwhere\n((\nb\n)\n \n=\n \nb\n.\nid\n).\nequalTo\n(\n1\n)\n\n  \n..\njoin\n(\nobject:\n \n(\na\n)\n \n=\n \na\n.\nauthor\n);\n\n\nfinal\n \nbooks\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nExample: One-to-One Relationship\n\n\nclass\n \nCountry\n \nextends\n \nManagedObject\n_Country\n \nimplements\n \n_Country\n \n{}\n\n\nclass\n \n_Country\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \nCity\n \ncapital\n;\n\n\n}\n\n\n\nclass\n \nCity\n \nextends\n \nManagedObject\n_City\n \nimplements\n \n_City\n \n{}\n\n\nclass\n \n_City\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \n@\nRelate\n(\n#\ncapital\n)\n\n  \nCountry\n \ncountry\n;\n\n\n}\n\n\n\n\n\n\nTo fetch a country and its capital:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nCountry\n(\ncontext\n)\n\n  \n..\nwhere\n((\nc\n)\n \n=\n \nc\n.\nid\n).\nequalTo\n(\n1\n)\n\n  \n..\njoin\n(\nobject:\n \n(\na\n)\n \n=\n \na\n.\ncapital\n);\n\n\nfinal\n \ncountries\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nExample: Many-to-Many Relationship\n\n\nclass\n \nTeam\n \nextends\n \nManagedObject\n_Team\n \nimplements\n \n_Team\n \n{}\n\n\nclass\n \n_Team\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \nManagedSet\nTeamPlayer\n \nteamPlayers\n;\n\n\n}\n\n\n\n// This type is a join table\n\n\nclass\n \nTeamPlayer\n \nextends\n \nManagedObject\n_TeamPlayer\n \nimplements\n \n_TeamPlayer\n \n{}\n\n\nclass\n \n_TeamPlayer\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n  \n\n  \n@\nRelate\n(\n#\nteamPlayers\n)\n\n  \nTeam\n \nteam\n;\n\n\n  \n@\nRelate\n(\n#\nteamPlayers\n)\n\n  \nPlayer\n \nplayer\n;\n\n\n}\n\n\n\nclass\n \nPlayer\n \nextends\n \nManagedObject\n_Player\n \nimplements\n \n_Player\n \n{}\n\n\nclass\n \n_Player\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \nManagedSet\nTeamPlayer\n \nteamPlayers\n;\n\n\n}\n\n\n\n\n\n\nTo fetch a team and its players:\n\n\n// Note that the final join is not cascaded from the Team query,\n\n\n// but from the Query created by joining with TeamPlayer\n\n\nfinal\n \nquery\n \n=\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\nwhere\n((\nt\n)\n \n=\n \nt\n.\nid\n).\nequalTo\n(\n1\n)\n\n  \n..\njoin\n(\nset\n:\n \n(\nt\n)\n \n=\n \nt\n.\nteamPlayers\n).\njoin\n(\nobject:\n \n(\ntp\n)\n \n=\n \ntp\n.\nplayer\n);\n\n\nfinal\n \nteam\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nThe structure of this object is:\n\n\n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBadgers\n,\n\n  \nteamPlayers\n:\n \n[\n\n    \n{\n\n      \nid\n:\n \n1\n,\n\n      \nteam\n:\n \n{\n\n        \nid\n:\n \n1\n\n      \n},\n\n      \nplayer\n:\n \n{\n\n        \nid\n:\n \n1\n,\n\n        \nname\n:\n \nFred\n\n      \n}\n\n    \n}\n\n  \n]\n\n\n}\n\n\n\n\n\n\nYou can flatten this structure in a number of ways. In the simplest form, add a \nSerialize\n-annotated transient property to the \nManagedObject\n subclass, and each time you fetch, remove the join table from the object and place the players in the transient property.\n\n\nclass\n \nTeam\n \nextends\n \nManagedObject\n_Team\n \nimplements\n \n_Team\n \n{\n\n  \n@\nSerialize\n(\ninput:\n \nfalse\n,\n \noutput:\n \ntrue\n)\n\n  \nList\nMap\nString\n,\n \ndynamic\n \nplayers\n;\n\n\n}\n\n\n\nfinal\n \nteam\n \n=\n \n...;\n\n\nteam\n.\nplayers\n \n=\n \nteam\n.\nteamPlayers\n.\nmap\n((\nt\n)\n \n=\n \nt\n.\nplayer\n.\nasMap\n()).\ntoList\n();\n\n\n// Remove teamPlayers; it is redundant\n\n\nteam\n.\nbacking\n.\nremoveProperty\n(\nteamPlayers\n);\n\n\n\n\n\n\nExample: Hierarchical Relationships (Self Referencing)\n\n\nHierarchical relationships follow the same rules as all other relationship, but declare the foreign key property and the inverse in the same type.\n\n\nclass\n \nPerson\n \nextends\n \nManagedObject\n_Person\n \nimplements\n \n_Person\n \n{}\n\n\nclass\n \n_Person\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \nManagedSet\nPerson\n \nchildren\n;\n\n\n  \n@\nRelate\n(\n#\nchildren\n)\n\n  \nPerson\n \nparent\n;\n\n\n}", 
            "title": "Modeling Data and Relationships"
        }, 
        {
            "location": "/db/modeling_data/#modeling-data", 
            "text": "In this guide, you will learn how to create types that are mapped to database tables. At the end of this guide are additional examples of data model types.", 
            "title": "Modeling Data"
        }, 
        {
            "location": "/db/modeling_data/#defining-a-table", 
            "text": "In your application, you declare types whose instances are stored in a database. Each of these types is mapped to a database table, where each property of the type is a column of the table. For example, consider modeling newspaper articles, where each article has a unique identifier, text contents and published date:  // This is a table definition of an  article  class   _Article   { \n   @ Column ( primaryKey:   true ) \n   int   id ; \n\n   String   contents ; \n\n   @ Column ( indexed:   true ) \n   DateTime   publishedDate ;  }   This plain Dart class is called a  table definition  because it defines a database table named  _Article . The table has three columns,  id ,  contents ,  publishedDate . An example of the data stored in this table might look like this:     id  contents  publishedDate      1  Today, the local...  2018-02-01 00:00:00.000    2  In other news, ...  2018-03-01 04:30:00.000     A property in a table definition can optionally have a  Column  annotation. This annotation configures the behavior of the associated database column. If a property doesn't have an annotation, the column has default behavior. These behaviors are shown in the table below:     Option  Type  Behavior  Default      primaryKey  bool  sets primary key column  false (not primary key)    databaseType  ManagedPropertyType  sets underlying column type  inferred from Dart type    nullable  bool  toggles whether column can be null  false (not nullable)    unique  bool  toggles whether column is unique across all rows  false (not unique)    defaultValue  String  provides default value for new rows when value is undefined  null    indexed  bool  whether an index should be created for the column  false (no index)    omitByDefault  bool  whether this column should be left out by default  false (fetch column value)    autoincrement  bool  whether this column's value is automatically generated from a series  false (not generated)     You must use either zero or one  Column  annotation per property, and you must set all behaviors in one annotation, e.g.:  @ Column ( nullable:   true ,   unique:   true ,   indexed:   true )  int   field ;   The data type of a column is inferred from the Dart type of the property as shown by the following table.     Dart Type  General Column Type  PostgreSQL Column Type      int  integer number  INT  or  SERIAL    double  floating point number  DOUBLE PRECISION    String  text  TEXT    DateTime  timestamp  TIMESTAMP    bool  boolean  BOOLEAN    Document  a JSON object or array  JSONB    Any  enum  text, restricted to enum cases  TEXT     Some types can be represented by many database types; for example, an integer can be stored as 2, 4 or 8 bytes. Use the  databaseType  of a  Column  annotation to specify:  @ Column ( databaseType:   ManagedPropertyType . bigInteger )  int   bigNumber ;   The only requirement of a table definition type is that it has exactly one primary key property. A primary key is an indexed, unique identifier for a database row and is set through the  Column  annotation.  @ Column ( primaryKey:   true )  int   id ;   A primary key can be any supported data type, and it is always unique and indexed. It is common for primary keys to be 64-bit, auto-incrementing integers. The  primaryKey  constant exists as a convenience for a  Column  with these behaviors.  class   _Article   { \n   @ primaryKey   // equivalent to @Column(primaryKey: true, databaseType: ManagedPropertyType.bigInteger, autoincrement: true) \n   int   id ; \n\n   ...  }    Creating Tables  Tables are created in a database by using the  aqueduct  command line tool to generate and execute migration scripts. The tool inspects your database types and automatically synchronizes a databases schema to match your them.   By default, the name of the table definition is the name of the database table. You can configure this with the  Table  annotation.  @ Table ( name:   ArticleTable )  class   _Article   { \n   @ primaryKey \n   int   id ; \n\n   String   contents ; \n\n   @ Column ( indexed:   true ) \n   DateTime   publishedDate ;  }   It is convention that table definitions are  private classes , that is, their name is prefixed with an underscore ( _ ). This convention is discussed later in this guide.", 
            "title": "Defining a Table"
        }, 
        {
            "location": "/db/modeling_data/#defining-a-managed-object-subclass", 
            "text": "A table definition by itself is just a plain Dart class. You must also declare a  ManagedObject  subclass to bring your table definition to life. Here's an example:  class   Article   extends   ManagedObject _Article   implements   _Article   {}   A managed object subclass, also called the  instance type , is the object type that you work with in your application code. For example, when you fetch rows from a database, you will get a list of managed objects. A managed object subclass declares its table definition in two places: once as the type argument of its superclass, and again as an interface it implements.  A managed object subclass inherits all of the properties from its table definition; i.e., an  Article  has an  id ,  contents  and  publishedDate  because  _Article  declares those properties. You create and use instances of a managed object subclass like any other object:  final   article   =   new   Article ();  article . text   =   Today, ... ;  article . publishedDate   =   DateTime . now ();    Managed Object Constructors  You can add new constructors to a managed object subclass, but you must always have a default, no-argument constructor. This default constructor is used when the ORM creates instances from rows in your database.", 
            "title": "Defining a Managed Object Subclass"
        }, 
        {
            "location": "/db/modeling_data/#modeling-relationships", 
            "text": "A managed object can have  relationships  to other managed objects. For example, an author can have many books, an article can belong to a newspaper, and an employee can have a manager. In a relational database, relationships between tables are established by storing the primary key of a table row in a column of the related table. This column is a  foreign key reference  to the related table.  When a table has a foreign key reference, it is said to  belong to  the related table. In the example of an employee and manager, the employee  belongs to  the manager and therefore the employee table has a foreign key reference to the manager table. The inverse of this statement is also true: a manager  has  employees. A manager has-many employees - this is called a  has-many relationship . There are also  has-one relationships  - for example, a country has-one capital.  The following is an example of a country and a has-one relationship to a capital city:  class   City   extends   ManagedObject _City   implements   _City   {}  class   _City   { \n   @ primaryKey \n   int   id ; \n\n   @ Relate ( # capital ) \n   Country   country ;  }  class   Country   extends   ManagedObject _Country   implements   _Country   {}  class   _Country   { \n   @ primaryKey \n   int   id ; \n\n   City   capital ;  }   A relationship is formed between two tables by declaring properties in both table definition types. The type of those properties is the related managed object subclass - so a  Country  has a property of type  City , and a  City  has a property of type  Country .  Exactly one of those properties must have a  Relate  annotation. The  Relate  annotation designates the underlying column as a foreign key column. In this example, the city table has a foreign key column to the country table. Conceptually, then, a city  belongs to  a country and a country has-one capital city. A city can only belong to one country through this relationship, and that is true of all belongs-to relationship properties.   Foreign Key Column Names  A foreign key column in the database is named by joining the name of the relationship property and the primary key of the related table with an underscore. For example, the column in the city table is named  country_id .   The property without  Relate  is the  inverse  of the relationship and is conceptually either a has-one or has-many relationship property. In this example, a country's relationship to its capital is has-one. A relationship is has-many when the type of the inverse property is a  ManagedSet . For example, if we wanted to model a relationship between a country and all of its cities, we'd declare a  ManagedSet City  property in the country:  class   City   extends   ManagedObject _City   implements   _City   {}  class   _City   { \n   ... \n\n   @ Relate ( # cities ) \n   Country   country ;  }  class   Country   extends   ManagedObject _Country   implements   _Country   {}  class   _Country   { \n   ... \n\n   ManagedSet City   cities ;  }    ManagedSet Behavior  A  Relate  property can never be a  ManagedSet . A  ManagedSet  is a  List , and therefore can be used in the same way a list is used.   Notice that the  Relate  annotation takes at least one argument: a symbol that matches the name of the inverse property. This is what links two relationship properties to each other. In the first example, this argument was  #capital  because the name of the inverse property is  capital ; likewise,  #cities  and  cities . This pairing name must match or an error will be thrown.   Symbols  A symbol is a name identifier in Dart; a symbol can refer to a class, method, or property. The  #name  syntax is a  symbol literal .   The  Relate  annotation has optional arguments to further define the relationship. Like  Column , these are optional arguments, e.g.:  @ Relate ( # cities ,   isRequired:   true ,   onDelete:   DeleteRule . cascade )   A relationship may be be required or optional. For example, if  City.country  were required, then a  City  must always have a  Country . By default, relationships are optional.  A relationship has a delete rule. When an object is deleted, any objects that belong to its relationships are subject to this rule. The following table shows the rules and their behavior:     Rule  Behavior  Example      nullify (default)  inverse is set to null  When deleting an author, its articles' author becomes null    cascade  related objects are also deleted  When deleting an author, its articles are deleted    restrict  delete fails  When attempting to delete an author with articles, the delete operation fails    default  inverse set to a default value  When deleting an author, its articles author is set to the default value of the column", 
            "title": "Modeling Relationships"
        }, 
        {
            "location": "/db/modeling_data/#special-behaviors", 
            "text": "", 
            "title": "Special Behaviors"
        }, 
        {
            "location": "/db/modeling_data/#enum-types", 
            "text": "Enums types can be used to declare properties in a table definition. The database will store the column as a string representation of the enumeration. Here's an example where a user can be an administrator or a normal user:  enum   UserType   { \n   admin ,   user  }  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   UserType   role ;  }  var   query   =   Query User ( context ) \n   .. values . name   =   Bob \n   .. values . role   =   UserType . admin ;  final   bob   =   await   query . insert ();  query   =   Query User ( context ) \n   .. where (( u )   =   u . role ). equalTo ( UserType . admin );  final   allAdmins   =   await   query . fetch ();   In the database, the  role  column is stored as a string. Its value is either \"admin\" or \"user\".", 
            "title": "Enum Types"
        }, 
        {
            "location": "/db/modeling_data/#private-variables", 
            "text": "A private variable in a table definition removes it from the serialized representation of an object. A private variable is always fetched when making a database query, but it is not read when invoking  read  and is not written when invoking  asMap . Both of these methods are invoked when reading a managed object from a request body, or writing it to a response body.", 
            "title": "Private Variables"
        }, 
        {
            "location": "/db/modeling_data/#transient-properties", 
            "text": "Properties declared in a managed object subclass are called  transient  because they are not stored in a database. For example, consider an  Author  type that stores first and last name as separate columns. Instead of redundantly storing a 'full name' in the database, a transient property can combine the first and last name:  class   Author   extends   ManagedObject _Author   implements   _Author   { \n   String   get   name   =   $ firstName   $ lastName ; \n   set   name ( String   fullName )   { \n     firstName   =   fullName . split (   ). first ; \n     lastName   =   fullName . split (   ). last ; \n   }  }  class   _Author   { \n   @ primaryKey \n   int   id ; \n\n   String   firstName ; \n   String   lastName ;  }   By default, a transient property is ignored when reading an object from a request body or writing the object to a response body (see the guide on  serialization  for more details). You can annotate a transient property with  Serialize  so that it is able to be read from a request body, written to a response body, or both. For example:  class   Author   extends   ManagedObject _Author   implements   _Author   { \n   @ Serialize () \n   String   get   name   =   $ firstName   $ lastName ; \n\n   @ Serialize () \n   set   name ( String   fullName )   { \n     firstName   =   fullName . split (   ). first ; \n     lastName   =   fullName . split (   ). last ; \n   }  }   You may declare getters, setters and properties to be serialized in this way. When declaring a property, you can control it with arguments to  Serialize :  class   Author   extends   ManagedObject _Author   implements   _Author   { \n   @ Serialize ( input:   false ,   output:   true ) \n   bool   isCurrentlyPromoted ;  }", 
            "title": "Transient Properties"
        }, 
        {
            "location": "/db/modeling_data/#project-file-structure", 
            "text": "A managed object subclass and its table definition together are called an  entity . Each entity should be declared in the same file, and the table definition should be prefixed with an  _  to prevent it from being used elsewhere in the project. It is preferable to declare one entity per file, and store all entities in the  lib/model/  directory of your project.  The files your model definitions are declared in must be visible to Aqueduct tooling. In normal circumstances, this happens automatically because of the following:   Aqueduct tooling can find any file that is imported (directly or transitively) from your library file.  Your library file, by default, can see the file your  ApplicationChannel  is declared in.  Your application channel file must import any controller that it links.  Your controllers must import any model file they use.   When you use the  aqueduct  CLI to generate database migration scripts, it will report all of the  ManagedObject s in your application that it was able to find. If a particular type is not listed, it may reveal that you aren't using that type. If you need to ensure that the tooling can see a particular model file that it is not locating, you may import it in your  channel.dart  file.", 
            "title": "Project File Structure"
        }, 
        {
            "location": "/db/modeling_data/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/db/modeling_data/#example-one-to-many-relationship", 
            "text": "An author has many books:  class   Author   extends   ManagedObject _Author   implements   _Author   {}  class   _Author   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   ManagedSet Book   books ;  }  class   Book   extends   ManagedObject _Book   implements   _Book   {}  class   _Book   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   @ Relate ( # books ) \n   Author   author ;  }   To insert an author and a book associated with that author:  final   authorQuery   =   Query Author ( context ) \n   .. values . name   =   Fred ;  final   author   =   await   authorQuery . insert ();  final   bookQuery   =   Query Book ( context ) \n   .. values . name   =   Title \n   .. values . author . id   =   author . id ;  final   book   =   await   bookQuery . insert ();     To fetch authors and their books:  final   query   =   Query Author ( context ) \n   .. join ( set :   ( a )   =   a . books );  final   authors   =   await   query . fetch ();   To fetch a book and their full author object:  final   query   =   Query Book ( context ) \n   .. where (( b )   =   b . id ). equalTo ( 1 ) \n   .. join ( object:   ( a )   =   a . author );  final   books   =   await   query . fetch ();", 
            "title": "Example: One-to-Many Relationship"
        }, 
        {
            "location": "/db/modeling_data/#example-one-to-one-relationship", 
            "text": "class   Country   extends   ManagedObject _Country   implements   _Country   {}  class   _Country   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   City   capital ;  }  class   City   extends   ManagedObject _City   implements   _City   {}  class   _City   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   @ Relate ( # capital ) \n   Country   country ;  }   To fetch a country and its capital:  final   query   =   Query Country ( context ) \n   .. where (( c )   =   c . id ). equalTo ( 1 ) \n   .. join ( object:   ( a )   =   a . capital );  final   countries   =   await   query . fetch ();", 
            "title": "Example: One-to-One Relationship"
        }, 
        {
            "location": "/db/modeling_data/#example-many-to-many-relationship", 
            "text": "class   Team   extends   ManagedObject _Team   implements   _Team   {}  class   _Team   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   ManagedSet TeamPlayer   teamPlayers ;  }  // This type is a join table  class   TeamPlayer   extends   ManagedObject _TeamPlayer   implements   _TeamPlayer   {}  class   _TeamPlayer   { \n   @ primaryKey \n   int   id ;   \n\n   @ Relate ( # teamPlayers ) \n   Team   team ; \n\n   @ Relate ( # teamPlayers ) \n   Player   player ;  }  class   Player   extends   ManagedObject _Player   implements   _Player   {}  class   _Player   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   ManagedSet TeamPlayer   teamPlayers ;  }   To fetch a team and its players:  // Note that the final join is not cascaded from the Team query,  // but from the Query created by joining with TeamPlayer  final   query   =   Query Team ( context ) \n   .. where (( t )   =   t . id ). equalTo ( 1 ) \n   .. join ( set :   ( t )   =   t . teamPlayers ). join ( object:   ( tp )   =   tp . player );  final   team   =   await   query . fetchOne ();   The structure of this object is:  { \n   id :   1 , \n   name :   Badgers , \n   teamPlayers :   [ \n     { \n       id :   1 , \n       team :   { \n         id :   1 \n       }, \n       player :   { \n         id :   1 , \n         name :   Fred \n       } \n     } \n   ]  }   You can flatten this structure in a number of ways. In the simplest form, add a  Serialize -annotated transient property to the  ManagedObject  subclass, and each time you fetch, remove the join table from the object and place the players in the transient property.  class   Team   extends   ManagedObject _Team   implements   _Team   { \n   @ Serialize ( input:   false ,   output:   true ) \n   List Map String ,   dynamic   players ;  }  final   team   =   ...;  team . players   =   team . teamPlayers . map (( t )   =   t . player . asMap ()). toList ();  // Remove teamPlayers; it is redundant  team . backing . removeProperty ( teamPlayers );", 
            "title": "Example: Many-to-Many Relationship"
        }, 
        {
            "location": "/db/modeling_data/#example-hierarchical-relationships-self-referencing", 
            "text": "Hierarchical relationships follow the same rules as all other relationship, but declare the foreign key property and the inverse in the same type.  class   Person   extends   ManagedObject _Person   implements   _Person   {}  class   _Person   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   ManagedSet Person   children ; \n\n   @ Relate ( # children ) \n   Person   parent ;  }", 
            "title": "Example: Hierarchical Relationships (Self Referencing)"
        }, 
        {
            "location": "/db/serialization/", 
            "text": "ManagedObject Serialization and Deserialization\n\n\nIn this guide, you will learn how \nManagedObject\nT\ns are read from HTTP request bodies and written to HTTP response bodies.\n\n\nBasic Conversion\n\n\nA \nManagedObject\nT\n can be converted to and from \nMap\nString, dynamic\n objects. Each key is the name of a property in the object. To decode a \nManagedObject\n into a \nMap\n, call its \nread\n method:\n\n\nfinal\n \nobject\n \n=\n \nMyManagedObject\n();\n\n\nobject\n.\nread\n({\n\n  \nkey\n:\n \nvalue\n\n\n});\n\n\n\n// object.key == \nvalue\n\n\n\n\n\n\nValidation exceptions (status code: 400) are thrown is the input data is invalid: if a key doesn't have a corresponding property, the type of a value does not match the expected type or some constraint of the managed object is violated.\n\n\nFilters can be applied to keys of the object being read. Filters can ignore keys, require keys or throw an exception if a key is present. Here is an example, where the read will throw an exception because 'id' is required but not provided:\n\n\nobject\n.\nread\n({\n\n  \nkey\n:\n \nvalue\n\n\n},\n \nrequire:\n \n[\nid\n]);\n\n\n\n\n\n\n\n\nManagedObjects inherit Serializable\n\n\nThe \nread\n method and its filters are inherited from \nSerializable\n and are discussed in more detail \nhere\n. Managed objects, like serializables, can be bound to operation method parameters.\n\n\n\n\nManaged objects have a list of default keys that can be used as a base filter set:\n\n\nobject\n.\nread\n({},\n \nrequire:\n \nobject\n.\nentity\n.\ndefaultProperties\n);\n\n\n\n\n\n\nTo serialize a managed object into a map, use the instance method \nasMap\n:\n\n\nfinal\n \nobject\n \n=\n \nMyManagedObject\n();\n\n\nMap\nString\n,\n \ndynamic\n \nmap\n \n=\n \nobject\n.\nasMap\n();\n\n\n\n\n\n\nIf a property has not been set on the object, it will not be written to the map.\n\n\nThe values of a \nMap\n equivalent of a managed object are always primitive values that can be encoded as JSON, sent across an isolate, etc. The following shows a table of the serialization format:\n\n\n\n\n\n\n\n\nDart Type\n\n\nSerialized Type\n\n\n\n\n\n\n\n\n\n\nint\n\n\nnumber (\nint\n)\n\n\n\n\n\n\ndouble\n\n\nnumber (\ndouble\n)\n\n\n\n\n\n\nString\n\n\nstring (\nString\n)\n\n\n\n\n\n\nDateTime\n\n\nISO 8601 Timestamp (\nString\n)\n\n\n\n\n\n\nbool\n\n\nboolean (\nbool\n)\n\n\n\n\n\n\nDocument\n\n\nmap or list (\nMap\nString, dynamic\n or \nList\ndynamic\n)\n\n\n\n\n\n\nAny \nenum\n\n\nstring (\nString\n)\n\n\n\n\n\n\nBelongs-To or Has-One Relationship\n\n\nmap (\nMap\nString, dynamic\n)\n\n\n\n\n\n\nHas-Many Relationship\n\n\nlist of maps (\nList\nMap\nString, dynamic\n)\n\n\n\n\n\n\n\n\nBehavior of Null Values\n\n\nA property of a managed object can be null for two reasons: the value is actually null, or the value is not available. For example, when you create a new instance of a managed object, none of its values are available (the object is empty). When encoding an object into a map, only the available values are included and the keys for any unavailable properties are omitted:\n\n\nfinal\n \nmyObject\n \n=\n \nMyManagedObject\n();\n \n// empty object\n\n\nmyObject\n.\nasMap\n()\n \n==\n \n{};\n \n// true\n\n\n\nmyObject\n.\nid\n \n=\n \n1\n;\n\n\nmyObject\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n\n\n};\n \n// true\n\n\n\n\n\n\nA value in managed object's \nasMap\n will only be null if the property value truly is null:\n\n\nmyObject\n.\nid\n \n=\n \nnull\n;\n\n\nmyObject\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \nnull\n\n\n};\n \n// true\n\n\n\n\n\n\nA property value becomes available when it is set through an accessor, when using \nread\n, or when returning objects from a query.\n\n\nBehavior of Transient Properties\n\n\nBy default, transient properties - those declared in the managed object subclass, not the table definition - are \nnot\n included in an object's \nasMap()\n. The \nSerialize\n annotation allows a transient property to be included in this map.\n\n\nclass\n \nEmployee\n \nextends\n \nManagedObject\n_Employee\n \nimplements\n \n_Employee\n \n{\n\n  \nint\n \na\n;\n \n// NOT included in asMap, NOT read in read\n\n\n  \n@\nSerialize\n()\n\n  \nint\n \nb\n;\n \n// included in asMap, read in read\n\n\n  \n@\nSerialize\n(\ninput:\n \ntrue\n,\n \noutput:\n \nfalse\n)\n\n  \nint\n \nc\n;\n \n// NOT included in asMap, read in read\n\n\n  \n@\nSerialize\n(\ninput:\n \nfalse\n,\n \noutput:\n \ntrue\n)\n\n  \nint\n \nd\n;\n \n// included in asMap, NOT read in read\n\n\n}\n\n\n\nclass\n \n_Employee\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n}\n\n\n\n\n\n\nA separate getter and setter may exist instead of a property. With this annotation, getters are added to \nasMap\n and setters will be input for \nread\n.\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nSerialize\n()\n\n  \nset\n \ntransientValue\n(\nString\n \ns\n)\n \n{\n\n    \n...\n\n  \n}\n\n\n  \n@\nSerialize\n()\n\n  \nString\n \nget\n \ntransientValue\n \n=\n \n...;\n\n\n}\n\n\n\n\n\n\nA transient property's key will not be present in \nasMap()\n if its value is null.\n\n\nBehavior of Relationship Properties\n\n\nWhen a managed object is encoded, relationship properties are represented as maps (for belongs-to or has-one relationships) or a list of maps (for has-many relationships). The same rules for property availability apply to relationship properties. The following shows an example map that mirrors a managed object with aptly named relationship properties:\n\n\n{\n\n  \nid\n:\n \n1\n,\n\n  \nbelongsTo\n:\n \n{\n\n    \nid\n:\n \n1\n\n  \n},\n\n  \nhasOne\n:\n \n{\n\n    \nid\n:\n \n2\n,\n\n    \nname\n:\n \nFred\n\n  \n},\n\n  \nhasMany\n:\n \n[\n\n    \n{\nid\n:\n \n3\n,\n \nname\n:\n \nBob\n},\n\n    \n{\nid\n:\n \n4\n,\n \nname\n:\n \nJoe\n},\n\n  \n]\n\n\n}\n\n\n\n\n\n\nA belongs-to relationship is \nalways\n a map. This is important for client applications that will often create or update an object's belongs-to relationships. For example, a client wishing to create a child named Timmy with the parent that has \nid == 1\n would send the following JSON:\n\n\n{\n\n  \nname\n:\n \nTimmy\n,\n\n  \nparent\n:\n \n{\n\n    \nid\n:\n \n1\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis is different from some frameworks that would flatten this structure, e.g.:\n\n\n{\n\n  \nname\n:\n \nTimmy\n,\n\n  \nparent_id\n:\n \n1\n\n\n}", 
            "title": "Serialization and Deserialization"
        }, 
        {
            "location": "/db/serialization/#managedobject-serialization-and-deserialization", 
            "text": "In this guide, you will learn how  ManagedObject T s are read from HTTP request bodies and written to HTTP response bodies.", 
            "title": "ManagedObject Serialization and Deserialization"
        }, 
        {
            "location": "/db/serialization/#basic-conversion", 
            "text": "A  ManagedObject T  can be converted to and from  Map String, dynamic  objects. Each key is the name of a property in the object. To decode a  ManagedObject  into a  Map , call its  read  method:  final   object   =   MyManagedObject ();  object . read ({ \n   key :   value  });  // object.key ==  value   Validation exceptions (status code: 400) are thrown is the input data is invalid: if a key doesn't have a corresponding property, the type of a value does not match the expected type or some constraint of the managed object is violated.  Filters can be applied to keys of the object being read. Filters can ignore keys, require keys or throw an exception if a key is present. Here is an example, where the read will throw an exception because 'id' is required but not provided:  object . read ({ \n   key :   value  },   require:   [ id ]);    ManagedObjects inherit Serializable  The  read  method and its filters are inherited from  Serializable  and are discussed in more detail  here . Managed objects, like serializables, can be bound to operation method parameters.   Managed objects have a list of default keys that can be used as a base filter set:  object . read ({},   require:   object . entity . defaultProperties );   To serialize a managed object into a map, use the instance method  asMap :  final   object   =   MyManagedObject ();  Map String ,   dynamic   map   =   object . asMap ();   If a property has not been set on the object, it will not be written to the map.  The values of a  Map  equivalent of a managed object are always primitive values that can be encoded as JSON, sent across an isolate, etc. The following shows a table of the serialization format:     Dart Type  Serialized Type      int  number ( int )    double  number ( double )    String  string ( String )    DateTime  ISO 8601 Timestamp ( String )    bool  boolean ( bool )    Document  map or list ( Map String, dynamic  or  List dynamic )    Any  enum  string ( String )    Belongs-To or Has-One Relationship  map ( Map String, dynamic )    Has-Many Relationship  list of maps ( List Map String, dynamic )", 
            "title": "Basic Conversion"
        }, 
        {
            "location": "/db/serialization/#behavior-of-null-values", 
            "text": "A property of a managed object can be null for two reasons: the value is actually null, or the value is not available. For example, when you create a new instance of a managed object, none of its values are available (the object is empty). When encoding an object into a map, only the available values are included and the keys for any unavailable properties are omitted:  final   myObject   =   MyManagedObject ();   // empty object  myObject . asMap ()   ==   {};   // true  myObject . id   =   1 ;  myObject . asMap ()   ==   { \n   id :   1  };   // true   A value in managed object's  asMap  will only be null if the property value truly is null:  myObject . id   =   null ;  myObject . asMap ()   ==   { \n   id :   null  };   // true   A property value becomes available when it is set through an accessor, when using  read , or when returning objects from a query.", 
            "title": "Behavior of Null Values"
        }, 
        {
            "location": "/db/serialization/#behavior-of-transient-properties", 
            "text": "By default, transient properties - those declared in the managed object subclass, not the table definition - are  not  included in an object's  asMap() . The  Serialize  annotation allows a transient property to be included in this map.  class   Employee   extends   ManagedObject _Employee   implements   _Employee   { \n   int   a ;   // NOT included in asMap, NOT read in read \n\n   @ Serialize () \n   int   b ;   // included in asMap, read in read \n\n   @ Serialize ( input:   true ,   output:   false ) \n   int   c ;   // NOT included in asMap, read in read \n\n   @ Serialize ( input:   false ,   output:   true ) \n   int   d ;   // included in asMap, NOT read in read  }  class   _Employee   { \n   @ primaryKey \n   int   id ;  }   A separate getter and setter may exist instead of a property. With this annotation, getters are added to  asMap  and setters will be input for  read .  class   User   extends   ManagedObject _User   implements   _User   { \n   @ Serialize () \n   set   transientValue ( String   s )   { \n     ... \n   } \n\n   @ Serialize () \n   String   get   transientValue   =   ...;  }   A transient property's key will not be present in  asMap()  if its value is null.", 
            "title": "Behavior of Transient Properties"
        }, 
        {
            "location": "/db/serialization/#behavior-of-relationship-properties", 
            "text": "When a managed object is encoded, relationship properties are represented as maps (for belongs-to or has-one relationships) or a list of maps (for has-many relationships). The same rules for property availability apply to relationship properties. The following shows an example map that mirrors a managed object with aptly named relationship properties:  { \n   id :   1 , \n   belongsTo :   { \n     id :   1 \n   }, \n   hasOne :   { \n     id :   2 , \n     name :   Fred \n   }, \n   hasMany :   [ \n     { id :   3 ,   name :   Bob }, \n     { id :   4 ,   name :   Joe }, \n   ]  }   A belongs-to relationship is  always  a map. This is important for client applications that will often create or update an object's belongs-to relationships. For example, a client wishing to create a child named Timmy with the parent that has  id == 1  would send the following JSON:  { \n   name :   Timmy , \n   parent :   { \n     id :   1 \n   }  }   This is different from some frameworks that would flatten this structure, e.g.:  { \n   name :   Timmy , \n   parent_id :   1  }", 
            "title": "Behavior of Relationship Properties"
        }, 
        {
            "location": "/db/executing_queries/", 
            "text": "Inserting, Updating, Deleting and Fetching Objects\n\n\nTo send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of \nQuery\nT\n. The type argument must be a subclass of \nManagedObject\n, which determines the table the query will operate on.\n\n\nA query compiles and executes a SQL query and requires a \nManagedContext\n to determine the database to connect to. Here's an example of a \nQuery\nT\n that fetches all instances of \nUser\n:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\nfinal\n \nallUsers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nA \nQuery\nT\n has four basic execution methods: \nfetch\n, \nupdate\n, \ninsert\n, \ndelete\n.\n\n\n\n\nfetch\n will retrieve data from a database (it is equivalent to the SQL operation \nSELECT\n).\n\n\nupdate\n will modify existing data in a database (it is equivalent to the SQL operation \nUPDATE\n).\n\n\ninsert\n will add new data to a database (it is equivalent to the SQL operation \nINSERT\n).\n\n\ndelete\n will remove data from a database (it is equivalent to the SQL operation \nDELETE\n).\n\n\n\n\nA \nQuery\nT\n has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on.\n\n\nIn the following sections, assume that a \nUser\n managed object subclass exists that is declared like so:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \nemail\n;\n\n\n  \nString\n \nname\n;\n\n\n}\n\n\n\n\n\n\nInserting Data with a Query\n\n\nTo insert data with a query, you create a new \nQuery\nT\n object, configure its \nvalues\n property and then call its \ninsert()\n method.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n\n  \n..\nvalues\n.\nemail\n \n=\n \nbob@stablekernel.com\n;\n  \n\n\nfinal\n \nuser\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n  \n\n\n\n\n\nThe \nvalues\n of a \nQuery\nT\n is an instance of \nT\n (the managed object type you are inserting). You can configure individual properties of \nvalues\n, or you can assign \nvalues\n to an instance you have created elsewhere:\n\n\nfinal\n \nuserValues\n \n=\n \nUser\n()\n\n  \n..\nname\n \n=\n \nBob\n\n  \n..\nemail\n \n=\n \nbob@stablekernel.com\n;\n\n\nfinal\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)..\nvalues\n \n=\n \nuserValues\n;\n\n\nfinal\n \nuser\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n  \n\n\n\n\n\nEither way, this query is translated into the following SQL:\n\n\nINSERT\n \nINTO\n \n_user\n \n(\nname\n,\n \nemail\n)\n \nVALUES\n \n(\nBob\n,\n \nbob@stablekernel.com\n)\n \nRETURNING\n \nid\n,\n \nname\n,\n \nemail\n;\n\n\n\n\n\n\nNotice that only the values set on the \nvalues\n object are included in the SQL INSERT query. In this example, both \nname\n and \nemail\n were set, but not \nid\n and therefore only \nname\n and \nemail\n were included in the query. (In this case, the primary key is auto-incrementing and the database will generate it.)\n\n\nValues that are explicitly set to \nnull\n will be sent as \nNULL\n. For example, consider the following \nQuery\nT\n and its SQL:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nnull\n\n  \n..\nemail\n \n=\n \nbob@stablekernel.com\n;\n\n\n\n// INSERT INTO _user (name, email) VALUES (NULL, \nbob@stablekernel.com\n) RETURNING id, name, email;\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nAn insert query will return a managed object that represents the row that is inserted.\n\n\n\n\nPrefer the Inserted Object\n\n\nAfter you insert an object, you should prefer to use the object returned by an insert query rather than the values you used to populate the query. The object returned from the query will be an accurate representation of the database row, while the object used to build the query may be incomplete or different. For example, an auto-incrementing primary key won't be available in your query-building instance, but will in the object returned from the successful query.\n\n\n\n\nThere is one difference to note when choosing between assigning an instance to \nvalues\n, or configuring the properties of \nvalues\n. In an instance you create, a relationship property must be instantiated before accessing its properties. When accessing the relationship properties of \nvalues\n, an empty instance of the related object is created immediately upon access.\n\n\nfinal\n \nemployee\n \n=\n \nEmployee\n()\n\n  \n..\nmanager\n.\nid\n \n=\n \n1\n;\n \n// this is a null pointer exception because manager is null\n\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nvalues\n.\nmanager\n.\nid\n \n=\n \n1\n;\n \n// this is OK because of special behavior of Query\n\n\n\n\n\n\nOnce you assign an object to \nvalues\n, it will adopt the behavior of \nvalues\n and instantiate relationships when accessed. Also note that after assigning an object to \nvalues\n, changes to the original object are not reflected in \nvalues\n. In other words, the object is copied instead of referenced.\n\n\nFor simple insertions and for inserting more than one object, you can use the methods on the context:\n\n\nfinal\n \ncontext\n \n=\n \nManagedContext\n(...);\n\n\nfinal\n \nbob\n \n=\n \nUser\n()..\nname\n \n=\n \nBob\n;\n\n\nfinal\n \njay\n \n=\n \nUser\n()..\nname\n \n=\n \nJay\n;\n\n\n\nfinal\n \ninsertedObject\n \n=\n \nawait\n \ncontext\n.\ninsertObject\n(\nbob\n);\n\n\nfinal\n \ninsertedObjects\n \n=\n \nawait\n \ncontext\n.\ninsertObjects\n([\nbob\n,\n \njay\n]);\n\n\n\n\n\n\nUpdating Data with a Query\n\n\nUpdating rows with a \nQuery\nT\n is similar to inserting data: you set the \nQuery.values\n for properties you want to change. The type parameter for the \nQuery\nT\n indicates which database table will get updated when the query is executed.\n\n\nAn update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the \nQuery.where\n property - which gets translated into the \nwhere clause\n of the SQL command. Here's an example:\n\n\n// A Query that will change any user\ns whose name is \nBob\n to \nFred\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nFred\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n).\nequalTo\n(\nBob\n);\n\n\n\nList\nUser\n \nbobsThatAreNowFreds\n \n=\n \nawait\n \nquery\n.\nupdate\n();\n\n\n\n\n\n\nLike \nvalues\n, \nwhere\n is also the same managed object type the query is being executed on. In the above example, then, both \nvalues\n and \nwhere\n and instances of \nUser\n. This query executes the following SQL:\n\n\nUPDATE\n \n_user\n \nSET\n \nname\n=\nFred\n \nWHERE\n \nname\n=\nBob\n;\n\n\n\n\n\n\nThe \nwhere\n property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to \nupdate()\n.\n\n\nLike \ninsert()\n, only the values set in the \nvalues\n property of a query get updated when executing \nupdate()\n. Values that are omitted are not included. Values that need to be set to \nnull\n must explicitly be set to \nnull\n in the query:\n\n\n// A Query that will remove names from anyone currently named Bob.\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nnull\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n).\nequalTo\n(\nBob\n);\n\n\n\n\n\n\nAn update query returns every modified row as a result. If no rows are updated, the return value is an empty list.  \n\n\nThere is a variant to \nQuery\nT\n.update\n named \nupdateOne\n. The \nupdateOne\n method will build and execute a SQL query in the same way a normal \nupdate\n does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list:\n\n\n// Update user with id = 1 to have the name \nFred\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nFred\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\nvar\n \nupdatedUser\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n\n\n\n\n\nThe \nupdateOne\n method will return \nnull\n if no rows were updated. It is important to note that if \nupdateOne\n is used and more than one row is updated, \nupdateOne\n will throw an exception and the changes to the data \nare not reversible\n. Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular \nupdateOne\n query would impact multiple rows.\n\n\nUpdate queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a \nQuery\nT\n to do an update without configuring \nwhere\n, an exception is thrown prior to carrying out the request. If you actually want to update every row of a table, you must set the \nQuery.canModifyAllInstances\n to \ntrue\n prior to execution. (This property defaults to \nfalse\n.)\n\n\nDeleting Data with a Query\n\n\nA \nQuery\nT\n will delete rows from a database when using \ndelete()\n. Like update queries, you should specify a row or rows using \nwhere\n properties of the \nQuery\nT\n. The result of a delete operation will be a \nFuture\nint\n with the number of rows deleted.\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\nint\n \nusersDeleted\n \n=\n \nawait\n \nquery\n.\ndelete\n();\n\n\n\n\n\n\nAlso like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with \ncanModifyAllInstances\n.\n\n\nAny properties set in the query's \nvalues\n are ignored when executing a delete.\n\n\nFetching Data with a Query\n\n\nOf the four basic operations of a \nQuery\nT\n, fetching data is the most configurable. A simple \nQuery\nT\n that would fetch every instance of some entity looks like this:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\n\nList\nUser\n \nallUsers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFetch queries can be limited to a number of instances with the \nfetchLimit\n property. You may also set the \noffset\n of a \nQuery\nT\n to skip the first \noffset\n number of rows. Between \nfetchLimit\n and \noffset\n, you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections.\n\n\nA fetch \nQuery\nT\n uses its \nwhere\n property to filter the result set, just like delete and update queries. The \nvalues\n of a query are ignored when fetching objects. You may also fetch a single instance with \nfetchOne\n. If no instance is found, \nnull\n is returned. Only use this method when the search criteria is guaranteed to be unique.\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\nUser\n \noneUser\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nWhen you are fetching an object by its primary key, you can use a shorthand method \nManagedContext.fetchObjectWithID\n. The method must be able to infer the type of the object, or you must provide it:\n\n\nfinal\n \nobject\n \n=\n \nawait\n \ncontext\n.\nfetchObjectWithID\nUser\n(\n1\n);\n\n\n\n\n\n\nSorting\n\n\nResults of a fetch can be sorted using the \nsortBy\n method of a \nQuery\nT\n. Here's an example:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\ndateCreated\n,\n \nQuerySortOrder\n.\nascending\n);\n\n\n\n\n\n\nsortBy\n takes two arguments: a closure that returns which property to sort by and the order of the sort.\n\n\nA \nQuery\nT\n results can be sorted by multiple properties. When multiple \nsortBy\ns are invoked on a \nQuery\nT\n, later \nsortBy\ns are used to break ties in previous \nsortBy\ns. For example, the following query will sort by last name, then by first name:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\nlastName\n,\n \nQuerySortOrder\n.\nascending\n)\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\nfirstName\n,\n \nQuerySortOrder\n.\nascending\n);\n\n\n\n\n\n\nThus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'.\n\n\nProperty Selectors\n\n\nIn the section on sorting, you saw the use of a \nproperty selector\n to select the property of the user to sort by. This syntax is used for many other query manipulations, like filtering and joining. A property selector is a closure that gives you an object of the type you are querying and must return a property of that object. The selector \n(u) =\n u.lastName\n in the previous section is a property selector that selects the last name of a user.\n\n\nThe Dart analyzer will infer that the argument of a property selector, and it is always the same type as the object being queried. This enables IDE auto-completion, static error checking, and other tools like project-wide renaming.\n\n\n\n\nLive Templates\n\n\nTo speed up query building, create a Live Template in IntelliJ that generates a property selector when typing 'ps'. The source of the template is \n(o) =\n o.$END$\n. A downloadable settings configuration for IntelliJ exists \nhere\n that includes this shortcut.\n\n\n\n\nSpecifying Result Properties\n\n\nWhen executing queries that return managed objects (i.e., \ninsert()\n, \nupdate()\n and \nfetch()\n), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the table definition. A managed object's default properties can be modified when declaring its table definition:\n\n\nclass\n \n_User\n \n{\n\n  \n@\nColumn\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nhashedPassword\n;\n\n\n}\n\n\n\n\n\n\nAny property with \nomitByDefault\n set to true will not be fetched by default.\n\n\nA property that is \nomitByDefault\n can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each \nQuery\nT\n has a \nreturningProperties\n method to adjust which properties do get returned from the query. Its usage looks like this:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\nuser\n)\n \n=\n \n[\nuser\n.\nid\n,\n \nuser\n.\nname\n]);\n\n\n\n\n\n\nreturningProperties\n is a multiple property selector - instead of returning just one property, it returns a list of properties.\n\n\nYou may include 'belongs-to' relationships in \nreturningProperties\n, but you may not include 'has-many' or 'has-one' relationships. An exception will be thrown if you attempt to. To include properties from relationships like these, see \njoin in Advanced Queries\n.\n\n\nNote that if you omit the primary key of a managed object from \nreturningProperties\n, it will automatically be added. The primary key is necessary to transform the rows into instances of their \nManagedObject\nT\n subclass.\n\n\nExceptions and Errors\n\n\nWhen executing a query, it may fail for any number of reasons: the query is invalid, a database couldn't be reached, constraints were violated, etc. In many cases, this exception originates from the underlying database driver. When thrown in a controller, these exceptions will trigger a 500 Server Error response.\n\n\nExceptions that are thrown in response to user input (e.g., violating a database constraint, invalid data type) are re-interpreted into a \nQueryException\n or \nValidationException\n. Both of these exception types have an associated \nResponse\n object that is sent instead of the default 500 Server error.\n\n\nFor this reason, you don't need to catch database query exceptions in a controller; an appropriate response will be sent on your behalf.\n\n\nStatement Reuse\n\n\nAqueduct will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.", 
            "title": "Basic Queries"
        }, 
        {
            "location": "/db/executing_queries/#inserting-updating-deleting-and-fetching-objects", 
            "text": "To send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of  Query T . The type argument must be a subclass of  ManagedObject , which determines the table the query will operate on.  A query compiles and executes a SQL query and requires a  ManagedContext  to determine the database to connect to. Here's an example of a  Query T  that fetches all instances of  User :  final   query   =   Query User ( context );  final   allUsers   =   await   query . fetch ();   A  Query T  has four basic execution methods:  fetch ,  update ,  insert ,  delete .   fetch  will retrieve data from a database (it is equivalent to the SQL operation  SELECT ).  update  will modify existing data in a database (it is equivalent to the SQL operation  UPDATE ).  insert  will add new data to a database (it is equivalent to the SQL operation  INSERT ).  delete  will remove data from a database (it is equivalent to the SQL operation  DELETE ).   A  Query T  has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on.  In the following sections, assume that a  User  managed object subclass exists that is declared like so:  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( indexed:   true ) \n   String   email ; \n\n   String   name ;  }", 
            "title": "Inserting, Updating, Deleting and Fetching Objects"
        }, 
        {
            "location": "/db/executing_queries/#inserting-data-with-a-query", 
            "text": "To insert data with a query, you create a new  Query T  object, configure its  values  property and then call its  insert()  method.  final   query   =   Query User ( context ) \n   .. values . name   =   Bob \n   .. values . email   =   bob@stablekernel.com ;    final   user   =   await   query . insert ();     The  values  of a  Query T  is an instance of  T  (the managed object type you are inserting). You can configure individual properties of  values , or you can assign  values  to an instance you have created elsewhere:  final   userValues   =   User () \n   .. name   =   Bob \n   .. email   =   bob@stablekernel.com ;  final   query   =   Query User ( context ).. values   =   userValues ;  final   user   =   await   query . insert ();     Either way, this query is translated into the following SQL:  INSERT   INTO   _user   ( name ,   email )   VALUES   ( Bob ,   bob@stablekernel.com )   RETURNING   id ,   name ,   email ;   Notice that only the values set on the  values  object are included in the SQL INSERT query. In this example, both  name  and  email  were set, but not  id  and therefore only  name  and  email  were included in the query. (In this case, the primary key is auto-incrementing and the database will generate it.)  Values that are explicitly set to  null  will be sent as  NULL . For example, consider the following  Query T  and its SQL:  var   query   =   Query User ( context ) \n   .. values . name   =   null \n   .. email   =   bob@stablekernel.com ;  // INSERT INTO _user (name, email) VALUES (NULL,  bob@stablekernel.com ) RETURNING id, name, email;  await   query . insert ();   An insert query will return a managed object that represents the row that is inserted.   Prefer the Inserted Object  After you insert an object, you should prefer to use the object returned by an insert query rather than the values you used to populate the query. The object returned from the query will be an accurate representation of the database row, while the object used to build the query may be incomplete or different. For example, an auto-incrementing primary key won't be available in your query-building instance, but will in the object returned from the successful query.   There is one difference to note when choosing between assigning an instance to  values , or configuring the properties of  values . In an instance you create, a relationship property must be instantiated before accessing its properties. When accessing the relationship properties of  values , an empty instance of the related object is created immediately upon access.  final   employee   =   Employee () \n   .. manager . id   =   1 ;   // this is a null pointer exception because manager is null  final   query   =   Query Employee ( context ) \n   .. values . manager . id   =   1 ;   // this is OK because of special behavior of Query   Once you assign an object to  values , it will adopt the behavior of  values  and instantiate relationships when accessed. Also note that after assigning an object to  values , changes to the original object are not reflected in  values . In other words, the object is copied instead of referenced.  For simple insertions and for inserting more than one object, you can use the methods on the context:  final   context   =   ManagedContext (...);  final   bob   =   User ().. name   =   Bob ;  final   jay   =   User ().. name   =   Jay ;  final   insertedObject   =   await   context . insertObject ( bob );  final   insertedObjects   =   await   context . insertObjects ([ bob ,   jay ]);", 
            "title": "Inserting Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#updating-data-with-a-query", 
            "text": "Updating rows with a  Query T  is similar to inserting data: you set the  Query.values  for properties you want to change. The type parameter for the  Query T  indicates which database table will get updated when the query is executed.  An update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the  Query.where  property - which gets translated into the  where clause  of the SQL command. Here's an example:  // A Query that will change any user s whose name is  Bob  to  Fred  var   query   =   Query User ( context ) \n   .. values . name   =   Fred \n   .. where (( u )   =   u . name ). equalTo ( Bob );  List User   bobsThatAreNowFreds   =   await   query . update ();   Like  values ,  where  is also the same managed object type the query is being executed on. In the above example, then, both  values  and  where  and instances of  User . This query executes the following SQL:  UPDATE   _user   SET   name = Fred   WHERE   name = Bob ;   The  where  property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to  update() .  Like  insert() , only the values set in the  values  property of a query get updated when executing  update() . Values that are omitted are not included. Values that need to be set to  null  must explicitly be set to  null  in the query:  // A Query that will remove names from anyone currently named Bob.  var   query   =   Query User ( context ) \n   .. values . name   =   null \n   .. where (( u )   =   u . name ). equalTo ( Bob );   An update query returns every modified row as a result. If no rows are updated, the return value is an empty list.    There is a variant to  Query T .update  named  updateOne . The  updateOne  method will build and execute a SQL query in the same way a normal  update  does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list:  // Update user with id = 1 to have the name  Fred  var   query   =   Query User ( context ) \n   .. values . name   =   Fred \n   .. where (( u )   =   u . id ). equalTo ( 1 );  var   updatedUser   =   await   query . updateOne ();   The  updateOne  method will return  null  if no rows were updated. It is important to note that if  updateOne  is used and more than one row is updated,  updateOne  will throw an exception and the changes to the data  are not reversible . Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular  updateOne  query would impact multiple rows.  Update queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a  Query T  to do an update without configuring  where , an exception is thrown prior to carrying out the request. If you actually want to update every row of a table, you must set the  Query.canModifyAllInstances  to  true  prior to execution. (This property defaults to  false .)", 
            "title": "Updating Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#deleting-data-with-a-query", 
            "text": "A  Query T  will delete rows from a database when using  delete() . Like update queries, you should specify a row or rows using  where  properties of the  Query T . The result of a delete operation will be a  Future int  with the number of rows deleted.  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . id ). equalTo ( 1 );  int   usersDeleted   =   await   query . delete ();   Also like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with  canModifyAllInstances .  Any properties set in the query's  values  are ignored when executing a delete.", 
            "title": "Deleting Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#fetching-data-with-a-query", 
            "text": "Of the four basic operations of a  Query T , fetching data is the most configurable. A simple  Query T  that would fetch every instance of some entity looks like this:  var   query   =   Query User ( context );  List User   allUsers   =   await   query . fetch ();   Fetch queries can be limited to a number of instances with the  fetchLimit  property. You may also set the  offset  of a  Query T  to skip the first  offset  number of rows. Between  fetchLimit  and  offset , you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections.  A fetch  Query T  uses its  where  property to filter the result set, just like delete and update queries. The  values  of a query are ignored when fetching objects. You may also fetch a single instance with  fetchOne . If no instance is found,  null  is returned. Only use this method when the search criteria is guaranteed to be unique.  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . id ). equalTo ( 1 );  User   oneUser   =   await   query . fetchOne ();   When you are fetching an object by its primary key, you can use a shorthand method  ManagedContext.fetchObjectWithID . The method must be able to infer the type of the object, or you must provide it:  final   object   =   await   context . fetchObjectWithID User ( 1 );", 
            "title": "Fetching Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#sorting", 
            "text": "Results of a fetch can be sorted using the  sortBy  method of a  Query T . Here's an example:  var   q   =   Query User ( context ) \n   .. sortBy (( u )   =   u . dateCreated ,   QuerySortOrder . ascending );   sortBy  takes two arguments: a closure that returns which property to sort by and the order of the sort.  A  Query T  results can be sorted by multiple properties. When multiple  sortBy s are invoked on a  Query T , later  sortBy s are used to break ties in previous  sortBy s. For example, the following query will sort by last name, then by first name:  var   q   =   Query User ( context ) \n   .. sortBy (( u )   =   u . lastName ,   QuerySortOrder . ascending ) \n   .. sortBy (( u )   =   u . firstName ,   QuerySortOrder . ascending );   Thus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'.", 
            "title": "Sorting"
        }, 
        {
            "location": "/db/executing_queries/#property-selectors", 
            "text": "In the section on sorting, you saw the use of a  property selector  to select the property of the user to sort by. This syntax is used for many other query manipulations, like filtering and joining. A property selector is a closure that gives you an object of the type you are querying and must return a property of that object. The selector  (u) =  u.lastName  in the previous section is a property selector that selects the last name of a user.  The Dart analyzer will infer that the argument of a property selector, and it is always the same type as the object being queried. This enables IDE auto-completion, static error checking, and other tools like project-wide renaming.   Live Templates  To speed up query building, create a Live Template in IntelliJ that generates a property selector when typing 'ps'. The source of the template is  (o) =  o.$END$ . A downloadable settings configuration for IntelliJ exists  here  that includes this shortcut.", 
            "title": "Property Selectors"
        }, 
        {
            "location": "/db/executing_queries/#specifying-result-properties", 
            "text": "When executing queries that return managed objects (i.e.,  insert() ,  update()  and  fetch() ), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the table definition. A managed object's default properties can be modified when declaring its table definition:  class   _User   { \n   @ Column ( omitByDefault:   true ) \n   String   hashedPassword ;  }   Any property with  omitByDefault  set to true will not be fetched by default.  A property that is  omitByDefault  can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each  Query T  has a  returningProperties  method to adjust which properties do get returned from the query. Its usage looks like this:  var   query   =   Query User ( context ) \n   .. returningProperties (( user )   =   [ user . id ,   user . name ]);   returningProperties  is a multiple property selector - instead of returning just one property, it returns a list of properties.  You may include 'belongs-to' relationships in  returningProperties , but you may not include 'has-many' or 'has-one' relationships. An exception will be thrown if you attempt to. To include properties from relationships like these, see  join in Advanced Queries .  Note that if you omit the primary key of a managed object from  returningProperties , it will automatically be added. The primary key is necessary to transform the rows into instances of their  ManagedObject T  subclass.", 
            "title": "Specifying Result Properties"
        }, 
        {
            "location": "/db/executing_queries/#exceptions-and-errors", 
            "text": "When executing a query, it may fail for any number of reasons: the query is invalid, a database couldn't be reached, constraints were violated, etc. In many cases, this exception originates from the underlying database driver. When thrown in a controller, these exceptions will trigger a 500 Server Error response.  Exceptions that are thrown in response to user input (e.g., violating a database constraint, invalid data type) are re-interpreted into a  QueryException  or  ValidationException . Both of these exception types have an associated  Response  object that is sent instead of the default 500 Server error.  For this reason, you don't need to catch database query exceptions in a controller; an appropriate response will be sent on your behalf.", 
            "title": "Exceptions and Errors"
        }, 
        {
            "location": "/db/executing_queries/#statement-reuse", 
            "text": "Aqueduct will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.", 
            "title": "Statement Reuse"
        }, 
        {
            "location": "/db/advanced_queries/", 
            "text": "Advanced Queries: Filtering, Joins, Paging and Reduce\n\n\nPaging Fetched Result Sets\n\n\nThe rows from a table can be sorted and fetched in contiguous chunks. This sorting can occur on most properties. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Aqueduct has two mechanisms in \nQuery\nT\n for building queries that can fetch a subset of rows within a certain range.\n\n\nNaive paging can be accomplished using the \nfetchLimit\n and \noffset\n properties of a \nQuery\nT\n. For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its \nfetchLimit\n. The first query would have an \noffset\n of 0, then 10, then 20, and so on. Especially when using \nsortBy\n, this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches.\n\n\n\n\nFor example, consider the seven objects above that are ordered by time. If we page by two objects at a time (\nfetchLimit=2\n) starting at the first item (\noffset=0\n), our first result set is the first two objects. The next page is the original offset plus the same limit - we grab the next two rows. But before the next page is fetched, a new object is inserted and its at an index that we already fetched. The next page would return \n3:00pm\n again. A similar problem occurs if a row is deleted when paging in this way.\n\n\nIt is really annoying for client applications to have to check for and merge duplicates. Another paging technique that doesn't suffer from this problem relies on the client sending a value from the last object in the previous page, instead of an offset. So in the above example, instead of asking for offset 2 in the second query, it'd send the value \n1:30pm\n. The query filters out rows with a value less than the one it was sent, orders the remaining rows and then fetches the newest from the top.\n\n\nQuery.pageBy\n uses this technique. Its usage is similar to \nsortBy\n:\n\n\nvar\n \nfirstQuery\n \n=\n \nQuery\nPost\n(\ncontext\n)\n\n  \n..\npageBy\n((\np\n)\n \n=\n \np\n.\ndateCreated\n,\n \nQuerySortOrder\n.\ndescending\n)\n\n  \n..\nfetchLimit\n \n=\n \n10\n;\n\n\n\nvar\n \nfirstQueryResults\n \n=\n \nawait\n \nfirstQuery\n.\nfetch\n();\n\n\n\nvar\n \noldestPostWeGot\n \n=\n \nfirstQueryResults\n.\nlast\n.\ndateCreated\n;\n\n\nvar\n \nnextQuery\n \n=\n \nQuery\nPost\n(\ncontext\n)\n\n  \n..\npageBy\n((\np\n)\n \n=\n \np\n.\ndateCreated\n,\n \nQuerySortOrder\n.\ndescending\n,\n \nboundingValue:\n \noldestPostWeGot\n)\n\n  \n..\nfetchLimit\n \n=\n \n10\n;\n\n\n\n\n\n\nThis query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set.\n\n\nWhen paging, the query must have a \nfetchLimit\n - otherwise you're just sorting and returning every row. You identify which property to page on by using a property selector. The second argument to \npageBy\n defines the order the rows will be sorted in.\n\n\nWhen you first start paging, you don't have any results yet, so you can't specify a value from the last result set. In this case, the \nboundingValue\n of \npageBy\n is null - meaning start from the beginning. Once the first set has been fetched, the \nboundingValue\n is the value of the paging property in the last object returned.\n\n\nThis is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See \nManagedObjectController\nT\n as an example.)\n\n\nA \npageBy\n query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the \nfetchLimit\n, only those objects will be returned. For example, if there four more objects left and the \nfetchLimit\n is 10, the number of objects returned will be four.\n\n\nYou should index properties that will be paged by:\n\n\n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n\nint\n \npageableProperty\n;\n\n\n\n\n\n\nFiltering Results of a Fetch Operation\n\n\nFetching every row of a table usually doesn't make sense. Instead, we want a specific object or a set of objects matching some criteria.\n\n\nA \nQuery\n's \nwhere\n method is a safe and elegant way to add this criteria to a query. This method allows you to assign boolean expressions to the properties of the object being queried. Each expression is added to the WHERE clause of the generated SQL query. Here's an example of a query that finds a \nUser\n with an \nid\n equal to 1:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\n\n\n\n(The generated SQL here would be \nSELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1\n.)\n\n\nThere are many expression methods like \nequalTo\n - see the documentation for \nQueryExpression\nT\n for a complete list.\n\n\nYou may add multiple criteria to a query by invoking \nwhere\n multiple times. Each criteria is combined together with a logical 'and'. For example, the following query will find all users whose \nname\n is \"Bob\" \nand\n \nemail\n is not null:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n).\nequalTo\n(\nBob\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nemail\n).\nisNotNull\n();\n\n\n\n\n\n\nYou may apply criteria to relationship properties, too. For nullable relationships, you can apply null/not null checks:\n\n\nvar\n \nemployedQuery\n \n=\n \nQuery\nPerson\n(\ncontext\n)\n\n  \n..\nwhere\n((\np\n)\n \n=\n \np\n.\ncompany\n).\nisNotNull\n();\n\n\n\n\n\n\nMore often, you use the \nidentifiedBy\n expression for finding objects that belong to a specific object. For example, when finding all employees for a given company:\n\n\nvar\n \npreferredQuery\n \n=\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ncompany\n).\nidentifiedBy\n(\n23\n);\n\n\n\n\n\n\nThe above will only return employees who work for company with a primary key value of 23. It is equivalent to the following, and both are acceptable:\n\n\nvar\n \nsameQuery\n \n=\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ncompany\n.\nid\n).\nequalTo\n(\n23\n);\n\n\n\n\n\n\nNotice in the above that you may select properties of relationships when building a query. Since an employee 'belongs-to' a company, the employee table has a column to store the primary key of a company. This is called a foreign key column. When building a query that selects the primary key of a belongs-to relationship, Aqueduct can interpret this to use the foreign key column value.\n\n\nFor selecting properties that are not backed by a foreign key column in the table being queried, see the next section on Joins.\n\n\nIncluding Relationships in a Fetch (aka, Joins)\n\n\nA \nQuery\nT\n can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database.\n\n\nBy default, relationship properties are not fetched in a query and therefore aren't included in an object's \nasMap()\n. For example, consider the following definitions, where a \nUser\n has-many \nTask\ns:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n  \nManagedSet\nTask\n \ntasks\n;\n  \n\n}\n\n\n\nclass\n \nTask\n \nextends\n \nManagedObject\n_Task\n \nimplements\n \n_Task\n \n{}\n\n\nclass\n \n_Task\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nRelate\n(\n#\ntasks\n)\n\n  \nUser\n \nuser\n;\n\n\n  \nString\n \ncontents\n;\n\n\n}\n\n\n\n\n\n\nA \nQuery\nUser\n will fetch the \nname\n and \nid\n of each \nUser\n. A \nUser\n's \ntasks\n are not fetched, so the data returned looks like this:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\nvar\n \nusers\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\nusers\n.\nfirst\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n\n\n};\n \n// yup\n\n\n\n\n\n\nThe \njoin()\n method will tell a query to also include related objects. The following shows a fetch that gets users and their tasks:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\njoin\n(\nset\n:\n \n(\nu\n)\n \n=\n \nu\n.\ntasks\n);\n\n\nvar\n \nusers\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\nusers\n.\nfirst\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \ntasks\n:\n \n[\n\n      \n{\nid\n:\n \n1\n,\n \ncontents\n:\n \nTake out trash\n,\n \nuser\n \n:\n \n{\nid\n:\n \n1\n}},\n\n      \n...\n\n  \n]\n\n\n};\n \n// yup\n\n\n\n\n\n\nWhen joining a has-many relationship, the \nset:\n argument takes a property selector that must select a \nManagedSet\n. (When fetching a has-one or belongs-to relationship, use the \nobject:\n argument.)\n\n\nThe method \njoin()\n returns a new \nQuery\nT\n, where \nT\n is the type of the joined object. That is, the above code could also be written as such:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\n\n// type annotation added for clarity\n\n\nQuery\nTask\n \ntaskSubQuery\n \n=\n \nq\n.\njoin\n(\nset\n:\n \n(\nu\n)\n \n=\n \nu\n.\ntasks\n);\n\n\n\n\n\n\nConfiguring Join Queries\n\n\nYou do not execute a query created by a join, but you do configure it like any other query. (The parent query keeps track of the joined query and you execute the parent query.) For example, you may modify the properties that are returned for the joined objects:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\n\nq\n.\njoin\n(\nset\n:\n \n(\nu\n)\n \n=\n \nu\n.\ntasks\n)\n  \n  \n..\nreturningProperties\n((\nt\n)\n \n=\n \n[\nt\n.\nid\n,\n \nt\n.\ncontents\n]);\n\n\n\nfinal\n \nusersAndTasks\n \n=\n \nawait\n \nq\n.\nfetch\n();\n  \n\n\n\n\n\nYou may also apply filtering criteria to a join query. Consider a \nParent\n that has-many \nChildren\n. When fetching parents and joining their children, a \nwhere\n expression on the join query impacts which children are returned, but does not impact which parents are returned. For example, the following query would fetch every parent, but would only include children who are greater than 1 years old:\n\n\nfinal\n \nq\n \n=\n \nQuery\nParent\n(\ncontext\n);\n\n\nq\n.\njoin\n(\nset\n:\n \n(\np\n)\n \n=\n \np\n.\nchildren\n)\n\n  \n..\nwhere\n((\nc\n)\n \n=\n \nc\n.\nage\n).\ngreaterThan\n(\n1\n);\n\n\n\nfinal\n \nparentsAndTheirChildren\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\n\n\n\nFiltering Objects by Their Relationships\n\n\nHowever, consider if we applied a similar expression to the parent query - it would only return parents \nwho have children that are greater than 1 years old\n.\n\n\nfinal\n \nq\n \n=\n \nQuery\nParent\n(\ncontext\n)\n\n  \n..\nwhere\n((\nc\n)\n \n=\n \nc\n.\nchildren\n.\nhaveAtLeastOneWhere\n.\nage\n).\ngreaterThan\n(\n1\n);\n\n  \n..\njoin\n(\nset\n:\n \n(\np\n)\n \n=\n \np\n.\nchildren\n);\n\n\n\nfinal\n \nparentsWithOlderChildren\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\n\n\n\nThe difference is where the expression is applied. When applying it to the child query, it removes child objects that don't meet the criteria. When applying it to the parent query, it removes parents that don't meet the criteria. The property \nhaveAtLeastOneWhere\n is specific to has-many relationships. When selecting properties of a has-one or belongs-to relationship, you access the property directly:\n\n\nfinal\n \nq\n \n=\n \nQuery\nChild\n(\ncontext\n)\n\n  \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nparent\n.\nage\n).\ngreaterThan\n(\n30\n)\n\n  \n..\njoin\n(\nobject:\n \n(\np\n)\n \n=\n \ne\n.\nparent\n);\n\n\n\nfinal\n \nchildrenWithParentsOver30\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\n\n\n\nNote that you may use relationship properties without explicitly joining the property. A SQL JOIN is still performed, but the related object is not included in the result set.\n\n\nfinal\n \nq\n \n=\n \nQuery\nChild\n(\ncontext\n)\n\n  \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nparent\n.\nage\n).\ngreaterThan\n(\n30\n);\n\n\n\nfinal\n \nemployeesWithManagersOver30YearsOld\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\n\n\n\nMultiple Joins\n\n\nMore than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\njoin\n(\nobject:\n \n(\nu\n)\n \n=\n \nu\n.\naddress\n);\n\n\n\nq\n.\njoin\n(\nset\n:\n \n(\nu\n)\n \n=\n \nu\n.\ntasks\n)\n\n  \n..\njoin\n(\nobject:\n \n(\nu\n)\n \n=\n \nu\n.\nlocation\n);\n\n\n\n\n\n\nThis would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here.\n\n\nReduce Functions (aka, Aggregate Functions)\n\n\nQueries can also be used to perform functions like \ncount\n, \nsum\n, \naverage\n, \nmin\n and \nmax\n. Here's an example:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\nvar\n \nnumberOfUsers\n \n=\n \nawait\n \nquery\n.\nreduce\n.\ncount\n();\n\n\n\n\n\n\nFor reduce functions that use the value of some property, a property selector is used to identify that property.\n\n\nvar\n \naverageSalary\n \n=\n \nawait\n \nquery\n.\nreduce\n.\nsum\n((\nu\n)\n \n=\n \nu\n.\nsalary\n);\n\n\n\n\n\n\nAny values configured in a \nQuery\nT\n also impact the \nreduce\n function. For example, applying a \nQuery.where\n and then executing a \nsum\n function will only sum the rows that meet the criteria of the where clause:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n.\nequalTo\n(\nBob\n);\n\n\nvar\n \naverageSalaryOfPeopleNamedBob\n \n=\n \nawait\n \nquery\n.\nreduce\n.\nsum\n((\nu\n)\n \n=\n \nu\n.\nsalary\n);\n\n\n\n\n\n\nFallbacks\n\n\nYou may always execute arbitrary SQL with \nPersistentStore.execute\n. Note that the objects returned will be a \nList\nList\ndynamic\n - a list of rows, for each a list of columns.\n\n\nYou may also provide raw WHERE clauses with \nQuery.predicate\n. A \nQueryPredicate\n is a \nString\n that is set as the query's where clause. A \nQueryPredicate\n has two properties, a format string and a \nMap\nString, dynamic\n of parameter values. The \nformat\n string can (and should) parameterize any input values. Parameters are indicated in the format string using the \n@\n token:\n\n\n// Creates a predicate that would only include instances where some column \nid\n is less than 2\n\n\nvar\n \npredicate\n \n=\n \nQueryPredicate\n(\nid \n @idVariable\n,\n \n{\nidVariable\n \n:\n \n2\n});\n\n\n\n\n\n\nThe text following the \n@\n token may contain \n[A-Za-z0-9_]\n. The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the column. If a key is not present in the \nMap\n, an exception will be thrown. Extra keys will be ignored.", 
            "title": "Advanced Queries"
        }, 
        {
            "location": "/db/advanced_queries/#advanced-queries-filtering-joins-paging-and-reduce", 
            "text": "", 
            "title": "Advanced Queries: Filtering, Joins, Paging and Reduce"
        }, 
        {
            "location": "/db/advanced_queries/#paging-fetched-result-sets", 
            "text": "The rows from a table can be sorted and fetched in contiguous chunks. This sorting can occur on most properties. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Aqueduct has two mechanisms in  Query T  for building queries that can fetch a subset of rows within a certain range.  Naive paging can be accomplished using the  fetchLimit  and  offset  properties of a  Query T . For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its  fetchLimit . The first query would have an  offset  of 0, then 10, then 20, and so on. Especially when using  sortBy , this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches.   For example, consider the seven objects above that are ordered by time. If we page by two objects at a time ( fetchLimit=2 ) starting at the first item ( offset=0 ), our first result set is the first two objects. The next page is the original offset plus the same limit - we grab the next two rows. But before the next page is fetched, a new object is inserted and its at an index that we already fetched. The next page would return  3:00pm  again. A similar problem occurs if a row is deleted when paging in this way.  It is really annoying for client applications to have to check for and merge duplicates. Another paging technique that doesn't suffer from this problem relies on the client sending a value from the last object in the previous page, instead of an offset. So in the above example, instead of asking for offset 2 in the second query, it'd send the value  1:30pm . The query filters out rows with a value less than the one it was sent, orders the remaining rows and then fetches the newest from the top.  Query.pageBy  uses this technique. Its usage is similar to  sortBy :  var   firstQuery   =   Query Post ( context ) \n   .. pageBy (( p )   =   p . dateCreated ,   QuerySortOrder . descending ) \n   .. fetchLimit   =   10 ;  var   firstQueryResults   =   await   firstQuery . fetch ();  var   oldestPostWeGot   =   firstQueryResults . last . dateCreated ;  var   nextQuery   =   Query Post ( context ) \n   .. pageBy (( p )   =   p . dateCreated ,   QuerySortOrder . descending ,   boundingValue:   oldestPostWeGot ) \n   .. fetchLimit   =   10 ;   This query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set.  When paging, the query must have a  fetchLimit  - otherwise you're just sorting and returning every row. You identify which property to page on by using a property selector. The second argument to  pageBy  defines the order the rows will be sorted in.  When you first start paging, you don't have any results yet, so you can't specify a value from the last result set. In this case, the  boundingValue  of  pageBy  is null - meaning start from the beginning. Once the first set has been fetched, the  boundingValue  is the value of the paging property in the last object returned.  This is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See  ManagedObjectController T  as an example.)  A  pageBy  query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the  fetchLimit , only those objects will be returned. For example, if there four more objects left and the  fetchLimit  is 10, the number of objects returned will be four.  You should index properties that will be paged by:  @ Column ( indexed:   true )  int   pageableProperty ;", 
            "title": "Paging Fetched Result Sets"
        }, 
        {
            "location": "/db/advanced_queries/#filtering-results-of-a-fetch-operation", 
            "text": "Fetching every row of a table usually doesn't make sense. Instead, we want a specific object or a set of objects matching some criteria.  A  Query 's  where  method is a safe and elegant way to add this criteria to a query. This method allows you to assign boolean expressions to the properties of the object being queried. Each expression is added to the WHERE clause of the generated SQL query. Here's an example of a query that finds a  User  with an  id  equal to 1:  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . id ). equalTo ( 1 );   (The generated SQL here would be  SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1 .)  There are many expression methods like  equalTo  - see the documentation for  QueryExpression T  for a complete list.  You may add multiple criteria to a query by invoking  where  multiple times. Each criteria is combined together with a logical 'and'. For example, the following query will find all users whose  name  is \"Bob\"  and   email  is not null:  final   query   =   Query User ( context ) \n   .. where (( u )   =   u . name ). equalTo ( Bob ) \n   .. where (( u )   =   u . email ). isNotNull ();   You may apply criteria to relationship properties, too. For nullable relationships, you can apply null/not null checks:  var   employedQuery   =   Query Person ( context ) \n   .. where (( p )   =   p . company ). isNotNull ();   More often, you use the  identifiedBy  expression for finding objects that belong to a specific object. For example, when finding all employees for a given company:  var   preferredQuery   =   Query Employee ( context ) \n   .. where (( e )   =   e . company ). identifiedBy ( 23 );   The above will only return employees who work for company with a primary key value of 23. It is equivalent to the following, and both are acceptable:  var   sameQuery   =   Query Employee ( context ) \n   .. where (( e )   =   e . company . id ). equalTo ( 23 );   Notice in the above that you may select properties of relationships when building a query. Since an employee 'belongs-to' a company, the employee table has a column to store the primary key of a company. This is called a foreign key column. When building a query that selects the primary key of a belongs-to relationship, Aqueduct can interpret this to use the foreign key column value.  For selecting properties that are not backed by a foreign key column in the table being queried, see the next section on Joins.", 
            "title": "Filtering Results of a Fetch Operation"
        }, 
        {
            "location": "/db/advanced_queries/#including-relationships-in-a-fetch-aka-joins", 
            "text": "A  Query T  can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database.  By default, relationship properties are not fetched in a query and therefore aren't included in an object's  asMap() . For example, consider the following definitions, where a  User  has-many  Task s:  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n   ManagedSet Task   tasks ;    }  class   Task   extends   ManagedObject _Task   implements   _Task   {}  class   _Task   { \n   @ primaryKey \n   int   id ; \n\n   @ Relate ( # tasks ) \n   User   user ; \n\n   String   contents ;  }   A  Query User  will fetch the  name  and  id  of each  User . A  User 's  tasks  are not fetched, so the data returned looks like this:  var   q   =   Query User ( context );  var   users   =   await   q . fetch ();  users . first . asMap ()   ==   { \n   id :   1 , \n   name :   Bob  };   // yup   The  join()  method will tell a query to also include related objects. The following shows a fetch that gets users and their tasks:  var   q   =   Query User ( context ) \n   .. join ( set :   ( u )   =   u . tasks );  var   users   =   await   q . fetch ();  users . first . asMap ()   ==   { \n   id :   1 , \n   name :   Bob , \n   tasks :   [ \n       { id :   1 ,   contents :   Take out trash ,   user   :   { id :   1 }}, \n       ... \n   ]  };   // yup   When joining a has-many relationship, the  set:  argument takes a property selector that must select a  ManagedSet . (When fetching a has-one or belongs-to relationship, use the  object:  argument.)  The method  join()  returns a new  Query T , where  T  is the type of the joined object. That is, the above code could also be written as such:  var   q   =   Query User ( context );  // type annotation added for clarity  Query Task   taskSubQuery   =   q . join ( set :   ( u )   =   u . tasks );", 
            "title": "Including Relationships in a Fetch (aka, Joins)"
        }, 
        {
            "location": "/db/advanced_queries/#configuring-join-queries", 
            "text": "You do not execute a query created by a join, but you do configure it like any other query. (The parent query keeps track of the joined query and you execute the parent query.) For example, you may modify the properties that are returned for the joined objects:  var   q   =   Query User ( context );  q . join ( set :   ( u )   =   u . tasks )   \n   .. returningProperties (( t )   =   [ t . id ,   t . contents ]);  final   usersAndTasks   =   await   q . fetch ();     You may also apply filtering criteria to a join query. Consider a  Parent  that has-many  Children . When fetching parents and joining their children, a  where  expression on the join query impacts which children are returned, but does not impact which parents are returned. For example, the following query would fetch every parent, but would only include children who are greater than 1 years old:  final   q   =   Query Parent ( context );  q . join ( set :   ( p )   =   p . children ) \n   .. where (( c )   =   c . age ). greaterThan ( 1 );  final   parentsAndTheirChildren   =   await   q . fetch ();", 
            "title": "Configuring Join Queries"
        }, 
        {
            "location": "/db/advanced_queries/#filtering-objects-by-their-relationships", 
            "text": "However, consider if we applied a similar expression to the parent query - it would only return parents  who have children that are greater than 1 years old .  final   q   =   Query Parent ( context ) \n   .. where (( c )   =   c . children . haveAtLeastOneWhere . age ). greaterThan ( 1 ); \n   .. join ( set :   ( p )   =   p . children );  final   parentsWithOlderChildren   =   await   q . fetch ();   The difference is where the expression is applied. When applying it to the child query, it removes child objects that don't meet the criteria. When applying it to the parent query, it removes parents that don't meet the criteria. The property  haveAtLeastOneWhere  is specific to has-many relationships. When selecting properties of a has-one or belongs-to relationship, you access the property directly:  final   q   =   Query Child ( context ) \n   .. where (( p )   =   p . parent . age ). greaterThan ( 30 ) \n   .. join ( object:   ( p )   =   e . parent );  final   childrenWithParentsOver30   =   await   q . fetch ();   Note that you may use relationship properties without explicitly joining the property. A SQL JOIN is still performed, but the related object is not included in the result set.  final   q   =   Query Child ( context ) \n   .. where (( p )   =   p . parent . age ). greaterThan ( 30 );  final   employeesWithManagersOver30YearsOld   =   await   q . fetch ();", 
            "title": "Filtering Objects by Their Relationships"
        }, 
        {
            "location": "/db/advanced_queries/#multiple-joins", 
            "text": "More than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist:  var   q   =   Query User ( context ) \n   .. join ( object:   ( u )   =   u . address );  q . join ( set :   ( u )   =   u . tasks ) \n   .. join ( object:   ( u )   =   u . location );   This would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here.", 
            "title": "Multiple Joins"
        }, 
        {
            "location": "/db/advanced_queries/#reduce-functions-aka-aggregate-functions", 
            "text": "Queries can also be used to perform functions like  count ,  sum ,  average ,  min  and  max . Here's an example:  var   query   =   Query User ( context );  var   numberOfUsers   =   await   query . reduce . count ();   For reduce functions that use the value of some property, a property selector is used to identify that property.  var   averageSalary   =   await   query . reduce . sum (( u )   =   u . salary );   Any values configured in a  Query T  also impact the  reduce  function. For example, applying a  Query.where  and then executing a  sum  function will only sum the rows that meet the criteria of the where clause:  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . name . equalTo ( Bob );  var   averageSalaryOfPeopleNamedBob   =   await   query . reduce . sum (( u )   =   u . salary );", 
            "title": "Reduce Functions (aka, Aggregate Functions)"
        }, 
        {
            "location": "/db/advanced_queries/#fallbacks", 
            "text": "You may always execute arbitrary SQL with  PersistentStore.execute . Note that the objects returned will be a  List List dynamic  - a list of rows, for each a list of columns.  You may also provide raw WHERE clauses with  Query.predicate . A  QueryPredicate  is a  String  that is set as the query's where clause. A  QueryPredicate  has two properties, a format string and a  Map String, dynamic  of parameter values. The  format  string can (and should) parameterize any input values. Parameters are indicated in the format string using the  @  token:  // Creates a predicate that would only include instances where some column  id  is less than 2  var   predicate   =   QueryPredicate ( id   @idVariable ,   { idVariable   :   2 });   The text following the  @  token may contain  [A-Za-z0-9_] . The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the column. If a key is not present in the  Map , an exception will be thrown. Extra keys will be ignored.", 
            "title": "Fallbacks"
        }, 
        {
            "location": "/db/transactions/", 
            "text": "Database Transactions\n\n\nLearn how to execute multiple \nQuery\nT\ns in a database transaction.\n\n\nTransactions\n\n\nA transaction is a series of queries that are executed together. If one of the queries in that set fails, then all of the queries fail and their changes are reversed if they had already been executed.\n\n\nConsider an application that stores employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. An straightforward (but problematic) implementation would look like this:\n\n\n// Create the new department\n\n\nfinal\n \nnewDepartment\n \n=\n \nawait\n \nctx\n.\ninsertObject\n(\nDepartment\n()..\nname\n \n=\n \nNew Department\n);\n\n\n\n// Set employee\ns departments to the new one\n\n\nfinal\n \nchangeDepartmentQuery\n \n=\n \nQuery\nEmployee\n(\nctx\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n])\n      \n  \n..\nvalues\n.\ndepartment\n.\nid\n \n=\n \nnewDepartment\n.\nid\n;\n\n\nawait\n \nchangeDepartmentQuery\n.\nupdate\n();\n\n\n\n// Delete the old ones\n\n\nfinal\n \ndeleteDepartmentQuery\n \n=\n \nQuery\nDepartment\n(\nctx\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n]);\n\n\nawait\n \ndeleteDepartmentQuery\n.\ndelete\n();\n      \n\n\n\n\n\nThis change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department.\n\n\nA database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking \nManagedContext.transaction\n and writing your queries in its closure argument.\n\n\nawait\n \ncontext\n.\ntransaction\n((\ntransaction\n)\n \nasync\n \n{\n\n  \n// note that \ntransaction\n is the context for each of these queries.\n\n  \nfinal\n \nnewDepartment\n \n=\n \nawait\n \ntransaction\n.\ninsertObject\n(\nDepartment\n()..\nname\n \n=\n \nNew Department\n);\n\n\n  \nfinal\n \nchangeDepartmentQuery\n \n=\n \nQuery\nEmployee\n(\ntransaction\n)\n\n    \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n])\n      \n    \n..\nvalues\n.\ndepartment\n.\nid\n \n=\n \nnewDepartment\n.\nid\n;\n\n  \nawait\n \nchangeDepartmentQuery\n.\nupdate\n();\n\n\n  \nfinal\n \ndeleteDepartmentQuery\n \n=\n \nQuery\nDepartment\n(\ntransaction\n)\n\n    \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n]);\n\n  \nawait\n \ndeleteDepartmentQuery\n.\ndelete\n();\n      \n\n});\n\n\n\n\n\n\nThe closure has a \ntransaction\n object that all queries in the transaction must use as their context. Queries that use this transaction context will be grouped in the same transaction. Once they have all succeeded, the \ntransaction\n method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the \ntransaction\n method re-throws that exception.\n\n\n\n\nFailing to Use the Transaction Context will Deadlock your Application\n\n\nIf you use the transaction's parent context in a query inside a transaction closure, the database connection will deadlock and will stop working.\n\n\n\n\nReturning Values\n\n\nThe value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope.\n\n\nfinal\n \nemployees\n \n=\n \n[...];\n\n\nfinal\n \ninsertedEmployees\n \n=\n \nawait\n \ncontext\n.\ntransaction\n((\ntransaction\n)\n \nasync\n \n{\n\n  \nreturn\n \nFuture\n.\nwait\n(\nemployees\n.\nmap\n((\ne\n)\n \n=\n \ntransaction\n.\ninsertObject\n(\ne\n)));\n\n\n});\n\n\n\n\n\n\nRollbacks\n\n\nYou can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a \nRollback\n object.\n\n\ntry\n \n{\n\n  \nawait\n \ncontext\n.\ntransaction\n((\nt\n)\n \nasync\n \n{\n\n    \n// do something\n\n\n    \nif\n \n(\nsomethingIsTrue\n)\n \n{\n\n      \nthrow\n \nRollback\n(\nsomething was true\n);\n    \n    \n}\n\n\n    \n// do something\n\n  \n});\n\n\n}\n \non\n \nRollback\n \ncatch\n \n(\nrollback\n)\n \n{\n\n  \nprint\n(\n${\nrollback\n.\nreason\n}\n);\n \n// prints \nsomething was true\n\n\n}\n\n\n\n\n\n\nWhen you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The \ntransaction\n method completes with an error, where the error object is the \nRollback\n.", 
            "title": "Transactions"
        }, 
        {
            "location": "/db/transactions/#database-transactions", 
            "text": "Learn how to execute multiple  Query T s in a database transaction.", 
            "title": "Database Transactions"
        }, 
        {
            "location": "/db/transactions/#transactions", 
            "text": "A transaction is a series of queries that are executed together. If one of the queries in that set fails, then all of the queries fail and their changes are reversed if they had already been executed.  Consider an application that stores employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. An straightforward (but problematic) implementation would look like this:  // Create the new department  final   newDepartment   =   await   ctx . insertObject ( Department ().. name   =   New Department );  // Set employee s departments to the new one  final   changeDepartmentQuery   =   Query Employee ( ctx ) \n   .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ])       \n   .. values . department . id   =   newDepartment . id ;  await   changeDepartmentQuery . update ();  // Delete the old ones  final   deleteDepartmentQuery   =   Query Department ( ctx ) \n   .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ]);  await   deleteDepartmentQuery . delete ();         This change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department.  A database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking  ManagedContext.transaction  and writing your queries in its closure argument.  await   context . transaction (( transaction )   async   { \n   // note that  transaction  is the context for each of these queries. \n   final   newDepartment   =   await   transaction . insertObject ( Department ().. name   =   New Department ); \n\n   final   changeDepartmentQuery   =   Query Employee ( transaction ) \n     .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ])       \n     .. values . department . id   =   newDepartment . id ; \n   await   changeDepartmentQuery . update (); \n\n   final   deleteDepartmentQuery   =   Query Department ( transaction ) \n     .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ]); \n   await   deleteDepartmentQuery . delete ();        });   The closure has a  transaction  object that all queries in the transaction must use as their context. Queries that use this transaction context will be grouped in the same transaction. Once they have all succeeded, the  transaction  method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the  transaction  method re-throws that exception.   Failing to Use the Transaction Context will Deadlock your Application  If you use the transaction's parent context in a query inside a transaction closure, the database connection will deadlock and will stop working.", 
            "title": "Transactions"
        }, 
        {
            "location": "/db/transactions/#returning-values", 
            "text": "The value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope.  final   employees   =   [...];  final   insertedEmployees   =   await   context . transaction (( transaction )   async   { \n   return   Future . wait ( employees . map (( e )   =   transaction . insertObject ( e )));  });", 
            "title": "Returning Values"
        }, 
        {
            "location": "/db/transactions/#rollbacks", 
            "text": "You can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a  Rollback  object.  try   { \n   await   context . transaction (( t )   async   { \n     // do something \n\n     if   ( somethingIsTrue )   { \n       throw   Rollback ( something was true );     \n     } \n\n     // do something \n   });  }   on   Rollback   catch   ( rollback )   { \n   print ( ${ rollback . reason } );   // prints  something was true  }   When you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The  transaction  method completes with an error, where the error object is the  Rollback .", 
            "title": "Rollbacks"
        }, 
        {
            "location": "/db/validations/", 
            "text": "Validating Data\n\n\nData is added to a database through \nupdate\n and \ninsert\n queries. As part of these two operations, a \nManagedObject\nT\n will ensure that its properties have valid values. For example, a \nPerson\n object might ensure that its name starts with a capital letter and that its phone number has only numeric values.  If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a \nQueryException\n that returns an HTTP response with error messaging to help the client correct their request.\n\n\nThe preferred way of setting a validation is to add \nValidate\n metadata to properties of a table definition. Here's an example of a validation that ensures a tweet is less than 140 characters:\n\n\nclass\n \nTweet\n \nextends\n \nManagedObject\n_Tweet\n \nimplements\n \n_Tweet\n \n{}\n\n\nclass\n \n_Tweet\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidate\n.\nlength\n(\nlessThan:\n \n140\n)\n\n  \nString\n \nmessage\n;\n\n\n}\n\n\n\n\n\n\nBuilt-in Validators\n\n\nThere are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it is formatted correctly or to restrict the possible values to a list of available options. Common validators are available as named constructors of the \nValidate\n class. Here is an example:\n\n\nclass\n \n_Story\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidate\n.\noneOf\n(\nconst\n \n[\nstarted\n,\n \naccepted\n,\n \nrejected\n,\n \ndelivered\n])\n\n  \nString\n \nstate\n;\n\n\n}\n\n\n\n\n\n\nA built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the \nstate\n property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be:\n\n\nThe value `invalidValue` is not valid for `state`. Valid values are: \nstarted\n, \naccepted\n, \nrejected\n, \ndelivered\n.\n.\n\n\n\n\n\nSee the API reference for \nValidate\n and its named constructors for possible options.\n\n\nValidate\n annotations on properties declared in a managed object subclass (transient properties) have no effect.\n\n\nValidating Relationships\n\n\nValidations are only valid for properties declared in a table definition. Validators applied to relationship properties are applied to the primary key of the related object (i.e. the foreign key value). Validation logic is only ran on the properties of the managed object being validated - validations on properties of a related object are \nnot\n run. When validating a graph of managed objects, you must initiate validation on any related objects manually.\n\n\n\n\nValidating Related Objects\nThe behavior of a validation is different when an object is being validated as a relationship. In other words, a validation applied to the primary key of an object likely requires different behavior when being applied to a foreign key reference to that object.\n\n\n\n\n\n\nCustom Validators\n\n\nThere will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of \nValidate\n to provide custom validation behavior. For example, if there were a \nValidatePhoneNumber\n class:\n\n\nclass\n \n_Person\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidatePhoneNumber\n()\n\n  \nString\n \nphoneNumber\n;\n\n\n}\n\n\n\n\n\n\nA subclass of \nValidate\n must override \nValidate.validate()\n and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator:\n\n\nclass\n \nValidatePhoneNumber\n \nextends\n \nValidate\n \n{\n\n  \nValidatePhoneNumber\n({\nbool\n \nonUpdate:\n \ntrue\n,\n \nbool\n \nonInsert:\n \ntrue\n})\n \n:\n\n    \nsuper\n(\nonUpdate:\n \nonUpdate\n,\n \nonInsert:\n \nonInsert\n);\n\n\n  \n@\noverride\n\n  \nvoid\n \nvalidate\n(\nValidationContext\n \ncontext\n,\n \ndynamic\n \nvalue\n)\n \n{\n  \n    \nif\n \n(\nvalue\n.\nlength\n \n!=\n \n15\n)\n \n{\n\n      \ncontext\n.\naddError\n(\nmust be 15 digits\n);\n      \n    \n}\n\n\n    \nif\n \n(\ncontainsNonNumericValues\n(\nvalue\n))\n \n{\n\n      \ncontext\n.\naddError\n(\nmust contain characters 0-9 only.\n);\n      \n    \n}\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIf \nvalue\n is doesn't meet the validation criteria, this method adds an error string to the \nValidationContext\n it is passed. Error messages should be brief and indicate the successful criteria that failed. Information about the property being validated will automatically be added to the error message, so you do not need to include that information. If the context has no errors at the end of validation, the validation succeeds; otherwise, it fails.\n\n\nA \nValidationContext\n also has information about the property being validated, and whether the validation is running for an object being inserted or an object being updated.\n\n\nValidation Behavior\n\n\nA property may have more than one \nValidate\n metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters:\n\n\n@\nValidate\n.\nlength\n(\nequalTo:\n \n10\n)\n\n\n@\nValidate\n.\nmatches\n(\nr\n$[A-Z]+^\n)\n\n\nString\n \ntenCapitalLetters\n;\n\n\n\n\n\n\nBy default, validations are executed when a \nQuery\nT\n's \ninsert\n or \nupdate\n method is invoked. A validator can be restricted to only run on \ninsert\n or \nupdate\n by passing values for its optional constructor arguments \nonUpdate\n and \nonInsert\n:\n\n\n@\nValidate\n.\nmatches\n(\nr\n^[A-Z]+$\n,\n \nonInsert:\n \ntrue\n,\n \nonUpdate:\n \nfalse\n)\n\n\nString\n \nvalidateOnInsertOnly\n;\n\n\n\n\n\n\nIt is important to understand how validations work when a value for a property is \nnot\n specified in an insert or update query. For example, consider a \nPerson\n with a \nname\n and \nemail\n property and then inserted in a query where \nemail\n hasn't been set:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n;\n\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nBecause \nemail\n was not set on \nQuery.values\n, validations will not be run on that property.\n\n\nThere are two special validators that can require a property to be set, or require that a property \nnot\n be set. \nValidate.present()\n requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. For example, the following declaration requires that \nemail\n is set on insertion, but doesn't have to be for updates:\n\n\n@\nValidate\n.\npresent\n(\nonUpdate:\n \nfalse\n,\n \nonInsert:\n \ntrue\n)\n\n\nString\n \nemail\n;\n\n\n\n\n\n\nThe inverse of \nValidate.present()\n is \nValidate.absent()\n. This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example:\n\n\n@\nValidate\n.\nabsent\n(\nonUpdate:\n \ntrue\n,\n \nonInsert:\n \nfalse\n)\n\n\nString\n \ncanOnlyBeSetOnce\n;\n\n\n\n\n\n\nIn the above declaration, the validator is only run on update operations and ensures that the property \ncanOnlyBeSetOnce\n does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted.\n\n\nValidators are not run when a value is null. For example, the following insertion explicitly inserts \nnull\n for the property \nemail\n:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n(\ncontext\n)\n\n  \n..\nvalues\n.\nemail\n \n=\n \nnull\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n;\n\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nNullability is enforced by \nColumn.isNullable\n property. Consider the following declaration:\n\n\n@\nColumn\n(\nnullable:\n \nfalse\n)\n\n\n@\nValidate\n.\nlength\n(\ngreaterThan:\n \n10\n)\n\n\nString\n \nname\n;\n\n\n\n\n\n\nHere, the property \nname\n must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table.\n\n\n\n\n\n\n\n\nInput Value for Name\n\n\nValidation Runs?\n\n\nOutcome\n\n\n\n\n\n\n\n\n\n\nInsert value longer than 10 characters\n\n\nYes\n\n\nSuccessful database insert\n\n\n\n\n\n\nInsert value shorter than 10 characters\n\n\nYes\n\n\nDatabase insert not executed, exception thrown\n\n\n\n\n\n\nInsert value not specified\n\n\nNo\n\n\nDatabase insert fails with non-null violation, exception thrown\n\n\n\n\n\n\nInsert value is null\n\n\nNo\n\n\nDatabase insert fails with non-null violation, exception thrown\n\n\n\n\n\n\nUpdate value longer than 10 characters\n\n\nYes\n\n\nSuccessful database update\n\n\n\n\n\n\nUpdate value shorter than 10 characters\n\n\nYes\n\n\nDatabase update not executed, exception thrown\n\n\n\n\n\n\nUpdate value not specified\n\n\nNo\n\n\nSuccessful database update\n\n\n\n\n\n\nUpdate value is explicit null\n\n\nNo\n\n\nSuccessful database update\n\n\n\n\n\n\n\n\nThis behavior allows \nManagedObject\nT\n instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding \nValidate.present()\n metadata to all properties.\n\n\nThis also means that any custom validator can assert that a value passed to \nValidate.validate()\n is non-null.\n\n\nOther Validator Behavior\n\n\nFor validators that can't be built by subclassing \nValidate\n, you may override \nManagedObject\nT\n.validate()\n. This method is useful when a validation involves more than one property. Here's an example:\n\n\nclass\n \nPerson\n \nextends\n \nManagedObject\n_Person\n \nimplements\n \n_Person\n \n{\n\n  \n@\noverride\n\n  \nValidationContext\n \nvalidate\n({\nValidating\n \nforEvent:\n \nValidating\n.\ninsert\n})\n \n{\n\n   \nfinal\n \nctx\n \n=\n \nsuper\n.\nvalidate\n(\nforEvent:\n \nforEvent\n);\n\n\n    \nif\n \n(\na\n \n+\n \nb\n \n \n10\n)\n \n{\n\n      \nctx\n.\naddError\n(\na + b must be greater than 10\n);\n\n    \n}\n\n\n    \nreturn\n \nctx\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nWhen overriding this method, the \nsuper\n implementation must be invoked to run validations managed by annotations. You must return the \nValidationContext\n created by the superclass' implementation.\n\n\nSkipping Validations\n\n\nValidations are only run when values are set via \nQuery\nT\n.values\n. Values set via \nQuery\nT\n.valueMap\n are not validated and is useful for inserting data without validation. Here's an example of skipping validation:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n(\ncontext\n)\n\n  \n..\nvalueMap\n \n=\n \n{\n\n    \nname\n \n:\n \nxyz\n,\n\n    \nemail\n \n:\n \nwhatever\n\n  \n};\n\n\n\n\n\n\nUpdate and Insert Callbacks\n\n\nManagedObject\nT\n subclasses may override \nwillUpdate\n and \nwillInsert\n to make changes prior to being updated or inserted. For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated:\n\n\nclass\n \nPerson\n \nextends\n \nManagedObject\n_Person\n \nimplements\n \n_Person\n \n{\n\n  \n@\noverride\n\n  \nvoid\n \nwillUpdate\n()\n \n{\n\n    \nupdatedAt\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nvoid\n \nwillInsert\n()\n \n{\n\n    \ncreatedAt\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n  \n}\n\n\n}\n\n\nclass\n \n_Person\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n  \nDateTime\n \ncreatedAt\n;\n\n  \nDateTime\n \nupdatedAt\n;\n\n\n}\n\n\n\n\n\n\nBoth \nwillUpdate\n and \nwillInsert\n are run before any validation occurs. Like validations, \nwillUpdate\n and \nwillInsert\n are skipped when using \nQuery.valueMap\n.", 
            "title": "Validations"
        }, 
        {
            "location": "/db/validations/#validating-data", 
            "text": "Data is added to a database through  update  and  insert  queries. As part of these two operations, a  ManagedObject T  will ensure that its properties have valid values. For example, a  Person  object might ensure that its name starts with a capital letter and that its phone number has only numeric values.  If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a  QueryException  that returns an HTTP response with error messaging to help the client correct their request.  The preferred way of setting a validation is to add  Validate  metadata to properties of a table definition. Here's an example of a validation that ensures a tweet is less than 140 characters:  class   Tweet   extends   ManagedObject _Tweet   implements   _Tweet   {}  class   _Tweet   { \n   @ primaryKey \n   int   id ; \n\n   @ Validate . length ( lessThan:   140 ) \n   String   message ;  }", 
            "title": "Validating Data"
        }, 
        {
            "location": "/db/validations/#built-in-validators", 
            "text": "There are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it is formatted correctly or to restrict the possible values to a list of available options. Common validators are available as named constructors of the  Validate  class. Here is an example:  class   _Story   { \n   @ primaryKey \n   int   id ; \n\n   @ Validate . oneOf ( const   [ started ,   accepted ,   rejected ,   delivered ]) \n   String   state ;  }   A built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the  state  property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be:  The value `invalidValue` is not valid for `state`. Valid values are:  started ,  accepted ,  rejected ,  delivered . .  See the API reference for  Validate  and its named constructors for possible options.  Validate  annotations on properties declared in a managed object subclass (transient properties) have no effect.", 
            "title": "Built-in Validators"
        }, 
        {
            "location": "/db/validations/#validating-relationships", 
            "text": "Validations are only valid for properties declared in a table definition. Validators applied to relationship properties are applied to the primary key of the related object (i.e. the foreign key value). Validation logic is only ran on the properties of the managed object being validated - validations on properties of a related object are  not  run. When validating a graph of managed objects, you must initiate validation on any related objects manually.   Validating Related Objects The behavior of a validation is different when an object is being validated as a relationship. In other words, a validation applied to the primary key of an object likely requires different behavior when being applied to a foreign key reference to that object.", 
            "title": "Validating Relationships"
        }, 
        {
            "location": "/db/validations/#custom-validators", 
            "text": "There will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of  Validate  to provide custom validation behavior. For example, if there were a  ValidatePhoneNumber  class:  class   _Person   { \n   @ primaryKey \n   int   id ; \n\n   @ ValidatePhoneNumber () \n   String   phoneNumber ;  }   A subclass of  Validate  must override  Validate.validate()  and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator:  class   ValidatePhoneNumber   extends   Validate   { \n   ValidatePhoneNumber ({ bool   onUpdate:   true ,   bool   onInsert:   true })   : \n     super ( onUpdate:   onUpdate ,   onInsert:   onInsert ); \n\n   @ override \n   void   validate ( ValidationContext   context ,   dynamic   value )   {   \n     if   ( value . length   !=   15 )   { \n       context . addError ( must be 15 digits );       \n     } \n\n     if   ( containsNonNumericValues ( value ))   { \n       context . addError ( must contain characters 0-9 only. );       \n     } \n   }  }   If  value  is doesn't meet the validation criteria, this method adds an error string to the  ValidationContext  it is passed. Error messages should be brief and indicate the successful criteria that failed. Information about the property being validated will automatically be added to the error message, so you do not need to include that information. If the context has no errors at the end of validation, the validation succeeds; otherwise, it fails.  A  ValidationContext  also has information about the property being validated, and whether the validation is running for an object being inserted or an object being updated.", 
            "title": "Custom Validators"
        }, 
        {
            "location": "/db/validations/#validation-behavior", 
            "text": "A property may have more than one  Validate  metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters:  @ Validate . length ( equalTo:   10 )  @ Validate . matches ( r $[A-Z]+^ )  String   tenCapitalLetters ;   By default, validations are executed when a  Query T 's  insert  or  update  method is invoked. A validator can be restricted to only run on  insert  or  update  by passing values for its optional constructor arguments  onUpdate  and  onInsert :  @ Validate . matches ( r ^[A-Z]+$ ,   onInsert:   true ,   onUpdate:   false )  String   validateOnInsertOnly ;   It is important to understand how validations work when a value for a property is  not  specified in an insert or update query. For example, consider a  Person  with a  name  and  email  property and then inserted in a query where  email  hasn't been set:  var   query   =   new   Query Person ( context ) \n   .. values . name   =   Bob ;  await   query . insert ();   Because  email  was not set on  Query.values , validations will not be run on that property.  There are two special validators that can require a property to be set, or require that a property  not  be set.  Validate.present()  requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. For example, the following declaration requires that  email  is set on insertion, but doesn't have to be for updates:  @ Validate . present ( onUpdate:   false ,   onInsert:   true )  String   email ;   The inverse of  Validate.present()  is  Validate.absent() . This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example:  @ Validate . absent ( onUpdate:   true ,   onInsert:   false )  String   canOnlyBeSetOnce ;   In the above declaration, the validator is only run on update operations and ensures that the property  canOnlyBeSetOnce  does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted.  Validators are not run when a value is null. For example, the following insertion explicitly inserts  null  for the property  email :  var   query   =   new   Query Person ( context ) \n   .. values . email   =   null \n   .. values . name   =   Bob ;  await   query . insert ();   Nullability is enforced by  Column.isNullable  property. Consider the following declaration:  @ Column ( nullable:   false )  @ Validate . length ( greaterThan:   10 )  String   name ;   Here, the property  name  must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table.     Input Value for Name  Validation Runs?  Outcome      Insert value longer than 10 characters  Yes  Successful database insert    Insert value shorter than 10 characters  Yes  Database insert not executed, exception thrown    Insert value not specified  No  Database insert fails with non-null violation, exception thrown    Insert value is null  No  Database insert fails with non-null violation, exception thrown    Update value longer than 10 characters  Yes  Successful database update    Update value shorter than 10 characters  Yes  Database update not executed, exception thrown    Update value not specified  No  Successful database update    Update value is explicit null  No  Successful database update     This behavior allows  ManagedObject T  instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding  Validate.present()  metadata to all properties.  This also means that any custom validator can assert that a value passed to  Validate.validate()  is non-null.", 
            "title": "Validation Behavior"
        }, 
        {
            "location": "/db/validations/#other-validator-behavior", 
            "text": "For validators that can't be built by subclassing  Validate , you may override  ManagedObject T .validate() . This method is useful when a validation involves more than one property. Here's an example:  class   Person   extends   ManagedObject _Person   implements   _Person   { \n   @ override \n   ValidationContext   validate ({ Validating   forEvent:   Validating . insert })   { \n    final   ctx   =   super . validate ( forEvent:   forEvent ); \n\n     if   ( a   +   b     10 )   { \n       ctx . addError ( a + b must be greater than 10 ); \n     } \n\n     return   ctx ; \n   }  }   When overriding this method, the  super  implementation must be invoked to run validations managed by annotations. You must return the  ValidationContext  created by the superclass' implementation.", 
            "title": "Other Validator Behavior"
        }, 
        {
            "location": "/db/validations/#skipping-validations", 
            "text": "Validations are only run when values are set via  Query T .values . Values set via  Query T .valueMap  are not validated and is useful for inserting data without validation. Here's an example of skipping validation:  var   query   =   new   Query Person ( context ) \n   .. valueMap   =   { \n     name   :   xyz , \n     email   :   whatever \n   };", 
            "title": "Skipping Validations"
        }, 
        {
            "location": "/db/validations/#update-and-insert-callbacks", 
            "text": "ManagedObject T  subclasses may override  willUpdate  and  willInsert  to make changes prior to being updated or inserted. For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated:  class   Person   extends   ManagedObject _Person   implements   _Person   { \n   @ override \n   void   willUpdate ()   { \n     updatedAt   =   new   DateTime . now (). toUtc (); \n   } \n\n   @ override \n   void   willInsert ()   { \n     createdAt   =   new   DateTime . now (). toUtc (); \n   }  }  class   _Person   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n   DateTime   createdAt ; \n   DateTime   updatedAt ;  }   Both  willUpdate  and  willInsert  are run before any validation occurs. Like validations,  willUpdate  and  willInsert  are skipped when using  Query.valueMap .", 
            "title": "Update and Insert Callbacks"
        }, 
        {
            "location": "/db/db_tools/", 
            "text": "Database Migration and Tooling\n\n\nThe \naqueduct db\n command line tool creates and executes \nmigration files\n. A migration file contains Dart code that executes SQL commands to create and modify database tables. \n\n\n\n\nPostgreSQL 9.6 and Greater\n\n\nThe minimum version of PostgreSQL needed to work with Aqueduct is 9.6.\n\n\n\n\nMigration Files\n\n\nAn application's data model is described by its \nManagedObject\nT\n subclasses and their \ntable definition\n. Migration files describe a series of database commands that will create or modify a database schema to match an application's data model. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new \nManagedObject\nT\n subclasses or adding an database index to a property.\n\n\nA migration file is automatically generated from your code. Each migration file contains only the changes made since the last migration file was generated. For example, if you began your application with a \nAuthor\n type and generated a migration file, the migration file would create the author table. If you then added a \nBook\n type and generated a new migration file, the new file would only create the book table. When a migration is used to upgrade a database schema, every migration file that has not yet been run will be run.\n\n\nMigration files must be stored in version control so that you can manage multiple databases for different environments.\n\n\nGenerating Migration Files\n\n\nThe \naqueduct db generate\n command generates a new migration file. This tool finds all \nManagedObject\nT\n subclasses - your data model - in your application and compares them to the data model the last time the tool was run. Any differences between the data models are represented as a command in the generated migration file. If the new migration file were to be used to upgrade a database, the database would match the current data model in your application.\n\n\n\n\nFinding ManagedObjects\nA managed object subclass must be directly or transitively imported into your application channel file. A file in your project directory that is not imported will not be found. There is typically no need to import a managed object subclass file directly: your application is initialized in your channel, where imports all of your controllers and services, which in turn import the managed object subclasses they use. As long as you are using your managed object declarations in your application, they'll be found.\n\n\n\n\n\n\nMigration files are stored in an project's \nmigrations/\n directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with \n.migration.dart\n. For example, \n00000001_initial.migration.dart\n is a migration filename. The version number portion of the filename is required, as is the \n.migration.dart\n suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names:\n\n\n00000001_initial.migration.dart\n00000002_add_user_nickname.migration.dart\n\n\n\n\n\nThe version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended. Migration files may be altered after they are generated (see \nseeding data\n).\n\n\nValidating Migration Files\n\n\nThe \naqueduct db validate\n tool validates that the database schema after running all migration files matches the application's data model. The validate tool will display differences found between the schema in code and the schema created by migration files.\n\n\nListing Migration Files\n\n\nUse \naqueduct db list\n to list all database migration files and their resolved version number.\n\n\nGetting a Database's Version\n\n\nYou can fetch a database's current version number with \naqueduct db get-version\n. This command takes \n--connect\n or a \ndatabase.yaml\n file as described in the next section to get connection info for the database.\n\n\nUpgrading a Database Schema by Executing Migration Files\n\n\nThe tool \naqueduct db upgrade\n will apply the commands of migration files to a running database. This tool is run in an application's directory and database connection info is provided with the \n--connect\n option. For example, the following would execute the current project directory's migration files on a PostgreSQL database:\n\n\naqueduct db upgrade --connect postgres://username:password@localhost:5432/my_application\n\n\n\n\n\nEvery migration file that has not yet been run on the targeted database will be run. This tool manages a version table in each database it upgrades that allows it to determine which migration files need to be run.\n\n\nConnection information can alternatively be stored in a database configuration file named \ndatabase.yaml\n in the application directory. If this file exists with the following format, \n--connect\n can be omitted and connection information will be read from this file:\n\n\nusername: \nuser\n\npassword: \npassword\n\nhost: \nhost\n\nport: port\ndatabaseName: \ndatabase\n\n\n\n\n\n\nWhen to Execute Migration Files\n\n\nDuring development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application.\n\n\nYou may delete migration files (as long as you haven't run them on a production database!). When \naqueduct db generate\n is run again, it will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.\n\n\nSeeding Data\n\n\nYou may insert, delete, or edit rows during a database migration by overriding its \nseed\n method. You must run SQL queries instead of using \nQuery\nT\n when seeding data. The \nMigration\n base class that all of your migrations extends have a property for a \nPersistentStore\n connected to the database the migration is being run on.\n\n\nclass\n \nMigration2\n \nextends\n \nMigration\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nupgrade\n()\n \nasync\n \n{\n\n    \n...\n\n  \n}\n\n\n  \n@\noverride\n\n  \nFuture\n \ndowngrade\n()\n \nasync\n \n{\n\n    \n...\n\n  \n}\n\n\n  \n@\noverride\n\n  \nFuture\n \nseed\n()\n \nasync\n \n{\n\n    \nawait\n \nstore\n.\nexecuteQuery\n(\nINSERT IN _mytable (a) VALUES (1)\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSeeding is run after a migration's \nugprade\n method has completed. Seeding data also occurs in the same transaction as \nupgrade\n.\n\n\nHandling Non-nullable Additions\n\n\nSome database upgrades can fail depending on the data currently in the database. A common scenario is adding a property to an existing managed object that is not-nullable. If the database table already has rows, those rows would not have a value for the new column and the migration would fail. If the database does not have any rows, the migration will succeed correctly. If the property has a default value attribute or is auto-incrementing, the migration will always succeed and the existing rows will have the default value for the new column.\n\n\nYou may also provide a value just for the existing rows to make the migration succeed. This is added as an argument to the schema-altering command that would violate non-nullability:\n\n\n@\noverride\n\n\nFuture\n \nupgrade\n()\n \nasync\n \n{\n\n  \ndatabase\n.\naddColumn\n(\n_mytable\n,\n \nSchemaColumn\n(...),\n \nunencodedInitialValue:\n \ntext\n)\n\n\n}\n\n\n\n\n\n\nThe unencoded initial value is inserted directly into a SQL command. This requires that the value be a SQL value literal as shown in the table:\n\n\n\n\n\n\n\n\nType\n\n\nUnencoded Initial Value\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nint\n\n\n\"1\"\n\n\n1\n\n\n\n\n\n\nString\n\n\n\"'string'\"\n\n\n'string'\n\n\n\n\n\n\ndouble\n\n\n\"2.0\"\n\n\n2.0\n\n\n\n\n\n\nDateTime\n\n\n\"'1900-01-02T00:00:00.000Z'\"\n\n\n1/2/1900", 
            "title": "Migration and Tooling"
        }, 
        {
            "location": "/db/db_tools/#database-migration-and-tooling", 
            "text": "The  aqueduct db  command line tool creates and executes  migration files . A migration file contains Dart code that executes SQL commands to create and modify database tables.    PostgreSQL 9.6 and Greater  The minimum version of PostgreSQL needed to work with Aqueduct is 9.6.", 
            "title": "Database Migration and Tooling"
        }, 
        {
            "location": "/db/db_tools/#migration-files", 
            "text": "An application's data model is described by its  ManagedObject T  subclasses and their  table definition . Migration files describe a series of database commands that will create or modify a database schema to match an application's data model. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new  ManagedObject T  subclasses or adding an database index to a property.  A migration file is automatically generated from your code. Each migration file contains only the changes made since the last migration file was generated. For example, if you began your application with a  Author  type and generated a migration file, the migration file would create the author table. If you then added a  Book  type and generated a new migration file, the new file would only create the book table. When a migration is used to upgrade a database schema, every migration file that has not yet been run will be run.  Migration files must be stored in version control so that you can manage multiple databases for different environments.", 
            "title": "Migration Files"
        }, 
        {
            "location": "/db/db_tools/#generating-migration-files", 
            "text": "The  aqueduct db generate  command generates a new migration file. This tool finds all  ManagedObject T  subclasses - your data model - in your application and compares them to the data model the last time the tool was run. Any differences between the data models are represented as a command in the generated migration file. If the new migration file were to be used to upgrade a database, the database would match the current data model in your application.   Finding ManagedObjects A managed object subclass must be directly or transitively imported into your application channel file. A file in your project directory that is not imported will not be found. There is typically no need to import a managed object subclass file directly: your application is initialized in your channel, where imports all of your controllers and services, which in turn import the managed object subclasses they use. As long as you are using your managed object declarations in your application, they'll be found.    Migration files are stored in an project's  migrations/  directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with  .migration.dart . For example,  00000001_initial.migration.dart  is a migration filename. The version number portion of the filename is required, as is the  .migration.dart  suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names:  00000001_initial.migration.dart\n00000002_add_user_nickname.migration.dart  The version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended. Migration files may be altered after they are generated (see  seeding data ).", 
            "title": "Generating Migration Files"
        }, 
        {
            "location": "/db/db_tools/#validating-migration-files", 
            "text": "The  aqueduct db validate  tool validates that the database schema after running all migration files matches the application's data model. The validate tool will display differences found between the schema in code and the schema created by migration files.", 
            "title": "Validating Migration Files"
        }, 
        {
            "location": "/db/db_tools/#listing-migration-files", 
            "text": "Use  aqueduct db list  to list all database migration files and their resolved version number.", 
            "title": "Listing Migration Files"
        }, 
        {
            "location": "/db/db_tools/#getting-a-databases-version", 
            "text": "You can fetch a database's current version number with  aqueduct db get-version . This command takes  --connect  or a  database.yaml  file as described in the next section to get connection info for the database.", 
            "title": "Getting a Database's Version"
        }, 
        {
            "location": "/db/db_tools/#upgrading-a-database-schema-by-executing-migration-files", 
            "text": "The tool  aqueduct db upgrade  will apply the commands of migration files to a running database. This tool is run in an application's directory and database connection info is provided with the  --connect  option. For example, the following would execute the current project directory's migration files on a PostgreSQL database:  aqueduct db upgrade --connect postgres://username:password@localhost:5432/my_application  Every migration file that has not yet been run on the targeted database will be run. This tool manages a version table in each database it upgrades that allows it to determine which migration files need to be run.  Connection information can alternatively be stored in a database configuration file named  database.yaml  in the application directory. If this file exists with the following format,  --connect  can be omitted and connection information will be read from this file:  username:  user \npassword:  password \nhost:  host \nport: port\ndatabaseName:  database", 
            "title": "Upgrading a Database Schema by Executing Migration Files"
        }, 
        {
            "location": "/db/db_tools/#when-to-execute-migration-files", 
            "text": "During development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application.  You may delete migration files (as long as you haven't run them on a production database!). When  aqueduct db generate  is run again, it will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.", 
            "title": "When to Execute Migration Files"
        }, 
        {
            "location": "/db/db_tools/#seeding-data", 
            "text": "You may insert, delete, or edit rows during a database migration by overriding its  seed  method. You must run SQL queries instead of using  Query T  when seeding data. The  Migration  base class that all of your migrations extends have a property for a  PersistentStore  connected to the database the migration is being run on.  class   Migration2   extends   Migration   { \n   @ override \n   Future   upgrade ()   async   { \n     ... \n   } \n\n   @ override \n   Future   downgrade ()   async   { \n     ... \n   } \n\n   @ override \n   Future   seed ()   async   { \n     await   store . executeQuery ( INSERT IN _mytable (a) VALUES (1) ); \n   }  }   Seeding is run after a migration's  ugprade  method has completed. Seeding data also occurs in the same transaction as  upgrade .", 
            "title": "Seeding Data"
        }, 
        {
            "location": "/db/db_tools/#handling-non-nullable-additions", 
            "text": "Some database upgrades can fail depending on the data currently in the database. A common scenario is adding a property to an existing managed object that is not-nullable. If the database table already has rows, those rows would not have a value for the new column and the migration would fail. If the database does not have any rows, the migration will succeed correctly. If the property has a default value attribute or is auto-incrementing, the migration will always succeed and the existing rows will have the default value for the new column.  You may also provide a value just for the existing rows to make the migration succeed. This is added as an argument to the schema-altering command that would violate non-nullability:  @ override  Future   upgrade ()   async   { \n   database . addColumn ( _mytable ,   SchemaColumn (...),   unencodedInitialValue:   text )  }   The unencoded initial value is inserted directly into a SQL command. This requires that the value be a SQL value literal as shown in the table:     Type  Unencoded Initial Value  Value      int  \"1\"  1    String  \"'string'\"  'string'    double  \"2.0\"  2.0    DateTime  \"'1900-01-02T00:00:00.000Z'\"  1/2/1900", 
            "title": "Handling Non-nullable Additions"
        }, 
        {
            "location": "/db/json_columns/", 
            "text": "JSON Document Storage\n\n\nLearn how to store unstructured, binary JSON data in \nManagedObject\nT\n properties.\n\n\nJSON Columns in Relational Databases\n\n\nPostgreSQL supports many column data types like integers, strings, booleans and dates. A column may also be JSON data. This allows for storing unstructured data and simple objects in a table column. The data from JSON columns can be fetched all at once, or in pieces. Elements of JSON data can be used to filter the results of a query.\n\n\nThe Document Data Type\n\n\nJSON document columns are added to a database table by declaring a \nDocument\n property in a \nManagedObject\nT\n's table definition. In PostgreSQL, a \nDocument\n column data type is \njsonb\n. A document column can only contain JSON-encodable data. This data is typically a \nMap\n or \nList\n that contains only JSON-encodable data. The following \nManagedObject\nT\n declaration will have a \ncontents\n column of type \njsonb\n.\n\n\nclass\n \nEvent\n \nextends\n \nManagedObject\n_Event\n \nimplements\n \n_Event\n \n{}\n\n\nclass\n \n_Event\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nDateTime\n \ntimestamp\n;\n\n\n  \nDocument\n \ncontents\n;\n\n\n}\n\n\n\n\n\n\nA \nDocument\n object has a \ndata\n property to hold its JSON-encodable data. When instantiating \nDocument\n, this property defaults to null unless a value has been provided to the optional, ordered parameter in its constructor.\n\n\nfinal\n \ndoc\n \n=\n \nnew\n \nDocument\n();\n\n\nassert\n(\ndoc\n.\ndata\n \n==\n \nnull\n);\n\n\n\nfinal\n \ndoc\n \n=\n \nnew\n \nDocument\n({\nkey\n:\n \nvalue\n});\n\n\nassert\n(\ndoc\n.\ndata\n \nis\n \nMap\n);\n\n\n\nfinal\n \ndoc\n \n=\n \nnew\n \nDocument\n([\n0\n]);\n\n\nassert\n(\ndoc\n.\ndata\n \nis\n \nList\n);\n\n\n\n\n\n\nThe data in a document can be accessed through its \ndata\n property, or through its subscript operator. \nDocument\n's subscript operator forwards the invocation to its \ndata\n property.\n\n\nfinal\n \ndoc\n \n=\n \nnew\n \nDocument\n({\nkey\n:\n \nvalue\n});\n\n\n\nassert\n(\ndoc\n[\nkey\n]\n \n==\n \ndoc\n.\ndata\n[\nkey\n]);\n\n\n\n\n\n\nThe argument to the subscript operator may be a string (if \ndata\n is a map) or an integer (if \ndata\n is a list).\n\n\nBasic Operations on Document Properties\n\n\nDocument\n columns are like any other type of column, and can therefore be set during an insert or update, and read during a fetch.\n\n\nInserting Rows with Document Properties\n\n\nA \nDocument\n property is first set when inserting with a \nQuery\nT\n. The \nvalues\n property of the query is set to a \nDocument\n object initialized with a JSON-encodable value.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nvalues\n.\ntimestamp\n \n=\n \nDateTime\n.\nnow\n()\n\n  \n..\nvalues\n.\ncontents\n \n=\n \nDocument\n({\n\n    \ntype\n:\n \npush\n,\n\n    \nuser\n:\n \nbob\n,\n\n    \ntags\n:\n \n[\nv1\n]\n\n  \n});\n\n\nfinal\n \nevent\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n  \n\n\n\n\n\nIn the above, the argument to \nDocument\n will be JSON-encoded and stored in the database for column \ncontents\n. If the object can't be encoded as JSON, an exception will be thrown.\n\n\nFetching Rows with Document Properties\n\n\nWhen fetching an object with \nDocument\n properties with a \nQuery\nT\n, you access the column's value through the document's \ndata\n property.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nid\n).\nequalTo\n(\n1\n);\n\n\nfinal\n \nevent1\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\nevent1\n.\ncontents\n.\ndata\n \n==\n \n{\n\n  \ntype\n:\n \npush\n,\n\n  \nuser\n:\n \nbob\n,\n\n  \ntags\n:\n \n[\nv1\n]\n\n\n};\n\n\n\n\n\n\nWhen fetching \nDocument\n properties, the JSON data is decoded into the appropriate type. This is likely a \nMap\n or \nList\n, but can be any JSON-encodable object. Because the data stored in a \nDocument\n property is unstructured, the type of \ndata\n is \ndynamic\n. It is good practice to store consistent data structures in a column; i.e., always storing a \nMap\n or always storing a \nList\n.\n\n\nUpdating Rows with Document Properties\n\n\nUpdating a row with \nDocument\n properties works the same as inserting rows.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nid\n).\nequalTo\n(\n1\n)\n\n  \n..\nvalues\n.\ncontents\n \n=\n \nDocument\n({\n\n    \ntype\n:\n \npush\n,\n\n    \nuser\n:\n \nbob\n,\n\n    \ntags\n:\n \n[\nv1\n,\n \nnew\n]\n\n  \n});\n\n\nfinal\n \nevent\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n  \n\n\n\n\n\nWhen updating in this way, the document stored in the column is replaced entirely.\n\n\nAccessing Document Values\n\n\nThe type of \nDocument.data\n is \ndynamic\n - it can be any valid JSON type and may be casted to the expected type when used. This data can also be nested - a \nList\n of \nMaps\n, for example. When accessing object keys or list indices, you may use the subscript operator directly on \nDocument\n.\n\n\n// Object Access by key\n\n\nfinal\n \ndoc\n \n=\n \nDocument\n({\nkey\n:\n \nvalue\n});\n\n\nfinal\n \nvalue\n \n=\n \ndoc\n[\nkey\n]\n \n==\n \nvalue\n;\n\n\n\n// List Access by index\n\n\nfinal\n \ndoc\n \n=\n \nDocument\n([\nv1\n,\n \nv2\n]);\n\n\nfinal\n \nvalue\n \n=\n \ndoc\n[\n0\n]\n \n==\n \nv1\n;\n\n\n\n\n\n\nYou can access nested elements with the same syntax:\n\n\nfinal\n \ndoc\n \n=\n \nDocument\n([\n\n  \n{\nid\n:\n \n1\n},\n\n  \n{\nid\n:\n \n2\n}\n\n\n]);\n\n\n\nfinal\n \nobj1\n \n=\n \ndoc\n[\n0\n][\nid\n];\n \n// == 1\n\n\nfinal\n \nobj2\n \n=\n \ndoc\n[\n1\n][\nid\n];\n \n// == 2\n\n\n\n\n\n\nNote that using the subscript operator on a \nDocument\n simply invokes it on its \ndata\n property. Therefore, any subscript values must be valid for Dart \nList\n and \nMap\n types.\n\n\nFetching Sub-documents\n\n\nWhen fetching a \nDocument\n property, the default behavior is to return the entire JSON document as it is stored in the database column. You may fetch parts of the document you need by using \nQuery.returningProperties\n and the subscript operator.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntags\n]]);\n\n\nfinal\n \neventsWithTags\n \n=\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nWhen using the subscript operator on a returned \nDocument\n property, only the value for that key is returned. For example, if the above query were executed and the stored column's value were:\n\n\n{\n\n  \ntype\n:\n \npush\n,\n  \n  \nuser\n:\n \nbob\n,\n\n  \ntags\n:\n \n[\nv1\n]\n  \n\n}\n\n\n\n\n\n\nThe value of \nEvent.contents\n would only contain the array for the key \"tags\":\n\n\n[\nv1\n]\n\n\n\n\n\n\nYou may also index arrays in a JSON column using the same subscript operator, and the subscript operator can also be nested. For example, the following query would fetch the \"tags\" array, and then fetch the string at index 0 from it:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntags\n][\n0\n]]);\n\n\nfinal\n \neventsWithFirstTag\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\neventsWithFirstTag\n.\ncontents\n.\ndata\n \n==\n \nv1\n;\n\n\n\n\n\n\nIf a key or index does not exist in the JSON document, the value of the returned property will be null. For this reason, you should use null-aware operators when accessing \nDocument.data\n:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntags\n][\n7\n]]);\n \n// 7 is out of bounds\n\n\nfinal\n \neventsWithFirstTag\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\nif\n \n(\neventsWithFirstTag\n.\ncontents\n?\n.\ndata\n \n==\n \nv1\n)\n \n{\n\n  \n...\n\n\n}\n\n\n\n\n\n\nWhen fetching elements from a JSON array, you may use negative indices to specify a index from the end of the array.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntags\n][\n-\n1\n]]);\n\n\nfinal\n \neventsWithLastTag\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nNote that you can only fetch a single sub-structure from a \nDocument\n column per query. That is, you may not do the following:\n\n\n// Invalid\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntype\n],\n \ne\n.\ncontents\n[\nuser\n]]);\n\n\n\n\n\n\nFor operations not supported by \nQuery\nT\n, you may use SQL directly:\n\n\nfinal\n \neventTagCounts\n \n=\n \nawait\n \ncontext\n.\npersistentStore\n.\nexecute\n(\nSELECT jsonb_array_length(contents-\ntags\n) from _Event\n);", 
            "title": "JSON Document Storage"
        }, 
        {
            "location": "/db/json_columns/#json-document-storage", 
            "text": "Learn how to store unstructured, binary JSON data in  ManagedObject T  properties.", 
            "title": "JSON Document Storage"
        }, 
        {
            "location": "/db/json_columns/#json-columns-in-relational-databases", 
            "text": "PostgreSQL supports many column data types like integers, strings, booleans and dates. A column may also be JSON data. This allows for storing unstructured data and simple objects in a table column. The data from JSON columns can be fetched all at once, or in pieces. Elements of JSON data can be used to filter the results of a query.", 
            "title": "JSON Columns in Relational Databases"
        }, 
        {
            "location": "/db/json_columns/#the-document-data-type", 
            "text": "JSON document columns are added to a database table by declaring a  Document  property in a  ManagedObject T 's table definition. In PostgreSQL, a  Document  column data type is  jsonb . A document column can only contain JSON-encodable data. This data is typically a  Map  or  List  that contains only JSON-encodable data. The following  ManagedObject T  declaration will have a  contents  column of type  jsonb .  class   Event   extends   ManagedObject _Event   implements   _Event   {}  class   _Event   { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( indexed:   true ) \n   DateTime   timestamp ; \n\n   Document   contents ;  }   A  Document  object has a  data  property to hold its JSON-encodable data. When instantiating  Document , this property defaults to null unless a value has been provided to the optional, ordered parameter in its constructor.  final   doc   =   new   Document ();  assert ( doc . data   ==   null );  final   doc   =   new   Document ({ key :   value });  assert ( doc . data   is   Map );  final   doc   =   new   Document ([ 0 ]);  assert ( doc . data   is   List );   The data in a document can be accessed through its  data  property, or through its subscript operator.  Document 's subscript operator forwards the invocation to its  data  property.  final   doc   =   new   Document ({ key :   value });  assert ( doc [ key ]   ==   doc . data [ key ]);   The argument to the subscript operator may be a string (if  data  is a map) or an integer (if  data  is a list).", 
            "title": "The Document Data Type"
        }, 
        {
            "location": "/db/json_columns/#basic-operations-on-document-properties", 
            "text": "Document  columns are like any other type of column, and can therefore be set during an insert or update, and read during a fetch.", 
            "title": "Basic Operations on Document Properties"
        }, 
        {
            "location": "/db/json_columns/#inserting-rows-with-document-properties", 
            "text": "A  Document  property is first set when inserting with a  Query T . The  values  property of the query is set to a  Document  object initialized with a JSON-encodable value.  final   query   =   Query Event ( context ) \n   .. values . timestamp   =   DateTime . now () \n   .. values . contents   =   Document ({ \n     type :   push , \n     user :   bob , \n     tags :   [ v1 ] \n   });  final   event   =   await   query . insert ();     In the above, the argument to  Document  will be JSON-encoded and stored in the database for column  contents . If the object can't be encoded as JSON, an exception will be thrown.", 
            "title": "Inserting Rows with Document Properties"
        }, 
        {
            "location": "/db/json_columns/#fetching-rows-with-document-properties", 
            "text": "When fetching an object with  Document  properties with a  Query T , you access the column's value through the document's  data  property.  final   query   =   Query Event ( context ) \n   .. where (( e )   =   e . id ). equalTo ( 1 );  final   event1   =   await   query . fetchOne ();  event1 . contents . data   ==   { \n   type :   push , \n   user :   bob , \n   tags :   [ v1 ]  };   When fetching  Document  properties, the JSON data is decoded into the appropriate type. This is likely a  Map  or  List , but can be any JSON-encodable object. Because the data stored in a  Document  property is unstructured, the type of  data  is  dynamic . It is good practice to store consistent data structures in a column; i.e., always storing a  Map  or always storing a  List .", 
            "title": "Fetching Rows with Document Properties"
        }, 
        {
            "location": "/db/json_columns/#updating-rows-with-document-properties", 
            "text": "Updating a row with  Document  properties works the same as inserting rows.  final   query   =   Query Event ( context ) \n   .. where (( e )   =   e . id ). equalTo ( 1 ) \n   .. values . contents   =   Document ({ \n     type :   push , \n     user :   bob , \n     tags :   [ v1 ,   new ] \n   });  final   event   =   await   query . updateOne ();     When updating in this way, the document stored in the column is replaced entirely.", 
            "title": "Updating Rows with Document Properties"
        }, 
        {
            "location": "/db/json_columns/#accessing-document-values", 
            "text": "The type of  Document.data  is  dynamic  - it can be any valid JSON type and may be casted to the expected type when used. This data can also be nested - a  List  of  Maps , for example. When accessing object keys or list indices, you may use the subscript operator directly on  Document .  // Object Access by key  final   doc   =   Document ({ key :   value });  final   value   =   doc [ key ]   ==   value ;  // List Access by index  final   doc   =   Document ([ v1 ,   v2 ]);  final   value   =   doc [ 0 ]   ==   v1 ;   You can access nested elements with the same syntax:  final   doc   =   Document ([ \n   { id :   1 }, \n   { id :   2 }  ]);  final   obj1   =   doc [ 0 ][ id ];   // == 1  final   obj2   =   doc [ 1 ][ id ];   // == 2   Note that using the subscript operator on a  Document  simply invokes it on its  data  property. Therefore, any subscript values must be valid for Dart  List  and  Map  types.", 
            "title": "Accessing Document Values"
        }, 
        {
            "location": "/db/json_columns/#fetching-sub-documents", 
            "text": "When fetching a  Document  property, the default behavior is to return the entire JSON document as it is stored in the database column. You may fetch parts of the document you need by using  Query.returningProperties  and the subscript operator.  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ tags ]]);  final   eventsWithTags   =   query . fetch ();   When using the subscript operator on a returned  Document  property, only the value for that key is returned. For example, if the above query were executed and the stored column's value were:  { \n   type :   push ,   \n   user :   bob , \n   tags :   [ v1 ]    }   The value of  Event.contents  would only contain the array for the key \"tags\":  [ v1 ]   You may also index arrays in a JSON column using the same subscript operator, and the subscript operator can also be nested. For example, the following query would fetch the \"tags\" array, and then fetch the string at index 0 from it:  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ tags ][ 0 ]]);  final   eventsWithFirstTag   =   await   query . fetchOne ();  eventsWithFirstTag . contents . data   ==   v1 ;   If a key or index does not exist in the JSON document, the value of the returned property will be null. For this reason, you should use null-aware operators when accessing  Document.data :  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ tags ][ 7 ]]);   // 7 is out of bounds  final   eventsWithFirstTag   =   await   query . fetchOne ();  if   ( eventsWithFirstTag . contents ? . data   ==   v1 )   { \n   ...  }   When fetching elements from a JSON array, you may use negative indices to specify a index from the end of the array.  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ tags ][ - 1 ]]);  final   eventsWithLastTag   =   await   query . fetchOne ();   Note that you can only fetch a single sub-structure from a  Document  column per query. That is, you may not do the following:  // Invalid  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ type ],   e . contents [ user ]]);   For operations not supported by  Query T , you may use SQL directly:  final   eventTagCounts   =   await   context . persistentStore . execute ( SELECT jsonb_array_length(contents- tags ) from _Event );", 
            "title": "Fetching Sub-documents"
        }, 
        {
            "location": "/auth/", 
            "text": "Tasks\n\n\nAqueduct has types to manage authentication and authorization according to the \nOAuth 2.0 specification\n.\n\n\nYou create an \nAuthServer\n service object for your application that manages authentication and authorization logic. An \nAuthServer\n requires a helper object that implements \nAuthServerDelegate\n to handle configuration and required data storage. Most often, this object is a \nManagedAuthDelegate\nT\n that uses the Aqueduct ORM to manage this storage.\n\n\nAn \nAuthServer\n service object is injected into \nAuthorizer\n controllers that protect access to controller channels. An \nAuthServer\n is also injected into \nAuthCodeController\n and \nAuthController\n to provide HTTP APIs for authentication.\n\n\nThe \naqueduct auth\n command-line tool manages configuration - such as client identifier management - for live applications.\n\n\n\n\nGuides\n\n\n\n\nWhat is OAuth 2.0?\n\n\nCreating and Using AuthServers\n\n\nSecuring Routes with Authorizer\n\n\nAdding Authentication Endpoints\n\n\nUsing Scopes to Control Access\n\n\nManaging OAuth 2.0 Clients", 
            "title": "Overview"
        }, 
        {
            "location": "/auth/#tasks", 
            "text": "Aqueduct has types to manage authentication and authorization according to the  OAuth 2.0 specification .  You create an  AuthServer  service object for your application that manages authentication and authorization logic. An  AuthServer  requires a helper object that implements  AuthServerDelegate  to handle configuration and required data storage. Most often, this object is a  ManagedAuthDelegate T  that uses the Aqueduct ORM to manage this storage.  An  AuthServer  service object is injected into  Authorizer  controllers that protect access to controller channels. An  AuthServer  is also injected into  AuthCodeController  and  AuthController  to provide HTTP APIs for authentication.  The  aqueduct auth  command-line tool manages configuration - such as client identifier management - for live applications.", 
            "title": "Tasks"
        }, 
        {
            "location": "/auth/#guides", 
            "text": "What is OAuth 2.0?  Creating and Using AuthServers  Securing Routes with Authorizer  Adding Authentication Endpoints  Using Scopes to Control Access  Managing OAuth 2.0 Clients", 
            "title": "Guides"
        }, 
        {
            "location": "/auth/server/", 
            "text": "Creating AuthServers to Authenticate and Authorize\n\n\nAn \nAuthServer\n is a service that handles creating, verifying and refreshing authorization tokens. You create an \nAuthServer\n in your application channel and inject into types that deal with authorization. This types include:\n\n\n\n\nAuthorizer\n: middleware controller that protects endpoint controllers from unauthorized access\n\n\nAuthController\n: endpoint controller that grants access tokens\n\n\nAuthCodeController\n: endpoint controller that grants authorization codes to be exchanged for access tokens\n\n\n\n\nAn \nAuthServer\n must persist the data it uses and creates - like client identifiers and access tokens. Storage is often performed by a database, but it can be in memory, a cache or some other medium. Because of the many different storage mediums, an \nAuthServer\n doesn't perform any storage itself - it relies on an instance of \nAuthServerDelegate\n specific to your application. This allows storage to be independent of verification logic.\n\n\nCreating Instances of AuthServer and AuthServerDelegate\n\n\nAuthServerDelegate\n is an interface that an \nAuthServer\n uses to handle storage of client identifiers, tokens and other authorization artifacts. An \nAuthServer\n must be created with a concrete implementation of \nAuthServerDelegate\n. Aqueduct contains a concrete implementation of \nAuthServerDelegate\n that uses the ORM. It is highly recommended to use this implementation instead of implementing your own storage because it has been thoroughly tested and handles cleaning up expired data correctly.\n\n\nThis concrete implementation is named \nManagedAuthDelegate\nT\n. It exists in a sub-package of Aqueduct and must be explicitly imported. Here's an example of creating an \nAuthServer\n and \nManagedAuthDelegate\nT\n:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \nAuthServer\n \nauthServer\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \ncontext\n \n=\n \nManagedContext\n(...);\n\n    \nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\n(Notice that \nManagedAuthDelegate\n has a type argument - this will be covered in the next section.)\n\n\nWhile \nAuthServer\n has methods for handling authorization tasks, it is rarely used directly. Instead, \nAuthCodeController\n and \nAuthController\n are hooked up to routes to grant authorization tokens through your application's HTTP API. Instances of \nAuthorizer\n secure routes in channels. All of these types invoke the appropriate methods on the \nAuthServer\n. Here's an example \nApplicationChannel\n subclass that sets up and uses authorization:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ncontext\n \n=\n \nManagedContext\n(...);\n\n    \nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \n// Set up auth token route- this grants and refresh tokens\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n\n\n    \n// Set up auth code route- this grants temporary access codes that can be exchanged for token\n\n    \nrouter\n.\nroute\n(\n/auth/code\n).\nlink\n(()\n \n=\n \nAuthCodeController\n(\nauthServer\n));\n\n\n    \n// Set up protected route\n\n    \nrouter\n\n      \n.\nroute\n(\n/protected\n)\n\n      \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n      \n.\nlink\n(()\n \n=\n \nProtectedController\n());\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nFor more details on authorization controllers like \nAuthController\n, see \nAuthorization Controllers\n. For more details on securing routes, see \nAuthorizers\n.\n\n\nUsing ManagedAuthDelegate\n\n\nManagedAuthDelegate\nT\n is a concrete implementation of \nAuthServerDelegate\n, providing storage of authorization tokens and clients for an \nAuthServer\n. Storage is accomplished by Aqueduct's ORM. \nManagedAuthDelegate\nT\n, by default, is not part of the standard \naqueduct\n library. To use this class, an application must import \npackage:aqueduct/managed_auth.dart\n.\n\n\nThe type argument to \nManagedAuthDelegate\nT\n represents the application's concept of a 'user' or 'account' - OAuth 2.0 terminology would refer to this type as a \nresource owner\n. A resource owner must be a \nManagedObject\nT\n subclass that is specific to your application. Its table definition \nmust extend\n \nResourceOwnerTableDefinition\n and the instance type must implement \nManagedAuthResourceOwner\nT\n, where \nT\n is the table definition. A basic definition may look like this:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n\n    \nimplements\n \n_User\n,\n \nManagedAuthResourceOwner\n_User\n \n{\n\n\n}\n\n\n\nclass\n \n_User\n \nextends\n \nResourceOwnerTableDefinition\n \n{\n\n  \n@\nColumn\n(\nunique:\n \ntrue\n)\n\n  \nString\n \nemail\n;\n\n\n}\n\n\n\n\n\n\nBy extending \nResourceOwnerTableDefinition\n in the table definition, the database table has the following four columns:\n\n\n\n\nan integer primary key named \nid\n\n\na unique string \nusername\n\n\na password hash\n\n\na salt used to generate the password hash\n\n\n\n\nA \nResourceOwnerTableDefinition\n also has a \nManagedSet\n of \ntokens\n for each token that has been granted on its behalf.\n\n\nThe interface \nManagedAuthResourceOwner\nT\n is a requirement that ensures the type argument is both a \nManagedObject\nT\n and \nResourceOwnerTableDefinition\n, and serves no other purpose than to restrict \nManagedAuthDelegate\nT\n's type parameter.\n\n\nThis structure allows an application to declare its own 'user' type while still enforcing the needs of Aqueduct's OAuth 2.0 implementation.\n\n\nThe \nmanaged_auth\n library also declares two \nManagedObject\nT\n subclasses. \nManagedAuthToken\n represents instances of authorization tokens and codes, and \nManagedAuthClient\n represents instances of OAuth 2.0 clients. This means that an Aqueduct application that uses \nManagedAuthDelegate\nT\n has a minimum of three database tables: users, tokens and clients.\n\n\nManagedAuthDelegate\nT\n will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating \nManagedAuthDelegate\nT\n:\n\n\nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\n(\ncontext\n,\n \ntokenLimit:\n \n20\n);\n\n\n\n\n\n\nConfiguring the Database\n\n\nManagedAuthDelegate\nT\n requires database tables for its users, tokens and clients. Use the \ndatabase command-line tool\n on your project to generate migration scripts and execute them against a database. This tool will see the declarations for your user type, \nManagedAuthToken\n and \nManagedAuthClient\n and create the appropriate tables.", 
            "title": "Setting up Authorization"
        }, 
        {
            "location": "/auth/server/#creating-authservers-to-authenticate-and-authorize", 
            "text": "An  AuthServer  is a service that handles creating, verifying and refreshing authorization tokens. You create an  AuthServer  in your application channel and inject into types that deal with authorization. This types include:   Authorizer : middleware controller that protects endpoint controllers from unauthorized access  AuthController : endpoint controller that grants access tokens  AuthCodeController : endpoint controller that grants authorization codes to be exchanged for access tokens   An  AuthServer  must persist the data it uses and creates - like client identifiers and access tokens. Storage is often performed by a database, but it can be in memory, a cache or some other medium. Because of the many different storage mediums, an  AuthServer  doesn't perform any storage itself - it relies on an instance of  AuthServerDelegate  specific to your application. This allows storage to be independent of verification logic.", 
            "title": "Creating AuthServers to Authenticate and Authorize"
        }, 
        {
            "location": "/auth/server/#creating-instances-of-authserver-and-authserverdelegate", 
            "text": "AuthServerDelegate  is an interface that an  AuthServer  uses to handle storage of client identifiers, tokens and other authorization artifacts. An  AuthServer  must be created with a concrete implementation of  AuthServerDelegate . Aqueduct contains a concrete implementation of  AuthServerDelegate  that uses the ORM. It is highly recommended to use this implementation instead of implementing your own storage because it has been thoroughly tested and handles cleaning up expired data correctly.  This concrete implementation is named  ManagedAuthDelegate T . It exists in a sub-package of Aqueduct and must be explicitly imported. Here's an example of creating an  AuthServer  and  ManagedAuthDelegate T :  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   MyApplicationChannel   extends   ApplicationChannel   {   \n   AuthServer   authServer ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   context   =   ManagedContext (...); \n     final   delegate   =   ManagedAuthDelegate User ( context ); \n     authServer   =   AuthServer ( delegate ); \n   } \n\n   ...  }   (Notice that  ManagedAuthDelegate  has a type argument - this will be covered in the next section.)  While  AuthServer  has methods for handling authorization tasks, it is rarely used directly. Instead,  AuthCodeController  and  AuthController  are hooked up to routes to grant authorization tokens through your application's HTTP API. Instances of  Authorizer  secure routes in channels. All of these types invoke the appropriate methods on the  AuthServer . Here's an example  ApplicationChannel  subclass that sets up and uses authorization:  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   MyApplicationChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     context   =   ManagedContext (...); \n     final   delegate   =   ManagedAuthDelegate User ( context ); \n     authServer   =   AuthServer ( delegate ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     // Set up auth token route- this grants and refresh tokens \n     router . route ( /auth/token ). link (()   =   AuthController ( authServer )); \n\n     // Set up auth code route- this grants temporary access codes that can be exchanged for token \n     router . route ( /auth/code ). link (()   =   AuthCodeController ( authServer )); \n\n     // Set up protected route \n     router \n       . route ( /protected ) \n       . link (()   =   Authorizer . bearer ( authServer )) \n       . link (()   =   ProtectedController ()); \n\n     return   router ; \n   }  }   For more details on authorization controllers like  AuthController , see  Authorization Controllers . For more details on securing routes, see  Authorizers .", 
            "title": "Creating Instances of AuthServer and AuthServerDelegate"
        }, 
        {
            "location": "/auth/server/#using-managedauthdelegate", 
            "text": "ManagedAuthDelegate T  is a concrete implementation of  AuthServerDelegate , providing storage of authorization tokens and clients for an  AuthServer . Storage is accomplished by Aqueduct's ORM.  ManagedAuthDelegate T , by default, is not part of the standard  aqueduct  library. To use this class, an application must import  package:aqueduct/managed_auth.dart .  The type argument to  ManagedAuthDelegate T  represents the application's concept of a 'user' or 'account' - OAuth 2.0 terminology would refer to this type as a  resource owner . A resource owner must be a  ManagedObject T  subclass that is specific to your application. Its table definition  must extend   ResourceOwnerTableDefinition  and the instance type must implement  ManagedAuthResourceOwner T , where  T  is the table definition. A basic definition may look like this:  class   User   extends   ManagedObject _User \n     implements   _User ,   ManagedAuthResourceOwner _User   {  }  class   _User   extends   ResourceOwnerTableDefinition   { \n   @ Column ( unique:   true ) \n   String   email ;  }   By extending  ResourceOwnerTableDefinition  in the table definition, the database table has the following four columns:   an integer primary key named  id  a unique string  username  a password hash  a salt used to generate the password hash   A  ResourceOwnerTableDefinition  also has a  ManagedSet  of  tokens  for each token that has been granted on its behalf.  The interface  ManagedAuthResourceOwner T  is a requirement that ensures the type argument is both a  ManagedObject T  and  ResourceOwnerTableDefinition , and serves no other purpose than to restrict  ManagedAuthDelegate T 's type parameter.  This structure allows an application to declare its own 'user' type while still enforcing the needs of Aqueduct's OAuth 2.0 implementation.  The  managed_auth  library also declares two  ManagedObject T  subclasses.  ManagedAuthToken  represents instances of authorization tokens and codes, and  ManagedAuthClient  represents instances of OAuth 2.0 clients. This means that an Aqueduct application that uses  ManagedAuthDelegate T  has a minimum of three database tables: users, tokens and clients.  ManagedAuthDelegate T  will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating  ManagedAuthDelegate T :  final   delegate   =   ManagedAuthDelegate ( context ,   tokenLimit:   20 );", 
            "title": "Using ManagedAuthDelegate"
        }, 
        {
            "location": "/auth/server/#configuring-the-database", 
            "text": "ManagedAuthDelegate T  requires database tables for its users, tokens and clients. Use the  database command-line tool  on your project to generate migration scripts and execute them against a database. This tool will see the declarations for your user type,  ManagedAuthToken  and  ManagedAuthClient  and create the appropriate tables.", 
            "title": "Configuring the Database"
        }, 
        {
            "location": "/auth/authorizer/", 
            "text": "Securing Routes with Authorizer\n\n\nInstances of \nAuthorizer\n are added to an application channel to verify HTTP request's authorization information before passing the request onwards. They protect channel access and typically come right after \nroute\n. Here's an example:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/protected\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n    \n.\nlink\n(()\n \n=\n \nProtectedController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/other\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbasic\n(\nauthServer\n))\n\n    \n.\nlink\n(()\n \n=\n \nOtherProtectedController\n());\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nAn \nAuthorizer\n parses the Authorization header of an HTTP request. The named constructors of \nAuthorizer\n indicate the required format of Authorization header. The \nAuthorization.bearer()\n constructor expects an OAuth 2.0 bearer token in the header, which has the following format:\n\n\nAuthorization\n:\n \nBearer\n \n768\niuzjkx82jkasjkd9z9\n\n\n\n\n\n\nAuthorizer.basic\n expects HTTP Basic Authentication, where the username and password are joined with the colon character (\n:\n) and Base 64-encoded:\n\n\n// \ndXNlcjpwYXNzd29yZA==\n is \nuser:password\n\nAuthorization: Basic dXNlcjpwYXNzd29yZA==\n\n\n\n\n\nIf the header can't be parsed, doesn't exist or is in the wrong format, an \nAuthorizer\n responds to the request with a 401 status code and prevents the next controller from receiving the request.\n\n\nOnce parsed, an \nAuthorizer\n sends the information - either the bearer token, or the username and password - to its \nAuthServer\n for verification. If the \nAuthServer\n rejects the authorization info, the \nAuthorizer\n responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller.\n\n\nFor \nAuthorizer.bearer\n, the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user.\n\n\nFor \nAuthorizer.basic\n authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as \nclient authenticated\n routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user.\n\n\nAuthorizer and OAuth 2.0 Scope\n\n\nAn \nAuthorizer\n may restrict access to controllers based on the scope of the request's bearer token. By default, an \nAuthorizer.bearer\n allows any valid bearer token to pass through it. If desired, an \nAuthorizer\n is initialized with a list of required scopes. A request may only pass the \nAuthorizer\n if it has access to \nall\n scopes listed in the \nAuthorizer\n. For example, the following requires at least \nuser:posts\n and \nlocation\n scope:\n\n\nrouter\n\n  \n.\nroute\n(\n/checkin\n)\n\n  \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n,\n \nscopes:\n \n[\nuser:posts\n,\n \nlocation\n]))\n\n  \n.\nlink\n(()\n \n=\n \nCheckInController\n());\n\n\n\n\n\n\nNote that you don't have to use an \nAuthorizer\n to restrict access based on scope. A controller has access to scope information after the request has passed through an \nAuthorizer\n, so it can use the scope to make more granular authorization decisions.\n\n\nAuthorization Objects\n\n\nA bearer token represents a granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent in the authorization header of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of \nAuthorization\n after the token has been verified and is assigned to \nRequest.authorization\n.\n\n\nControllers protected by an \nAuthorizer\n can access this information to further determine their behavior. For example, a social networking application might have a \n/news_feed\n endpoint protected by an \nAuthorizer\n. When an authenticated user makes a request for \n/news_feed\n, the controller will return that user's news feed. It can determine this by using the \nAuthorization\n:\n\n\nclass\n \nNewsFeedController\n \nextends\n \nResourceController\n \n{\n\n  \nNewsFeedController\n(\nthis\n.\ncontext\n);\n\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetNewsFeed\n()\n \nasync\n \n{\n\n    \nvar\n \nforUserID\n \n=\n \nrequest\n.\nauthorization\n.\nownerID\n;\n\n\n    \nvar\n \nquery\n \n=\n \nQuery\nPost\n(\ncontext\n)\n\n      \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nauthor\n).\nidentifiedBy\n(\nforUserID\n);\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nfetch\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIn the above controller, it's impossible for a user to access another user's posts.\n\n\nAuthorization\n objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an \nAuthorization\n has access to a particular scope is accomplished by either looking at the list of its \nscopes\n or using \nauthorizedForScope\n:\n\n\nclass\n \nNewsFeedController\n \nextends\n \nResourceController\n \n{\n\n  \nNewsFeedController\n(\nthis\n.\ncontext\n);\n\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetNewsFeed\n()\n \nasync\n \n{\n\n    \nif\n \n(\n!\nrequest\n.\nauthorization\n.\nauthorizedForScope\n(\nuser:feed\n))\n \n{\n\n      \nreturn\n \nResponse\n.\nunauthorized\n();\n\n    \n}\n\n\n    \nvar\n \nforUserID\n \n=\n \nrequest\n.\nauthorization\n.\nownerID\n;\n\n\n    \nvar\n \nquery\n \n=\n \nQuery\nPost\n(\ncontext\n)\n\n      \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nauthor\n).\nidentifiedBy\n(\nforUserID\n);\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nfetch\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nUsing Authorizers Without AuthServer\n\n\nThroughout this guide, the argument to an instance of \nAuthorizer\n has been referred to as an \nAuthServer\n. This is true - but only because \nAuthServer\n implements \nAuthValidator\n. \nAuthValidator\n is an interface for verifying bearer tokens and username/password credentials.\n\n\nYou may use \nAuthorizer\n without using \nAuthServer\n. For example, an application that doesn't use OAuth 2.0 could provide its own \nAuthValidator\n interface to simply verify the username and password of every request:\n\n\nclass\n \nBasicValidator\n \nimplements\n \nAuthValidator\n \n{\n\n  \n@\noverride\n\n  \nFutureOr\nAuthorization\n \nvalidate\nT\n(\nAuthorizationParser\nT\n \nparser\n,\n \nT\n \nauthorizationData\n,\n \n{\nList\nAuthScope\n \nrequiredScope\n})\n \n{}\n\n    \nvar\n \nuser\n \n=\n \nawait\n \nuserForName\n(\nusernameAndPassword\n.\nusername\n);\n\n    \nif\n \n(\nuser\n.\npassword\n \n==\n \nhash\n(\nusernameAndPassword\n.\npassword\n,\n \nuser\n.\nsalt\n))\n \n{\n\n      \nreturn\n \nAuthorization\n(...);\n\n    \n}\n\n\n    \n// Will end up creating a 401 Not Authorized Response\n\n    \nreturn\n \nnull\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nvalidate\n method must return an \nAuthorization\n if the credentials are valid, or null if they are not. The \nparser\n lets the validator know the format of the Authorization header (e.g., 'Basic' or 'Bearer') and \nauthorizationData\n is the meaningful information in that header. There are two concrete types of \nAuthorizationParser\nT\n: \nAuthorizationBasicParser\n and \nAuthorizationBearerParser\n. The authorization data for a basic parser is an instance of \nAuthBasicCredentials\n that contain the username and password, while the bearer parser's authorization data is the bearer token string.", 
            "title": "Protecting Routes"
        }, 
        {
            "location": "/auth/authorizer/#securing-routes-with-authorizer", 
            "text": "Instances of  Authorizer  are added to an application channel to verify HTTP request's authorization information before passing the request onwards. They protect channel access and typically come right after  route . Here's an example:  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /protected ) \n     . link (()   =   Authorizer . bearer ( authServer )) \n     . link (()   =   ProtectedController ()); \n\n   router \n     . route ( /other ) \n     . link (()   =   Authorizer . basic ( authServer )) \n     . link (()   =   OtherProtectedController ()); \n\n   return   router ;  }   An  Authorizer  parses the Authorization header of an HTTP request. The named constructors of  Authorizer  indicate the required format of Authorization header. The  Authorization.bearer()  constructor expects an OAuth 2.0 bearer token in the header, which has the following format:  Authorization :   Bearer   768 iuzjkx82jkasjkd9z9   Authorizer.basic  expects HTTP Basic Authentication, where the username and password are joined with the colon character ( : ) and Base 64-encoded:  //  dXNlcjpwYXNzd29yZA==  is  user:password \nAuthorization: Basic dXNlcjpwYXNzd29yZA==  If the header can't be parsed, doesn't exist or is in the wrong format, an  Authorizer  responds to the request with a 401 status code and prevents the next controller from receiving the request.  Once parsed, an  Authorizer  sends the information - either the bearer token, or the username and password - to its  AuthServer  for verification. If the  AuthServer  rejects the authorization info, the  Authorizer  responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller.  For  Authorizer.bearer , the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user.  For  Authorizer.basic  authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as  client authenticated  routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user.", 
            "title": "Securing Routes with Authorizer"
        }, 
        {
            "location": "/auth/authorizer/#authorizer-and-oauth-20-scope", 
            "text": "An  Authorizer  may restrict access to controllers based on the scope of the request's bearer token. By default, an  Authorizer.bearer  allows any valid bearer token to pass through it. If desired, an  Authorizer  is initialized with a list of required scopes. A request may only pass the  Authorizer  if it has access to  all  scopes listed in the  Authorizer . For example, the following requires at least  user:posts  and  location  scope:  router \n   . route ( /checkin ) \n   . link (()   =   Authorizer . bearer ( authServer ,   scopes:   [ user:posts ,   location ])) \n   . link (()   =   CheckInController ());   Note that you don't have to use an  Authorizer  to restrict access based on scope. A controller has access to scope information after the request has passed through an  Authorizer , so it can use the scope to make more granular authorization decisions.", 
            "title": "Authorizer and OAuth 2.0 Scope"
        }, 
        {
            "location": "/auth/authorizer/#authorization-objects", 
            "text": "A bearer token represents a granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent in the authorization header of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of  Authorization  after the token has been verified and is assigned to  Request.authorization .  Controllers protected by an  Authorizer  can access this information to further determine their behavior. For example, a social networking application might have a  /news_feed  endpoint protected by an  Authorizer . When an authenticated user makes a request for  /news_feed , the controller will return that user's news feed. It can determine this by using the  Authorization :  class   NewsFeedController   extends   ResourceController   { \n   NewsFeedController ( this . context ); \n\n   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getNewsFeed ()   async   { \n     var   forUserID   =   request . authorization . ownerID ; \n\n     var   query   =   Query Post ( context ) \n       .. where (( p )   =   p . author ). identifiedBy ( forUserID ); \n\n     return   Response . ok ( await   query . fetch ()); \n   }  }   In the above controller, it's impossible for a user to access another user's posts.  Authorization  objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an  Authorization  has access to a particular scope is accomplished by either looking at the list of its  scopes  or using  authorizedForScope :  class   NewsFeedController   extends   ResourceController   { \n   NewsFeedController ( this . context ); \n\n   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getNewsFeed ()   async   { \n     if   ( ! request . authorization . authorizedForScope ( user:feed ))   { \n       return   Response . unauthorized (); \n     } \n\n     var   forUserID   =   request . authorization . ownerID ; \n\n     var   query   =   Query Post ( context ) \n       .. where (( p )   =   p . author ). identifiedBy ( forUserID ); \n\n     return   Response . ok ( await   query . fetch ()); \n   }  }", 
            "title": "Authorization Objects"
        }, 
        {
            "location": "/auth/authorizer/#using-authorizers-without-authserver", 
            "text": "Throughout this guide, the argument to an instance of  Authorizer  has been referred to as an  AuthServer . This is true - but only because  AuthServer  implements  AuthValidator .  AuthValidator  is an interface for verifying bearer tokens and username/password credentials.  You may use  Authorizer  without using  AuthServer . For example, an application that doesn't use OAuth 2.0 could provide its own  AuthValidator  interface to simply verify the username and password of every request:  class   BasicValidator   implements   AuthValidator   { \n   @ override \n   FutureOr Authorization   validate T ( AuthorizationParser T   parser ,   T   authorizationData ,   { List AuthScope   requiredScope })   {} \n     var   user   =   await   userForName ( usernameAndPassword . username ); \n     if   ( user . password   ==   hash ( usernameAndPassword . password ,   user . salt ))   { \n       return   Authorization (...); \n     } \n\n     // Will end up creating a 401 Not Authorized Response \n     return   null ; \n   }  }   The  validate  method must return an  Authorization  if the credentials are valid, or null if they are not. The  parser  lets the validator know the format of the Authorization header (e.g., 'Basic' or 'Bearer') and  authorizationData  is the meaningful information in that header. There are two concrete types of  AuthorizationParser T :  AuthorizationBasicParser  and  AuthorizationBearerParser . The authorization data for a basic parser is an instance of  AuthBasicCredentials  that contain the username and password, while the bearer parser's authorization data is the bearer token string.", 
            "title": "Using Authorizers Without AuthServer"
        }, 
        {
            "location": "/auth/controllers/", 
            "text": "Issue Access Tokens with AuthController\n\n\nAn application using Aqueduct's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an \nAuthServer\n, the OAuth 2.0 specification is where happiness goes to die. Therefore, there exist two \nController\ns in Aqueduct that handle granting and refreshing authorization tokens - \nAuthController\n and \nAuthCodeController\n.\n\n\nIssue, Refresh and Exchange Tokens with AuthController\n\n\nAn \nAuthController\n grants access tokens and refreshes them. It also exchanges authorization codes obtained from \nAuthCodeController\n for access tokens.\n\n\nUsing an \nAuthController\n in an application is straightforward - hook it up to a \nRouter\n and pass it an \nAuthServer\n.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/token\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nTo grant an access token, a client application sends a HTTP \nPOST\n to the controller. The request must have:\n\n\n\n\nan Authorization header with the Client ID and Client Secret (if one exists) and,\n\n\na \nx-www-form-urlencoded\n body with the username and password of the authenticating user.\n\n\n\n\nThe body must also contain the key-value pair \ngrant_type=password\n. For example, the following Dart code will initiate successful authentication:\n\n\nvar\n \nclientID\n \n=\n \ncom.app.demo\n;\n\n\nvar\n \nclientSecret\n \n=\n \nmySecret\n;\n\n\nvar\n \nbody\n \n=\n \nusername=bob@stablekernel.com\npassword=foobar\ngrant_type=password\n;\n\n\nvar\n \nclientCredentials\n \n=\n \nBase64Encoder\n().\nconvert\n(\n$\nclientID\n:\n$\nclientSecret\n.\ncodeUnits\n);\n\n\n\nvar\n \nresponse\n \n=\n \nawait\n \nhttp\n.\npost\n(\n\n  \nhttps://stablekernel.com/auth/token\n,\n\n  \nheaders:\n \n{\n\n    \nContent-Type\n:\n \napplication/x-www-form-urlencoded\n,\n\n    \nAuthorization\n:\n \nBasic \n$\nclientCredentials\n\n  \n},\n\n  \nbody:\n \nbody\n);\n\n\n\n\n\n\nIf the OAuth 2.0 client ID is public - that is, it does not have a client secret - the secret is omitted from the authorization header:\n\n\n// Notice that the separating colon (:) is still present.\n\n\nvar\n \nclientCredentials\n \n=\n \nBase64Encoder\n().\nconvert\n(\n$\nclientID\n:\n.\ncodeUnits\n);\n\n\n\n\n\n\nThe response to a password token request is a JSON body that follows the OAuth 2.0 specification:\n\n\n{\n  \naccess_token\n: \n...\n\n  \nrefresh_token\n: \n...\n,\n  \nexpires_in\n: 3600,\n  \ntoken_type\n: \nbearer\n\n}\n\n\n\n\n\n\n\nThe \nexpires_in\n field is a computed property based on the delta of the issue date and expiration date. The unit is seconds. You should avoid manually editing the values for the columns \nissuedate\n and \nexpirationdate\n\n\n\n\nTokens are refreshed through the same endpoint, but with a payload that only contains the refresh token and \ngrant_type=refresh_token\n.\n\n\ngrant_type=refresh_token\nrefresh_token=kjasdiuz9u3namnsd\n\n\n\n\n\nSee \nAqueduct Auth CLI\n for more details on creating OAuth 2.0 client identifier and secrets.\n\n\nIf an Aqueduct application is using scope, an additional \nscope\n parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body.\n\n\nIt is important that an \nAuthorizer\n \nmust not\n protect instances of \nAuthController\n. The Authorization header is parsed and verified by \nAuthController\n.\n\n\nOnce granted, an access token can be used to pass \nAuthorizer.bearer()\ns in the application channel.\n\n\nIssue Authorization Codes with AuthCodeController\n\n\nAn \nAuthCodeController\n manages the OAuth 2.0 authorization code flow. The authorization code flow is used when an Aqueduct application allows third party applications access to authorized resources.\n\n\nLet's say you've built an Aqueduct application that allows people to store notes for themselves. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants users of their application to access the notes the user has stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers.\n\n\nYour friend adds a link to their application that takes the user to an HTML page hosted by your server. The user enters their credentials in this page, which sends a \nPOST\n request to your server. Your server responds by redirecting the user's browser back into your friend's application. An \nauthorization code\n is included in the query string of the redirect URL.\n\n\nYour friend's application parses the code from the URL and sends it to \ntheir\n server. Behind the scenes, their server exchanges this code with your server for an access token.\n\n\nAn \nAuthCodeController\n responds to both \nGET\n and \nPOST\n requests. When issued a \nGET\n, it serves up a HTML page with a login form. This login form's submit action sends a \nPOST\n to the same endpoint with the username and password of the user. Upon success, the response from the \nPOST\n is a 302 redirect with an authorization code.\n\n\nSetting up an \nAuthCodeController\n is nearly as simple as setting up an \nAuthController\n, but requires a function that renders the HTML login form. Here's an example:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/code\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthCodeController\n(\n\n      \nauthServer\n,\n \nrenderAuthorizationPageHTML:\n \nrenderLogin\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\nFuture\nString\n \nrenderLogin\n(\n\n    \nAuthCodeController\n \nrequestingController\n,\n\n    \nURI\n \nrequestURI\n,\n\n    \nMap\nString\n,\n \nString\n \nqueryParameters\n)\n \n{\n\n  \nvar\n \nhtml\n \n=\n \nHTMLRenderer\n.\ntemplateWithSubstitutions\n(\n\n    \nweb/login.html\n,\n \nrequestURI\n,\n \nqueryParameters\n);\n\n\n  \nreturn\n \nhtml\n;\n\n\n}\n\n\n\n\n\n\nIt is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information.\n\n\nWhen your friend's application links to your login page - \nGET /auth/code\n - they must include three query parameters: \nstate\n, \nclient_id\n, \nresponse_type\n. They may optionally include \nscope\n.\n\n\nhttps://stablekernel.com/auth/code?client_id=friend.app\nresponse_type=code\nstate=87uijn3rkja\n\n\n\n\n\nThe value of \nclient_id\n must be created specifically for your friend's application and stored in your database. (See more on generating client identifiers with \naqueduct auth\n in \nAqueduct Auth CLI\n.) The \nresponse_type\n must always be \ncode\n. The \nstate\n must be a value your friend's application creates - it is often some random value like a session cookie.\n\n\nWhen a user of your friend's application goes through this process, they are redirected back into your friend's application. Both the generated authorization code and the value for \nstate\n will be query parameters in the URL. That redirect URL will look like:\n\n\nhttps://friends.app/code_callback?code=abcd672kk\nstate=87uijn3rkja\n\n\n\n\n\nThe redirect URL is pre-determined when generating the client identifier with \naqueduct auth\n.\n\n\nYour friend's application verifies that \nstate\n matches the \nstate\n they sent in \nGET /auth/code\n. They then send the \ncode\n to their server. The server then exchanges this code with your server by issuing a \nPOST\n to an \nAuthController\n - \nNOT\n the \nAuthCodeController\n - with the following \napplication/x-www-form-urlencoded\n body:\n\n\ngrant_type=authorization_code\ncode=abcd672kk\n\n\n\n\n\nAn access token will be returned to the server which your friend then stores in their database. Whenever one of their users makes a request that requires accessing your application's data, they will execute requests with that access token.", 
            "title": "Issuing Access Tokens"
        }, 
        {
            "location": "/auth/controllers/#issue-access-tokens-with-authcontroller", 
            "text": "An application using Aqueduct's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an  AuthServer , the OAuth 2.0 specification is where happiness goes to die. Therefore, there exist two  Controller s in Aqueduct that handle granting and refreshing authorization tokens -  AuthController  and  AuthCodeController .", 
            "title": "Issue Access Tokens with AuthController"
        }, 
        {
            "location": "/auth/controllers/#issue-refresh-and-exchange-tokens-with-authcontroller", 
            "text": "An  AuthController  grants access tokens and refreshes them. It also exchanges authorization codes obtained from  AuthCodeController  for access tokens.  Using an  AuthController  in an application is straightforward - hook it up to a  Router  and pass it an  AuthServer .  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /auth/token ) \n     . link (()   =   AuthController ( authServer )); \n\n   return   router ;  }   To grant an access token, a client application sends a HTTP  POST  to the controller. The request must have:   an Authorization header with the Client ID and Client Secret (if one exists) and,  a  x-www-form-urlencoded  body with the username and password of the authenticating user.   The body must also contain the key-value pair  grant_type=password . For example, the following Dart code will initiate successful authentication:  var   clientID   =   com.app.demo ;  var   clientSecret   =   mySecret ;  var   body   =   username=bob@stablekernel.com password=foobar grant_type=password ;  var   clientCredentials   =   Base64Encoder (). convert ( $ clientID : $ clientSecret . codeUnits );  var   response   =   await   http . post ( \n   https://stablekernel.com/auth/token , \n   headers:   { \n     Content-Type :   application/x-www-form-urlencoded , \n     Authorization :   Basic  $ clientCredentials \n   }, \n   body:   body );   If the OAuth 2.0 client ID is public - that is, it does not have a client secret - the secret is omitted from the authorization header:  // Notice that the separating colon (:) is still present.  var   clientCredentials   =   Base64Encoder (). convert ( $ clientID : . codeUnits );   The response to a password token request is a JSON body that follows the OAuth 2.0 specification:  {\n   access_token :  ... \n   refresh_token :  ... ,\n   expires_in : 3600,\n   token_type :  bearer \n}   The  expires_in  field is a computed property based on the delta of the issue date and expiration date. The unit is seconds. You should avoid manually editing the values for the columns  issuedate  and  expirationdate   Tokens are refreshed through the same endpoint, but with a payload that only contains the refresh token and  grant_type=refresh_token .  grant_type=refresh_token refresh_token=kjasdiuz9u3namnsd  See  Aqueduct Auth CLI  for more details on creating OAuth 2.0 client identifier and secrets.  If an Aqueduct application is using scope, an additional  scope  parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body.  It is important that an  Authorizer   must not  protect instances of  AuthController . The Authorization header is parsed and verified by  AuthController .  Once granted, an access token can be used to pass  Authorizer.bearer() s in the application channel.", 
            "title": "Issue, Refresh and Exchange Tokens with AuthController"
        }, 
        {
            "location": "/auth/controllers/#issue-authorization-codes-with-authcodecontroller", 
            "text": "An  AuthCodeController  manages the OAuth 2.0 authorization code flow. The authorization code flow is used when an Aqueduct application allows third party applications access to authorized resources.  Let's say you've built an Aqueduct application that allows people to store notes for themselves. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants users of their application to access the notes the user has stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers.  Your friend adds a link to their application that takes the user to an HTML page hosted by your server. The user enters their credentials in this page, which sends a  POST  request to your server. Your server responds by redirecting the user's browser back into your friend's application. An  authorization code  is included in the query string of the redirect URL.  Your friend's application parses the code from the URL and sends it to  their  server. Behind the scenes, their server exchanges this code with your server for an access token.  An  AuthCodeController  responds to both  GET  and  POST  requests. When issued a  GET , it serves up a HTML page with a login form. This login form's submit action sends a  POST  to the same endpoint with the username and password of the user. Upon success, the response from the  POST  is a 302 redirect with an authorization code.  Setting up an  AuthCodeController  is nearly as simple as setting up an  AuthController , but requires a function that renders the HTML login form. Here's an example:  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /auth/code ) \n     . link (()   =   AuthCodeController ( \n       authServer ,   renderAuthorizationPageHTML:   renderLogin )); \n\n   return   router ;  }  Future String   renderLogin ( \n     AuthCodeController   requestingController , \n     URI   requestURI , \n     Map String ,   String   queryParameters )   { \n   var   html   =   HTMLRenderer . templateWithSubstitutions ( \n     web/login.html ,   requestURI ,   queryParameters ); \n\n   return   html ;  }   It is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information.  When your friend's application links to your login page -  GET /auth/code  - they must include three query parameters:  state ,  client_id ,  response_type . They may optionally include  scope .  https://stablekernel.com/auth/code?client_id=friend.app response_type=code state=87uijn3rkja  The value of  client_id  must be created specifically for your friend's application and stored in your database. (See more on generating client identifiers with  aqueduct auth  in  Aqueduct Auth CLI .) The  response_type  must always be  code . The  state  must be a value your friend's application creates - it is often some random value like a session cookie.  When a user of your friend's application goes through this process, they are redirected back into your friend's application. Both the generated authorization code and the value for  state  will be query parameters in the URL. That redirect URL will look like:  https://friends.app/code_callback?code=abcd672kk state=87uijn3rkja  The redirect URL is pre-determined when generating the client identifier with  aqueduct auth .  Your friend's application verifies that  state  matches the  state  they sent in  GET /auth/code . They then send the  code  to their server. The server then exchanges this code with your server by issuing a  POST  to an  AuthController  -  NOT  the  AuthCodeController  - with the following  application/x-www-form-urlencoded  body:  grant_type=authorization_code code=abcd672kk  An access token will be returned to the server which your friend then stores in their database. Whenever one of their users makes a request that requires accessing your application's data, they will execute requests with that access token.", 
            "title": "Issue Authorization Codes with AuthCodeController"
        }, 
        {
            "location": "/auth/cli/", 
            "text": "Manage OAuth 2.0 Clients\n\n\nThe \naqueduct auth\n command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use \nManagedAuthDelegate\nT\n and\nyour database must be contain the tables to support it (see \nthis guide\n for more details).\n\n\nExchanging a username and password for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of \nManagedAuthClient\n from \naqueduct/managed_auth\n. Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens.\n\n\nAn OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example, \ncom.food_app.mobile\n may be a client identifier for the mobile applications for some 'Food App'.\n\n\nTo create a simple OAuth 2.0 client, the following command line utility can be run:\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nThe \nconnect\n option identifies the database for the application, which this tool will connect to and insert a record into the \nManagedAuthClient\n database table. The identifier is provided through the \nid\n option.\n\n\nAn OAuth 2.0 client created in this way is a \npublic\n client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret, should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially be disassembled to reveal a client secret, but isn't necessarily required.\n\n\nWhen making requests to client authenticated endpoints (those protected with \nAuthorizer.basic\n), the client secret is omitted from the authorization header. The string to base64 encode is \nclientID:\n, where the colon (\n:\n) is required. For example, to generate an authorization header in Dart for a public client:\n\n\nvar\n \nclientID\n \n=\n \ncom.foobar.xyz\n;\n\n\nvar\n \nclientCredentials\n \n=\n \nBase64Encoder\n()\n.\nconvert\n(\n$clientID:\n.\ncodeUnits\n);\n\n\nvar\n \nheader\n \n=\n \nBasic $clientCredentials\n;\n\n\n\n\n\n\nConfidential Clients\n\n\nAn OAuth 2.0 client is \nconfidential\n if it has a client secret. Client secrets can be provided with the \nauth\n tool:\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nClient secrets are hashed (many times) with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.)\n\n\nRedirect URIs\n\n\nTo allow the authorization code flow (provided by \nAuthCodeController\n), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI.\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --redirect-uri https://someapp.com/callback \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nScopes\n\n\nIf an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with.\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --allowed-scopes \nscopeA scopeB scopeC.readonly\n \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nScopes are space-delimited and must be enclosed in quotes so that your shell will treat the entire string as one value.\n\n\nScope may be set after a client has already been created with \naqueduct auth set-scope\n:\n\n\naqueduct auth set-scope \\\n  --id com.food_app.mobile \\\n  --scopes \nscopeA scopeC\n \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nOther Info\n\n\nLike all \naqueduct\n commands that send commands to a database, the \nconnect\n option can be replaced by a \ndatabase.yaml\n file in the project directory with the following format:\n\n\nusername: \nuser\n\npassword: \npassword\n\nhost: \nhost\n\nport: 5432\ndatabaseName: \nmy_app", 
            "title": "Managing OAuth 2.0 Clients"
        }, 
        {
            "location": "/auth/cli/#manage-oauth-20-clients", 
            "text": "The  aqueduct auth  command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use  ManagedAuthDelegate T  and\nyour database must be contain the tables to support it (see  this guide  for more details).  Exchanging a username and password for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of  ManagedAuthClient  from  aqueduct/managed_auth . Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens.  An OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example,  com.food_app.mobile  may be a client identifier for the mobile applications for some 'Food App'.  To create a simple OAuth 2.0 client, the following command line utility can be run:  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --connect postgres://user:password@dbhost:5432/food_app  The  connect  option identifies the database for the application, which this tool will connect to and insert a record into the  ManagedAuthClient  database table. The identifier is provided through the  id  option.  An OAuth 2.0 client created in this way is a  public  client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret, should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially be disassembled to reveal a client secret, but isn't necessarily required.  When making requests to client authenticated endpoints (those protected with  Authorizer.basic ), the client secret is omitted from the authorization header. The string to base64 encode is  clientID: , where the colon ( : ) is required. For example, to generate an authorization header in Dart for a public client:  var   clientID   =   com.foobar.xyz ;  var   clientCredentials   =   Base64Encoder () . convert ( $clientID: . codeUnits );  var   header   =   Basic $clientCredentials ;", 
            "title": "Manage OAuth 2.0 Clients"
        }, 
        {
            "location": "/auth/cli/#confidential-clients", 
            "text": "An OAuth 2.0 client is  confidential  if it has a client secret. Client secrets can be provided with the  auth  tool:  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --connect postgres://user:password@dbhost:5432/food_app  Client secrets are hashed (many times) with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.)", 
            "title": "Confidential Clients"
        }, 
        {
            "location": "/auth/cli/#redirect-uris", 
            "text": "To allow the authorization code flow (provided by  AuthCodeController ), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI.  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --redirect-uri https://someapp.com/callback \\\n  --connect postgres://user:password@dbhost:5432/food_app", 
            "title": "Redirect URIs"
        }, 
        {
            "location": "/auth/cli/#scopes", 
            "text": "If an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with.  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --allowed-scopes  scopeA scopeB scopeC.readonly  \\\n  --connect postgres://user:password@dbhost:5432/food_app  Scopes are space-delimited and must be enclosed in quotes so that your shell will treat the entire string as one value.  Scope may be set after a client has already been created with  aqueduct auth set-scope :  aqueduct auth set-scope \\\n  --id com.food_app.mobile \\\n  --scopes  scopeA scopeC  \\\n  --connect postgres://user:password@dbhost:5432/food_app", 
            "title": "Scopes"
        }, 
        {
            "location": "/auth/cli/#other-info", 
            "text": "Like all  aqueduct  commands that send commands to a database, the  connect  option can be replaced by a  database.yaml  file in the project directory with the following format:  username:  user \npassword:  password \nhost:  host \nport: 5432\ndatabaseName:  my_app", 
            "title": "Other Info"
        }, 
        {
            "location": "/auth/auth_scopes/", 
            "text": "Granular Authorization with OAuth 2.0 Scopes\n\n\nIn many applications, operations have varying levels of access control. For example, a user may need special permission to create 'notes', but every user can read notes. In OAuth 2.0, permissions for operations are determined by an access token's \nscope\n. Operations can be defined to require certain scopes, and a request may only invoke those operations if its access token was granted with those scopes.\n\n\nA scope is a string identifier, like \nnotes\n or \nnotes.readonly\n. When a client application authenticates on behalf of a user, it requests one or more of these scope identifiers to be granted to the access token. Valid scopes will be stored with the access token, so that the scope can be referenced by subsequent uses of the access token.\n\n\nScope Usage in Aqueduct\n\n\nAn access token's scope is determined when a user authenticates. During authentication, a client application indicates the requested scope, and the Aqueduct application determines if that scope is permissible for the client application and the user. This scope information is attached to the access token.\n\n\nWhen a request is made with an access token, an \nAuthorizer\n retrieves the token's scope. After the request is validated, the \nAuthorizer\n stores scope information in \nRequest.authorization\n. Linked controllers can use this information to determine how the request is handled. In general, a controller will reject a request and send a 403 Forbidden response when an access token has insufficient scope for an operation.\n\n\nTherefore, adding scopes to an application consists of three steps:\n\n\n\n\nAdding scope restrictions to operations.\n\n\nAdding permissible scopes for OAuth2 client identifiers (and optionally users).\n\n\nUpdating client applications to request scope when authenticating.\n\n\n\n\nAdding Scope Restrictions to Operations\n\n\nWhen an \nAuthorizer\n handles a request, it creates an \nAuthorization\n object that is attached to the request. An \nAuthorization\n object has a \nscopes\n property that contains every scope granted for the access token. This object also has a convenience method for checking if a particular scope is valid for that list of scopes:\n\n\nclass\n \nNoteController\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\n!\nrequest\n.\nauthorization\n.\nisAuthorizedForScope\n(\nnotes\n))\n \n{\n\n      \nreturn\n \nResponse\n.\nforbidden\n();\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \ngetAllNotes\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\n\nUse an Authorizer\n\n\nThe \nauthorization\n property of \nRequest\n is only valid after the request is handled by an \nAuthorizer\n. It is \nnull\n otherwise.\n\n\n\n\nAn \nAuthorizer\n may also validate the scope of a request before letting it pass to its linked controller.\n\n\nrouter\n\n  \n.\nroute\n(\n/notes\n)\n\n  \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n,\n \nscopes:\n \n[\nnotes\n]))\n\n  \n.\nlink\n(()\n \n=\n \nNoteController\n());\n\n\n\n\n\n\nIn the above, the \nNoteController\n will only be reached if the request's bearer token has 'notes' scope. If there is insufficient scope, a 403 Forbidden response is sent. This applies to all operations of the \nNoteController\n.\n\n\nIt often makes sense to have separate scope for different operations on the same resource. The \nScope\n annotation may be added to \nResourceController\n operation methods for this purpose.\n\n\nclass\n \nNoteController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nScope\n([\nnotes.readonly\n])\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetNotes\n()\n \nasync\n \n=\n \n...;\n\n\n  \n@\nScope\n([\nnotes\n])\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \ncreateNote\n(\n@\nBind\n.\nbody\n()\n \nNote\n \nnote\n)\n \nasync\n \n=\n \n...;\n\n\n}\n\n\n\n\n\n\nIf a request does not have sufficient scope for the intended operation method, a 403 Forbidden response is sent. When using \nScope\n annotations, you must link an \nAuthorizer\n prior to the \nResourceController\n, but it is not necessary to specify \nAuthorizer\n scopes.  \n\n\nIf a \nScope\n annotation or \nAuthorizer\n contains multiple scope entries, an access token must have scope for each of those entries. For example, the annotation \n@Scope(['notes', 'user'])\n requires an access token to have both 'notes' and 'user' scope.\n\n\nDefining Permissible Scope\n\n\nWhen a client application authenticates on behalf of a user, it includes a list of request scopes for the access token. An Aqueduct application will grant the requested scopes to the  token if the scopes are permissible for both the authenticating client identifier and the authenticating user.\n\n\nTo add permissible scopes to an authenticating client, you use the \naqueduct auth\n command-line tool. When creating a new client identifier, include the \n--allowed-scopes\n options:\n\n\naqueduct auth add-client \n\\\n\n  --id com.app.mobile \n\\\n\n  --secret myspecialsecret \n\\\n\n  --allowed-scopes \nnotes users\n \n\\\n\n  --connect postgres://user:password@dbhost:5432/db_name\n\n\n\n\n\nWhen modifying an existing client identifier, use the command \naqueduct auth set-scope\n:\n\n\naqueduct auth set-scope \n\\\n\n  --id com.app.mobile \n\\\n\n  --scopes \nnotes users\n \n\\\n\n  --connect postgres://user:password@dbhost:5432/db_name\n\n\n\n\n\nEach scope is a space-delimited string; the above examples allow clients authenticating with the \ncom.app.mobile\n client ID to grant access tokens with 'notes' and 'users' scope. If a client application requests scopes that are not available for that client application, the granted access token will not contain that scope. If none of the request scopes are available for the client identifier, no access token is granted. When adding scope restrictions to your application, you must ensure that all of the client applications that have access to those operations are able to grant that scope.\n\n\nScopes may also be limited by some attribute of your application's concept of a 'user'. This user-level filtering is done by overriding \ngetAllowedScopes\n in \nAuthServerDelegate\n. By default, this method returns \nAuthScope.Any\n - which means there are no restrictions. If the client application allows the scope, then any user that logs in with that application can request that scope.\n\n\nThis method may return a list of \nAuthScope\ns that are valid for the authenticating user. The following example shows a \nManagedAuthDelegate\nT\n subclass that allows any scope for \n@stablekernel.com\n usernames, no scopes for \n@hotmail.com\n addresses and some limited scope for everyone else:\n\n\nclass\n \nDomainBasedAuthDelegate\n \nextends\n \nManagedAuthDelegate\nUser\n \n{\n\n  \nDomainBasedAuthDelegate\n(\nManagedContext\n \ncontext\n,\n \n{\nint\n \ntokenLimit:\n \n40\n})\n \n:\n\n        \nsuper\n(\ncontext\n,\n \ntokenLimit:\n \ntokenLimit\n);\n\n\n  \n@\noverride\n\n  \nList\nAuthScope\n \ngetAllowedScopes\n(\ncovariant\n \nUser\n \nuser\n)\n \n{\n\n    \nif\n \n(\nuser\n.\nusername\n.\nendsWith\n(\n@stablekernel.com\n))\n \n{\n\n      \nreturn\n \nAuthScope\n.\nAny\n;\n\n    \n}\n \nelse\n \nif\n \n(\nuser\n.\nusername\n.\nendsWith\n(\n@hotmail.com\n))\n \n{\n\n      \nreturn\n \n[];\n\n    \n}\n \nelse\n \n{\n\n      \nreturn\n \n[\nAuthScope\n(\nuser\n)];\n\n    \n}\n\n  \n}\n      \n\n}\n\n\n\n\n\n\nThe \nuser\n passed to \ngetAllowedScopes\n is the user being authenticated. It will have previously been fetched by the \nAuthServer\n. The \nAuthServer\n fetches this object by invoking \nAuthDelegate.getResourceOwner\n. The default implementation of this method for \nManagedAuthDelegate\nT\n only fetches the \nid\n, \nusername\n, \nsalt\n and \nhashedPassword\n of the user.\n\n\nWhen using some other attribute of an application's user object to restrict allowed scopes, you must also override \ngetResourceOwner\n to fetch these attributes. For example, if your application's user has a \nrole\n attribute, you must fetch it and the other four required properties. Here's an example implementation:\n\n\nclass\n \nRoleBasedAuthDelegate\n \nextends\n \nManagedAuthDelegate\nUser\n \n{\n\n  \nRoleBasedAuthDelegate\n(\nManagedContext\n \ncontext\n,\n \n{\nint\n \ntokenLimit:\n \n40\n})\n \n:\n\n        \nsuper\n(\ncontext\n,\n \ntokenLimit:\n \ntokenLimit\n);\n\n\n  \n@\noverride\n\n  \nFuture\nUser\n \ngetResourceOwner\n(\n\n      \nAuthServer\n \nserver\n,\n \nString\n \nusername\n)\n \n{\n\n    \nfinal\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n      \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nusername\n).\nequalTo\n(\nusername\n)\n\n      \n..\nreturningProperties\n((\nt\n)\n \n=\n\n        \n[\nt\n.\nid\n,\n \nt\n.\nusername\n,\n \nt\n.\nhashedPassword\n,\n \nt\n.\nsalt\n,\n \nt\n.\nrole\n]);\n\n\n    \nreturn\n \nquery\n.\nfetchOne\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nList\nAuthScope\n \ngetAllowedScopes\n(\ncovariant\n \nUser\n \nuser\n)\n \n{\n\n    \nvar\n \nscopeStrings\n \n=\n \n[];\n\n    \nif\n \n(\nuser\n.\nrole\n \n==\n \nadmin\n)\n \n{\n\n      \nscopeStrings\n \n=\n \n[\nadmin\n,\n \nuser\n];\n\n    \n}\n \nelse\n \nif\n \n(\nuser\n.\nrole\n \n==\n \nuser\n)\n \n{\n\n      \nscopeStrings\n \n=\n \n[\nuser:email\n];\n\n    \n}\n\n\n    \nreturn\n \nscopeStrings\n.\nmap\n((\nstr\n)\n \n=\n \nAuthScope\n(\nstr\n)).\ntoList\n();\n\n  \n}\n\n\n}\n\n\n\n\n\n\nClient Application Integration\n\n\nClient applications that integrate with your scoped Aqueduct application must include a list of requested scopes when performing authentication. When authenticating through \nAuthController\n, a \nscope\n parameter must be added to the form data body. This parameter's value must be a space-delimited, URL-encoded list of requested scopes.\n\n\nusername=bob\npassword=foo\ngrant_type=password\nscope=notes%20users\n\n\n\n\n\nWhen authenticating via an \nAuthCodeController\n, this same query parameter is added to the initial \nGET\n request to render the login form.\n\n\nWhen authentication is complete, the list of granted scopes will be available in the JSON response body as a space-delimited string.\n\n\n{\n\n  \naccess_token\n:\n \n...\n,\n\n  \nrefresh_token\n:\n \n...\n,\n\n  \ntoken_type\n:\n \nbearer\n,\n\n  \nexpires_in\n:\n \n3600\n,\n\n  \nscopes\n:\n \nnotes users\n\n\n}\n\n\n\n\n\n\nScope Format and Hierarchy\n\n\nThere is no definitive guide on what a scope string should look like, other than being restricted to alphanumeric characters and some symbols. Aqueduct, however, provides a simple scoping structure - there are two special symbols, \n:\n and \n.\n.\n\n\nHierarchy is specified by the \n:\n character. For example, the following is a hierarchy of scopes related to a user and its sub-resources:\n\n\n\n\nuser\n (can read/write everything a user has)\n\n\nuser:email\n (can read/write a user's email)\n\n\nuser:documents\n (can read/write a user's documents)\n\n\nuser:documents:spreadsheets\n (can read/write a user's spreadsheet documents)\n\n\n\n\nNotice how these scopes form a hierarchy. Each segment makes the scope more restrictive. For example, if an access token has \nuser:email\n scope, it only allows access to a user's email. However, if the access token has \nuser\n scope, it allows access to everything a user has, including their email.\n\n\nAs another example, an access token with \nuser:documents\n scope can access all of a user's documents, but the scope \nuser:documents:spreadsheets\n is limited to only spreadsheet documents.\n\n\nScope is often used to indicate read vs. write access. At first glance, it might sound like a good idea to use the hierarchy operator, e.g. \nuser:email:read\n and \nuser:email:write\n. However, an access token with \nuser:email:write\n \ndoes not\n have permission to read email and this is likely unintended.\n\n\nThis is where \nscope modifiers\n come in. A scope modifier is added after a \n.\n at the end of a scope string. For example, \nuser:email.readonly\n grants readonly access to a user's email whereas \nuser:email\n grants read and write access.\n\n\nAn access token without a modifier has permission \nany\n modifier. Thus, \nuser\n and \nuser:email\n can both access \nuser:email.readonly\n protected resources and actions, but \nuser:email.readonly\n cannot access resources protected by \nuser:email\n.\n\n\nA scope modifier is only valid for the last segment of a scope string. That is, \nuser:documents.readonly:spreadsheets\n is not valid, but \nuser:documents:spreadsheets.readonly\n is.", 
            "title": "OAuth 2.0 Scoping"
        }, 
        {
            "location": "/auth/auth_scopes/#granular-authorization-with-oauth-20-scopes", 
            "text": "In many applications, operations have varying levels of access control. For example, a user may need special permission to create 'notes', but every user can read notes. In OAuth 2.0, permissions for operations are determined by an access token's  scope . Operations can be defined to require certain scopes, and a request may only invoke those operations if its access token was granted with those scopes.  A scope is a string identifier, like  notes  or  notes.readonly . When a client application authenticates on behalf of a user, it requests one or more of these scope identifiers to be granted to the access token. Valid scopes will be stored with the access token, so that the scope can be referenced by subsequent uses of the access token.", 
            "title": "Granular Authorization with OAuth 2.0 Scopes"
        }, 
        {
            "location": "/auth/auth_scopes/#scope-usage-in-aqueduct", 
            "text": "An access token's scope is determined when a user authenticates. During authentication, a client application indicates the requested scope, and the Aqueduct application determines if that scope is permissible for the client application and the user. This scope information is attached to the access token.  When a request is made with an access token, an  Authorizer  retrieves the token's scope. After the request is validated, the  Authorizer  stores scope information in  Request.authorization . Linked controllers can use this information to determine how the request is handled. In general, a controller will reject a request and send a 403 Forbidden response when an access token has insufficient scope for an operation.  Therefore, adding scopes to an application consists of three steps:   Adding scope restrictions to operations.  Adding permissible scopes for OAuth2 client identifiers (and optionally users).  Updating client applications to request scope when authenticating.", 
            "title": "Scope Usage in Aqueduct"
        }, 
        {
            "location": "/auth/auth_scopes/#adding-scope-restrictions-to-operations", 
            "text": "When an  Authorizer  handles a request, it creates an  Authorization  object that is attached to the request. An  Authorization  object has a  scopes  property that contains every scope granted for the access token. This object also has a convenience method for checking if a particular scope is valid for that list of scopes:  class   NoteController   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     if   ( ! request . authorization . isAuthorizedForScope ( notes ))   { \n       return   Response . forbidden (); \n     } \n\n     return   Response . ok ( await   getAllNotes ()); \n   }  }    Use an Authorizer  The  authorization  property of  Request  is only valid after the request is handled by an  Authorizer . It is  null  otherwise.   An  Authorizer  may also validate the scope of a request before letting it pass to its linked controller.  router \n   . route ( /notes ) \n   . link (()   =   Authorizer . bearer ( authServer ,   scopes:   [ notes ])) \n   . link (()   =   NoteController ());   In the above, the  NoteController  will only be reached if the request's bearer token has 'notes' scope. If there is insufficient scope, a 403 Forbidden response is sent. This applies to all operations of the  NoteController .  It often makes sense to have separate scope for different operations on the same resource. The  Scope  annotation may be added to  ResourceController  operation methods for this purpose.  class   NoteController   extends   ResourceController   { \n   @ Scope ([ notes.readonly ]) \n   @ Operation . get () \n   Future Response   getNotes ()   async   =   ...; \n\n   @ Scope ([ notes ]) \n   @ Operation . post () \n   Future Response   createNote ( @ Bind . body ()   Note   note )   async   =   ...;  }   If a request does not have sufficient scope for the intended operation method, a 403 Forbidden response is sent. When using  Scope  annotations, you must link an  Authorizer  prior to the  ResourceController , but it is not necessary to specify  Authorizer  scopes.    If a  Scope  annotation or  Authorizer  contains multiple scope entries, an access token must have scope for each of those entries. For example, the annotation  @Scope(['notes', 'user'])  requires an access token to have both 'notes' and 'user' scope.", 
            "title": "Adding Scope Restrictions to Operations"
        }, 
        {
            "location": "/auth/auth_scopes/#defining-permissible-scope", 
            "text": "When a client application authenticates on behalf of a user, it includes a list of request scopes for the access token. An Aqueduct application will grant the requested scopes to the  token if the scopes are permissible for both the authenticating client identifier and the authenticating user.  To add permissible scopes to an authenticating client, you use the  aqueduct auth  command-line tool. When creating a new client identifier, include the  --allowed-scopes  options:  aqueduct auth add-client  \\ \n  --id com.app.mobile  \\ \n  --secret myspecialsecret  \\ \n  --allowed-scopes  notes users   \\ \n  --connect postgres://user:password@dbhost:5432/db_name  When modifying an existing client identifier, use the command  aqueduct auth set-scope :  aqueduct auth set-scope  \\ \n  --id com.app.mobile  \\ \n  --scopes  notes users   \\ \n  --connect postgres://user:password@dbhost:5432/db_name  Each scope is a space-delimited string; the above examples allow clients authenticating with the  com.app.mobile  client ID to grant access tokens with 'notes' and 'users' scope. If a client application requests scopes that are not available for that client application, the granted access token will not contain that scope. If none of the request scopes are available for the client identifier, no access token is granted. When adding scope restrictions to your application, you must ensure that all of the client applications that have access to those operations are able to grant that scope.  Scopes may also be limited by some attribute of your application's concept of a 'user'. This user-level filtering is done by overriding  getAllowedScopes  in  AuthServerDelegate . By default, this method returns  AuthScope.Any  - which means there are no restrictions. If the client application allows the scope, then any user that logs in with that application can request that scope.  This method may return a list of  AuthScope s that are valid for the authenticating user. The following example shows a  ManagedAuthDelegate T  subclass that allows any scope for  @stablekernel.com  usernames, no scopes for  @hotmail.com  addresses and some limited scope for everyone else:  class   DomainBasedAuthDelegate   extends   ManagedAuthDelegate User   { \n   DomainBasedAuthDelegate ( ManagedContext   context ,   { int   tokenLimit:   40 })   : \n         super ( context ,   tokenLimit:   tokenLimit ); \n\n   @ override \n   List AuthScope   getAllowedScopes ( covariant   User   user )   { \n     if   ( user . username . endsWith ( @stablekernel.com ))   { \n       return   AuthScope . Any ; \n     }   else   if   ( user . username . endsWith ( @hotmail.com ))   { \n       return   []; \n     }   else   { \n       return   [ AuthScope ( user )]; \n     } \n   }        }   The  user  passed to  getAllowedScopes  is the user being authenticated. It will have previously been fetched by the  AuthServer . The  AuthServer  fetches this object by invoking  AuthDelegate.getResourceOwner . The default implementation of this method for  ManagedAuthDelegate T  only fetches the  id ,  username ,  salt  and  hashedPassword  of the user.  When using some other attribute of an application's user object to restrict allowed scopes, you must also override  getResourceOwner  to fetch these attributes. For example, if your application's user has a  role  attribute, you must fetch it and the other four required properties. Here's an example implementation:  class   RoleBasedAuthDelegate   extends   ManagedAuthDelegate User   { \n   RoleBasedAuthDelegate ( ManagedContext   context ,   { int   tokenLimit:   40 })   : \n         super ( context ,   tokenLimit:   tokenLimit ); \n\n   @ override \n   Future User   getResourceOwner ( \n       AuthServer   server ,   String   username )   { \n     final   query   =   Query User ( context ) \n       .. where (( u )   =   u . username ). equalTo ( username ) \n       .. returningProperties (( t )   = \n         [ t . id ,   t . username ,   t . hashedPassword ,   t . salt ,   t . role ]); \n\n     return   query . fetchOne (); \n   } \n\n   @ override \n   List AuthScope   getAllowedScopes ( covariant   User   user )   { \n     var   scopeStrings   =   []; \n     if   ( user . role   ==   admin )   { \n       scopeStrings   =   [ admin ,   user ]; \n     }   else   if   ( user . role   ==   user )   { \n       scopeStrings   =   [ user:email ]; \n     } \n\n     return   scopeStrings . map (( str )   =   AuthScope ( str )). toList (); \n   }  }", 
            "title": "Defining Permissible Scope"
        }, 
        {
            "location": "/auth/auth_scopes/#client-application-integration", 
            "text": "Client applications that integrate with your scoped Aqueduct application must include a list of requested scopes when performing authentication. When authenticating through  AuthController , a  scope  parameter must be added to the form data body. This parameter's value must be a space-delimited, URL-encoded list of requested scopes.  username=bob password=foo grant_type=password scope=notes%20users  When authenticating via an  AuthCodeController , this same query parameter is added to the initial  GET  request to render the login form.  When authentication is complete, the list of granted scopes will be available in the JSON response body as a space-delimited string.  { \n   access_token :   ... , \n   refresh_token :   ... , \n   token_type :   bearer , \n   expires_in :   3600 , \n   scopes :   notes users  }", 
            "title": "Client Application Integration"
        }, 
        {
            "location": "/auth/auth_scopes/#scope-format-and-hierarchy", 
            "text": "There is no definitive guide on what a scope string should look like, other than being restricted to alphanumeric characters and some symbols. Aqueduct, however, provides a simple scoping structure - there are two special symbols,  :  and  . .  Hierarchy is specified by the  :  character. For example, the following is a hierarchy of scopes related to a user and its sub-resources:   user  (can read/write everything a user has)  user:email  (can read/write a user's email)  user:documents  (can read/write a user's documents)  user:documents:spreadsheets  (can read/write a user's spreadsheet documents)   Notice how these scopes form a hierarchy. Each segment makes the scope more restrictive. For example, if an access token has  user:email  scope, it only allows access to a user's email. However, if the access token has  user  scope, it allows access to everything a user has, including their email.  As another example, an access token with  user:documents  scope can access all of a user's documents, but the scope  user:documents:spreadsheets  is limited to only spreadsheet documents.  Scope is often used to indicate read vs. write access. At first glance, it might sound like a good idea to use the hierarchy operator, e.g.  user:email:read  and  user:email:write . However, an access token with  user:email:write   does not  have permission to read email and this is likely unintended.  This is where  scope modifiers  come in. A scope modifier is added after a  .  at the end of a scope string. For example,  user:email.readonly  grants readonly access to a user's email whereas  user:email  grants read and write access.  An access token without a modifier has permission  any  modifier. Thus,  user  and  user:email  can both access  user:email.readonly  protected resources and actions, but  user:email.readonly  cannot access resources protected by  user:email .  A scope modifier is only valid for the last segment of a scope string. That is,  user:documents.readonly:spreadsheets  is not valid, but  user:documents:spreadsheets.readonly  is.", 
            "title": "Scope Format and Hierarchy"
        }, 
        {
            "location": "/auth/what_is_oauth/", 
            "text": "What is OAuth 2.0?\n\n\nMost applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are.\n\n\nThe simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe.\n\n\nIn OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. The application doesn't have to store the password and doesn't have to ask the user for their password again.\n\n\nThis credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, an Aqueduct application's route for this is \n/auth/token\n and handled by an instance of \nAuthController\n.\n\n\nOAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application and \nthe application\n makes the request to the server. The server \ngrants\n the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\"\n\n\nThis is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The client application usually stores that identifier in a database. This identifier is called a \nclient identifier\n. Client identifiers are added to Aqueduct applications with the \naqueduct auth\n tool (see \nAqueduct Auth CLI\n).\n\n\nWhen the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application sends a request with the user's username and password in the request body, and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like:\n\n\nvar\n \nrequest\n \n=\n \nHTTPRequest\n(\n/auth/token\n);\n\n\nrequest\n.\nmethod\n \n=\n \nPOST\n;\n\n\nrequest\n.\ncontentType\n \n=\n \napplication/x-www-form-urlencoded\n;\n\n\nrequest\n.\nauthorization\n \n=\n \nBase64\n.\nencode\n(\n$\nclientID\n:\n);\n\n\nrequest\n.\nbody\n \n=\n \n{\n\n  \nusername\n \n:\n \nbob@stablekernel.com\n,\n\n  \npassword\n \n:\n \nsupersecretstuff\n,\n\n  \ngrant_type\n \n:\n \npassword\n\n\n};\n\n\n\n\n\n\nAn access token can expire. How long it takes to expire is up to the server - Aqueduct defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a \nrefresh token\n. The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this:\n\n\n{\n\n  \naccess_token\n \n:\n \nAbca09zzzza2o2kelmzlli3ijlka\n,\n\n  \ntoken_type\n \n:\n \nbearer\n,\n\n  \nrefresh_token\n \n:\n \nlkmLIAmooa898nm20jannnnnxaww\n,\n\n  \nexpire_in\n \n:\n \n3600\n\n\n}\n\n\n\n\n\n\nThe application hangs on to both an access token and a refresh token. When the token expires, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from - \n/auth/token\n - except the parameters are a bit different:\n\n\nvar\n \nrequest\n \n=\n \nHTTPRequest\n(\n/auth/token\n);\n\n\nrequest\n.\nmethod\n \n=\n \nPOST\n;\n\n\nrequest\n.\ncontentType\n \n=\n \napplication/x-www-form-urlencoded\n;\n\n\nrequest\n.\nauthorization\n \n=\n \nBase64\n.\nencode\n(\n$\nclientID\n:\n);\n\n\nrequest\n.\nbody\n \n=\n \n{\n\n  \nrefresh_token\n \n:\n \nlkmLIAmooa898nm20jannnnnxaww\n,\n\n  \ngrant_type\n \n:\n \nrefresh_token\n\n\n};\n\n\n\n\n\n\nExchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed.\n\n\nThe verification and storage of authorization and authentication information is managed by an \nAuthServer\n.\n\n\nOther Methods for Obtaining Authorization\n\n\nThe method of getting a token above - sending a username and password to \n/auth/token\n - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the \nresource owner password credentials grant\n. A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server.\n\n\nThe other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf.\n\n\nThis is called the \nauthorization code grant\n - or just 'auth code flow'. An instance of \nAuthCodeController\n handles granting authorization codes. Once a code is received, it can be exchanged for a token via an \nAuthController\n.", 
            "title": "What is OAuth 2.0?"
        }, 
        {
            "location": "/auth/what_is_oauth/#what-is-oauth-20", 
            "text": "Most applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are.  The simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe.  In OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. The application doesn't have to store the password and doesn't have to ask the user for their password again.  This credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, an Aqueduct application's route for this is  /auth/token  and handled by an instance of  AuthController .  OAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application and  the application  makes the request to the server. The server  grants  the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\"  This is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The client application usually stores that identifier in a database. This identifier is called a  client identifier . Client identifiers are added to Aqueduct applications with the  aqueduct auth  tool (see  Aqueduct Auth CLI ).  When the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application sends a request with the user's username and password in the request body, and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like:  var   request   =   HTTPRequest ( /auth/token );  request . method   =   POST ;  request . contentType   =   application/x-www-form-urlencoded ;  request . authorization   =   Base64 . encode ( $ clientID : );  request . body   =   { \n   username   :   bob@stablekernel.com , \n   password   :   supersecretstuff , \n   grant_type   :   password  };   An access token can expire. How long it takes to expire is up to the server - Aqueduct defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a  refresh token . The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this:  { \n   access_token   :   Abca09zzzza2o2kelmzlli3ijlka , \n   token_type   :   bearer , \n   refresh_token   :   lkmLIAmooa898nm20jannnnnxaww , \n   expire_in   :   3600  }   The application hangs on to both an access token and a refresh token. When the token expires, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from -  /auth/token  - except the parameters are a bit different:  var   request   =   HTTPRequest ( /auth/token );  request . method   =   POST ;  request . contentType   =   application/x-www-form-urlencoded ;  request . authorization   =   Base64 . encode ( $ clientID : );  request . body   =   { \n   refresh_token   :   lkmLIAmooa898nm20jannnnnxaww , \n   grant_type   :   refresh_token  };   Exchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed.  The verification and storage of authorization and authentication information is managed by an  AuthServer .", 
            "title": "What is OAuth 2.0?"
        }, 
        {
            "location": "/auth/what_is_oauth/#other-methods-for-obtaining-authorization", 
            "text": "The method of getting a token above - sending a username and password to  /auth/token  - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the  resource owner password credentials grant . A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server.  The other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf.  This is called the  authorization code grant  - or just 'auth code flow'. An instance of  AuthCodeController  handles granting authorization codes. Once a code is received, it can be exchanged for a token via an  AuthController .", 
            "title": "Other Methods for Obtaining Authorization"
        }, 
        {
            "location": "/testing/", 
            "text": "Tasks\n\n\nAqueduct applications can be run, tested, debugged and profiled.\n\n\nYou create a subclass of \nTestHarness\nT\n in your application's \ntest/\n directory. For each test suite, you install this harness to start and stop your application in 'test' mode. A test harness runs your application like a live application.\n\n\nYou use \nAgent\n objects to send HTTP requests to your application under test. Agents add default information to all of their requests, like authorization information. You use test matchers like \nhasResponse\n or \nhasStatus\n to validate the response your application sends for a given request.\n\n\nYou provide mock services for external services that your application communicates with. These are often driven by the contents of a configuration file. (By convention, a configuration file for tests is named \nconfig.src.yaml\n.) You may also create mock services with \nMockHTTPServer\n to use during testing.\n\n\nGuides\n\n\n\n\nWriting Tests with a Test Harness\n\n\nTesting with the ORM and OAuth 2.0\n\n\nDeveloping Client Applications\n\n\nUsing the Debugger and Profiling\n\n\nUse Mock Services", 
            "title": "Overview"
        }, 
        {
            "location": "/testing/#tasks", 
            "text": "Aqueduct applications can be run, tested, debugged and profiled.  You create a subclass of  TestHarness T  in your application's  test/  directory. For each test suite, you install this harness to start and stop your application in 'test' mode. A test harness runs your application like a live application.  You use  Agent  objects to send HTTP requests to your application under test. Agents add default information to all of their requests, like authorization information. You use test matchers like  hasResponse  or  hasStatus  to validate the response your application sends for a given request.  You provide mock services for external services that your application communicates with. These are often driven by the contents of a configuration file. (By convention, a configuration file for tests is named  config.src.yaml .) You may also create mock services with  MockHTTPServer  to use during testing.", 
            "title": "Tasks"
        }, 
        {
            "location": "/testing/#guides", 
            "text": "Writing Tests with a Test Harness  Testing with the ORM and OAuth 2.0  Developing Client Applications  Using the Debugger and Profiling  Use Mock Services", 
            "title": "Guides"
        }, 
        {
            "location": "/testing/tests/", 
            "text": "Testing in Aqueduct\n\n\nFrom the ground up, Aqueduct is built to be tested. In practice, this means two things:\n\n\n\n\nA deployed Aqueduct application has zero code differences from an Aqueduct application under test.\n\n\nThere are helpful utilities for writing tests in Aqueduct.\n\n\n\n\nHow Tests are Written\n\n\nAn Aqueduct test suite starts your application with a configuration file specifically built for a test instance of your application. You write test cases that verify the responses of requests sent to this application. Sometimes, you might reach into your application's services to validate that an intended side-effect was triggered. For example, you might ensure that after a request was executed, a row was added to a database table.\n\n\nA \nTestHarness\nT\n is a type from \npackage:aqueduct_test\n that handles the initialization of your application under test. It is often subclassed to add application-specific startup tasks, like seeding a database with test users or adding OAuth 2.0 clients. A test harness is installed at the beginning of your test's \nmain\n function.\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nfinal\n \nharness\n \n=\n \nnew\n \nTestHarness\nMyApplicationChannel\n()..\ninstall\n();\n\n\n  \ntest\n(\nGET /endpoint returns 200 and a simple object\n,\n \n()\n \nasync\n \n{\n\n    \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/endpoint\n);\n\n    \nexpectResponse\n(\nresponse\n,\n \n200\n,\n \nbody:\n \n{\nkey\n:\n \nvalue\n});\n\n  \n});\n\n\n}}\n\n\n\n\n\n\nWhen \nTestHarness.install\n is invoked, it installs two callbacks that will start your application in 'test mode' when the tests start, and stop it after the tests complete. An application running in 'test mode' creates a local HTTP server and instantiates your \nApplicationChannel\n \non the same isolate as your tests are running on\n. This allows you to reach into your application channel's services to add test expectations on the state that the services manage.\n\n\nWhen your application is started in this way, its options have some default values:\n\n\n\n\nthe application listens on a random port\n\n\nthe \nconfigurationFilePath\n is \nconfig.src.yaml\n\n\n\n\nThe \nconfig.src.yaml\n file must have the same structure as your deployment configurations, but values are substituted with test control values. For example, database connection configuration will point at a local test database instead of a production database. For more details on configuring an application, see \nthis guide\n.\n\n\n\n\nHarness Install\n\n\nThe \ninstall\n method calls \nsetUpAll\n and \ntearDownAll\n from \npackage:test\n to start and stop your application. You can manually start and stop your application by invoking \nTestHarness.start\n and \nTestHarness.stop\n. However, this is not recommended because \nonSetUp\n and \nonTearDown\n will not be called for each test.\n\n\n\n\n\n\nUncaught Exceptions when Testing\n\n\nA test harness configures the application to let uncaught exceptions escape so that they trigger a failure in your test. This is different than when running an application normally, where all exceptions are caught and send an error response to the HTTP client.\n\n\n\n\nUsing a TestHarness Subclass\n\n\nMost applications should subclass \nTestHarness\nT\n to provide application customization. (Applications created through the CLI have a suclass in \ntest/harness/app.dart\n.) You override callback methods for events that occur during testing, like when the application starts, and before and after each test.\n\n\nclass\n \nHarness\n \nextends\n \nTestHarness\nWildfireChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nonSetUp\n()\n \nasync\n \n{\n\n    \n// called before each test\n\n  \n}\n\n\n}\n\n\n\n\n\n\nYou must invoke \ninstall\n on your test harness at the beginning of test suite for these callbacks to be called.\n\n\nSee \nharness mixins\n for classes that can be mixed into your harness for testing applications that use the ORM or OAuth 2.0.\n\n\nUsing an Agent to Execute Requests\n\n\nA \nTestHarness\nT\n has an \nagent\n property that is used to execute requests against the application being tested. An \nAgent\n has methods like \nget\n and \npost\n to execute requests and return a response object that can be validated. Its usage looks like this:\n\n\ntest\n(\nAfter POST to /thing, GET /thing/:id returns created thing\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \npostResponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\npost\n(\n/thing\n,\n \nbody:\n \n{\nkey\n:\n \nvalue\n});\n\n  \nexpectResponse\n(\npostResponse\n,\n \n200\n);\n\n\n  \nfinal\n \nthingId\n \n=\n \npostResponse\n.\nbody\n.\nas\nMap\n()[\nid\n];\n\n  \nfinal\n \ngetResponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/thing/\n$\nthingId\n);\n\n  \nexpectResponse\n(\ngetResponse\n,\n \n200\n,\n \nbody:\n \n{\n\n    \nid\n:\n \nthingId\n,\n\n    \nkey\n:\n \nvalue\n\n  \n});\n\n\n});\n\n\n\n\n\n\nMost requests can be configured and executed in methods like \nTestHarness.get\n and \nTestHarness.post\n. For additional configuration options, use \nTestHarness.request\n to create a request object that can be further customized by its properties:\n\n\nfinal\n \nrequest\n \n=\n \nharness\n.\nagent\n.\nrequest\n(\n/endpoint\n)\n\n  \n..\nheaders\n[\nX-Header\n]\n \n=\n \nValue\n;\n\n\n\n\n\n\nWhen a request includes a body, the body is encoded according to the content-type of the request (defaults to JSON). The encoding behavior is provided by \nCodecRegistry\n, the same type that manages encoding and decoding for your application logic. When adding a body to a test request, you provide the unencoded value (a Dart \nMap\n, for example) and it is encoded into the correct value (a JSON object, for example). On the inverse side, when validating a response body, the body is already decoded to a Dart type prior to your test code receiving the response.\n\n\n\n\nCodecs and CodecRegistry\n\n\nYour tests will run on the same isolate as your application. Whatever codecs have been registered in the codec repository by your application are automatically made available to the code that encodes and decodes your tests requests. You don't have to do anything special to opt-in to non-default codecs.\n\n\n\n\nAgents Add Default Values to Requests\n\n\nAn \nAgent\n has defaults values that it applies to requests from it. These values include headers and the request body content-type. For example, you might want all requests to have an extra header value, without having to write the code to add the header for each request.\n\n\nThe default agent of a harness creates requests that have a \napplication/json\n \ncontentType\n. Additional agents can be created for different sets of defaults.\n\n\nThis is especially useful when testing endpoints that require authorization, where credentials need to be attached to each request. This is a common enough task that there are \nharness mixins\n that make this task easier.\n\n\nWriting Test Expectations\n\n\nAfter an agent executes a request, you write test expectations on its response. These expectations include verifying the status code, headers and body of the response are the desired values. Expectations are set by applying matchers to the properties of a response. For example:\n\n\ntest\n(\nGET /foo returns 200 OK\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/foo\n);\n\n\n  \nexpect\n(\nresponse\n.\nstatusCode\n,\n \n200\n);\n\n  \nexpect\n(\nresponse\n,\n \nhasHeaders\n({\nx-timestamp\n:\n \ngreaterThan\n(\nDateTime\n(\n2020\n))}));\n\n  \nexpect\n(\nresponse\n,\n \nhasBody\n(\nisNull\n));\n\n\n});\n\n\n\n\n\n\nValidating response headers and bodies can be more complex than validating a status code. The \nhasBody\n and \nhasHeaders\n matchers make expectations on the response headers and body easier to write.\n\n\nThe \nhasHeaders\n matcher takes a map of header names and values, and expects that the response's headers contains a matching header for each one in the map. The value may be a \nString\n or another \nMatcher\n. The response can have more headers than expected - those headers are ignored. If you want to exactly specify all headers, there is an optional flag to pass \nhasHeaders\n.\n\n\nThe \nhasBody\n matcher takes any object or matcher that is compared to the \ndecoded\n body of the response. The body is decoded according to its content-type prior to this comparison. For example, if your response returns a JSON object \n{\"key\": \"value\"}\n, this object is first decoded into a Dart \nMap\n with the value \n{'key': 'value'}\n. The following matchers would all be true:\n\n\n// exact match of Dart Map\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n({\nkey\n:\n \nvalue\n}));\n\n\n\n// a map that contains a key whose value starts with \nv\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n({\nkey\n:\n \nstartsWith\n(\nv\n)}));\n\n\n\n// a map that contains the key \nkey\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n(\ncontainsKey\n(\nkey\n)));\n\n\n\n// a map with one entry\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n(\nhasLength\n(\n1\n)));\n\n\n\n\n\n\nFor large response bodies where you have other test coverage, you may only want to set expectations for a few values. For example, you might have a map with 50 keys, but all you care about it making sure that \nstatus='pending'\n. For this, there is a \npartial\n map matcher. It behaves similar to \nhasHeaders\n in that it only checks the keys you provide - any other keys are ignored. For example:\n\n\n// Just ensure the body contains an object with at least status=pending, version\n1\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n(\npartial\n({\n\n  \nstatus\n:\n \npending\n,\n\n  \nversion\n:\n \ngreaterThan\n(\n1\n)\n\n\n})));\n\n\n\n\n\n\nWhen using \npartial\n, you can also ensure that a map doesn't have a key with the \nisNotPresent\n matcher.\n\n\ntest\n(\nGet 200 that at least have these keys\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \npartial\n({\n\n    \nkey3\n:\n \nisNotPresent\n\n  \n})));\n\n\n});\n\n\n\n\n\n\nThis ensures that \nkey3\n is not in the map. This is different than verifying \nkey3: null\n, which would be true if \nkey3\n's value was actually the null value. See the \nAPI Reference\n for \naqueduct/test\n for more matchers.\n\n\nVerifying Side Effects\n\n\nFor requests that are not idempotent (they change data in some way), you must also verify the state of the data has changed correctly after the request. This is often done by sending another request your application handles to get the updated data. For example, after you create an employee with \nPOST /employees\n, you verify the employee was stored correctly by expecting \nGET /employees/:id\n has the same data you just sent it.\n\n\nSometimes, the expected changes are not accessible through your API. For example, let's say that creating a new employee adds a record to an auditing database, but this database is not accessible through a public API. When testing, however, you would want to ensure that record was added to the database. You can access your application's services (like its database connection) in your tests through \nTestHarness.channel\n. For example, you might execute a \nQuery\nT\n against your application's test database:\n\n\ntest\n(\nPOST /employees adds an audit log record\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\npost\n(\n/employees\n,\n \nbody:\n \n{\n\n    \nname\n:\n \nFred\n\n  \n});\n\n\n  \nexpect\n(\nresponse\n,\n \nhasStatus\n(\n202\n));\n\n\n  \nfinal\n \ncontext\n \n=\n \nharness\n.\nchannel\n.\ncontext\n;\n\n  \nfinal\n \nquery\n \n=\n \nnew\n \nQuery\nAuditRecord\n(\ncontext\n)\n\n    \n..\nwhere\n((\nrecord\n)\n \n=\n \nrecord\n.\nuser\n.\nid\n).\nequalTo\n(\nresponse\n.\nbody\n.\nas\nMap\n()[\nid\n]);\n\n  \nfinal\n \nrecord\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n  \nexpect\n(\nrecord\n,\n \nisNotNull\n);\n\n\n});\n\n\n\n\n\n\nAnything the \nApplicationChannel\n can access, so too can the tests.\n\n\nFurther Reading\n\n\nFor testing applications that use OAuth 2.0 or the ORM, see the guide on \nmixins\n for important behavior.", 
            "title": "Writing Tests"
        }, 
        {
            "location": "/testing/tests/#testing-in-aqueduct", 
            "text": "From the ground up, Aqueduct is built to be tested. In practice, this means two things:   A deployed Aqueduct application has zero code differences from an Aqueduct application under test.  There are helpful utilities for writing tests in Aqueduct.", 
            "title": "Testing in Aqueduct"
        }, 
        {
            "location": "/testing/tests/#how-tests-are-written", 
            "text": "An Aqueduct test suite starts your application with a configuration file specifically built for a test instance of your application. You write test cases that verify the responses of requests sent to this application. Sometimes, you might reach into your application's services to validate that an intended side-effect was triggered. For example, you might ensure that after a request was executed, a row was added to a database table.  A  TestHarness T  is a type from  package:aqueduct_test  that handles the initialization of your application under test. It is often subclassed to add application-specific startup tasks, like seeding a database with test users or adding OAuth 2.0 clients. A test harness is installed at the beginning of your test's  main  function.  void   main ()   { \n   final   harness   =   new   TestHarness MyApplicationChannel ().. install (); \n\n   test ( GET /endpoint returns 200 and a simple object ,   ()   async   { \n     final   response   =   await   harness . agent . get ( /endpoint ); \n     expectResponse ( response ,   200 ,   body:   { key :   value }); \n   });  }}   When  TestHarness.install  is invoked, it installs two callbacks that will start your application in 'test mode' when the tests start, and stop it after the tests complete. An application running in 'test mode' creates a local HTTP server and instantiates your  ApplicationChannel   on the same isolate as your tests are running on . This allows you to reach into your application channel's services to add test expectations on the state that the services manage.  When your application is started in this way, its options have some default values:   the application listens on a random port  the  configurationFilePath  is  config.src.yaml   The  config.src.yaml  file must have the same structure as your deployment configurations, but values are substituted with test control values. For example, database connection configuration will point at a local test database instead of a production database. For more details on configuring an application, see  this guide .   Harness Install  The  install  method calls  setUpAll  and  tearDownAll  from  package:test  to start and stop your application. You can manually start and stop your application by invoking  TestHarness.start  and  TestHarness.stop . However, this is not recommended because  onSetUp  and  onTearDown  will not be called for each test.    Uncaught Exceptions when Testing  A test harness configures the application to let uncaught exceptions escape so that they trigger a failure in your test. This is different than when running an application normally, where all exceptions are caught and send an error response to the HTTP client.", 
            "title": "How Tests are Written"
        }, 
        {
            "location": "/testing/tests/#using-a-testharness-subclass", 
            "text": "Most applications should subclass  TestHarness T  to provide application customization. (Applications created through the CLI have a suclass in  test/harness/app.dart .) You override callback methods for events that occur during testing, like when the application starts, and before and after each test.  class   Harness   extends   TestHarness WildfireChannel   { \n   @ override \n   Future   onSetUp ()   async   { \n     // called before each test \n   }  }   You must invoke  install  on your test harness at the beginning of test suite for these callbacks to be called.  See  harness mixins  for classes that can be mixed into your harness for testing applications that use the ORM or OAuth 2.0.", 
            "title": "Using a TestHarness Subclass"
        }, 
        {
            "location": "/testing/tests/#using-an-agent-to-execute-requests", 
            "text": "A  TestHarness T  has an  agent  property that is used to execute requests against the application being tested. An  Agent  has methods like  get  and  post  to execute requests and return a response object that can be validated. Its usage looks like this:  test ( After POST to /thing, GET /thing/:id returns created thing ,   ()   async   { \n   final   postResponse   =   await   harness . agent . post ( /thing ,   body:   { key :   value }); \n   expectResponse ( postResponse ,   200 ); \n\n   final   thingId   =   postResponse . body . as Map ()[ id ]; \n   final   getResponse   =   await   harness . agent . get ( /thing/ $ thingId ); \n   expectResponse ( getResponse ,   200 ,   body:   { \n     id :   thingId , \n     key :   value \n   });  });   Most requests can be configured and executed in methods like  TestHarness.get  and  TestHarness.post . For additional configuration options, use  TestHarness.request  to create a request object that can be further customized by its properties:  final   request   =   harness . agent . request ( /endpoint ) \n   .. headers [ X-Header ]   =   Value ;   When a request includes a body, the body is encoded according to the content-type of the request (defaults to JSON). The encoding behavior is provided by  CodecRegistry , the same type that manages encoding and decoding for your application logic. When adding a body to a test request, you provide the unencoded value (a Dart  Map , for example) and it is encoded into the correct value (a JSON object, for example). On the inverse side, when validating a response body, the body is already decoded to a Dart type prior to your test code receiving the response.   Codecs and CodecRegistry  Your tests will run on the same isolate as your application. Whatever codecs have been registered in the codec repository by your application are automatically made available to the code that encodes and decodes your tests requests. You don't have to do anything special to opt-in to non-default codecs.", 
            "title": "Using an Agent to Execute Requests"
        }, 
        {
            "location": "/testing/tests/#agents-add-default-values-to-requests", 
            "text": "An  Agent  has defaults values that it applies to requests from it. These values include headers and the request body content-type. For example, you might want all requests to have an extra header value, without having to write the code to add the header for each request.  The default agent of a harness creates requests that have a  application/json   contentType . Additional agents can be created for different sets of defaults.  This is especially useful when testing endpoints that require authorization, where credentials need to be attached to each request. This is a common enough task that there are  harness mixins  that make this task easier.", 
            "title": "Agents Add Default Values to Requests"
        }, 
        {
            "location": "/testing/tests/#writing-test-expectations", 
            "text": "After an agent executes a request, you write test expectations on its response. These expectations include verifying the status code, headers and body of the response are the desired values. Expectations are set by applying matchers to the properties of a response. For example:  test ( GET /foo returns 200 OK ,   ()   async   { \n   final   response   =   await   harness . agent . get ( /foo ); \n\n   expect ( response . statusCode ,   200 ); \n   expect ( response ,   hasHeaders ({ x-timestamp :   greaterThan ( DateTime ( 2020 ))})); \n   expect ( response ,   hasBody ( isNull ));  });   Validating response headers and bodies can be more complex than validating a status code. The  hasBody  and  hasHeaders  matchers make expectations on the response headers and body easier to write.  The  hasHeaders  matcher takes a map of header names and values, and expects that the response's headers contains a matching header for each one in the map. The value may be a  String  or another  Matcher . The response can have more headers than expected - those headers are ignored. If you want to exactly specify all headers, there is an optional flag to pass  hasHeaders .  The  hasBody  matcher takes any object or matcher that is compared to the  decoded  body of the response. The body is decoded according to its content-type prior to this comparison. For example, if your response returns a JSON object  {\"key\": \"value\"} , this object is first decoded into a Dart  Map  with the value  {'key': 'value'} . The following matchers would all be true:  // exact match of Dart Map  expect ( response ,   hasBody ({ key :   value }));  // a map that contains a key whose value starts with  v  expect ( response ,   hasBody ({ key :   startsWith ( v )}));  // a map that contains the key  key  expect ( response ,   hasBody ( containsKey ( key )));  // a map with one entry  expect ( response ,   hasBody ( hasLength ( 1 )));   For large response bodies where you have other test coverage, you may only want to set expectations for a few values. For example, you might have a map with 50 keys, but all you care about it making sure that  status='pending' . For this, there is a  partial  map matcher. It behaves similar to  hasHeaders  in that it only checks the keys you provide - any other keys are ignored. For example:  // Just ensure the body contains an object with at least status=pending, version 1  expect ( response ,   hasBody ( partial ({ \n   status :   pending , \n   version :   greaterThan ( 1 )  })));   When using  partial , you can also ensure that a map doesn't have a key with the  isNotPresent  matcher.  test ( Get 200 that at least have these keys ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasResponse ( 200 ,   partial ({ \n     key3 :   isNotPresent \n   })));  });   This ensures that  key3  is not in the map. This is different than verifying  key3: null , which would be true if  key3 's value was actually the null value. See the  API Reference  for  aqueduct/test  for more matchers.", 
            "title": "Writing Test Expectations"
        }, 
        {
            "location": "/testing/tests/#verifying-side-effects", 
            "text": "For requests that are not idempotent (they change data in some way), you must also verify the state of the data has changed correctly after the request. This is often done by sending another request your application handles to get the updated data. For example, after you create an employee with  POST /employees , you verify the employee was stored correctly by expecting  GET /employees/:id  has the same data you just sent it.  Sometimes, the expected changes are not accessible through your API. For example, let's say that creating a new employee adds a record to an auditing database, but this database is not accessible through a public API. When testing, however, you would want to ensure that record was added to the database. You can access your application's services (like its database connection) in your tests through  TestHarness.channel . For example, you might execute a  Query T  against your application's test database:  test ( POST /employees adds an audit log record ,   ()   async   { \n   final   response   =   await   harness . agent . post ( /employees ,   body:   { \n     name :   Fred \n   }); \n\n   expect ( response ,   hasStatus ( 202 )); \n\n   final   context   =   harness . channel . context ; \n   final   query   =   new   Query AuditRecord ( context ) \n     .. where (( record )   =   record . user . id ). equalTo ( response . body . as Map ()[ id ]); \n   final   record   =   await   query . fetchOne (); \n   expect ( record ,   isNotNull );  });   Anything the  ApplicationChannel  can access, so too can the tests.", 
            "title": "Verifying Side Effects"
        }, 
        {
            "location": "/testing/tests/#further-reading", 
            "text": "For testing applications that use OAuth 2.0 or the ORM, see the guide on  mixins  for important behavior.", 
            "title": "Further Reading"
        }, 
        {
            "location": "/testing/mixins/", 
            "text": "Testing Applications That Use ORM and OAuth 2.0\n\n\nThis document describes how to set up your test code to test applications that use the ORM and OAuth 2.0. These types of applications require extra initialization steps, e.g. set up a test database.\n\n\nTesting Applications That Use the ORM\n\n\nAqueduct's ORM uses PostgreSQL as its database. Before your tests run, Aqueduct will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use a mock implementation (e.g., SQLite).\n\n\n\n\nYou Must Install PostgreSQL Locally\nOn macOS, \nPostgres.app\n is a simple, self-contained PostgreSQL instance that you can run as a normal application. (See \nPostgreSQL installation for other platforms\n.)\n\n\n\n\n\n\nLocal Database for Tests\n\n\nThe same database is reused for testing all of your applications. You only have to create this database once per development machine, or when running in a CI tool like TravisCI. From PostgreSQL's prompt, run:\n\n\nCREATE\n \nDATABASE\n \ndart_test\n;\n\n\nCREATE\n \nUSER\n \ndart\n \nWITH\n \ncreatedb\n;\n\n\nALTER\n \nUSER\n \ndart\n \nWITH\n \npassword\n \ndart\n;\n\n\nGRANT\n \nall\n \nON\n \nDATABASE\n \ndart_test\n \nTO\n \ndart\n;\n\n\n\n\n\n\nA database configuration in your application's \nconfig.yaml.src\n must match the following:\n\n\nusername\n:\n \ndart\n\n\npassword\n:\n \ndart\n\n\nhost\n:\n \nlocalhost\n\n\nport\n:\n \n5432\n\n\ndatabaseName\n:\n \ndart_test\n\n\n\n\n\n\nYour application, when run with a subclass of \nTestHarness\nT\n, will configure its database connection to connect to the local test database. You must mixin \nTestHarnessORMMixin\n with your test harness and invoke \nresetData\n by overriding \nonSetUp\n. You may also override \nseed\n to insert test data into the database.\n\n\nclass\n \nHarness\n \nextends\n \nTestHarness\nAppChannel\n \nwith\n \nTestHarnessORMMixin\n \n{\n\n  \n@\noverride\n\n  \nManagedContext\n \nget\n \ncontext\n \n=\n \nchannel\n.\ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nonSetUp\n()\n \nasync\n \n{\n\n    \nawait\n \nresetData\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nFuture\n \nseed\n()\n \nasync\n \n{\n\n    \n/* insert some rows here */\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\n\nSeeding Data\nYou should only seed static data in the \nseed\n method; this may include things like categories or country codes that cannot be changed during runtime. Data that is manipulated for specific test cases should be invoked in a test \nsetUp\n callback or the test itself.\n\n\n\n\n\n\nLocal Database for Running an Application\n\n\nA database separate from the test database should be used for \nrunning\n an application locally. You can create a database locally by running \npsql\n to open a PostgreSQL terminal and run the following commands:\n\n\nCREATE DATABASE my_app_name;\nCREATE USER my_app_user WITH PASSWORD \nmypassword\n;\nGRANT ALL ON DATABASE my_app_name TO my_app_user;\n\n\n\n\n\nAdd your schema to the local database by generating and executing migration scripts:\n\n\naqueduct db generate\naqueduct db upgrade --connect postgres://my_app_user:mypassword@localhost:5432/my_app_name\n\n\n\n\n\nTesting Applications That Use OAuth 2.0\n\n\nApplications that use OAuth 2.0 should mixin \nTestHarnessAuthMixin\n. This mixin adds methods for registering a client identifier and authenticating a user. Both methods return an \nAgent\n with default headers with authorization information for the client identifier or user.\n\n\nMost often, you use \npackage:aqueduct/managed_auth\n for an ORM-driven OAuth2 delegate. You must also mixin \nTestHarnessORMMixin\n when using this mixin.\n\n\nclass\n \nHarness\n \nextends\n \nTestHarness\nAppChannel\n \nwith\n \nTestHarnessAuthMixin\nAppChannel\n,\n \nTestHarnessORMMixin\n \n{\n\n  \n@\noverride\n\n  \nManagedContext\n \nget\n \ncontext\n \n=\n \nchannel\n.\ncontext\n;\n\n\n  \n@\noverride\n\n  \nAuthServer\n \nget\n \nauthServer\n \n=\n \nchannel\n.\nauthServer\n;\n\n\n  \nAgent\n \npublicAgent\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nonSetUp\n()\n \nasync\n \n{\n    \n    \nawait\n \nresetData\n();\n\n    \npublicAgent\n \n=\n \nawait\n \naddClient\n(\ncom.aqueduct.public\n);\n\n  \n}\n\n\n  \nFuture\nAgent\n \nregisterUser\n(\nUser\n \nuser\n,\n \n{\nAgent\n \nwithClient\n})\n \nasync\n \n{\n\n    \nwithClient\n \n??=\n \npublicAgent\n;\n\n\n    \nfinal\n \nreq\n \n=\n \nwithClient\n.\nrequest\n(\n/register\n)\n\n      \n..\nbody\n \n=\n \n{\nusername\n:\n \nuser\n.\nusername\n,\n \npassword\n:\n \nuser\n.\npassword\n};\n\n    \nawait\n \nreq\n.\npost\n();\n\n\n    \nreturn\n \nloginUser\n(\nwithClient\n,\n \nuser\n.\nusername\n,\n \nuser\n.\npassword\n);\n\n  \n}\n\n\n}", 
            "title": "Testing with the ORM and OAuth 2.0"
        }, 
        {
            "location": "/testing/mixins/#testing-applications-that-use-orm-and-oauth-20", 
            "text": "This document describes how to set up your test code to test applications that use the ORM and OAuth 2.0. These types of applications require extra initialization steps, e.g. set up a test database.", 
            "title": "Testing Applications That Use ORM and OAuth 2.0"
        }, 
        {
            "location": "/testing/mixins/#testing-applications-that-use-the-orm", 
            "text": "Aqueduct's ORM uses PostgreSQL as its database. Before your tests run, Aqueduct will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use a mock implementation (e.g., SQLite).   You Must Install PostgreSQL Locally On macOS,  Postgres.app  is a simple, self-contained PostgreSQL instance that you can run as a normal application. (See  PostgreSQL installation for other platforms .)", 
            "title": "Testing Applications That Use the ORM"
        }, 
        {
            "location": "/testing/mixins/#local-database-for-tests", 
            "text": "The same database is reused for testing all of your applications. You only have to create this database once per development machine, or when running in a CI tool like TravisCI. From PostgreSQL's prompt, run:  CREATE   DATABASE   dart_test ;  CREATE   USER   dart   WITH   createdb ;  ALTER   USER   dart   WITH   password   dart ;  GRANT   all   ON   DATABASE   dart_test   TO   dart ;   A database configuration in your application's  config.yaml.src  must match the following:  username :   dart  password :   dart  host :   localhost  port :   5432  databaseName :   dart_test   Your application, when run with a subclass of  TestHarness T , will configure its database connection to connect to the local test database. You must mixin  TestHarnessORMMixin  with your test harness and invoke  resetData  by overriding  onSetUp . You may also override  seed  to insert test data into the database.  class   Harness   extends   TestHarness AppChannel   with   TestHarnessORMMixin   { \n   @ override \n   ManagedContext   get   context   =   channel . context ; \n\n   @ override \n   Future   onSetUp ()   async   { \n     await   resetData (); \n   } \n\n   @ override \n   Future   seed ()   async   { \n     /* insert some rows here */ \n   }  }    Seeding Data You should only seed static data in the  seed  method; this may include things like categories or country codes that cannot be changed during runtime. Data that is manipulated for specific test cases should be invoked in a test  setUp  callback or the test itself.", 
            "title": "Local Database for Tests"
        }, 
        {
            "location": "/testing/mixins/#local-database-for-running-an-application", 
            "text": "A database separate from the test database should be used for  running  an application locally. You can create a database locally by running  psql  to open a PostgreSQL terminal and run the following commands:  CREATE DATABASE my_app_name;\nCREATE USER my_app_user WITH PASSWORD  mypassword ;\nGRANT ALL ON DATABASE my_app_name TO my_app_user;  Add your schema to the local database by generating and executing migration scripts:  aqueduct db generate\naqueduct db upgrade --connect postgres://my_app_user:mypassword@localhost:5432/my_app_name", 
            "title": "Local Database for Running an Application"
        }, 
        {
            "location": "/testing/mixins/#testing-applications-that-use-oauth-20", 
            "text": "Applications that use OAuth 2.0 should mixin  TestHarnessAuthMixin . This mixin adds methods for registering a client identifier and authenticating a user. Both methods return an  Agent  with default headers with authorization information for the client identifier or user.  Most often, you use  package:aqueduct/managed_auth  for an ORM-driven OAuth2 delegate. You must also mixin  TestHarnessORMMixin  when using this mixin.  class   Harness   extends   TestHarness AppChannel   with   TestHarnessAuthMixin AppChannel ,   TestHarnessORMMixin   { \n   @ override \n   ManagedContext   get   context   =   channel . context ; \n\n   @ override \n   AuthServer   get   authServer   =   channel . authServer ; \n\n   Agent   publicAgent ; \n\n   @ override \n   Future   onSetUp ()   async   {     \n     await   resetData (); \n     publicAgent   =   await   addClient ( com.aqueduct.public ); \n   } \n\n   Future Agent   registerUser ( User   user ,   { Agent   withClient })   async   { \n     withClient   ??=   publicAgent ; \n\n     final   req   =   withClient . request ( /register ) \n       .. body   =   { username :   user . username ,   password :   user . password }; \n     await   req . post (); \n\n     return   loginUser ( withClient ,   user . username ,   user . password ); \n   }  }", 
            "title": "Testing Applications That Use OAuth 2.0"
        }, 
        {
            "location": "/testing/debugger/", 
            "text": "Using the IntelliJ IDE Debugger\n\n\nThe debugger may be used when running tests or developing client applications locally.\n\n\nEnabling the Debugger\n\n\nApplications created by \naqueduct create\n ship with a \nbin/main.dart\n script that starts the application. When developing, running this script from an IDE is often preferred to \naqueduct serve\n because the IDE can leverage its full capabilities. One such capability is a debugger. In IntelliJ IDEA (and its suite of products), you may right-click on this file and select 'Debug' from the pop-up menu to run the application in the debugger.\n\n\n\n\nSetting Breakpoints\n\n\nA valuable feature of a debugger is the ability to set breakpoints. A breakpoint pauses execution of your application at a specific point in the code, allowing you to view variable values and monitor the code path line-by-line as execution continues.\n\n\nTo set a breakpoint, you simply click on the gutter area next to the line of code you wish to stop at.\n\n\n\n\nOnce a debugger stops, you can view variable values in the center pane of the debugging panel. The left pane (labeled 'Frames') shows the current stack trace. The row of buttons above the stack trace allow you to continue executing code line-by-line.\n\n\nEach button in this row has a slightly different behavior. From left to right:\n\n\n\n\nThe red arrow with the stack of lines continues execution until the next breakpoint is encountered.\n\n\nThe blue downwards arrow executes the current line and moves to the next line.\n\n\nThe blue right/downward arrow continues execution into the function that is about to be called and stops on its first line.\n\n\nThe red right/downward arrow is the same as above, but will also jump into dependency code.\n\n\nThe blue right/upwards arrow completes execution of the current method and stops right after the callsite.\n\n\n\n\nNote that currently asynchronous invocations confuse the debugger a bit. To continue past an asynchronous method to the next line, set a breakpoint on that next line and hit the big green arrow on the left column of buttons.\n\n\nTo jump into an asynchronous method, command-click on its definition and set a breakpoint on its first line and then click the big green arrow.\n\n\nProfiling with Observatory\n\n\nYou may also use \nObservatory\n to profile applications. Profiling consists of monitoring memory usage, allocations and how much time a function spends executing relative to the rest of your application.\n\n\nBoth \naqueduct serve\n and \nbin/main.dart\n support starting Observatory. When running the application with \naqueduct serve\n, add the \n--observe\n flag and Observatory will start listening on port 8181 and a web browser will automatically be opened.\n\n\naqueduct serve --observe\n\n\n\n\n\nWhen running the application through IntelliJ, Observatory will start listening on a random port. In the run console in IntelliJ, you may click on the Observatory hyperlink to open it in your web browser.", 
            "title": "Using the Debugger"
        }, 
        {
            "location": "/testing/debugger/#using-the-intellij-ide-debugger", 
            "text": "The debugger may be used when running tests or developing client applications locally.", 
            "title": "Using the IntelliJ IDE Debugger"
        }, 
        {
            "location": "/testing/debugger/#enabling-the-debugger", 
            "text": "Applications created by  aqueduct create  ship with a  bin/main.dart  script that starts the application. When developing, running this script from an IDE is often preferred to  aqueduct serve  because the IDE can leverage its full capabilities. One such capability is a debugger. In IntelliJ IDEA (and its suite of products), you may right-click on this file and select 'Debug' from the pop-up menu to run the application in the debugger.", 
            "title": "Enabling the Debugger"
        }, 
        {
            "location": "/testing/debugger/#setting-breakpoints", 
            "text": "A valuable feature of a debugger is the ability to set breakpoints. A breakpoint pauses execution of your application at a specific point in the code, allowing you to view variable values and monitor the code path line-by-line as execution continues.  To set a breakpoint, you simply click on the gutter area next to the line of code you wish to stop at.   Once a debugger stops, you can view variable values in the center pane of the debugging panel. The left pane (labeled 'Frames') shows the current stack trace. The row of buttons above the stack trace allow you to continue executing code line-by-line.  Each button in this row has a slightly different behavior. From left to right:   The red arrow with the stack of lines continues execution until the next breakpoint is encountered.  The blue downwards arrow executes the current line and moves to the next line.  The blue right/downward arrow continues execution into the function that is about to be called and stops on its first line.  The red right/downward arrow is the same as above, but will also jump into dependency code.  The blue right/upwards arrow completes execution of the current method and stops right after the callsite.   Note that currently asynchronous invocations confuse the debugger a bit. To continue past an asynchronous method to the next line, set a breakpoint on that next line and hit the big green arrow on the left column of buttons.  To jump into an asynchronous method, command-click on its definition and set a breakpoint on its first line and then click the big green arrow.", 
            "title": "Setting Breakpoints"
        }, 
        {
            "location": "/testing/debugger/#profiling-with-observatory", 
            "text": "You may also use  Observatory  to profile applications. Profiling consists of monitoring memory usage, allocations and how much time a function spends executing relative to the rest of your application.  Both  aqueduct serve  and  bin/main.dart  support starting Observatory. When running the application with  aqueduct serve , add the  --observe  flag and Observatory will start listening on port 8181 and a web browser will automatically be opened.  aqueduct serve --observe  When running the application through IntelliJ, Observatory will start listening on a random port. In the run console in IntelliJ, you may click on the Observatory hyperlink to open it in your web browser.", 
            "title": "Profiling with Observatory"
        }, 
        {
            "location": "/testing/clients/", 
            "text": "Using Aqueduct when Writing Client Applications\n\n\nRunning an Aqueduct server locally while developing client applications is an important part of the development process. Run applications through their \nbin/main.dart\n script or \naqueduct serve\n. The former allows for \ndebugging\n the application with a debugger.\n\n\nEnable Logging and Return Server Errors\n\n\nEnsure that logging is on while developing client applications by registering a listener on \nApplicationChannel.logger\n.\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nlogger\n.\nonRecord\n.\nlisten\n((\nrecord\n)\n \n{\n\n      \nprint\n(\n$\nrecord\n \n${\nrecord\n.\nerror\n \n??\n \n}\n \n${\nrecord\n.\nstackTrace\n \n??\n \n}\n);\n\n    \n});\n\n  \n}\n\n  \n...\n\n\n}\n\n\n\n\n\n\nA useful feature to turn on during debugging is sending stack traces for 500 Server Error responses. Turn this flag on in a \nApplicationChannel\n while debugging:\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nController\n.\nincludeErrorDetailsInServerErrorResponses\n \n=\n \ntrue\n;\n\n  \n}\n\n  \n...\n\n\n}\n\n\n\n\n\n\nWhen a 500 error is encountered, the server will send the stack trace back to the client so you can view it while developing the client application without having to switch terminals. This property should never be left on for production code.\n\n\nAvoid Port Conflicts\n\n\nApplications run with \naqueduct serve\n default to port 8888. You may use the \n--port\n command-line option to pick a different port:\n\n\naqueduct serve --port 4000\n\n\n\n\n\nProvision a Database for Client Testing\n\n\nFor applications that use the ORM, you must have a locally running database with a schema that matches your application's data model.\n\n\nIf you are using OAuth 2.0, you must have also added client identifiers to the locally running database. You may add client identifiers with the \naqueduct auth\n command-line tool.", 
            "title": "Developing Client Applications"
        }, 
        {
            "location": "/testing/clients/#using-aqueduct-when-writing-client-applications", 
            "text": "Running an Aqueduct server locally while developing client applications is an important part of the development process. Run applications through their  bin/main.dart  script or  aqueduct serve . The former allows for  debugging  the application with a debugger.", 
            "title": "Using Aqueduct when Writing Client Applications"
        }, 
        {
            "location": "/testing/clients/#enable-logging-and-return-server-errors", 
            "text": "Ensure that logging is on while developing client applications by registering a listener on  ApplicationChannel.logger .  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     logger . onRecord . listen (( record )   { \n       print ( $ record   ${ record . error   ??   }   ${ record . stackTrace   ??   } ); \n     }); \n   } \n   ...  }   A useful feature to turn on during debugging is sending stack traces for 500 Server Error responses. Turn this flag on in a  ApplicationChannel  while debugging:  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     Controller . includeErrorDetailsInServerErrorResponses   =   true ; \n   } \n   ...  }   When a 500 error is encountered, the server will send the stack trace back to the client so you can view it while developing the client application without having to switch terminals. This property should never be left on for production code.", 
            "title": "Enable Logging and Return Server Errors"
        }, 
        {
            "location": "/testing/clients/#avoid-port-conflicts", 
            "text": "Applications run with  aqueduct serve  default to port 8888. You may use the  --port  command-line option to pick a different port:  aqueduct serve --port 4000", 
            "title": "Avoid Port Conflicts"
        }, 
        {
            "location": "/testing/clients/#provision-a-database-for-client-testing", 
            "text": "For applications that use the ORM, you must have a locally running database with a schema that matches your application's data model.  If you are using OAuth 2.0, you must have also added client identifiers to the locally running database. You may add client identifiers with the  aqueduct auth  command-line tool.", 
            "title": "Provision a Database for Client Testing"
        }, 
        {
            "location": "/testing/mock/", 
            "text": "Mocking External Services\n\n\nAn Aqueduct application often communicates with another server. For example, an application might make requests to the GitHub API to collect analytics about a team's workflow. When running automated tests, consuming the actual GitHub API isn't feasible - because GitHub will probably rate limit you and because the data being returned is constantly changing.\n\n\nTo solve this problem, you can create \"mocks\" of a service during testing. Aqueduct has two testing utilities for this purpose - \nMockServer\n and \nMockHTTPServer\n - in the \naqueduct/test\n library.\n\n\nUsing a MockHTTPServer\n\n\nWhen testing your application, you send it requests using a \nTestClient\n. As part of the request handling logic, your application might issue requests to some other server. \nMockHTTPServer\n allows you to validate that the request your application sent was correct and gives you control what the responses are to those requests. For example, \ngithubMock\n is an instance of \nMockHTTPServer\n in the following test, which ensures that the request was constructed correctly:\n\n\ntest\n(\nWill get correct user from GitHub\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n\n    \nawait\n \napp\n.\nclient\n.\nauthenticatedRequest\n(\n/github_profile/fred\n).\nget\n();\n\n\n  \nvar\n \nrequestSentByYourApplicationToGitHub\n \n=\n \nawait\n \ngithubMock\n.\nnext\n();\n\n  \nexpect\n(\nrequestSentByYourApplicationToGitHub\n.\nmethod\n,\n \nGET\n);\n\n  \nexpect\n(\nrequestSentByYourApplicationToGitHub\n.\npath\n,\n \n/users/search?name=fred\n);\n\n\n});\n\n\n\n\n\n\nIn the above code, we are expecting that anytime the request \nGET /github_profile/fred\n is sent to your application, that it turns around and searches for a user in GitHub's API. This test ensures that we have correctly translated our request to a request to be made to the GitHub API. If no request was made - because of a programmer error - this test would fail because the \nFuture\n returned from \ngithubMock.next()\n would never complete. There is no next request, because none was ever delivered!\n\n\nBy default, any request sent to a \nMockHTTPServer\n is a 200 OK Response with an empty body. You may change this behavior by queuing responses in a mock server.\n\n\ntest\n(\nWill get correct user from GitHub\n,\n \n()\n \nasync\n \n{\n\n  \ngithubMock\n.\nqueueResponse\n(\nnew\n \nResponse\n.\nok\n({\nid\n:\n \n1\n,\n \nname\n:\n \nfred\n}));\n\n\n  \nvar\n \nresponse\n \n=\n\n    \nawait\n \napp\n.\nclient\n.\nauthenticatedRequest\n(\n/github_profile/fred\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \npartial\n({\n\n    \nid\n:\n \n1\n,\n\n    \nname\n:\n \nfred\n\n  \n})))\n\n\n});\n\n\n\n\n\n\nIn the above code, \nqueueResponse\n adds a 200 OK Response to the mock server queue with a specific body. The mock server will send that response for the next request it receives. In the implementation of \n/github_profile/fred\n, your application sends a \nGET /users/search?name=fred\n to the GitHub API - except the GitHub API is your mock server, and it returns the response you queued instead. Thus, the queued up response is the expected response of the GitHub API.\n\n\nAfter the request completes, the response is removed from the queue and subsequent responses will go back to the default. You may queue as many responses as you like. You may also simulate a failed request - one that never gets a response - like so:\n\n\nmockServer\n.\nqueueResponse\n(\nMockHTTPServer\n.\nmockConnectionFailureResponse\n);\n\n\n\n\n\n\nYou may also subclass \nMockHTTPServer\n and override its \nopen\n method to add logic to determine the response. Please see the implementation of \nMockHTTPServer.open\n for more details.\n\n\nConfiguring a MockHTTPServer\n\n\nA \nMockHTTPServer\n is created when setting up tests. It must be closed when tearing down tests. If you use the same mock server to across all tests (e.g., open it in \nsetUpAll\n), make sure to clear it after each test:\n\n\nimport\n \npackage:aqueduct/test.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nvar\n \nmockServer\n \n=\n \nnew\n \nMockHTTPServer\n(\n4000\n);\n\n\n  \nsetUpAll\n(()\n \nasync\n \n{\n\n    \nawait\n \nmockServer\n.\nopen\n();\n\n  \n});\n\n\n  \ntearDownAll\n(()\n \nasync\n \n{\n\n    \nawait\n \nmockServer\n.\nclose\n();\n\n  \n});\n\n\n  \ntearDown\n(()\n \nasync\n \n{\n\n    \nmockServer\n.\nclear\n();\n\n  \n});\n\n\n}\n\n\n\n\n\n\nAn instance of \nMockHTTPServer\n listens on localhost on a specific port. An application that makes testable external service requests should provide the base URI for those services in a configuration file. The URI for that service in the \nconfiguration file used during testing\n should point at localhost and a specific port. For example, if a deployed \nconfig.yaml\n file has the following key-values:\n\n\ngithub\n:\n\n  \nbaseURL\n:\n \nhttps\n://\napi\n.\ngithub\n.\ncom\n/\n  \n\n\n\n\n\nThen \nconfig.src.yaml\n would have:\n\n\ngithub\n:\n\n  \nbaseURL\n:\n \nhttp\n://\nlocalhost\n:\n4000\n/\n\n\n\n\n\n\nYour application reads this configuration file and injects the base URL into the service that will execute requests.\n\n\nclass\n \nAppConfiguration\n \nextends\n \nConfiguration\n \n{\n\n  \nAppConfiguration\n(\nString\n \nfileName\n)\n \n:\n \nsuper\n.\nfromFile\n(\nfileName\n);\n\n\n  \nAPIConfiguration\n \ngithub\n;\n\n\n}\n\n\n\nclass\n \nAppApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \nconfig\n \n=\n \nnew\n \nAppConfiguration\n(\noptions\n.\nconfigurationFilePath\n);\n\n\n    \ngithubService\n \n=\n \nnew\n \nGitHubService\n(\nbaseURL:\n \nconfig\n.\ngithub\n.\nbaseURL\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNote that \nAPIConfiguration\n is an existing type and is meant for this purpose.\n\n\nAlso note that the testing strategy for database connections is \nnot\n to use a mock but to use a temporary, local database that is set up and torn down during tests. This is possible because you own the data model generating code - whereas you probably don't have access to an external service's development API.", 
            "title": "Mocking Services"
        }, 
        {
            "location": "/testing/mock/#mocking-external-services", 
            "text": "An Aqueduct application often communicates with another server. For example, an application might make requests to the GitHub API to collect analytics about a team's workflow. When running automated tests, consuming the actual GitHub API isn't feasible - because GitHub will probably rate limit you and because the data being returned is constantly changing.  To solve this problem, you can create \"mocks\" of a service during testing. Aqueduct has two testing utilities for this purpose -  MockServer  and  MockHTTPServer  - in the  aqueduct/test  library.", 
            "title": "Mocking External Services"
        }, 
        {
            "location": "/testing/mock/#using-a-mockhttpserver", 
            "text": "When testing your application, you send it requests using a  TestClient . As part of the request handling logic, your application might issue requests to some other server.  MockHTTPServer  allows you to validate that the request your application sent was correct and gives you control what the responses are to those requests. For example,  githubMock  is an instance of  MockHTTPServer  in the following test, which ensures that the request was constructed correctly:  test ( Will get correct user from GitHub ,   ()   async   { \n   var   response   = \n     await   app . client . authenticatedRequest ( /github_profile/fred ). get (); \n\n   var   requestSentByYourApplicationToGitHub   =   await   githubMock . next (); \n   expect ( requestSentByYourApplicationToGitHub . method ,   GET ); \n   expect ( requestSentByYourApplicationToGitHub . path ,   /users/search?name=fred );  });   In the above code, we are expecting that anytime the request  GET /github_profile/fred  is sent to your application, that it turns around and searches for a user in GitHub's API. This test ensures that we have correctly translated our request to a request to be made to the GitHub API. If no request was made - because of a programmer error - this test would fail because the  Future  returned from  githubMock.next()  would never complete. There is no next request, because none was ever delivered!  By default, any request sent to a  MockHTTPServer  is a 200 OK Response with an empty body. You may change this behavior by queuing responses in a mock server.  test ( Will get correct user from GitHub ,   ()   async   { \n   githubMock . queueResponse ( new   Response . ok ({ id :   1 ,   name :   fred })); \n\n   var   response   = \n     await   app . client . authenticatedRequest ( /github_profile/fred ). get (); \n   expect ( response ,   hasResponse ( 200 ,   partial ({ \n     id :   1 , \n     name :   fred \n   })))  });   In the above code,  queueResponse  adds a 200 OK Response to the mock server queue with a specific body. The mock server will send that response for the next request it receives. In the implementation of  /github_profile/fred , your application sends a  GET /users/search?name=fred  to the GitHub API - except the GitHub API is your mock server, and it returns the response you queued instead. Thus, the queued up response is the expected response of the GitHub API.  After the request completes, the response is removed from the queue and subsequent responses will go back to the default. You may queue as many responses as you like. You may also simulate a failed request - one that never gets a response - like so:  mockServer . queueResponse ( MockHTTPServer . mockConnectionFailureResponse );   You may also subclass  MockHTTPServer  and override its  open  method to add logic to determine the response. Please see the implementation of  MockHTTPServer.open  for more details.", 
            "title": "Using a MockHTTPServer"
        }, 
        {
            "location": "/testing/mock/#configuring-a-mockhttpserver", 
            "text": "A  MockHTTPServer  is created when setting up tests. It must be closed when tearing down tests. If you use the same mock server to across all tests (e.g., open it in  setUpAll ), make sure to clear it after each test:  import   package:aqueduct/test.dart ;  void   main ()   { \n   var   mockServer   =   new   MockHTTPServer ( 4000 ); \n\n   setUpAll (()   async   { \n     await   mockServer . open (); \n   }); \n\n   tearDownAll (()   async   { \n     await   mockServer . close (); \n   }); \n\n   tearDown (()   async   { \n     mockServer . clear (); \n   });  }   An instance of  MockHTTPServer  listens on localhost on a specific port. An application that makes testable external service requests should provide the base URI for those services in a configuration file. The URI for that service in the  configuration file used during testing  should point at localhost and a specific port. For example, if a deployed  config.yaml  file has the following key-values:  github : \n   baseURL :   https :// api . github . com /     Then  config.src.yaml  would have:  github : \n   baseURL :   http :// localhost : 4000 /   Your application reads this configuration file and injects the base URL into the service that will execute requests.  class   AppConfiguration   extends   Configuration   { \n   AppConfiguration ( String   fileName )   :   super . fromFile ( fileName ); \n\n   APIConfiguration   github ;  }  class   AppApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     var   config   =   new   AppConfiguration ( options . configurationFilePath ); \n\n     githubService   =   new   GitHubService ( baseURL:   config . github . baseURL ); \n   }  }   Note that  APIConfiguration  is an existing type and is meant for this purpose.  Also note that the testing strategy for database connections is  not  to use a mock but to use a temporary, local database that is set up and torn down during tests. This is possible because you own the data model generating code - whereas you probably don't have access to an external service's development API.", 
            "title": "Configuring a MockHTTPServer"
        }, 
        {
            "location": "/deploy/", 
            "text": "Tasks\n\n\nAqueduct has a built in tool, \naqueduct\n, for deploying Aqueduct applications, managing database schemas, OAuth 2.0 clients and creating projects. See \nGetting Started\n for installation instructions. Many of the tasks for deployment rely on using this tool.\n\n\nAqueduct applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using \nHeroku\n to host your applications.\n\n\nGuides\n\n\n\n\nRunning an Aqueduct Application Locally\n\n\nRunning an Aqueduct Application with Docker, Docker Compose and Kubernetes\n\n\nRunning an Aqueduct Application on Heroku\n\n\nRunning an Aqueduct Application on Amazon Web Services (AWS)\n\n\nRunning an Aqueduct Application without aqueduct serve", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/#tasks", 
            "text": "Aqueduct has a built in tool,  aqueduct , for deploying Aqueduct applications, managing database schemas, OAuth 2.0 clients and creating projects. See  Getting Started  for installation instructions. Many of the tasks for deployment rely on using this tool.  Aqueduct applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using  Heroku  to host your applications.", 
            "title": "Tasks"
        }, 
        {
            "location": "/deploy/#guides", 
            "text": "Running an Aqueduct Application Locally  Running an Aqueduct Application with Docker, Docker Compose and Kubernetes  Running an Aqueduct Application on Heroku  Running an Aqueduct Application on Amazon Web Services (AWS)  Running an Aqueduct Application without aqueduct serve", 
            "title": "Guides"
        }, 
        {
            "location": "/deploy/deploy_local/", 
            "text": "Deploying an Aqueduct Application on a Local Machine\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nTo run a local development version of an Aqueduct application with persistent storage. This is useful when developing client applications with an Aqueduct application. Make sure to also read \nTesting Aqueduct Applications\n.\n\n\nPrerequisites\n\n\n\n\nDart has been installed.\n\n\nPostgreSQL has been installed locally.\n\n\nAqueduct has been activated globally.\n\n\nAn application has been created with \naqueduct create\n.\n\n\n\n\nIf one or more of these is not true, see \nGetting Started\n.\n\n\nOverview\n\n\n\n\nCreate a local database.\n\n\nUpload the application schema to the local database.\n\n\nAdd an OAuth 2.0 client.\n\n\nModify the configuration file.\n\n\nRun the application.\n\n\n\n\nEstimated Time: 5 minutes.\n\n\nStep 1: Create a Local Database\n\n\nCreate a database with the same name as your application and a user that can access that database. Run the following SQL locally with a user that has privileges to create databases.\n\n\nCREATE\n \nDATABASE\n \napp_name\n;\n\n\nCREATE\n \nUSER\n \napp_name_user\n \nWITH\n \nCREATEDB\n;\n\n\nALTER\n \nUSER\n \napp_name_user\n \nWITH\n \nPASSWORD\n \nyourpassword\n;\n\n\nGRANT\n \nALL\n \nON\n \nDATABASE\n \napp_name\n \nTO\n \napp_name_user\n;\n\n\n\n\n\n\n\n\ndart_test database\n\n\nDo not use the name 'dart_test' for the database; this database is used by Aqueduct to run tests by default.\n\n\n\n\nStep 2: Upload the Application Schema\n\n\nIf you have not yet created database migration files for your project, run the database schema generation tool from the project directory:\n\n\naqueduct db generate\n\n\n\n\n\nThis command creates the file \nmigrations/00000001_initial.migration.dart\n. Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option \n--connect\n match those of the database created in the last step.\n\n\naqueduct db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name\n\n\n\n\n\n(Note that you may provide database credentials in a file named \ndatabase.yaml\n instead of using \n--connect\n. See \naqueduct db --help\n for details.)\n\n\nStep 3: Add an OAuth 2.0 client.\n\n\nIf you are using \npackage:aqueduct/managed_auth\n, you'll want to create an OAuth2 client identifier. From the command line, run the following, ensuring that the values for the option \n--connect\n match the recently created database.\n\n\naqueduct auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name\n\n\n\n\n\nStep 4: Modify the Configuration File\n\n\nIf \nconfig.yaml\n doesn't exist, create it by copying the configuration file template \nconfig.yaml.src\n.\n\n\nIn \nconfig.yaml\n, update the database credentials to the local database.\n\n\ndatabase\n:\n\n \nusername\n:\n \napp_name_user\n\n \npassword\n:\n \nyourpassword\n\n \nhost\n:\n \nlocalhost\n\n \nport\n:\n \n5432\n\n \ndatabaseName\n:\n \napp_name\n\n\n\n\n\n\nStep 5: Run the Application\n\n\nFrom the project directory, run:\n\n\naqueduct serve\n\n\n\n\n\nYour application is now running. You may also run the generated start script in your project's \nbin\n directory:\n\n\ndart bin/main.dart\n\n\n\n\n\nIf you restart the application, the data in your database will remain.", 
            "title": "Deploy Locally"
        }, 
        {
            "location": "/deploy/deploy_local/#deploying-an-aqueduct-application-on-a-local-machine", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on a Local Machine"
        }, 
        {
            "location": "/deploy/deploy_local/#purpose", 
            "text": "To run a local development version of an Aqueduct application with persistent storage. This is useful when developing client applications with an Aqueduct application. Make sure to also read  Testing Aqueduct Applications .", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_local/#prerequisites", 
            "text": "Dart has been installed.  PostgreSQL has been installed locally.  Aqueduct has been activated globally.  An application has been created with  aqueduct create .   If one or more of these is not true, see  Getting Started .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/deploy/deploy_local/#overview", 
            "text": "Create a local database.  Upload the application schema to the local database.  Add an OAuth 2.0 client.  Modify the configuration file.  Run the application.   Estimated Time: 5 minutes.", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/deploy_local/#step-1-create-a-local-database", 
            "text": "Create a database with the same name as your application and a user that can access that database. Run the following SQL locally with a user that has privileges to create databases.  CREATE   DATABASE   app_name ;  CREATE   USER   app_name_user   WITH   CREATEDB ;  ALTER   USER   app_name_user   WITH   PASSWORD   yourpassword ;  GRANT   ALL   ON   DATABASE   app_name   TO   app_name_user ;    dart_test database  Do not use the name 'dart_test' for the database; this database is used by Aqueduct to run tests by default.", 
            "title": "Step 1: Create a Local Database"
        }, 
        {
            "location": "/deploy/deploy_local/#step-2-upload-the-application-schema", 
            "text": "If you have not yet created database migration files for your project, run the database schema generation tool from the project directory:  aqueduct db generate  This command creates the file  migrations/00000001_initial.migration.dart . Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option  --connect  match those of the database created in the last step.  aqueduct db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name  (Note that you may provide database credentials in a file named  database.yaml  instead of using  --connect . See  aqueduct db --help  for details.)", 
            "title": "Step 2: Upload the Application Schema"
        }, 
        {
            "location": "/deploy/deploy_local/#step-3-add-an-oauth-20-client", 
            "text": "If you are using  package:aqueduct/managed_auth , you'll want to create an OAuth2 client identifier. From the command line, run the following, ensuring that the values for the option  --connect  match the recently created database.  aqueduct auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name", 
            "title": "Step 3: Add an OAuth 2.0 client."
        }, 
        {
            "location": "/deploy/deploy_local/#step-4-modify-the-configuration-file", 
            "text": "If  config.yaml  doesn't exist, create it by copying the configuration file template  config.yaml.src .  In  config.yaml , update the database credentials to the local database.  database : \n  username :   app_name_user \n  password :   yourpassword \n  host :   localhost \n  port :   5432 \n  databaseName :   app_name", 
            "title": "Step 4: Modify the Configuration File"
        }, 
        {
            "location": "/deploy/deploy_local/#step-5-run-the-application", 
            "text": "From the project directory, run:  aqueduct serve  Your application is now running. You may also run the generated start script in your project's  bin  directory:  dart bin/main.dart  If you restart the application, the data in your database will remain.", 
            "title": "Step 5: Run the Application"
        }, 
        {
            "location": "/deploy/deploy_docker/", 
            "text": "Deploying an Aqueduct Application using Docker\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nThis document will describe the steps to deploy an Aqueduct application through Docker, Docker Compose or a container orchestration platform like Kubernetes. For Dockerfile and Kubernetes templates, see \nthis repository\n.\n\n\nIf you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover the topics of Docker, Docker Compose or Kubernetes.\n\n\nDockerfiles\n\n\nThe following Dockerfile will run an Aqueduct application.\n\n\nFROM google/dart\n\nWORKDIR /app\nADD pubspec.* /app/\nRUN pub get --no-precompile\nADD . /app/\nRUN pub get --offline --no-precompile\n\nWORKDIR /app\nEXPOSE 80\n\nENTRYPOINT [\npub\n, \nrun\n, \naqueduct:aqueduct\n, \nserve\n, \n--port\n, \n80\n]\n\n\n\n\n\nDocker Compose\n\n\nTo deploy your application (which uses the Aqueduct ORM) using Docker Compose, use this template:\n\n\nDockerfile\n\n\nUse the \nDockerfile\n specified above.\n\n\ndocker-compose.yml\n\n\nversion: \n3\n\nservices:\n  my-app:\n    build: .\n    ports:\n    - \n80:80\n\n\n  db:\n    image: \npostgres:11\n\n    container_name: \npostgres_database\n\n    environment:\n      - POSTGRES_PASSWORD=password-from-config-yaml\n      - POSTGRES_USER=user-from-config-yaml\n      - POSTGRES_DB=db-from-config-yaml\n    ports:\n      - \n65432:port-from-config-yaml\n # If you want to expose the db from the container\n    volumes:\n      - db_data:/var/lib/postgresql/data\n\nvolumes:\n  db_data: {}\n\n\n\n\n\nOnce the service is up (using \ndocker-compose up -d\n), you can run your database migrations using\n\n\naqueduct db upgrade --connect postgres://user-from-config-yaml:password-from-config-yaml@hostname:65432/db-from-config-yaml\n\n\nKubernetes Objects\n\n\nFor more Kubernetes objects - including tasks for database migrations and OAuth 2.0 client management - see \nthis repository\n. The following is Kubernetes configuration file for starting an Aqueduct application and exposing it as a service. Replace \nAPP_NAME\n with your application's name.\n\n\napiVersion\n:\n \nv1\n\n\nkind\n:\n \nService\n\n\nmetadata\n:\n\n  \nname\n:\n \napi\n-\nservice\n\n  \nnamespace\n:\n \nAPP_NAME\n\n\nspec\n:\n\n  \nselector\n:\n\n    \napp\n:\n \nAPP_NAME\n\n    \nrole\n:\n \nbackend\n\n    \ntype\n:\n \napi\n\n  \nports\n:\n\n    \n-\n \nport\n:\n \n80\n\n      \ntargetPort\n:\n \n8082\n\n\n---\n\n\napiVersion\n:\n \napps\n/\nv1beta1\n\n\nkind\n:\n \nDeployment\n\n\nmetadata\n:\n\n  \nname\n:\n \napi\n-\ndeployment\n\n  \nnamespace\n:\n \nAPP_NAME\n\n\nspec\n:\n\n  \nreplicas\n:\n \n2\n\n  \ntemplate\n:\n\n    \nmetadata\n:\n\n      \nlabels\n:\n\n        \napp\n:\n \nAPP_NAME\n\n        \nrole\n:\n \nbackend\n\n        \ntype\n:\n \napi\n\n    \nspec\n:\n\n      \ncontainers\n:\n\n        \n-\n \nname\n:\n \nAPP_NAME\n\n          \n#\n \nIn\n \ndevelopment\n,\n \nsetting\n \n`\nimagePullPolicy\n:\n \nAlways\n`\n \nand\n \nusing\n \n:\nlatest\n \ntag\n \nis\n \nuseful\n.\n\n          \n#\n \nimagePullPolicy\n:\n \nAlways\n\n          \nimage\n:\n \nIMAGE\n\n          \nenvFrom\n:\n\n            \n-\n \nsecretRef\n:\n\n                \nname\n:\n \nsecrets\n\n            \n-\n \nconfigMapRef\n:\n\n                \nname\n:\n \nconfig\n\n          \nports\n:\n\n            \n-\n \ncontainerPort\n:\n \n8082\n\n      \nsecurityContext\n:\n\n              \nrunAsNonRoot\n:\n \ntrue", 
            "title": "Deploying with Docker and Kubernetes"
        }, 
        {
            "location": "/deploy/deploy_docker/#deploying-an-aqueduct-application-using-docker", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application using Docker"
        }, 
        {
            "location": "/deploy/deploy_docker/#purpose", 
            "text": "This document will describe the steps to deploy an Aqueduct application through Docker, Docker Compose or a container orchestration platform like Kubernetes. For Dockerfile and Kubernetes templates, see  this repository .  If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover the topics of Docker, Docker Compose or Kubernetes.", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_docker/#dockerfiles", 
            "text": "The following Dockerfile will run an Aqueduct application.  FROM google/dart\n\nWORKDIR /app\nADD pubspec.* /app/\nRUN pub get --no-precompile\nADD . /app/\nRUN pub get --offline --no-precompile\n\nWORKDIR /app\nEXPOSE 80\n\nENTRYPOINT [ pub ,  run ,  aqueduct:aqueduct ,  serve ,  --port ,  80 ]", 
            "title": "Dockerfiles"
        }, 
        {
            "location": "/deploy/deploy_docker/#docker-compose", 
            "text": "To deploy your application (which uses the Aqueduct ORM) using Docker Compose, use this template:  Dockerfile  Use the  Dockerfile  specified above.  docker-compose.yml  version:  3 \nservices:\n  my-app:\n    build: .\n    ports:\n    -  80:80 \n\n  db:\n    image:  postgres:11 \n    container_name:  postgres_database \n    environment:\n      - POSTGRES_PASSWORD=password-from-config-yaml\n      - POSTGRES_USER=user-from-config-yaml\n      - POSTGRES_DB=db-from-config-yaml\n    ports:\n      -  65432:port-from-config-yaml  # If you want to expose the db from the container\n    volumes:\n      - db_data:/var/lib/postgresql/data\n\nvolumes:\n  db_data: {}  Once the service is up (using  docker-compose up -d ), you can run your database migrations using  aqueduct db upgrade --connect postgres://user-from-config-yaml:password-from-config-yaml@hostname:65432/db-from-config-yaml", 
            "title": "Docker Compose"
        }, 
        {
            "location": "/deploy/deploy_docker/#kubernetes-objects", 
            "text": "For more Kubernetes objects - including tasks for database migrations and OAuth 2.0 client management - see  this repository . The following is Kubernetes configuration file for starting an Aqueduct application and exposing it as a service. Replace  APP_NAME  with your application's name.  apiVersion :   v1  kind :   Service  metadata : \n   name :   api - service \n   namespace :   APP_NAME  spec : \n   selector : \n     app :   APP_NAME \n     role :   backend \n     type :   api \n   ports : \n     -   port :   80 \n       targetPort :   8082  ---  apiVersion :   apps / v1beta1  kind :   Deployment  metadata : \n   name :   api - deployment \n   namespace :   APP_NAME  spec : \n   replicas :   2 \n   template : \n     metadata : \n       labels : \n         app :   APP_NAME \n         role :   backend \n         type :   api \n     spec : \n       containers : \n         -   name :   APP_NAME \n           #   In   development ,   setting   ` imagePullPolicy :   Always `   and   using   : latest   tag   is   useful . \n           #   imagePullPolicy :   Always \n           image :   IMAGE \n           envFrom : \n             -   secretRef : \n                 name :   secrets \n             -   configMapRef : \n                 name :   config \n           ports : \n             -   containerPort :   8082 \n       securityContext : \n               runAsNonRoot :   true", 
            "title": "Kubernetes Objects"
        }, 
        {
            "location": "/deploy/deploy_heroku/", 
            "text": "Deploying an Aqueduct Application on Heroku\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nTo run a production Aqueduct application on Heroku. Make sure to also read \nTesting Aqueduct Applications\n.\n\n\nPrerequisites\n\n\n\n\nDart has been installed.\n\n\nA Heroku account.\n\n\ngit\n has been installed.\n\n\nheroku\n has been installed.\n\n\nAqueduct has been activated.\n\n\n\n\nOverview\n\n\n\n\nSetting up a Heroku application\n\n\nSetting up an Aqueduct application to run on Heroku\n\n\nConfiguring application values\n\n\nRunning the Aqueduct application\n\n\n\n\nEstimated Time: 5 minutes.\n\n\nStep 1: Setting up a Heroku Application\n\n\nCreate a new application in Heroku's web portal, and if you are using a database, add the 'Heroku Postgres' add-on.\n\n\nNavigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note that there is a DATABASE_URL environment variable that is the connection details for your PostgreSQL database. You won't need to remember the value, only that this environment variable exists.\n\n\nStep 2: Setting up an Aqueduct Application to Run on Heroku\n\n\nIf you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository if it is not already:\n\n\naqueduct create app_name\n\ncd\n app_name\ngit init\n\n\n\n\n\nRun the following commands to configure your project in Heroku's environment.\n\n\n\n\nHeroku Application Name\n\n\nIn the following commands, ensure that \napp_name\n is the name of your \nHeroku application\n created in their web portal, not the name of your Aqueduct application.\n\n\n\n\n# This is an interactive command that you have to enter your username and password.\n\nheroku login\n\n\n# This adds a remote repository hosted by Heroku for your application that you push to.\n\nheroku git:remote -a app_name\n\n\n# Specifies the Dart SDK to use\n\nheroku config:set \nDART_SDK_URL\n=\nhttps://storage.googleapis.com/dart-archive/channels/stable/release/latest/sdk/dartsdk-linux-x64-release.zip\n\n\n# Specifies the Heroku Buildpack to use\n\nheroku config:set \nBUILDPACK_URL\n=\nhttps://github.com/stablekernel/heroku-buildpack-dart.git\n\n\n# Specifies that aqueduct should be activated\n\nheroku config:set \nDART_GLOBAL_PACKAGES\n=\naqueduct@3.0.0\n\nheroku config:set \nPATH\n=\n/app/bin:/usr/local/bin:/usr/bin:/bin:/app/.pub-cache/bin:/app/dart-sdk/bin\nheroku config:set \nPUB_CACHE\n=\n/app/pub-cache\n\n\n\n\n\nThen, create a new file in your project directory named \nProcfile\n (with no suffix) and enter the following:\n\n\nrelease: /app/dart-sdk/bin/pub global run aqueduct:aqueduct db upgrade --connect $DATABASE_URL\nweb: /app/dart-sdk/bin/pub global run aqueduct:aqueduct serve --port $PORT --config-path heroku.yaml\n\n\n\n\n\nThis file tells Heroku how to run your application, and to execute any database migrations each time you push a release. Make sure this file is checked into version control:\n\n\ngit commit -am \nAdds Procfile\n\n\n\n\n\n\nStep 3: Configuring Application Values\n\n\nHeroku provides configuration values through environment variables. In our \nProcfile\n, we indicated that we will use a file named \nheroku.yaml\n for configuration. This file will map configuration values in our application to environment variables in the Heroku platform. Your configuration file may vary, but it is important to note that if you are using a database, the database credentials are provided through a \nconnection string\n. A connection string looks like this: \npostgres://user:password@host:5432/name\n and by default, Heroku stores it in the environment variable named \nDATABASE_URL\n.\n\n\nIn \nheroku.yaml\n (which you will need to create in your project directory), you can reference an environment variable by prefixing its name with a \n$\n. When using the built-in \nDatabaseConfiguration\n type, you can assign the connection string like so:\n\n\ndatabase\n:\n \n$DATABASE_URL\n\n\n\n\n\n\n\n\nYour heroku.yaml might be different\n\n\nMake sure the structure of your \nheroku.yaml\n file matches the expected structure in your application's \nConfiguration\n subclass.\n\n\n\n\nCheck \nheroku.yaml\n into version control.\n\n\ngit commit -am \nadd heroku.yaml\n\n\n\n\n\n\nStep 4: Running the Aqueduct Application\n\n\nIf your application uses a database, make sure you have generated your migration file(s) and added it to version control. The \nProcfile\n will ensure that database is up to date with any migrations checked into source control before running your app. Generate your migration file with the following command from your project directory and then check it into version control:\n\n\naqueduct db generate\ngit commit -am \nadds migration files\n\n\n\n\n\n\nNow, you can deploy your application. It's as simple as this:\n\n\ngit push heroku master\n\n\n\n\n\nThis command pushes your code to a remote git server hosted by Heroku, which triggers your application to run its release script.\n\n\nNow that your application's database schema has been uploaded, you can configure your OAuth 2 server with client identifiers if you are using \npackage:aqueduct/managed_auth\n. The following command will run within your application's remote environment.\n\n\nheroku run /app/dart-sdk/bin/pub global run aqueduct:aqueduct auth add-client --id com.app.standard --secret secret --connect \n\\$\nDATABASE_URL\n\n\n\n\n\nFinally, scale up a dyno and the application will start receiving requests:\n\n\nheroku ps:scale \nweb\n=\n1\n\n\n\n\n\n\nNow your application is running!", 
            "title": "Deploy on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#deploying-an-aqueduct-application-on-heroku", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#purpose", 
            "text": "To run a production Aqueduct application on Heroku. Make sure to also read  Testing Aqueduct Applications .", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_heroku/#prerequisites", 
            "text": "Dart has been installed.  A Heroku account.  git  has been installed.  heroku  has been installed.  Aqueduct has been activated.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/deploy/deploy_heroku/#overview", 
            "text": "Setting up a Heroku application  Setting up an Aqueduct application to run on Heroku  Configuring application values  Running the Aqueduct application   Estimated Time: 5 minutes.", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-1-setting-up-a-heroku-application", 
            "text": "Create a new application in Heroku's web portal, and if you are using a database, add the 'Heroku Postgres' add-on.  Navigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note that there is a DATABASE_URL environment variable that is the connection details for your PostgreSQL database. You won't need to remember the value, only that this environment variable exists.", 
            "title": "Step 1: Setting up a Heroku Application"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-2-setting-up-an-aqueduct-application-to-run-on-heroku", 
            "text": "If you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository if it is not already:  aqueduct create app_name cd  app_name\ngit init  Run the following commands to configure your project in Heroku's environment.   Heroku Application Name  In the following commands, ensure that  app_name  is the name of your  Heroku application  created in their web portal, not the name of your Aqueduct application.   # This is an interactive command that you have to enter your username and password. \nheroku login # This adds a remote repository hosted by Heroku for your application that you push to. \nheroku git:remote -a app_name # Specifies the Dart SDK to use \nheroku config:set  DART_SDK_URL = https://storage.googleapis.com/dart-archive/channels/stable/release/latest/sdk/dartsdk-linux-x64-release.zip # Specifies the Heroku Buildpack to use \nheroku config:set  BUILDPACK_URL = https://github.com/stablekernel/heroku-buildpack-dart.git # Specifies that aqueduct should be activated \nheroku config:set  DART_GLOBAL_PACKAGES = aqueduct@3.0.0 \nheroku config:set  PATH = /app/bin:/usr/local/bin:/usr/bin:/bin:/app/.pub-cache/bin:/app/dart-sdk/bin\nheroku config:set  PUB_CACHE = /app/pub-cache  Then, create a new file in your project directory named  Procfile  (with no suffix) and enter the following:  release: /app/dart-sdk/bin/pub global run aqueduct:aqueduct db upgrade --connect $DATABASE_URL\nweb: /app/dart-sdk/bin/pub global run aqueduct:aqueduct serve --port $PORT --config-path heroku.yaml  This file tells Heroku how to run your application, and to execute any database migrations each time you push a release. Make sure this file is checked into version control:  git commit -am  Adds Procfile", 
            "title": "Step 2: Setting up an Aqueduct Application to Run on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-3-configuring-application-values", 
            "text": "Heroku provides configuration values through environment variables. In our  Procfile , we indicated that we will use a file named  heroku.yaml  for configuration. This file will map configuration values in our application to environment variables in the Heroku platform. Your configuration file may vary, but it is important to note that if you are using a database, the database credentials are provided through a  connection string . A connection string looks like this:  postgres://user:password@host:5432/name  and by default, Heroku stores it in the environment variable named  DATABASE_URL .  In  heroku.yaml  (which you will need to create in your project directory), you can reference an environment variable by prefixing its name with a  $ . When using the built-in  DatabaseConfiguration  type, you can assign the connection string like so:  database :   $DATABASE_URL    Your heroku.yaml might be different  Make sure the structure of your  heroku.yaml  file matches the expected structure in your application's  Configuration  subclass.   Check  heroku.yaml  into version control.  git commit -am  add heroku.yaml", 
            "title": "Step 3: Configuring Application Values"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-4-running-the-aqueduct-application", 
            "text": "If your application uses a database, make sure you have generated your migration file(s) and added it to version control. The  Procfile  will ensure that database is up to date with any migrations checked into source control before running your app. Generate your migration file with the following command from your project directory and then check it into version control:  aqueduct db generate\ngit commit -am  adds migration files   Now, you can deploy your application. It's as simple as this:  git push heroku master  This command pushes your code to a remote git server hosted by Heroku, which triggers your application to run its release script.  Now that your application's database schema has been uploaded, you can configure your OAuth 2 server with client identifiers if you are using  package:aqueduct/managed_auth . The following command will run within your application's remote environment.  heroku run /app/dart-sdk/bin/pub global run aqueduct:aqueduct auth add-client --id com.app.standard --secret secret --connect  \\$ DATABASE_URL  Finally, scale up a dyno and the application will start receiving requests:  heroku ps:scale  web = 1   Now your application is running!", 
            "title": "Step 4: Running the Aqueduct Application"
        }, 
        {
            "location": "/deploy/deploy_aws/", 
            "text": "Deploying an Aqueduct Application on Remote VMs\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nThis document will describe the steps to deploy an Aqueduct application to a remote machine that you are able to \nssh\n into. This is often the case for Amazon Web Service (AWS) EC2 instances, Google Cloud Compute Instances, Azure Virtual Machines, and rented boxes on platforms like Digital Ocean or other cloud providers.\n\n\nIf you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover many of the steps necessary to deploy an application. Prefer to use a platform like Heroku or one that supports Docker. See the guides on \nHeroku\n and \nDocker\n for better options.\n\n\nSummary\n\n\nAqueduct applications are run by using \naqueduct serve\n or \ndart bin/main.dart\n.\n\n\n# in project directory\naqueduct serve\n\n# or\n\n# in project directory\ndart bin/main.dart\n\n\n\n\n\nThe target machine must have Dart installed. If you are using \naqueduct serve\n, you must also activate the CLI on the target machine:\n\n\npub global activate aqueduct\n\n\n\n\n\nYour source code must also be available on the target machine. You can transfer your source to a machine with tools like \nftp\n, \nscp\n, \nrsync\n and \ngit\n.\n\n\nAqueduct will listen on port 8888 by default. Change this value at the CLI \naqueduct serve --port 80\n or in \nbin/main.dart\n. Ensure that security controls on your instance can accept connections on the port Aqueduct is listening on. It is preferable to use a reverse proxy (e.g. nginx or a load balancer) instead of serving the application directly.\n\n\nUse tools like \nsupervisord\n to ensure the application restarts if the VM crashes.\n\n\nConfiguration Management\n\n\nWhen deploying directly to a VM, it is your responsibility to manage your configuration file. This can often be done by transferring an environment specific \nconfig.yaml\n file to your target machine and storing it in your project's directory on the remote machine.\n\n\nCLI Tools\n\n\nMany deployments will need to perform database migrations and OAuth 2.0 client identifier management with the \naqueduct\n CLI. You can run these tools locally with the \n--connect\n flag to specify the location of your database instance. Ensure that you have the propery security controls to access the database instance from your local machine.", 
            "title": "Deploy on AWS"
        }, 
        {
            "location": "/deploy/deploy_aws/#deploying-an-aqueduct-application-on-remote-vms", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on Remote VMs"
        }, 
        {
            "location": "/deploy/deploy_aws/#purpose", 
            "text": "This document will describe the steps to deploy an Aqueduct application to a remote machine that you are able to  ssh  into. This is often the case for Amazon Web Service (AWS) EC2 instances, Google Cloud Compute Instances, Azure Virtual Machines, and rented boxes on platforms like Digital Ocean or other cloud providers.  If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover many of the steps necessary to deploy an application. Prefer to use a platform like Heroku or one that supports Docker. See the guides on  Heroku  and  Docker  for better options.", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_aws/#summary", 
            "text": "Aqueduct applications are run by using  aqueduct serve  or  dart bin/main.dart .  # in project directory\naqueduct serve\n\n# or\n\n# in project directory\ndart bin/main.dart  The target machine must have Dart installed. If you are using  aqueduct serve , you must also activate the CLI on the target machine:  pub global activate aqueduct  Your source code must also be available on the target machine. You can transfer your source to a machine with tools like  ftp ,  scp ,  rsync  and  git .  Aqueduct will listen on port 8888 by default. Change this value at the CLI  aqueduct serve --port 80  or in  bin/main.dart . Ensure that security controls on your instance can accept connections on the port Aqueduct is listening on. It is preferable to use a reverse proxy (e.g. nginx or a load balancer) instead of serving the application directly.  Use tools like  supervisord  to ensure the application restarts if the VM crashes.", 
            "title": "Summary"
        }, 
        {
            "location": "/deploy/deploy_aws/#configuration-management", 
            "text": "When deploying directly to a VM, it is your responsibility to manage your configuration file. This can often be done by transferring an environment specific  config.yaml  file to your target machine and storing it in your project's directory on the remote machine.", 
            "title": "Configuration Management"
        }, 
        {
            "location": "/deploy/deploy_aws/#cli-tools", 
            "text": "Many deployments will need to perform database migrations and OAuth 2.0 client identifier management with the  aqueduct  CLI. You can run these tools locally with the  --connect  flag to specify the location of your database instance. Ensure that you have the propery security controls to access the database instance from your local machine.", 
            "title": "CLI Tools"
        }, 
        {
            "location": "/deploy/script/", 
            "text": "You may also run Aqueduct applications with a standalone script, instead of \naqueduct serve\n. In fact, \naqueduct serve\n creates a temporary Dart script to run the application. If you created your application with \naqueduct create\n, a standalone already exists in your project named \nbin/main.dart\n.\n\n\nA sample script looks like this:\n\n\nimport\n \ndart:async\n;\n\n\nimport\n \ndart:io\n;\n\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:my_application/my_application.dart\n;\n\n\n\nFuture\n \nmain\n()\n \nasync\n \n{\n\n  \nvar\n \napp\n \n=\n \nnew\n \nApplication\nMyApplicationChannel\n()\n\n    \n..\noptions\n.\nport\n \n=\n \n8888\n\n    \n..\noptions\n.\nconfigurationFilePath\n \n=\n \nconfig.yaml\n;\n\n\n  \nawait\n \napp\n.\nstart\n(\nnumberOfInstances:\n \n3\n);\n    \n\n}\n\n\n\n\n\n\nThis script can be used in place of \naqueduct serve\n, but you must configure all \nApplicationOptions\n in this script and not through the CLI.", 
            "title": "Deploying without aqueduct serve"
        }, 
        {
            "location": "/openapi/", 
            "text": "Tasks\n\n\nAqueduct applications auto-generate an OpenAPI 3.0 document.\n\n\nMost of your OpenAPI document is generated by reflecting on your application code, especially \nResourceController\n subclasses. You add customization or additional information by overriding methods in \nAPIComponentDocumenter\n and \nAPIOperationDocumenter\n. At minimum, you override methods in your \nResourceController\n to document the responses your application will send for a particular endpoint.\n\n\nYou create documents with the \naqueduct document\n command-line tool.\n\n\nGuides\n\n\n\n\nCreating an OpenAPI Document\n\n\nDocumenting Components\n\n\nDocumenting Endpoint Controllers\n\n\nDocumenting Middleware Controllers", 
            "title": "Overview"
        }, 
        {
            "location": "/openapi/#tasks", 
            "text": "Aqueduct applications auto-generate an OpenAPI 3.0 document.  Most of your OpenAPI document is generated by reflecting on your application code, especially  ResourceController  subclasses. You add customization or additional information by overriding methods in  APIComponentDocumenter  and  APIOperationDocumenter . At minimum, you override methods in your  ResourceController  to document the responses your application will send for a particular endpoint.  You create documents with the  aqueduct document  command-line tool.", 
            "title": "Tasks"
        }, 
        {
            "location": "/openapi/#guides", 
            "text": "Creating an OpenAPI Document  Documenting Components  Documenting Endpoint Controllers  Documenting Middleware Controllers", 
            "title": "Guides"
        }, 
        {
            "location": "/openapi/cli/", 
            "text": "Creating OpenAPI Documents\n\n\nIn this document, you'll learn how to use the \naqueduct\n command line tool to generate an OpenAPI document for your application.\n\n\nOpenAPI Documents\n\n\nOpenAPI documents describe the details of every request and possible response your application has. These documents are JSON objects that follow a specification. This specification defines which properties the document can (or must) have. By following this specification, your application can take advantage of tools such as documentation viewers and source code generators.\n\n\nThe two most important objects in an OpenAPI document are components and path operations. A path operation contains an expected request and possible responses. Components are reusable definitions that you can use in a path operation. For example, a 400 Bad Request response component can be reused across path operations that may send this response.\n\n\nMost of the documentation process revolves around registering components and creating path operations.\n\n\nThe aqueduct document Command\n\n\nDocuments can be written by hand, but it takes a lot of time and is hard to keep in sync with your code. Aqueduct analyzes your code to build (most) of a document for you. You run the \naqueduct document\n command in your project's directory, and it prints the JSON document to your console.\n\n\ncd\n my_project/\naqueduct document\n\n-- Aqueduct CLI Version: \n3\n.0.0\n-- Aqueduct project version: \n3\n.0.0\n\n{\nopenapi\n:\n3.0.0\n,\ninfo\n:...\n\n\n\n\n\nYou may copy the output to use it in another tool; for example, by entering it into \nSwagger Editor\n. If you want to build a tool that runs this command, but don't want to parse the version info from the output, use the \n--machine\n flag.\n\n\naqueduct document --machine\n\n{\nopenapi\n:\n3.0.0\n,\ninfo\n:...\n\n\n\n\n\nMuch of the metadata in an OpenAPI document - such as title or version - is derived from your application's \npubspec.yaml\n. If you want to override the derived values, or provide values that can't be derived, use options like \n--title\n or \n--license-name\n. See \naqueduct document --help\n for all options.\n\n\nHow Applications are Documented\n\n\nWhen you run the \naqueduct document\n command, it creates an empty \nAPIDocument\n that objects in your application will populate. Your application goes through its normal initialization process (i.e., \nprepare\n and \nentryPoint\n). Controllers and service objects are then told to register components. For example, all \nManagedObject\ns register themselves as a reusable schema component. After components are registered, the controllers in an application are told to create path operations that define the requests they handle.\n\n\n\n\nConfiguration Files\n\n\nBecause your application goes through initialization as if it were going to run the application, you must have a valid configuration file when documenting. This defaults to 'config.yaml.src', the same file you use for running tests. See \naqueduct document --help\n to use a different file.\n\n\n\n\nDocumenting Components\n\n\nObjects that register components implement \nAPIComponentDocumenter.documentComponents\n. Controllers - which implement this method - automatically document their components as long as they are linked to your application's entry point. Other types of objects that implement this method will be automatically documented if they are declared as a property of your \nApplicationChannel\n.\n\n\nFor example, in the following code, the \nAuthServer\n, \nRouter\n and \nPathController\n all automatically document their components.\n\n\nclass\n \nMyChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(...);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n    \nrouter\n.\nroute\n(\n/path\n).\nlink\n(()\n \n=\n \nnew\n \nPathController\n());\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIn most applications, the automatically documented objects are the only objects that register components. If you have an object that needs to register components, but aren't automatically documented, override \ndocumentComponents\n in your app channel to tell that object to register components. You must call the superclass' implementation.\n\n\nclass\n \nMyChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n...\n\n  \n@\noverride\n\n  \nvoid\n \ndocumentComponents\n(\nAPIDocumentContext\n \ncontext\n)\n \n{\n\n    \nsuper\n.\ndocumentComponents\n(\ncontext\n);\n\n\n    \nobjectWithComponents\n.\ndocumentComponents\n(\ncontext\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nYou can override \ndocumentComponents\n in controllers and services that you create. Read the \nguide on component documentation\n for more details.\n\n\nDocument Path Operations\n\n\nA path operation is the expected request and possible responses for a path (e.g., \n/users\n) and its request method (e.g., \nGET\n). Each operation describes how to send a request to the server, like which headers or query parameters to include. Responses describe the status code, headers and body that can be sent. Each controller implements \nAPIOperationDocumenter.documentOperations\n to define this information for the requests it handles.\n\n\nBuilt-in controllers like \nAuthorizer\n and \nResourceController\n already implement this method. You typically only override this method when creating your own middleware. For more information on documenting middleware, see \nthis guide\n.\n\n\nWhen creating documentation for \nResourceController\ns, request parameters are derived from your bindings, but you still need to provide the possible responses. For more information on documenting endpoint controllers, see \nthis guide\n.", 
            "title": "Creating an OpenAPI Document"
        }, 
        {
            "location": "/openapi/cli/#creating-openapi-documents", 
            "text": "In this document, you'll learn how to use the  aqueduct  command line tool to generate an OpenAPI document for your application.", 
            "title": "Creating OpenAPI Documents"
        }, 
        {
            "location": "/openapi/cli/#openapi-documents", 
            "text": "OpenAPI documents describe the details of every request and possible response your application has. These documents are JSON objects that follow a specification. This specification defines which properties the document can (or must) have. By following this specification, your application can take advantage of tools such as documentation viewers and source code generators.  The two most important objects in an OpenAPI document are components and path operations. A path operation contains an expected request and possible responses. Components are reusable definitions that you can use in a path operation. For example, a 400 Bad Request response component can be reused across path operations that may send this response.  Most of the documentation process revolves around registering components and creating path operations.", 
            "title": "OpenAPI Documents"
        }, 
        {
            "location": "/openapi/cli/#the-aqueduct-document-command", 
            "text": "Documents can be written by hand, but it takes a lot of time and is hard to keep in sync with your code. Aqueduct analyzes your code to build (most) of a document for you. You run the  aqueduct document  command in your project's directory, and it prints the JSON document to your console.  cd  my_project/\naqueduct document\n\n-- Aqueduct CLI Version:  3 .0.0\n-- Aqueduct project version:  3 .0.0 { openapi : 3.0.0 , info :...  You may copy the output to use it in another tool; for example, by entering it into  Swagger Editor . If you want to build a tool that runs this command, but don't want to parse the version info from the output, use the  --machine  flag.  aqueduct document --machine { openapi : 3.0.0 , info :...  Much of the metadata in an OpenAPI document - such as title or version - is derived from your application's  pubspec.yaml . If you want to override the derived values, or provide values that can't be derived, use options like  --title  or  --license-name . See  aqueduct document --help  for all options.", 
            "title": "The aqueduct document Command"
        }, 
        {
            "location": "/openapi/cli/#how-applications-are-documented", 
            "text": "When you run the  aqueduct document  command, it creates an empty  APIDocument  that objects in your application will populate. Your application goes through its normal initialization process (i.e.,  prepare  and  entryPoint ). Controllers and service objects are then told to register components. For example, all  ManagedObject s register themselves as a reusable schema component. After components are registered, the controllers in an application are told to create path operations that define the requests they handle.   Configuration Files  Because your application goes through initialization as if it were going to run the application, you must have a valid configuration file when documenting. This defaults to 'config.yaml.src', the same file you use for running tests. See  aqueduct document --help  to use a different file.", 
            "title": "How Applications are Documented"
        }, 
        {
            "location": "/openapi/cli/#documenting-components", 
            "text": "Objects that register components implement  APIComponentDocumenter.documentComponents . Controllers - which implement this method - automatically document their components as long as they are linked to your application's entry point. Other types of objects that implement this method will be automatically documented if they are declared as a property of your  ApplicationChannel .  For example, in the following code, the  AuthServer ,  Router  and  PathController  all automatically document their components.  class   MyChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n\n   @ override \n   Future   prepare ()   async   { \n     authServer   =   new   AuthServer (...); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n     router . route ( /path ). link (()   =   new   PathController ()); \n     return   router ; \n   }  }   In most applications, the automatically documented objects are the only objects that register components. If you have an object that needs to register components, but aren't automatically documented, override  documentComponents  in your app channel to tell that object to register components. You must call the superclass' implementation.  class   MyChannel   extends   ApplicationChannel   { \n   ... \n   @ override \n   void   documentComponents ( APIDocumentContext   context )   { \n     super . documentComponents ( context ); \n\n     objectWithComponents . documentComponents ( context ); \n   }  }   You can override  documentComponents  in controllers and services that you create. Read the  guide on component documentation  for more details.", 
            "title": "Documenting Components"
        }, 
        {
            "location": "/openapi/cli/#document-path-operations", 
            "text": "A path operation is the expected request and possible responses for a path (e.g.,  /users ) and its request method (e.g.,  GET ). Each operation describes how to send a request to the server, like which headers or query parameters to include. Responses describe the status code, headers and body that can be sent. Each controller implements  APIOperationDocumenter.documentOperations  to define this information for the requests it handles.  Built-in controllers like  Authorizer  and  ResourceController  already implement this method. You typically only override this method when creating your own middleware. For more information on documenting middleware, see  this guide .  When creating documentation for  ResourceController s, request parameters are derived from your bindings, but you still need to provide the possible responses. For more information on documenting endpoint controllers, see  this guide .", 
            "title": "Document Path Operations"
        }, 
        {
            "location": "/openapi/components/", 
            "text": "Document Components\n\n\nIn this document, you'll learn how to register and use OpenAPI components in your application's documentation.\n\n\nRegistering Components with APIDocumentContext\n\n\nWhen your application is being documented, a single instance of \nAPIDocumentContext\n is created and passed to every documentation method. The context stores the document being created, but more importantly, is a container for reusable components. You may register components by implementing \nAPIComponentDocumenter\n and implementing its abstract method. For example, the following code registers a reusable schema object:\n\n\nclass\n \nSourceRepository\n \nimplements\n \nAPIComponentDocumenter\n \n{\n\n  \n@\noverride\n\n  \nvoid\n \ndocumentComponents\n(\nAPIDocumentContext\n \ncontext\n)\n \n{\n\n    \nsuper\n.\ndocumentComponents\n(\ncontext\n);\n\n\n    \ncontext\n.\nschema\n.\nregister\n(\nSourceRepository\n,\n\n        \nAPISchemaObject\n.\nobject\n({\n\n          \nid\n:\n \nAPISchemaObject\n.\ninteger\n(),\n\n          \nname\n:\n \nAPISchemaObject\n.\nstring\n()\n\n        \n});\n          \n  \n}\n\n\n}\n\n\n\n\n\n\nA \"SourceRepository\" is an object that contains two fields, \"id\" (an integer) and \"name\" (a string). This component can be used anywhere a schema object can be used. Schema objects are one type of component that document what is typically considered to be a 'model object'. You most often see schema objects in request and response bodies. By default, each of your \nManagedObject\ns are registered as schema objects. The other types of components are: responses, request bodies, parameters, headers, security schemes, and callbacks.\n\n\nComponents must be registered with a name, but can additionally be registered with a type. This allows users of a component to reference it by its Dart type. Including a type reference for an object is an optional argument when registering.\n\n\ncontext\n.\nschema\n.\nregister\n(\nSourceRepository\n,\n\n    \nAPISchemaObject\n.\nobject\n({\n\n      \nid\n:\n \nAPISchemaObject\n.\ninteger\n(),\n\n      \nname\n:\n \nAPISchemaObject\n.\nstring\n()\n\n    \n},\n \nrepresentation:\n \nSourceRepository\n);\n          \n\n\n\n\n\nThe order in which components are registered and referenced does not matter. If you reference a component that is created later in the documentation process, it will be resolved prior to the document being completed. If a referenced component is never registered, an error is thrown and your document will fail to generate.\n\n\nUsing Components\n\n\nComponents can be used when declaring path operations, or as part of other components. For example, if you were to describe a response whose body was a component named \"SourceRepository\", it would look like this:\n\n\nclass\n \nRepositoryController\n \nextends\n \nResourceController\n \n{\n\n  \n...\n\n\n  \n@\noverride\n\n  \nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n    \nif\n \n(\noperation\n.\nmethod\n \n==\n \nGET\n)\n \n{\n\n      \nreturn\n \n{\n\n        \n200\n:\n \nAPIResponse\n.\nschema\n(\ncontext\n.\nschema\n[\nSourceRepository\n])\n\n      \n};\n\n    \n}\n\n    \nreturn\n \nnull\n;\n\n  \n}\n  \n\n}\n\n\n\n\n\n\nIf an object has been registered by its type, you may use \ngetObjectWithType\n.\n\n\nclass\n \nRepositoryController\n \nextends\n \nResourceController\n \n{\n\n  \n...\n\n\n  \n@\noverride\n\n  \nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n    \nif\n \n(\noperation\n.\nmethod\n \n==\n \nGET\n)\n \n{\n\n      \nreturn\n \n{\n\n        \n200\n:\n \nAPIResponse\n.\nschema\n(\ncontext\n.\nschema\n.\ngetObjectWithType\n(\nSourceRepository\n))\n\n      \n};\n\n    \n}\n\n    \nreturn\n \nnull\n;\n\n  \n}\n  \n\n}\n\n\n\n\n\n\nComponent Discovery\n\n\nAll controllers are can document components when they are linked to the entry point. Objects other than controllers will automatically document their components if they implement \nAPIComponentDocumenter\n \nand\n are declared properties of your \nApplicationChannel\n. (See \nthis guide\n for other options.)\n\n\nBuilt-in Aqueduct types will register any applicable components. This includes the types that handle OAuth2 as well as all \nManagedObject\n subclasses in your application.\n\n\nManagedObject Discovery\n\n\nDeclaring a \nManagedContext\n as a property of your \nApplicationChannel\n will automatically document the managed objects of your application as schema components.\n\n\nSerializable Discovery\n\n\nIf a \nSerializable\n object is bound to a request body in a \nResourceController\n, it will automatically be documented as a schema component. By default, the properties of the \nSerializable\n object are reflected on to produce this component. To override this behavior and provide your own component documentation, implement the following method in your \nSerializable\n subclass:\n\n\nclass\n \nPerson\n \nextends\n \nSerializable\n \n{\n\n  \nString\n \nname\n;\n\n\n  \nMap\nString\n,\n \ndynamic\n \nasMap\n()\n \n=\n \n{\nname\n:\n \nname\n};\n\n  \nvoid\n \nreadFromMap\n(\nMap\nString\n,\n \ndynamic\n \nmap\n)\n \n{\n\n    \nname\n \n=\n \nmap\n[\nname\n];\n\n  \n}\n\n\n  \nAPISchemaObject\n \ndocumentSchema\n(\nAPIDocumentContext\n \ncontext\n)\n \n{\n\n    \nreturn\n \nAPISchemaObject\n.\nobject\n(\nproperties:\n \n{\n\n      \nname\n:\n \nAPISchemaObject\n.\nstring\n()\n\n    \n});\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIf you \nSerializable\n type is not bound to a resource controller operation, you must register it yourself. This typically occurs by overriding \ndocumentComponents\n in the controller that uses the type.\n\n\nclass\n \nMyController\n \nextends\n \nResourceController\n \n{\n\n  \n...\n\n\n  \n@\noverride\n\n  \nvoid\n \ndocumentComponents\n(\nAPIDocumentContext\n \ncontext\n)\n \n{\n\n    \nsuper\n.\ndocumentComponents\n(\ncontext\n);\n\n\n    \nfinal\n \npersonSchema\n \n=\n \nPerson\n().\ndocumentSchema\n(\ncontext\n);\n\n    \ncontext\n.\nschema\n.\nregister\n(\n\n      \nPerson\n,\n\n      \npersonSchema\n,\n\n      \nrepresentation:\n \nPerson\n);\n          \n  \n}\n\n\n}", 
            "title": "Documenting Components"
        }, 
        {
            "location": "/openapi/components/#document-components", 
            "text": "In this document, you'll learn how to register and use OpenAPI components in your application's documentation.", 
            "title": "Document Components"
        }, 
        {
            "location": "/openapi/components/#registering-components-with-apidocumentcontext", 
            "text": "When your application is being documented, a single instance of  APIDocumentContext  is created and passed to every documentation method. The context stores the document being created, but more importantly, is a container for reusable components. You may register components by implementing  APIComponentDocumenter  and implementing its abstract method. For example, the following code registers a reusable schema object:  class   SourceRepository   implements   APIComponentDocumenter   { \n   @ override \n   void   documentComponents ( APIDocumentContext   context )   { \n     super . documentComponents ( context ); \n\n     context . schema . register ( SourceRepository , \n         APISchemaObject . object ({ \n           id :   APISchemaObject . integer (), \n           name :   APISchemaObject . string () \n         });           \n   }  }   A \"SourceRepository\" is an object that contains two fields, \"id\" (an integer) and \"name\" (a string). This component can be used anywhere a schema object can be used. Schema objects are one type of component that document what is typically considered to be a 'model object'. You most often see schema objects in request and response bodies. By default, each of your  ManagedObject s are registered as schema objects. The other types of components are: responses, request bodies, parameters, headers, security schemes, and callbacks.  Components must be registered with a name, but can additionally be registered with a type. This allows users of a component to reference it by its Dart type. Including a type reference for an object is an optional argument when registering.  context . schema . register ( SourceRepository , \n     APISchemaObject . object ({ \n       id :   APISchemaObject . integer (), \n       name :   APISchemaObject . string () \n     },   representation:   SourceRepository );             The order in which components are registered and referenced does not matter. If you reference a component that is created later in the documentation process, it will be resolved prior to the document being completed. If a referenced component is never registered, an error is thrown and your document will fail to generate.", 
            "title": "Registering Components with APIDocumentContext"
        }, 
        {
            "location": "/openapi/components/#using-components", 
            "text": "Components can be used when declaring path operations, or as part of other components. For example, if you were to describe a response whose body was a component named \"SourceRepository\", it would look like this:  class   RepositoryController   extends   ResourceController   { \n   ... \n\n   @ override \n   Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n     if   ( operation . method   ==   GET )   { \n       return   { \n         200 :   APIResponse . schema ( context . schema [ SourceRepository ]) \n       }; \n     } \n     return   null ; \n   }    }   If an object has been registered by its type, you may use  getObjectWithType .  class   RepositoryController   extends   ResourceController   { \n   ... \n\n   @ override \n   Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n     if   ( operation . method   ==   GET )   { \n       return   { \n         200 :   APIResponse . schema ( context . schema . getObjectWithType ( SourceRepository )) \n       }; \n     } \n     return   null ; \n   }    }", 
            "title": "Using Components"
        }, 
        {
            "location": "/openapi/components/#component-discovery", 
            "text": "All controllers are can document components when they are linked to the entry point. Objects other than controllers will automatically document their components if they implement  APIComponentDocumenter   and  are declared properties of your  ApplicationChannel . (See  this guide  for other options.)  Built-in Aqueduct types will register any applicable components. This includes the types that handle OAuth2 as well as all  ManagedObject  subclasses in your application.", 
            "title": "Component Discovery"
        }, 
        {
            "location": "/openapi/components/#managedobject-discovery", 
            "text": "Declaring a  ManagedContext  as a property of your  ApplicationChannel  will automatically document the managed objects of your application as schema components.", 
            "title": "ManagedObject Discovery"
        }, 
        {
            "location": "/openapi/components/#serializable-discovery", 
            "text": "If a  Serializable  object is bound to a request body in a  ResourceController , it will automatically be documented as a schema component. By default, the properties of the  Serializable  object are reflected on to produce this component. To override this behavior and provide your own component documentation, implement the following method in your  Serializable  subclass:  class   Person   extends   Serializable   { \n   String   name ; \n\n   Map String ,   dynamic   asMap ()   =   { name :   name }; \n   void   readFromMap ( Map String ,   dynamic   map )   { \n     name   =   map [ name ]; \n   } \n\n   APISchemaObject   documentSchema ( APIDocumentContext   context )   { \n     return   APISchemaObject . object ( properties:   { \n       name :   APISchemaObject . string () \n     }); \n   }  }   If you  Serializable  type is not bound to a resource controller operation, you must register it yourself. This typically occurs by overriding  documentComponents  in the controller that uses the type.  class   MyController   extends   ResourceController   { \n   ... \n\n   @ override \n   void   documentComponents ( APIDocumentContext   context )   { \n     super . documentComponents ( context ); \n\n     final   personSchema   =   Person (). documentSchema ( context ); \n     context . schema . register ( \n       Person , \n       personSchema , \n       representation:   Person );           \n   }  }", 
            "title": "Serializable Discovery"
        }, 
        {
            "location": "/openapi/endpoint/", 
            "text": "Documenting Endpoint Controllers\n\n\nIn this document, you'll learn how to document endpoint controllers.\n\n\nResourceController Auto-Documentation\n\n\nA \nResourceController\n does most of the heavy lifting when it comes to generating OpenAPI documents. It will reflect on the bound variables of operation methods to provide the majority of an OpenAPI document. You only need to provide the possible responses. You do this by overriding \ndocumentOperationResponses\n in your \nResourceController\n subclass. The below shows a trivial example of a resource controller that returns a 200 OK with no body for every request.\n\n\nclass\n \nMyController\n \nextends\n \nResourceController\n \n{\n\n  \n...\n\n\n  \nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n    \nreturn\n \n{\n200\n:\n \nAPIResponse\n(\nSuccessful response.\n)};\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis method must return a map, where each key is a string status code and each value is an \nAPIResponse\n object. An \nAPIResponse\n object is highly configurable, but in most cases, you only need to declare the schema of its body. For this purpose, a convenience constructor named \nAPIResponse.schema\n exists. Here is an example where the JSON response body contains a single integer field named 'id':\n\n\nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n  \nreturn\n \n{\n\n    \n200\n:\n \nAPIResponse\n.\nschema\n(\nSuccessful response.\n,\n \nAPISchemaObject\n.\nobject\n({\n\n      \nid\n:\n \nAPISchemaObject\n.\ninteger\n()\n\n    \n}))\n\n  \n};\n\n\n}\n\n\n\n\n\n\nIn practice, you'll want to have different responses depending on the request method and path variables. The \noperation\n argument tells you which operation you are documenting.\n\n\nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n  \nif\n \n(\noperation\n.\nmethod\n \n==\n \nGET\n)\n \n{\n\n    \nif\n \n(\noperation\n.\npathVariables\n.\ncontains\n(\nid\n))\n \n{\n\n      \nreturn\n \n{\n200\n:\n \nAPIResponse\n(\nAn object by its id.\n)};\n\n    \n}\n \nelse\n \n{\n\n      \nreturn\n \n{\n200\n:\n \nAPIResponse\n(\nAll objects.\n)};\n\n    \n}\n\n  \n}\n\n\n  \nreturn\n \nnull\n;\n\n\n}\n\n\n\n\n\n\nWhile a resource controller derives the rest of its documentation from your code, you may at times want to override this behavior. Individual elements may be modified by overriding methods like \ndocumentOperationParameters\n, or you may override \ndocumentOperations\n to take over the whole process.\n\n\nIf you are not using \nResourceController\n, you must override \ndocumentOperations\n in your controller and provide all of the operation information yourself.", 
            "title": "Documenting Endpoint Controllers"
        }, 
        {
            "location": "/openapi/endpoint/#documenting-endpoint-controllers", 
            "text": "In this document, you'll learn how to document endpoint controllers.", 
            "title": "Documenting Endpoint Controllers"
        }, 
        {
            "location": "/openapi/endpoint/#resourcecontroller-auto-documentation", 
            "text": "A  ResourceController  does most of the heavy lifting when it comes to generating OpenAPI documents. It will reflect on the bound variables of operation methods to provide the majority of an OpenAPI document. You only need to provide the possible responses. You do this by overriding  documentOperationResponses  in your  ResourceController  subclass. The below shows a trivial example of a resource controller that returns a 200 OK with no body for every request.  class   MyController   extends   ResourceController   { \n   ... \n\n   Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n     return   { 200 :   APIResponse ( Successful response. )}; \n   }  }   This method must return a map, where each key is a string status code and each value is an  APIResponse  object. An  APIResponse  object is highly configurable, but in most cases, you only need to declare the schema of its body. For this purpose, a convenience constructor named  APIResponse.schema  exists. Here is an example where the JSON response body contains a single integer field named 'id':  Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n   return   { \n     200 :   APIResponse . schema ( Successful response. ,   APISchemaObject . object ({ \n       id :   APISchemaObject . integer () \n     })) \n   };  }   In practice, you'll want to have different responses depending on the request method and path variables. The  operation  argument tells you which operation you are documenting.  Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n   if   ( operation . method   ==   GET )   { \n     if   ( operation . pathVariables . contains ( id ))   { \n       return   { 200 :   APIResponse ( An object by its id. )}; \n     }   else   { \n       return   { 200 :   APIResponse ( All objects. )}; \n     } \n   } \n\n   return   null ;  }   While a resource controller derives the rest of its documentation from your code, you may at times want to override this behavior. Individual elements may be modified by overriding methods like  documentOperationParameters , or you may override  documentOperations  to take over the whole process.  If you are not using  ResourceController , you must override  documentOperations  in your controller and provide all of the operation information yourself.", 
            "title": "ResourceController Auto-Documentation"
        }, 
        {
            "location": "/openapi/middleware/", 
            "text": "Documenting Middleware Controllers\n\n\nIn this document, you'll learn how to document middleware controllers.\n\n\nAdding to an Operation\n\n\nFor the purposes of documentation, a middleware controller does not create operation request and responses. Rather, it modifies the operation details provided by its endpoint controller. When writing middleware controllers, you must override \ndocumentOperations\n and call the superclass' implementation. This allows the middleware's linked controller to document its operations, which will eventually reach an endpoint controller.\n\n\nOnce the endpoint controller returns the meat of the operation document, a middleware controller can modify it. For example, a middleware that requires a query parameter named 'key' would like like so:\n\n\nclass\n \nMiddleware\n \nextends\n \nController\n \n{\n\n  \n...\n\n\n  \n@\noverride\n\n  \nMap\nString\n,\n \nAPIOperation\n \ndocumentOperations\n(\nAPIDocumentContext\n \ncontext\n,\n \nString\n \nroute\n,\n \nAPIPath\n \npath\n)\n \n{\n\n    \nfinal\n \nops\n \n=\n \nsuper\n.\ndocumentOperations\n(\ncontext\n,\n \nroute\n,\n \npath\n);\n\n\n    \n// ops has been filled out by an endpoint controller,\n\n    \n// add \nkey\n query parameter to each operation.\n\n    \nops\n.\nforEach\n((\nmethod\n,\n \nop\n)\n \n{\n\n      \nop\n.\naddParameter\n(\nAPIParameter\n.\nquery\n(\nkey\n,\n \nschema:\n \nAPISchemaObject\n.\nstring\n()));\n\n    \n});\n\n\n    \nreturn\n \nops\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nEach string key in an operations map is the lowercase name of an HTTP method, e.g. 'get' or 'post'. An \nAPIOperation\n encapsulates its request parameters and responses.", 
            "title": "Documenting Middleware Controllers"
        }, 
        {
            "location": "/openapi/middleware/#documenting-middleware-controllers", 
            "text": "In this document, you'll learn how to document middleware controllers.", 
            "title": "Documenting Middleware Controllers"
        }, 
        {
            "location": "/openapi/middleware/#adding-to-an-operation", 
            "text": "For the purposes of documentation, a middleware controller does not create operation request and responses. Rather, it modifies the operation details provided by its endpoint controller. When writing middleware controllers, you must override  documentOperations  and call the superclass' implementation. This allows the middleware's linked controller to document its operations, which will eventually reach an endpoint controller.  Once the endpoint controller returns the meat of the operation document, a middleware controller can modify it. For example, a middleware that requires a query parameter named 'key' would like like so:  class   Middleware   extends   Controller   { \n   ... \n\n   @ override \n   Map String ,   APIOperation   documentOperations ( APIDocumentContext   context ,   String   route ,   APIPath   path )   { \n     final   ops   =   super . documentOperations ( context ,   route ,   path ); \n\n     // ops has been filled out by an endpoint controller, \n     // add  key  query parameter to each operation. \n     ops . forEach (( method ,   op )   { \n       op . addParameter ( APIParameter . query ( key ,   schema:   APISchemaObject . string ())); \n     }); \n\n     return   ops ; \n   }  }   Each string key in an operations map is the lowercase name of an HTTP method, e.g. 'get' or 'post'. An  APIOperation  encapsulates its request parameters and responses.", 
            "title": "Adding to an Operation"
        }, 
        {
            "location": "/cli/", 
            "text": "Tasks\n\n\nThe Aqueduct command-line utility creates projects, runs applications, manages database schemas and other tasks.\n\n\nThis tool is installed through \npub\n:\n\n\npub global activate aqueduct\n\n\n\n\n\nThe above command updates the tool if a new version is available. You should ensure that \naqueduct\n and your application use the same version of Aqueduct.\n\n\nAll command-line tools have a \n--help\n option to show their options.\n\n\nGuides\n\n\n\n\nCreating Applications\n\n\nRunning Applications\n\n\nManaging a Database\n\n\nManaging OAuth 2.0 Clients and Scopes\n\n\nDocumenting an API", 
            "title": "Overview"
        }, 
        {
            "location": "/cli/#tasks", 
            "text": "The Aqueduct command-line utility creates projects, runs applications, manages database schemas and other tasks.  This tool is installed through  pub :  pub global activate aqueduct  The above command updates the tool if a new version is available. You should ensure that  aqueduct  and your application use the same version of Aqueduct.  All command-line tools have a  --help  option to show their options.", 
            "title": "Tasks"
        }, 
        {
            "location": "/cli/#guides", 
            "text": "Creating Applications  Running Applications  Managing a Database  Managing OAuth 2.0 Clients and Scopes  Documenting an API", 
            "title": "Guides"
        }, 
        {
            "location": "/cli/create/", 
            "text": "Creating Aqueduct Applications\n\n\nThe \naqueduct create\n command-line tool creates applications from a template. The usage is:\n\n\naqueduct create app_name\n\n\n\n\n\nThe application name must be snake_case - all lower case, no spaces, no symbols other than \n_\n.\n\n\nBy default, a generated project is fairly empty - it has the minimal content, but the structure of a complete application. For applications that use Aqueduct's ORM or OAuth 2.0 behavior, extended templates exist. These can be listed with the following:\n\n\naqueduct create list-templates\n\n\n\n\n\nTo pick a template, add the \n-t\n option to \naqueduct create\n. For example, the following uses the \ndb\n template:\n\n\naqueduct create -t db app_name\n\n\n\n\n\nThe templates are located in the Aqueduct package under \nexamples/templates\n. When creating a new project from a template, the tool copies the contents of one of the template directories into your current working directory and substitutes some names with your project name.", 
            "title": "Creating Applications"
        }, 
        {
            "location": "/cli/create/#creating-aqueduct-applications", 
            "text": "The  aqueduct create  command-line tool creates applications from a template. The usage is:  aqueduct create app_name  The application name must be snake_case - all lower case, no spaces, no symbols other than  _ .  By default, a generated project is fairly empty - it has the minimal content, but the structure of a complete application. For applications that use Aqueduct's ORM or OAuth 2.0 behavior, extended templates exist. These can be listed with the following:  aqueduct create list-templates  To pick a template, add the  -t  option to  aqueduct create . For example, the following uses the  db  template:  aqueduct create -t db app_name  The templates are located in the Aqueduct package under  examples/templates . When creating a new project from a template, the tool copies the contents of one of the template directories into your current working directory and substitutes some names with your project name.", 
            "title": "Creating Aqueduct Applications"
        }, 
        {
            "location": "/cli/running/", 
            "text": "Running Applications with Aqueduct Serve\n\n\nThe \naqueduct serve\n command-line tool runs applications. This tool is run in a project directory and it generates a Dart script that bootstraps your application.\n\n\nThe structure of the project does matter - if you are creating a project from the template, the appropriate structure already exists. Otherwise, you must ensure you have a library file with the same name as your application (as defined in \npubspec.yaml\n). For example, an application named \ntodo\n must have a \nlib/todo.dart\n file. This file must import the file that declares your application's \nApplicationChannel\n.\n\n\nYou may specify options like the number of isolates to run the application on and which port to listen for requests on. See more details with \naqueduct serve --help\n.\n\n\nHot Reload\n\n\nIn Flutter, a \nhot reload\n restarts an application after a code change, but keeps the state of the application intact - such as which screen the user is on and what data is available in memory. This is an incredible feature for faster development cycles in an environment that can often be difficult to test efficiently.\n\n\nHot reload is often requested as a feature of Aqueduct, but it doesn't quite make sense in an HTTP API which is not supposed to retain state. Truth be told, our team rarely uses a development cycle that involves making frequent code changes to a locally running instance. Instead, we use \npackage:aqueduct_test\n to ensure all of our testing efforts are captured in automated tests that continually run over the course of the project.\n\n\nA shortcut to restart the locally running application after a change is admittedly useful in some scenarios. However, this is already an existing feature of most IDEs and should not be implemented by \naqueduct\n. In IntelliJ, this feature is called 'Rerun' and the default keyboard shortcut is \n^F5\n in macOS. To use this shortcut, instead of running with \naqueduct serve\n, right-click on the \nbin/main.dart\n script that is generated when you create a new project and select \nRun\n. Once this process is running, you can rerun it with \n^F5\n or with the Rerun button on the Run panel.", 
            "title": "Running Applications"
        }, 
        {
            "location": "/cli/running/#running-applications-with-aqueduct-serve", 
            "text": "The  aqueduct serve  command-line tool runs applications. This tool is run in a project directory and it generates a Dart script that bootstraps your application.  The structure of the project does matter - if you are creating a project from the template, the appropriate structure already exists. Otherwise, you must ensure you have a library file with the same name as your application (as defined in  pubspec.yaml ). For example, an application named  todo  must have a  lib/todo.dart  file. This file must import the file that declares your application's  ApplicationChannel .  You may specify options like the number of isolates to run the application on and which port to listen for requests on. See more details with  aqueduct serve --help .", 
            "title": "Running Applications with Aqueduct Serve"
        }, 
        {
            "location": "/cli/running/#hot-reload", 
            "text": "In Flutter, a  hot reload  restarts an application after a code change, but keeps the state of the application intact - such as which screen the user is on and what data is available in memory. This is an incredible feature for faster development cycles in an environment that can often be difficult to test efficiently.  Hot reload is often requested as a feature of Aqueduct, but it doesn't quite make sense in an HTTP API which is not supposed to retain state. Truth be told, our team rarely uses a development cycle that involves making frequent code changes to a locally running instance. Instead, we use  package:aqueduct_test  to ensure all of our testing efforts are captured in automated tests that continually run over the course of the project.  A shortcut to restart the locally running application after a change is admittedly useful in some scenarios. However, this is already an existing feature of most IDEs and should not be implemented by  aqueduct . In IntelliJ, this feature is called 'Rerun' and the default keyboard shortcut is  ^F5  in macOS. To use this shortcut, instead of running with  aqueduct serve , right-click on the  bin/main.dart  script that is generated when you create a new project and select  Run . Once this process is running, you can rerun it with  ^F5  or with the Rerun button on the Run panel.", 
            "title": "Hot Reload"
        }, 
        {
            "location": "/cli/document/", 
            "text": "Documenting Aqueduct Applications\n\n\nThe \naqueduct document\n tool generates an OpenAPI (formerly Swagger) specification by reflecting on your application's code. This command is run in a project directory and will emit the JSON specification to stdout. You can redirect this to a file:\n\n\naqueduct document \n swagger.json\n\n\n\n\n\nThe file \nconfig.src.yaml\n must exist in your project directory so that the application can be initialized in 'test' mode for the documentation to be generated.", 
            "title": "Generating an OpenAPI/Swagger Specification"
        }, 
        {
            "location": "/cli/document/#documenting-aqueduct-applications", 
            "text": "The  aqueduct document  tool generates an OpenAPI (formerly Swagger) specification by reflecting on your application's code. This command is run in a project directory and will emit the JSON specification to stdout. You can redirect this to a file:  aqueduct document   swagger.json  The file  config.src.yaml  must exist in your project directory so that the application can be initialized in 'test' mode for the documentation to be generated.", 
            "title": "Documenting Aqueduct Applications"
        }, 
        {
            "location": "/snippets/", 
            "text": "Aqueduct Snippets\n\n\nThese snippets are quick examples of common code that you can use and modify in your application.\n\n\n\n\nHTTP Routing, Request and Response Snippets\n\n\nORM and Database Snippets\n\n\nAuthorization and Authentication Snippets\n\n\nIntegration Test Snippets", 
            "title": "Overview"
        }, 
        {
            "location": "/snippets/#aqueduct-snippets", 
            "text": "These snippets are quick examples of common code that you can use and modify in your application.   HTTP Routing, Request and Response Snippets  ORM and Database Snippets  Authorization and Authentication Snippets  Integration Test Snippets", 
            "title": "Aqueduct Snippets"
        }, 
        {
            "location": "/snippets/http/", 
            "text": "Aqueduct HTTP Snippets\n\n\nHello, World\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/hello_world\n).\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n(\nHello, world!\n)\n\n        \n..\ncontentType\n \n=\n \nContentType\n.\nTEXT\n;\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nRoute Variables\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/variable/[:variable]\n).\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n({\n\n        \nmethod\n:\n \nrequest\n.\nraw\n.\nmethod\n,\n\n        \npath\n:\n \nrequest\n.\npath\n.\nvariables\n[\nvariable\n]\n \n??\n \nnot specified\n\n      \n});\n      \n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nGrouping Routes and Binding Path Variables\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/users/[:id]\n)\n\n      \n.\nlink\n(()\n \n=\n \nMyController\n());\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\nclass\n \nMyController\n \nextends\n \nResourceController\n \n{\n\n  \nfinal\n \nList\nString\n \nthings\n \n=\n \n[\nthing1\n,\n \nthing2\n];\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetThings\n()\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n(\nthings\n);\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetThing\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nif\n \n(\nid\n \n \n0\n \n||\n \nid\n \n=\n \nthings\n.\nlength\n)\n \n{\n\n      \nreturn\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n    \nreturn\n \nResponse\n.\nok\n(\nthings\n[\nid\n]);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nCustom Middleware\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/rate_limit\n)\n\n      \n.\nlink\n(()\n \n=\n \nRateLimiter\n())\n\n      \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nResponse\n.\nok\n({\n\n        \nrequests_remaining\n:\n \nreq\n.\nattachments\n[\nremaining\n]\n\n      \n}));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\nclass\n \nRateLimiter\n \nextends\n \nRequestController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nfinal\n \napiKey\n \n=\n \nrequest\n.\nraw\n.\nheaders\n.\nvalue\n(\nx-apikey\n);\n\n    \nfinal\n \nrequestsRemaining\n \n=\n \nawait\n \nremainingRequestsForAPIKey\n(\napiKey\n);\n\n    \nif\n \n(\nrequestsRemaining\n \n=\n \n0\n)\n \n{\n\n      \nreturn\n \nResponse\n(\n429\n,\n \nnull\n,\n \nnull\n);\n\n    \n}\n\n\n    \nrequest\n.\naddResponseModifier\n((\nr\n)\n \n{\n\n      \nr\n.\nheaders\n[\nx-remaining-requests\n]\n \n=\n \nrequestsRemaining\n;\n\n    \n});\n\n\n    \nreturn\n \nrequest\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nApplication-Wide CORS Allowed Origins\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \n// All controllers will use this policy by default\n\n    \nCORSPolicy\n.\ndefaultPolicy\n.\nallowedOrigins\n \n=\n \n[\nhttps://mywebsite.com\n];\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/things\n).\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n([\nWidget\n,\n \nDoodad\n,\n \nTransformer\n]);\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nServe Files and Set Cache-Control Headers\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/files/*\n).\nlink\n(()\n \n=\n\n      \nFileController\n(\nweb\n)\n\n        \n..\naddCachePolicy\n(\nnew\n \nCachePolicy\n(\nexpirationFromNow:\n \nnew\n \nDuration\n(\ndays:\n \n365\n)),\n\n          \n(\npath\n)\n \n=\n \npath\n.\nendsWith\n(\n.js\n)\n \n||\n \npath\n.\nendsWith\n(\n.css\n))\n      \n    \n);\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nStreaming Responses (Server Side Events with text/event-stream)\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nfinal\n \nStreamController\nString\n \ncontroller\n \n=\n \nnew\n \nStreamController\nString\n();\n  \n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \ncount\n \n=\n \n0\n;\n\n     \nTimer\n.\nperiodic\n(\nnew\n \nDuration\n(\nseconds:\n \n1\n),\n \n(\n_\n)\n \n{\n\n      \ncount\n \n++\n;\n\n      \ncontroller\n.\nadd\n(\nThis server has been up for \n$\ncount\n seconds\n\\n\n);\n\n    \n});\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/stream\n).\nlinkFunction\n((\nreq\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n(\ncontroller\n.\nstream\n)\n\n          \n..\nbufferOutput\n \n=\n \nfalse\n\n          \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\n\n            \ntext\n,\n \nevent-stream\n,\n \ncharset:\n \nutf-8\n);\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nA websocket server\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nList\nWebSocket\n \nwebsockets\n \n=\n \n[];\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \n// When another isolate gets a websocket message, echo it to\n\n    \n// websockets connected on this isolate.\n\n    \nmessageHub\n.\nlisten\n(\nsendBytesToConnectedClients\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \n// Allow websocket clients to connect to ws://host/connect\n\n    \nrouter\n.\nroute\n(\n/connect\n).\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nvar\n \nwebsocket\n \n=\n \nawait\n \nWebSocketTransformer\n.\nupgrade\n(\nrequest\n.\nraw\n);\n\n      \nwebsocket\n.\nlisten\n(\necho\n,\n \nonDone:\n \n()\n \n{\n\n        \nwebsockets\n.\nremove\n(\nwebsocket\n);\n\n      \n},\n \ncancelOnError:\n \ntrue\n);\n\n      \nwebsockets\n.\nadd\n(\nwebsocket\n);\n\n\n      \n// Take request out of channel\n\n      \nreturn\n \nnull\n;\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n  \nvoid\n \nsendBytesToConnectedClients\n(\nList\nint\n \nbytes\n)\n \n{\n\n    \nwebsockets\n.\nforEach\n((\nws\n)\n \n{\n\n      \nws\n.\nadd\n(\nbytes\n);\n\n    \n});\n\n  \n}\n\n\n  \nvoid\n \necho\n(\nList\nint\n \nbytes\n)\n \n{\n\n    \nsendBytesToConnectedClients\n(\nbytes\n);\n\n\n    \n// Send to other isolates\n\n    \nmessageHub\n.\nadd\n(\nbytes\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSetting Content-Type and Encoding a Response Body\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nfinal\n \nContentType\n \nCSV\n \n=\n \nContentType\n(\ntext\n,\n \ncsv\n,\n \ncharset:\n \nutf-8\n);\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \n// CsvCodec extends dart:convert.Codec\n\n    \nCodecRegistry\n.\ndefaultInstance\n.\nadd\n(\nCSV\n,\n \nnew\n \nCsvCodec\n());\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/csv\n).\nlinkFunction\n((\nreq\n)\n \nasync\n \n{\n\n      \n// These values will get converted by CsvCodec into a comma-separated string\n\n      \nreturn\n \nResponse\n.\nok\n([[\n1\n,\n \n2\n,\n \n3\n],\n \n[\na\n,\n \nb\n,\n \nc\n]])\n\n        \n..\ncontentType\n \n=\n \nCSV\n;\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nProxy a File From Another Server\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/proxy/*\n).\nlinkFunction\n((\nreq\n)\n \nasync\n \n{\n\n      \nvar\n \nfileURL\n \n=\n \nhttps://otherserver/\n${\nreq\n.\npath\n.\nremainingPath\n}\n;\n\n      \nvar\n \nfileRequest\n \n=\n \nawait\n \nclient\n.\ngetUrl\n(\nurl\n);\n\n      \nvar\n \nfileResponse\n \n=\n \nawait\n \nreq\n.\nclose\n();\n\n      \nif\n \n(\nfileResponse\n.\nstatusCode\n \n!=\n \n200\n)\n \n{\n\n        \nreturn\n \nnew\n \nResponse\n.\nnotFound\n();\n\n      \n}\n\n\n      \n// A dart:io.HttpResponse is a Stream\nList\nint\n of its body bytes.\n\n      \nreturn\n \nnew\n \nResponse\n.\nok\n(\nfileResponse\n)\n\n        \n..\ncontentType\n \n=\n \nfileResponse\n.\nheaders\n.\ncontentType\n\n        \n// let the data just pass through because it has already been encoded\n\n        \n// according to content-type; applying encoding again would cause\n\n        \n// an issue\n\n        \n..\nencodeBody\n \n=\n \nfalse\n;\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}", 
            "title": "HTTP"
        }, 
        {
            "location": "/snippets/http/#aqueduct-http-snippets", 
            "text": "", 
            "title": "Aqueduct HTTP Snippets"
        }, 
        {
            "location": "/snippets/http/#hello-world", 
            "text": "class   AppChannel   extends   ApplicationChannel   {   \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /hello_world ). linkFunction (( request )   async   { \n       return   Response . ok ( Hello, world! ) \n         .. contentType   =   ContentType . TEXT ; \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Hello, World"
        }, 
        {
            "location": "/snippets/http/#route-variables", 
            "text": "class   AppChannel   extends   ApplicationChannel   {   \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /variable/[:variable] ). linkFunction (( request )   async   { \n       return   Response . ok ({ \n         method :   request . raw . method , \n         path :   request . path . variables [ variable ]   ??   not specified \n       });       \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Route Variables"
        }, 
        {
            "location": "/snippets/http/#grouping-routes-and-binding-path-variables", 
            "text": "class   AppChannel   extends   ApplicationChannel   {   \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router \n       . route ( /users/[:id] ) \n       . link (()   =   MyController ()); \n\n     return   router ; \n   }  }  class   MyController   extends   ResourceController   { \n   final   List String   things   =   [ thing1 ,   thing2 ]; \n\n   @ Operation . get () \n   Future Response   getThings ()   async   { \n     return   Response . ok ( things ); \n   } \n\n   @ Operation . get ( id ) \n   Future Response   getThing ( @ Bind . path ( id )   int   id )   async   { \n     if   ( id     0   ||   id   =   things . length )   { \n       return   Response . notFound (); \n     } \n     return   Response . ok ( things [ id ]); \n   }  }", 
            "title": "Grouping Routes and Binding Path Variables"
        }, 
        {
            "location": "/snippets/http/#custom-middleware", 
            "text": "class   AppChannel   extends   ApplicationChannel   {   \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router \n       . route ( /rate_limit ) \n       . link (()   =   RateLimiter ()) \n       . linkFunction (( req )   async   =   Response . ok ({ \n         requests_remaining :   req . attachments [ remaining ] \n       })); \n\n     return   router ; \n   }  }  class   RateLimiter   extends   RequestController   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     final   apiKey   =   request . raw . headers . value ( x-apikey ); \n     final   requestsRemaining   =   await   remainingRequestsForAPIKey ( apiKey ); \n     if   ( requestsRemaining   =   0 )   { \n       return   Response ( 429 ,   null ,   null ); \n     } \n\n     request . addResponseModifier (( r )   { \n       r . headers [ x-remaining-requests ]   =   requestsRemaining ; \n     }); \n\n     return   request ; \n   }  }", 
            "title": "Custom Middleware"
        }, 
        {
            "location": "/snippets/http/#application-wide-cors-allowed-origins", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     // All controllers will use this policy by default \n     CORSPolicy . defaultPolicy . allowedOrigins   =   [ https://mywebsite.com ]; \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /things ). linkFunction (( request )   async   { \n       return   Response . ok ([ Widget ,   Doodad ,   Transformer ]); \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Application-Wide CORS Allowed Origins"
        }, 
        {
            "location": "/snippets/http/#serve-files-and-set-cache-control-headers", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /files/* ). link (()   = \n       FileController ( web ) \n         .. addCachePolicy ( new   CachePolicy ( expirationFromNow:   new   Duration ( days:   365 )), \n           ( path )   =   path . endsWith ( .js )   ||   path . endsWith ( .css ))       \n     ); \n\n     return   router ; \n   }  }", 
            "title": "Serve Files and Set Cache-Control Headers"
        }, 
        {
            "location": "/snippets/http/#streaming-responses-server-side-events-with-textevent-stream", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   final   StreamController String   controller   =   new   StreamController String ();   \n\n   @ override \n   Future   prepare ()   async   { \n     var   count   =   0 ; \n      Timer . periodic ( new   Duration ( seconds:   1 ),   ( _ )   { \n       count   ++ ; \n       controller . add ( This server has been up for  $ count  seconds \\n ); \n     }); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router . route ( /stream ). linkFunction (( req )   async   { \n       return   Response . ok ( controller . stream ) \n           .. bufferOutput   =   false \n           .. contentType   =   new   ContentType ( \n             text ,   event-stream ,   charset:   utf-8 ); \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Streaming Responses (Server Side Events with text/event-stream)"
        }, 
        {
            "location": "/snippets/http/#a-websocket-server", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   List WebSocket   websockets   =   []; \n\n   @ override \n   Future   prepare ()   async   { \n     // When another isolate gets a websocket message, echo it to \n     // websockets connected on this isolate. \n     messageHub . listen ( sendBytesToConnectedClients ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     // Allow websocket clients to connect to ws://host/connect \n     router . route ( /connect ). linkFunction (( request )   async   { \n       var   websocket   =   await   WebSocketTransformer . upgrade ( request . raw ); \n       websocket . listen ( echo ,   onDone:   ()   { \n         websockets . remove ( websocket ); \n       },   cancelOnError:   true ); \n       websockets . add ( websocket ); \n\n       // Take request out of channel \n       return   null ; \n     }); \n\n     return   router ; \n   } \n\n   void   sendBytesToConnectedClients ( List int   bytes )   { \n     websockets . forEach (( ws )   { \n       ws . add ( bytes ); \n     }); \n   } \n\n   void   echo ( List int   bytes )   { \n     sendBytesToConnectedClients ( bytes ); \n\n     // Send to other isolates \n     messageHub . add ( bytes ); \n   }  }", 
            "title": "A websocket server"
        }, 
        {
            "location": "/snippets/http/#setting-content-type-and-encoding-a-response-body", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   final   ContentType   CSV   =   ContentType ( text ,   csv ,   charset:   utf-8 ); \n\n   @ override \n   Future   prepare ()   async   { \n     // CsvCodec extends dart:convert.Codec \n     CodecRegistry . defaultInstance . add ( CSV ,   new   CsvCodec ()); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /csv ). linkFunction (( req )   async   { \n       // These values will get converted by CsvCodec into a comma-separated string \n       return   Response . ok ([[ 1 ,   2 ,   3 ],   [ a ,   b ,   c ]]) \n         .. contentType   =   CSV ; \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Setting Content-Type and Encoding a Response Body"
        }, 
        {
            "location": "/snippets/http/#proxy-a-file-from-another-server", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /proxy/* ). linkFunction (( req )   async   { \n       var   fileURL   =   https://otherserver/ ${ req . path . remainingPath } ; \n       var   fileRequest   =   await   client . getUrl ( url ); \n       var   fileResponse   =   await   req . close (); \n       if   ( fileResponse . statusCode   !=   200 )   { \n         return   new   Response . notFound (); \n       } \n\n       // A dart:io.HttpResponse is a Stream List int  of its body bytes. \n       return   new   Response . ok ( fileResponse ) \n         .. contentType   =   fileResponse . headers . contentType \n         // let the data just pass through because it has already been encoded \n         // according to content-type; applying encoding again would cause \n         // an issue \n         .. encodeBody   =   false ; \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Proxy a File From Another Server"
        }, 
        {
            "location": "/snippets/orm/", 
            "text": "Aqueduct ORM Snippets\n\n\nFilter Query by Column/Property (WHERE clause)\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ntitle\n).\nequalTo\n(\nProgrammer\n);\n\n\nvar\n \nemployees\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFetching Only Some Columns/Properties\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nresultingProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\nname\n]);\n\n\nvar\n \nemployees\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nSorting Rows/Objects\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nsortBy\n((\ne\n)\n \n=\n \ne\n.\nsalary\n,\n \nQuerySortOrder\n.\nascending\n);\n\n\nvar\n \nemployees\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFetching Only One Row/Object\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nid\n).\nequalTo\n(\n1\n);\n\n\nvar\n \nemployee\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nExecuting a Join (Has-One)\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\njoin\n(\nobject:\n \n(\ne\n)\n \n=\n \ne\n.\nleague\n);\n\n\nvar\n \nteamsAndTheirLeague\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nExecuting a Join (Has-Many)\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\njoin\n(\nset\n:\n \n(\ne\n)\n \n=\n \ne\n.\nplayers\n);\n\n\nvar\n \nteamsAndTheirPlayers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFiltering Joined Rows/Objects\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n);\n\n\n\nvar\n \nsubquery\n \n=\n \nquery\n.\njoin\n(\nset\n:\n \n(\ne\n)\n \n=\n \ne\n.\nplayers\n)\n\n  \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nyearsPlayed\n).\nlessThanOrEqualTo\n(\n1\n);\n\n\n\nvar\n \nteamsAndTheirRookiePlayers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFilter Rows/Objects by Relationship Property\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\nwhere\n((\nt\n)\n \n=\n \nt\n.\nplayers\n.\nhaveAtLeastOneWhere\n.\nyearsPlayed\n).\nlessThanOrEqualTo\n(\n1\n);\n\n\n\nvar\n \nteamsWithRookies\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nComplex/Unsupported WHERE Clause (using 'OR')\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\npredicate\n \n=\n \nnew\n \nQueryPredicate\n(\nname = \n@name1\n OR name = \n@name2\n,\n \n{\n\n      \nname1\n:\n \nBadgers\n,\n\n      \nname2\n:\n \nGophers\n\n    \n});\n\n\n\nvar\n \nbadgerAndGopherTeams\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nUpdating a Row/Object\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\nwhere\n((\nt\n)\n \n=\n \nt\n.\nid\n).\nequalTo\n(\n10\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBadgers\n;\n\n\n\nvar\n \nteam\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n\n\n\n\n\nConfigure a Database Connection from Configuration File\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ncontext\n \n=\n \ncontextWithConnectionInfo\n(\noptions\n.\nconfigurationFilePath\n.\ndatabase\n);\n\n  \n}\n\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n    \n...\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n  \nManagedContext\n \ncontextWithConnectionInfo\n(\n\n      \nDatabaseConnectionConfiguration\n \nconnectionInfo\n)\n \n{\n\n    \nvar\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nvar\n \npsc\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n(\n\n        \nconnectionInfo\n.\nusername\n,\n\n        \nconnectionInfo\n.\npassword\n,\n\n        \nconnectionInfo\n.\nhost\n,\n\n        \nconnectionInfo\n.\nport\n,\n\n        \nconnectionInfo\n.\ndatabaseName\n);\n\n\n    \nreturn\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n  \n}\n\n\n}\n\n\n\nclass\n \nMyAppConfiguration\n \nextends\n \nConfiguration\n \n{\n\n  \nMyAppConfiguration\n(\nString\n \nfileName\n)\n \n:\n \nsuper\n.\nfromFile\n(\nFile\n(\nfileName\n));\n\n\n  \nDatabaseConnectionConfiguration\n \ndatabase\n;\n\n\n}", 
            "title": "ORM"
        }, 
        {
            "location": "/snippets/orm/#aqueduct-orm-snippets", 
            "text": "", 
            "title": "Aqueduct ORM Snippets"
        }, 
        {
            "location": "/snippets/orm/#filter-query-by-columnproperty-where-clause", 
            "text": "var   query   =   new   Query Employee ( context ) \n   .. where (( e )   =   e . title ). equalTo ( Programmer );  var   employees   =   await   query . fetch ();", 
            "title": "Filter Query by Column/Property (WHERE clause)"
        }, 
        {
            "location": "/snippets/orm/#fetching-only-some-columnsproperties", 
            "text": "var   query   =   new   Query Employee ( context ) \n   .. resultingProperties (( e )   =   [ e . id ,   e . name ]);  var   employees   =   await   query . fetch ();", 
            "title": "Fetching Only Some Columns/Properties"
        }, 
        {
            "location": "/snippets/orm/#sorting-rowsobjects", 
            "text": "var   query   =   new   Query Employee ( context ) \n   .. sortBy (( e )   =   e . salary ,   QuerySortOrder . ascending );  var   employees   =   await   query . fetch ();", 
            "title": "Sorting Rows/Objects"
        }, 
        {
            "location": "/snippets/orm/#fetching-only-one-rowobject", 
            "text": "var   query   =   new   Query Employee ( context ) \n   .. where (( e )   =   e . id ). equalTo ( 1 );  var   employee   =   await   query . fetchOne ();", 
            "title": "Fetching Only One Row/Object"
        }, 
        {
            "location": "/snippets/orm/#executing-a-join-has-one", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. join ( object:   ( e )   =   e . league );  var   teamsAndTheirLeague   =   await   query . fetch ();", 
            "title": "Executing a Join (Has-One)"
        }, 
        {
            "location": "/snippets/orm/#executing-a-join-has-many", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. join ( set :   ( e )   =   e . players );  var   teamsAndTheirPlayers   =   await   query . fetch ();", 
            "title": "Executing a Join (Has-Many)"
        }, 
        {
            "location": "/snippets/orm/#filtering-joined-rowsobjects", 
            "text": "var   query   =   new   Query Team ( context );  var   subquery   =   query . join ( set :   ( e )   =   e . players ) \n   .. where (( p )   =   p . yearsPlayed ). lessThanOrEqualTo ( 1 );  var   teamsAndTheirRookiePlayers   =   await   query . fetch ();", 
            "title": "Filtering Joined Rows/Objects"
        }, 
        {
            "location": "/snippets/orm/#filter-rowsobjects-by-relationship-property", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. where (( t )   =   t . players . haveAtLeastOneWhere . yearsPlayed ). lessThanOrEqualTo ( 1 );  var   teamsWithRookies   =   await   query . fetch ();", 
            "title": "Filter Rows/Objects by Relationship Property"
        }, 
        {
            "location": "/snippets/orm/#complexunsupported-where-clause-using-or", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. predicate   =   new   QueryPredicate ( name =  @name1  OR name =  @name2 ,   { \n       name1 :   Badgers , \n       name2 :   Gophers \n     });  var   badgerAndGopherTeams   =   await   query . fetch ();", 
            "title": "Complex/Unsupported WHERE Clause (using 'OR')"
        }, 
        {
            "location": "/snippets/orm/#updating-a-rowobject", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. where (( t )   =   t . id ). equalTo ( 10 ) \n   .. values . name   =   Badgers ;  var   team   =   await   query . updateOne ();", 
            "title": "Updating a Row/Object"
        }, 
        {
            "location": "/snippets/orm/#configure-a-database-connection-from-configuration-file", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     context   =   contextWithConnectionInfo ( options . configurationFilePath . database ); \n   } \n\n   ManagedContext   context ; \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n     ... \n     return   router ; \n   } \n\n   ManagedContext   contextWithConnectionInfo ( \n       DatabaseConnectionConfiguration   connectionInfo )   { \n     var   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n     var   psc   =   new   PostgreSQLPersistentStore ( \n         connectionInfo . username , \n         connectionInfo . password , \n         connectionInfo . host , \n         connectionInfo . port , \n         connectionInfo . databaseName ); \n\n     return   new   ManagedContext ( dataModel ,   psc ); \n   }  }  class   MyAppConfiguration   extends   Configuration   { \n   MyAppConfiguration ( String   fileName )   :   super . fromFile ( File ( fileName )); \n\n   DatabaseConnectionConfiguration   database ;  }", 
            "title": "Configure a Database Connection from Configuration File"
        }, 
        {
            "location": "/snippets/auth/", 
            "text": "Aqueduct Authorization and Authentication Snippets\n\n\nEnable OAuth 2.0\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npsc\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n(\n\n        \nusername\n,\n\n        \npassword\n,\n\n        \nlocalhost\n,\n\n        \n5432\n\n        \nmy_app\n);\n\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n\n    \nfinal\n \ndelegate\n \n=\n \nnew\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n  \n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAdd OAuth 2.0 Clients to Database\n\n\naqueduct auth add-client \\\n  --id com.app.test \\\n  --secret supersecret \\\n  --allowed-scopes \nprofile kiosk:location raw_db_access.readonly\n \\\n  --connect postgres://username:password@localhost:5432/my_app\n\n\n\n\n\nRequire OAuth 2.0 Scope to Access Routes\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npsc\n \n=\n \nPostgreSQLPersistentStore\n(\n\n        \nusername\n,\n\n        \npassword\n,\n\n        \nlocalhost\n,\n\n        \n5432\n\n        \nmy_app\n);\n\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n\n    \nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/profile\n)\n\n      \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n,\n \nscopes:\n \n[\nprofile.readonly\n]))\n\n      \n.\nlink\n(()\n \n=\n \nProfileController\n(\ncontext\n));\n\n  \n}\n\n\n}\n\n\n\nclass\n \nProfileController\n \nextends\n \nResourceController\n \n{\n\n  \nProfileController\n(\nthis\n.\ncontext\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetProfile\n()\n \nasync\n \n{\n\n    \nfinal\n \nid\n \n=\n \nrequest\n.\nauthorization\n.\nownerID\n;\n\n    \nfinal\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n(\ncontext\n)\n\n      \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\nid\n);\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nfetchOne\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nBasic Authentication\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n    \nrouter\n\n      \n.\nroute\n(\n/profile\n)\n\n      \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbasic\n(\nPasswordVerifier\n()))\n\n      \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nnew\n \nResponse\n.\nok\n(\nnull\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\nclass\n \nPasswordVerifier\n \nextends\n \nAuthValidator\n \n{\n\n  \n@\noverride\n\n  \nFutureOr\nAuthorization\n \nvalidate\nT\n(\nAuthorizationParser\nT\n \nparser\n,\n \nT\n \nauthorizationData\n,\n \n{\nList\nAuthScope\n \nrequiredScope\n})\n \n{\n\n    \nif\n \n(\n!\nisPasswordCorrect\n(\nauthorizationData\n))\n \n{\n\n      \nreturn\n \nnull\n;\n\n    \n}\n\n\n    \nreturn\n \nAuthorization\n(\nnull\n,\n \nauthorizationData\n.\nusername\n,\n \nthis\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAdd OAuth 2.0 Authorization Code Flow\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npsc\n \n=\n \nPostgreSQLPersistentStore\n(\n\n        \nusername\n,\n\n        \npassword\n,\n\n        \nlocalhost\n,\n\n        \n5432\n\n        \nmy_app\n);\n\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n\n    \nfinal\n \ndelegate\n \n=\n \nnew\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n  \n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n  \n\n    \nrouter\n.\nroute\n(\n/auth/code\n).\nlink\n(()\n \n=\n \nAuthCodeController\n(\nauthServer\n,\n \ndelegate:\n \nthis\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n  \nFuture\nString\n \nrender\n(\nAuthCodeController\n \nforController\n,\n \nUri\n \nrequestUri\n,\n \nString\n \nresponseType\n,\n \nString\n \nclientID\n,\n\n      \nString\n \nstate\n,\n \nString\n \nscope\n)\n \nasync\n \n{\n\n    \nreturn\n \n\n\n!DOCTYPE html\n\n\nhtml lang=\nen\n\n\n\nhead\n\n\n    \nmeta charset=\nUTF-8\n\n\n    \ntitle\nLogin\n/title\n\n\n/head\n\n\n\nbody\n\n\ndiv class=\ncontainer\n\n\n    \nh1\nLogin\n/h1\n\n\n    \nform action=\n${requestUri.path}\n method=\nPOST\n\n\n        \ninput type=\nhidden\n name=\nstate\n value=\n$state\n\n\n        \ninput type=\nhidden\n name=\nclient_id\n value=\n$clientID\n\n\n        \ninput type=\nhidden\n name=\nresponse_type\n value=\n$responseType\n\n\n        \ndiv class=\nform-group\n\n\n            \nlabel for=\nusername\nUser Name\n/label\n\n\n            \ninput type=\ntext\n class=\nform-control\n name=\nusername\n placeholder=\nPlease enter your user name\n\n\n        \n/div\n\n\n        \ndiv class=\nform-group\n\n\n            \nlabel for=\npassword\nPassword\n/label\n\n\n            \ninput type=\npassword\n class=\nform-control\n name=\npassword\n placeholder=\nPlease enter your password\n\n\n        \n/div\n\n\n        \nbutton type=\nsubmit\n class=\nbtn btn-success\nLogin\n/button\n\n\n    \n/form\n\n\n/div\n\n\n/body\n\n\n\n/html\n\n\n    \n;\n    \n  \n}\n\n\n}", 
            "title": "Authentication and Authorization"
        }, 
        {
            "location": "/snippets/auth/#aqueduct-authorization-and-authentication-snippets", 
            "text": "", 
            "title": "Aqueduct Authorization and Authentication Snippets"
        }, 
        {
            "location": "/snippets/auth/#enable-oauth-20", 
            "text": "import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   psc   =   new   PostgreSQLPersistentStore ( \n         username , \n         password , \n         localhost , \n         5432 \n         my_app ); \n\n     context   =   new   ManagedContext ( dataModel ,   psc ); \n\n     final   delegate   =   new   ManagedAuthDelegate User ( context ); \n     authServer   =   new   AuthServer ( delegate ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n     router . route ( /auth/token ). link (()   =   AuthController ( authServer ));   \n     return   router ; \n   }  }", 
            "title": "Enable OAuth 2.0"
        }, 
        {
            "location": "/snippets/auth/#add-oauth-20-clients-to-database", 
            "text": "aqueduct auth add-client \\\n  --id com.app.test \\\n  --secret supersecret \\\n  --allowed-scopes  profile kiosk:location raw_db_access.readonly  \\\n  --connect postgres://username:password@localhost:5432/my_app", 
            "title": "Add OAuth 2.0 Clients to Database"
        }, 
        {
            "location": "/snippets/auth/#require-oauth-20-scope-to-access-routes", 
            "text": "import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   psc   =   PostgreSQLPersistentStore ( \n         username , \n         password , \n         localhost , \n         5432 \n         my_app ); \n\n     context   =   new   ManagedContext ( dataModel ,   psc ); \n\n     final   delegate   =   ManagedAuthDelegate User ( context ); \n     authServer   =   AuthServer ( delegate ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     router . route ( /auth/token ). link (()   =   AuthController ( authServer )); \n\n     router \n       . route ( /profile ) \n       . link (()   =   Authorizer . bearer ( authServer ,   scopes:   [ profile.readonly ])) \n       . link (()   =   ProfileController ( context )); \n   }  }  class   ProfileController   extends   ResourceController   { \n   ProfileController ( this . context ); \n\n   final   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getProfile ()   async   { \n     final   id   =   request . authorization . ownerID ; \n     final   query   =   new   Query User ( context ) \n       .. where (( u )   =   u . id ). equalTo ( id ); \n\n     return   new   Response . ok ( await   query . fetchOne ()); \n   }  }", 
            "title": "Require OAuth 2.0 Scope to Access Routes"
        }, 
        {
            "location": "/snippets/auth/#basic-authentication", 
            "text": "import   package:aqueduct/aqueduct.dart ;  class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n     router \n       . route ( /profile ) \n       . link (()   =   Authorizer . basic ( PasswordVerifier ())) \n       . linkFunction (( req )   async   =   new   Response . ok ( null )); \n\n     return   router ; \n   }  }  class   PasswordVerifier   extends   AuthValidator   { \n   @ override \n   FutureOr Authorization   validate T ( AuthorizationParser T   parser ,   T   authorizationData ,   { List AuthScope   requiredScope })   { \n     if   ( ! isPasswordCorrect ( authorizationData ))   { \n       return   null ; \n     } \n\n     return   Authorization ( null ,   authorizationData . username ,   this ); \n   }  }", 
            "title": "Basic Authentication"
        }, 
        {
            "location": "/snippets/auth/#add-oauth-20-authorization-code-flow", 
            "text": "import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   psc   =   PostgreSQLPersistentStore ( \n         username , \n         password , \n         localhost , \n         5432 \n         my_app ); \n\n     context   =   new   ManagedContext ( dataModel ,   psc ); \n\n     final   delegate   =   new   ManagedAuthDelegate User ( context ); \n     authServer   =   new   AuthServer ( delegate ); \n   }   \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router . route ( /auth/token ). link (()   =   AuthController ( authServer ));   \n\n     router . route ( /auth/code ). link (()   =   AuthCodeController ( authServer ,   delegate:   this )); \n\n     return   router ; \n   } \n\n   Future String   render ( AuthCodeController   forController ,   Uri   requestUri ,   String   responseType ,   String   clientID , \n       String   state ,   String   scope )   async   { \n     return    !DOCTYPE html  html lang= en  head       meta charset= UTF-8       title Login /title  /head  body  div class= container       h1 Login /h1       form action= ${requestUri.path}  method= POST           input type= hidden  name= state  value= $state           input type= hidden  name= client_id  value= $clientID           input type= hidden  name= response_type  value= $responseType           div class= form-group               label for= username User Name /label               input type= text  class= form-control  name= username  placeholder= Please enter your user name           /div           div class= form-group               label for= password Password /label               input type= password  class= form-control  name= password  placeholder= Please enter your password           /div           button type= submit  class= btn btn-success Login /button       /form  /div  /body  /html       ;     \n   }  }", 
            "title": "Add OAuth 2.0 Authorization Code Flow"
        }, 
        {
            "location": "/snippets/test/", 
            "text": "Aqueduct Test Snippets\n\n\nExpect that Response Returns a JSON Object with an ID\n\n\ntest\n(\nthat Response Returns a JSON Object\n,\n \n()\n \nasync\n \n{\n\n  \nexpectResponse\n(\n\n    \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n(),\n\n    \n200\n,\n \nbody:\n \n{\n\n      \nid\n:\n \nisNumber\n\n    \n}\n\n  \n);\n\n\n});\n\n\n\n\n\n\nExpect that Response Returns a List of JSON Objects with IDs\n\n\ntest\n(\nthat Response returns a list of JSON Objects with IDs\n,\n \n()\n \nasync\n \n{\n\n  \nexpectResponse\n(\n\n    \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n(),\n\n    \n200\n,\n \nbody:\n \neveryElement\n({\n\n      \nid\n:\n \nisNumber\n\n    \n})\n\n  \n);\n\n\n});\n\n\n\n\n\n\nExpect that Last-Modified Header Is After Date\n\n\ntest\n(\nthat Last-Modified Header Is After Date \n,\n \n()\n \nasync\n \n{\n\n  \nexpect\n(\n\n    \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n(),\n\n    \nhasHeaders\n({\n\n      \nlast-modified\n:\n \nisAfter\n(\nnew\n \nDateTime\n(\n2017\n))\n\n    \n});\n\n\n});\n\n\n\n\n\n\nHTTP POST with JSON in Test\n\n\ntest\n(\nthat can send JSON body\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nrequest\n \n=\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n)\n\n    \n..\njson\n \n=\n \n{\n\n      \nid\n:\n \n1\n\n    \n};\n\n  \nexpect\n(\nawait\n \nrequest\n.\npost\n(),\n \nhasStatus\n(\n202\n));\n\n\n});", 
            "title": "Testing"
        }, 
        {
            "location": "/snippets/test/#aqueduct-test-snippets", 
            "text": "", 
            "title": "Aqueduct Test Snippets"
        }, 
        {
            "location": "/snippets/test/#expect-that-response-returns-a-json-object-with-an-id", 
            "text": "test ( that Response Returns a JSON Object ,   ()   async   { \n   expectResponse ( \n     await   app . client . request ( /endpoint ). get (), \n     200 ,   body:   { \n       id :   isNumber \n     } \n   );  });", 
            "title": "Expect that Response Returns a JSON Object with an ID"
        }, 
        {
            "location": "/snippets/test/#expect-that-response-returns-a-list-of-json-objects-with-ids", 
            "text": "test ( that Response returns a list of JSON Objects with IDs ,   ()   async   { \n   expectResponse ( \n     await   app . client . request ( /endpoint ). get (), \n     200 ,   body:   everyElement ({ \n       id :   isNumber \n     }) \n   );  });", 
            "title": "Expect that Response Returns a List of JSON Objects with IDs"
        }, 
        {
            "location": "/snippets/test/#expect-that-last-modified-header-is-after-date", 
            "text": "test ( that Last-Modified Header Is After Date  ,   ()   async   { \n   expect ( \n     await   app . client . request ( /endpoint ). get (), \n     hasHeaders ({ \n       last-modified :   isAfter ( new   DateTime ( 2017 )) \n     });  });", 
            "title": "Expect that Last-Modified Header Is After Date"
        }, 
        {
            "location": "/snippets/test/#http-post-with-json-in-test", 
            "text": "test ( that can send JSON body ,   ()   async   { \n   var   request   =   app . client . request ( /endpoint ) \n     .. json   =   { \n       id :   1 \n     }; \n   expect ( await   request . post (),   hasStatus ( 202 ));  });", 
            "title": "HTTP POST with JSON in Test"
        }
    ]
}